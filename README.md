

# Assessing the Factuality of System-generated Feedback (Data Augmentation)

Welcome to the Gears 2023 Internship Program! This repository focuses on addressing the challenge of assessing the factuality of system-generated feedback.

## Problem Statement

The main objective of this project is to develop a solution for evaluating the accuracy and factuality of feedback generated by automated systems. One promising approach is to build a "filter" that can automatically discern the factual correctness of generated statements. This filter will ensure that only accurate and pertinent feedback is delivered to students. We intend to leverage Natural Language Inference (NLI) models, such as BART, to perform this filtering task. In NLI, the goal is to determine whether a "hypothesis" is true (entailment), false (contradiction), or undetermined (neutral) given a "premise."

## Tasks

This project comprises two main tasks:

### Task A: Data Augmentation

Task A focuses on data augmentation techniques. It involves enhancing the dataset used for training the NLI model. 

### Task B: Query ChatGPT

Task B is centered around querying ChatGPT.  We work on creating queries and analyzing responses from ChatGPT to further enhance the capabilities of the system.

## Contents
- [Task A](#task-a)
- [Task B](#task-b)
- [TODO List](#todo-list)
- [Authors](#authors)


## Task A

**Task details：** Task A aims to increase the diversity of feedback text through multiple text enhancement techniques, thereby improving the quality and diversity of system-generated feedback. In this task, we use a series of text processing techniques, including negation processing, noun replacement, adjective antonym replacement, Unigram Noising, Instance Crossover Augmentation, voice transformation, etc.

**Code example：**

```python
# Negative Processing
if TextTransformation.negate(feedback[i]):
    pid_new.append(pid[i])
    doc_new.append(doc[i])
    new_feedback = TextTransformation.negate(feedback[i])
    feedback_new.append(new_feedback)
    if label[i] == 0:
        label_new.append(1)
    elif label[i] == 1:
        label_new.append(0)

# Noun Swap
if TextTransformation.noun_swap(feedback[i]):
    pid_new.append(pid[i])
    doc_new.append(doc[i])
    new_feedback = TextTransformation.noun_swap(feedback[i])
    feedback_new.append(new_feedback)
    label_new.append(label[i])

# Replace Adjectives
if TextTransformation.replace_adjectives(feedback[i]):
    pid_new.append(pid[i])
    doc_new.append(doc[i])
    new_feedback = TextTransformation.replace_adjectives(feedback[i])
    feedback_new.append(new_feedback)
    if label[i] == 0:
        label_new.append(1)
    elif label[i] == 1:
        label_new.append(0)

# Unigram Noising
if random.random() < 0.5:
    if feedback[i]:
        noised_feedback = TextTransformation.unigram_noising(feedback[i], noise_prob=0.1)
        pid_new.append(pid[i])
        doc_new.append(doc[i])
        feedback_new.append(noised_feedback)
        label_new.append(label[i])

# Instance Crossover Augmentation
if random.random() < 0.5:
    random_index = random.randint(0, l - 1)
    mixed_feedback = TextTransformation.InstanceCrossoverAugmentation(feedback[i], feedback[random_index], mixup_alpha=0.5)
    pid_new.append(pid[i])
    doc_new.append(doc[i])
    feedback_new.append(mixed_feedback)
    mixed_label = (label[i] + label[random_index]) / 2
    if mixed_label < 0.5:
        mixed_label = 0
    else:
        mixed_label = 1
    label_new.append(mixed_label)

# Sentence Voice Transformation
passive_sentence = TextTransformation.convert_to_passive(feedback[i])
if passive_sentence:
    pid_new.append(pid[i])
    doc_new.append(doc[i])
    feedback_new.append(passive_sentence)
    label_new.append(label[i])

active_sentence = TextTransformation.convert_to_active(passive_sentence)
if active_sentence:
    pid_new.append(pid[i])
    doc_new.append(doc[i])
    feedback_new.append(active_sentence)
    label_new.append(label[i])
```
**Progress report：** The goal of Task A is to improve the quality of system-generated feedback by diversifying the feedback text. We have successfully implemented several text enhancement techniques, including negation, noun replacement, adjective antonym replacement, Unigram Noising, Instance Crossover Augmentation, and voice transformation. These techniques have successfully enhanced feedback text and in some cases changed the tone and grammatical structure of the text. This will help generate more diverse feedback and improve the performance of the system.

## data.py

This Python file is intended for use in data augmentation and text processing to improve the quality and diversity of text data for various natural language processing and machine learning tasks.

## steps

1. **Prepare the dataset**: First, prepare a dataset containing information such as feedback text and labels, usually a CSV file. Make sure you have installed all necessary Python libraries such as pandas, nltk, rouge, etc.

2. **Configure Baidu Translate API**: In the Python file, replace the key information (APP_ID, API_KEY, SECRET_KEY) of Baidu Translate API with your own key information. This will be used for text translation operations.

3. **Import file**: In the Python file, make sure that your dataset is imported correctly, including feedback text, labels, and other information.

4. **Run data enhancement**: By calling different functions in the Python file, you can perform various data enhancement operations on the feedback text, such as negative processing, noun replacement, adjective antonym replacement, Unigram Noising, Instance Crossover Augmentation, etc. Depending on your needs, choose the appropriate enhancement method.

5. **Save Augmented Data**: Finally, the code saves the processed data to a new CSV file. You can specify the saved file path and name in code.

6. **Use Augmented Data**: You can now use Augmented Data for various Natural Language Processing or Machine Learning tasks such as Text Classification, Sentiment Analysis, Regression, etc. Load a new CSV file for enhanced text data.




## Task B

In Task B, we utilize OpenAI's GPT-3.5 Turbo model to generate feedback evaluations for student documentation. This process involves the following steps:

1. **API Key Setup**: We start by setting up the OpenAI API key for authentication.

    ```python
    api_key = " sk-********************"
    openai.api_key = api_key
    ```

2. **Feedback Generation Function**: We define a function `get_completion` to generate feedback for a given prompt using the GPT-3.5 Turbo model.

    ```python
    def get_completion(prompt, model="gpt-3.5-turbo"):
        # ...
    ```

3. **Processing Output**: We process the model's response to extract feedback sentences and their corresponding labels (0 or 1) using the `process_output` function.

    ```python
    def process_output(response):
        # ...
    ```

4. **Saving to CSV**: The feedback sentences and labels are saved to a CSV file using the `save_feedback_and_labels_to_csv` function.

    ```python
    def save_feedback_and_labels_to_csv(feedbacks, labels, output_file):
        # ...
    ```

5. **Execution**: Finally, we execute the code by providing a documentation (`doc`) and a sample feedback (`feedback`) for evaluation. The GPT-3.5 Turbo model generates feedback sentences with associated labels. The results are then saved to a CSV file.

    ```python
    doc = """
    # Documentation content goes here...
    """

    feedback = """
    # Sample feedback sentences go here...
    """

    prompt = """
    # Prompt for evaluation...
    """

    response = get_completion(prompt)
    feedbacks, labels = process_output(response)
    output_csv_file = "Your_file_path"
    save_feedback_and_labels_to_csv(feedbacks, labels, output_csv_file)
    ```

This code allows us to leverage AI-driven feedback generation to evaluate the relevance of feedback to student documentation. The generated feedback is saved to a CSV file for further analysis.
***
## GPT.py

This Python file uses OpenAI's GPT model to evaluate the relevance of the feedback text to a given document. You can use this model to automatically mark whether feedback text is relevant to a document.

## steps

1. **Prepare data**: In the Python file, you need to prepare two texts, one is document (doc) and the other is feedback (feedback). Make sure you have set up an API key.

2. **Configure API key**: In the Python file, replace `api_key` with your own OpenAI API key.

3. **Run the model**: Pass the document and feedback to the GPT model by calling the `get_completion` function to obtain the evaluation result. The input data is defined in `prompt`.

4. **Process output**: Use the `process_output` function to parse the output of GPT into feedback text and labels.

5. **Save results to CSV file**: Specify the path to the output CSV file (`output_csv_file`), then use the `save_feedback_and_labels_to_csv` function to save the feedback text and labels to the CSV file.

6. **Evaluation Results**: Open the CSV file and you will see that each feedback text is marked as relevant (1) or irrelevant (0). This can help you better understand the relevance of the feedback text to the document.

## data-prepare.py 

This Python file is used to modify the column names of the CSV file. You can use this file to change the column names in the CSV file, then save the modified data as a new CSV file.

## steps

1. **Prepare data**: In the Python file, you need to specify the path to the input CSV file (`input_file_path`) and the path to the output CSV file to save (`output_file_path`).

2. **Modify column names**: By calling the `modify_column_names` function, pass the path of the input CSV file and the path of the output CSV file to the function. Inside the function, modify the column name to the specified name. In this example, change the `document` column name to `prompt` and the `summary` column name to `completion`.

3. **Run Script**: Runs the Python script, which will read the input CSV file, modify the column names, and then save the modified data as a new CSV file.

4. **Check Results**: After the script runs, you will find the modified CSV file in the output CSV file path. You can open this file to check if the column names have been modified successfully.


## TODO List

- [ ]  Problem of uneven class: Retrofit loss function, like using Focal Loss, DR Loss
- [ ] Syntax tree: Use a defined rule grammar file or train a model
- [ ]  UDA: We can try to only do data expansion without determining the label, and use UDA to label the newly generated data
- [ ] Refinement of Prompt Text
- [ ] Add reasoning steps: Add an inference step before the final answer. Giving the model some extra time and space to think out loud can improve its chances of getting the correct answer.
- [ ] Prepare the project paper

## Authors

- Hongji Li
- Qinjin Jia
- Guanyu Jia
