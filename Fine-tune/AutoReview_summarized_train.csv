pid,document,summary
E2011,"This page provides a description of the Expertiza based OSS project. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The two major tasks for this project were the following: 1. Refactor existing test cases to follow good coding practices. 2. Check coverage of assignment_creation_spec.rb and improve upon it through additional testing. The assignment_creation_spec file contains test cases that ensure proper functionality of an instructor's workflow in regards to the creation of assignments. An instructor, when logged into Expertiza, should be able to create new assignments where each assignment has its own assigned parameters, rubrics, review strategies and due dates. At the start of this project, all logic and handling of testing this instructor workflow was handled within a single file. This single-file implementation leads to problems with maintenance, and such problems within this implementation can be abstracted into one of these forms: 1. File is too long : This file exceeds 250 lines of code, and should not. 2. Block has too many lines : Within the file, the code used to handle a certain operation is implemented with too many subroutines within one block. 3. Similar/Exact block(s) of code found : Across the file, there were duplicate/near-duplicate blocks of code being used. The first refactor that our team did was to extract methods from what otherwise would be duplicate code and large block sizes. The previous team had started this process, but we were able to follow it to completion. We also then moved all of these extracted methods into the helper class assignment_creation_helper.rb. Here is an example of extracted methods that the previous team had created: <code> The following is an example of how we were able to reduce block size and duplicate code with further extraction of methods into assignment_creation_helper.rb: <image> Another major refactor we did was to break up the one large 'describe' block in assignment_creation_spec, which contained all of the tests for that controller. Since assignment creation has many different pages, we created a separate file for testing each page or responsibility. Beyond the creation of the helper file, assignment_creation_spec.rb was broken up into the following files: 1. assignment_creation_dates_spec.rb 2. assignment_creation_deadlines_spec.rb 3. assignment_creation_general_tab_spec.rb 4. assignment_creation_page_spec.rb 5. assignment_creation_participants_spec.rb 6. assignment_creation_review_strategy_spec.rb 7. assignment_creation_rubrics_spec.rb 8. assignment_creation_topics_spec.rb In the relocation of assignment_creation_spec's functionality and creation of new constituent files, additional refactoring was done to ensure that trailing whitespace was deleted, files ended with a final newline character, and other unnecessary characters were removed. All of this was to remove any other problems that code climate detected. There were a few things that code climate detected that we decided did not need to be refactored. The first was a complaint about blocks being too large, even after we divided the one large 'describe' statement into many smaller ones. This is because, in rspec, each test has its own 'it' block, but all of those must be grouped in a larger 'describe' block. I suggest that this be discussed with the teams who may refactor the other test files or have code climate to be configured to instead look just at the 'it' block size. This is an diagram on how otherwise good ruby code may be flagged by code climate: <code> Additionally, code climate was suggesting to change DateTime to Date or Time. As assignments are due not only on a certain day but at a specific time and that this would require a large refactoring of the entire Expertiza system for tracking submission times, we decided it was beyond the scope of this refactor. As part of the refactoring, we fixed a few broken tests in the original assignments_controller_spec.rb and created additional ones to increase coverage. We used TDD to see which tests that were created were breaking and used that to drive our implementation of the controller. Looking at the methods that were covered in assignments_controller.rb we decided to create the following additional test cases for assignment creation. These are additions to the existing assignments_controller_spec.rb. Links to RSpec screencasts for new test cases. 1. <link> 2. <link> 3. <link>. 1. <link>.","The wiki was to the point and explains all the code changes they have made. Why they touched some parts of code and why they didn't touch the others. Their test plan mentions a list of all the test cases that are currently covered. It's not clear how that list is organized, and given that there are dozens of items, there needs to be a logical ordering to them. Also, they did not mention how they have tested it manually. Some reviewers complained that they did not know how to test it properly since their test plan did not cover it. "
E1682,"The scores in expertiza were calculated by taking the sum of weighted scores to calculate the total every time it is called. To achieve this, it is ideal to store overall holistic stores in addition to individual criterion scores. The current drawback of the expertiza system lies in how the scores are stored: Expertiza stores the scores based on each response to each criterion, but no holistic scores are stored. This means that if we need to know what score user A gives to user B based on 100, we have to rely on the code to calculate it (since in answers table we only have the score that A gives B on each criterion). Expertiza currently calculates scores dynamically when a page is called by taking the weighted scores of each question into consideration. To solve the issue we propose a solution to store the holistic scores in a database, retrieving it every time it is required. This reduces the calculation that is required every time the score is called. When the user wants to check the scores of a completed assignment, a method localDB_calc is called and expertiza retrieves the scores of the student from the database rather than calculating the total from weighted scores. But, when the scores of an ongoing assignment is required, a method on_the_fly_calc is called that calculates the current score of the user. To determine which method will be invoked(on_the_fly_calc and localDB_calc), the current system time will be compared with last_review_deadline 1. If system time is greater than last_review_deadline, indicating that the deadline has passed, the method localDbcal will retrieve the holistic score from the database 2. If system time is lesser than last_review_deadline, indicating that the deadline has not passed, the method on_the_fly_cal will calculate the holistic score and display it. When the assignment is still ongoing , this method is called and it calculates holistic scores over a set of data (in this case, a set of record in answers table, namely the responses from user A to user B on each criterion) and store it in localdbscores. This stored score is retrieved and printed when the user A clicks on the ""Your scores"" link. In the current implementation, when a user A wants to view the score given by user B, user A's score(i.e. out of 100) will be calculated everytime using the scores given by user B for each criterion (i.e.. score out of 5). Once the deadline for an assignment is completed, the method localDB_calc calculates the holistic score over a single db query (in this case, a query would be: “get the score that user A gives user B on assignment 999 on round 2”). To store the holistic scores when an assignment is completed, a database localdbscores needs to be created. The database Design is shown below. This is a subclass of class Scorecal contains a method calc_score whose functionality is to compute the holistic score. The individual scores are retrieved from the database ScoreView and is stored in QuestionnaireData from which the holistic score of a student is calculated . When the user accesses the scores for a review, the current implementation does not store a holistic score but rather calculates the holistic score from the score for every individual criterion. To calculate the total holistic score for a specific round, the individual scores are weighted and added. <image> The proposed implementation involves computing the holistic score once and storing it in the local_db_scores database for a particular user and for a specified round. The stored value is accessed and obtained instead of computing the holistic score every single time. This subclass retrieves the score from the database localDbscores for a corresponding student. If the score is not found in the database localDbscores, the function calc_score of on_the_fly_cal class is called to calculate the total from the weighted scores of each question. This calculated score is then inserted into the database. This score is now returned to the view from where it was called. <image> The proposed implementation retrieves the round wise scores from the local_db_scores database and displays the average score once the deadline has passed rather than computing the average of the weighted scores for every access of the page as shown below. The current implementation of this was to calculate the score and display it which as we know is a time consuming process. On the other hand, on_the_fly_cal is called when the current date has not surpassed the last_review_deadline, indicating that the assignment is ongoing and the holistic score is calculated and passed to the view. <image>. He allots scores out of 5 for every question and the avaerage of this score gets stored in the database when the reviewer clicks on submit. The reviewee views this stored score when he clicks on ""view scores"". The minimum and maximum score that an user gives for each criterion is checked.","The doc could be significantly improved by providing code examples of how to use the SSO service on each use case. e.g., what did you change on the rainbow service to use the SSO?"
E1628,"1. When a review is shown, use different background colors for adjacent responses or adjacent reviews, instead of so much whitespace. 2. In the “alternate view,” 1. Clicking on “Avg.” should sort the rows by average score, from highest to lowest. Clicking again should change the sort order to from lowest to highest. Clicking a 3rd time should change it back to highest to lowest, etc. 2. Clicking on some other button or icon should sort the columns in terms of total review scores. Clicking once should bring the highest-scored review to the right; clicking again should bring the lowest-scored review to the left, etc. 3. Hovering over a box that has a text comment associated with it should show the comment in a “tool tip” format. 4. Hovering over a number in the “Question id” column should bring up a “tool tip” that shows the text of the criterion (question). 5. The “Question ID” label should be changed to “Criterion”. In the view that displays the reviews for the given assignment, each of the reviews are individuals div elements. To make use of existing Bootstrap CSS for displaying individual reviews with different background color, the reviews need to be part of a table. After changing this to a table, the bootstrap's table table-striped class can be added to the table to get alternate grey and white rows. The extra white space tags, horizontal rules, are removed since the table will take care of separating individuals rows. To achieve task 2.a we intend to use tablesorter jQuery plugin. Tablesorter auto-detects the data types in the table and sort the rows either in ascending or descending order when a column header is clicked. Install Add the following line in Gemfile <code> Including tablesorter in the project Add the following line to app/assets/javascripts/application.js <code> Usage In the table add table sorter class as shown below <code> To achieve task 2.c and 2.d we will be including ""tooltip"" offered by Bootstrap to all the cells in the table with title attribute set to contain comment or criterion based on the data cell. The following attributes should be added to the respective cells in the table to get the tooltip text on hover <code> To achieve task 2.e we will be renaming ""Question Id"" table header to ""Criterion"". The UI mock-ups for the tasks of the project are shown below. Colored background for different reviews <image> Individual reviews before modification <image> Individual reviews after modification <image> Alternate view before modification <image> Alternate view after modification <image> Tooltip for individual cells (Note: The screenshot utility doesn't capture the mouse pointer) <image> <image>. But, the HTML code for these in the project is not in the view, but generated in the model. Here are the steps necessary to perform UI testing on the project. Alternate IDs: 1. student1861 > OSS/Final project 2. student1864 > Final project 3. student4332 > OSS/Final project 4. student5555 > CSC 515 project.. 5. instructor6 > Go to tree_display->assignments. Search for 'Final project'. View the individual team scores. 1. Login as student1864 , password is password . 2. Select the Final project assignment. 3. Select Your scores . 4. Select show reviews . 1.1. You'll see that reviews alternate in color between light gray and white. Some extra whitespace has been removed between reviews, so they appear more compact. 5. Select show review next to Review 1 in Round 2. 1.1. Here you'll see that the questions alternate in color between light yellow and light blue. The point value for the question is displayed in a colored circle. The colors are the same as in the heat table in the alternate view. The maximum point value is not located to the right of the question text. Extra whitespace has been removed. 1. Login as student1864 , password is password . 2. Select the Final project assignment. 3. Select Alternate view . 1.1. The Question Id column has been renamed to Criterion . 1.2. Hovering over a cell in the Criterion column will display a tooltip that shows the question text for that row. 1.3. Hovering over any cell in a review column will show the response text for the corresponding question and review. 1.4. The Avg column is sortable. Clicking it will sort in ascending order, then descending order, then back to ascending order. 1.5. The Criterion column is also sortable. 1.6. There are two links, ASC and DESC underneath the table. Clicking them will sort the review columns in the table in ascending/descending order of total review score.","The score should be x out of y, or ""x/y""."
E1758,"And also when a student responds to a teammate advertisement. 1) Enabled mailing when participant added to assignment : Initially the email were being sent to users when they were added using a CSV file on the users page only . <code> 2) Put validation in case of last round of review : Initially whenever a submission was being revised ,a mail was being sent to the the reviewer to revise the review. We put a check on the condition that if it is the last round of review then mail should not be sent to the reviewer for revision of his review. 1.1. E1758 Fall 17 <code> We also created a method in the assignment_participant.rb file to check if the round is valid for mail. <code> end In the submitted_content_controller.rb we created a check <code> 3) Enabled mailing to inform participant about an invitation : Initially no mail was going to the receiver when a participant was sending an invitation to another participant. We have edited the create method to put the mail functionality in invitations controller def create <code> <code> <code> we also created two partials for the respective view namely. <code> Now the instructor is recieving mail when a student is suggesting a topic. We also added two views which consist of the respective mail content. With this import the student was added as a course participant and the mail was successfully sent to expertiza.development@gmail.com. To check the email functionality for invitations we logged in as student5001 and sent an invite request to student5002 for program 1 and the invitation mail was successfully sent to expertiza.development@gmail.com. Then we logged in as student5002 and declined the invite request and mail stating a decline was successfully sent to the expertiza.development@gmail.com. We repeated the process of sending mail from student5001 but this time we accepted the invitation when logged in as student5002. This time also the invitation accepted mail was sent successfully. Again, when submission phase starts, student uploads other link or upload a file, after it the reviewer gets the email. But if the student submits another link in the last review phase (we had set the assignment to have 2 submission rounds and 2 review rounds), then this time the reviewer does not get an email, and this is how it was expected to be. To check the email on submission functionality we logged in as student5001 and suggested a topic test1. As we submitted the suggestion the mail was successfully sent to the instructor. 1) Enabled mailing when participant added to assignment : Initially the email were being sent to users when they were added using a CSV file on the users page only . <code> 2) Put validation in case of last round of review : Initially whenever a submission was being revised ,a mail was being sent to the the reviewer to revise the review. We put a check on the condition that if it is the last round of review then mail should not be sent to the reviewer for revision of his review. 1. E1758 Fall 17 <code> We also created a method in the assignment_participant.rb file to check if the round is valid for mail. <code> end In the submitted_content_controller.rb we created a check <code> 3) Enabled mailing to inform participant about an invitation : Initially no mail was going to the receiver when a participant was sending an invitation to another participant. We have edited the create method to put the mail functionality in invitations controller def create <code> <code> <code> we also created two partials for the respective view namely. <code> Now the instructor is recieving mail when a student is suggesting a topic. We also added two views which consist of the respective mail content. With this import the student was added as a course participant and the mail was successfully sent to expertiza.development@gmail.com. To check the email functionality for invitations we logged in as student5001 and sent an invite request to student5002 for program 1 and the invitation mail was successfully sent to expertiza.development@gmail.com. Then we logged in as student5002 and declined the invite request and mail stating a decline was successfully sent to the expertiza.development@gmail.com. We repeated the process of sending mail from student5001 but this time we accepted the invitation when logged in as student5002. This time also the invitation accepted mail was sent successfully. Again, when submission phase starts, student uploads other link or upload a file, after it the reviewer gets the email. But if the student submits another link in the last review phase (we had set the assignment to have 2 submission rounds and 2 review rounds), then this time the reviewer does not get an email, and this is how it was expected to be. To check the email on submission functionality we logged in as student5001 and suggested a topic test1. As we submitted the suggestion the mail was successfully sent to the instructor.","Design doc is quite readable.  Would have helped if there was a subheading for each change.  Other than that, it seems fine."
E2016,"Revision planning is a mechanism used to carry the interaction one step further by having authors to supply a revision plan based on the previous round reviews. 3. Revision planning cannot be enabled or disabled for an assignment. 4. Numeric labelings for the revision plan questions begin from 1 again, instead of continuing after the original rubric questions. 2. Allowing team members to create/edit their revision plan during each submission period after the first round. 3. Allowing both rubric questions and revision plan questions to appear on the same page and be serialized correctly. 4. Allowing feedback on the revision plan only to be viewed by the team that creates the plan and that team's instructor. This means both questions from the team’s revision plan and questions from the review rubric should be displayed together in the frontend. Since we decided to add revision plan questions to the review rubric of the round, we automatically linked every new question to the questionnaire of that round. A revision plan should be similar to other review questionnaires. Implementation of enabling/disabling revision planning for each assignment can be rather straightforward. This checkbox is labeled as ""Enable Revision Planning?"" If the instructor decided to include revision planning in this assignment, then the link to “Revision Planning” would appear on the student’s assignment page but would stay disabled during the first round. By clicking it, students would be redirected to a whole new page explained under the ‘Revision planning page’ subsection. [Revision planning should surely come before ""Your scores"".] The revision plan is just like other questionnaires in that it contains a set of questions for reviewers to answer. To distinguish between rubric questions set up by the instructor and the revision plan questions created by the team under review, all the revision plan questions are placed after the rubric questions, split by an enlarged “Revision planning” subheader. Scores for the second round review rubric and the author’s revision plan questions will be displayed on the same table and are serialized correctly. Let say the second round rubric has only 5 questions, the remaining questions (6-10) will be revision planning questions written by a particular team. Therefore, scores for revision planning questions can vary round by round. [It would be nice if there was a way to distinguish instructor questions from questions added by students. A “Revision Planning” subheader is also used here to indicate the starting of the revision planning section. will be needed to indicate whether the instructor would like to incorporate the revision planning feature. In this way, we minimize the change to the system to make the original rubric questions and the revision planning questions retrieved together more easily. : allow students could edit revision questionnaire. : allow students within a team to remove questions in revision plan. The revision planning questions could be get through questions in RevisionPlanQuestionnaire model. views/student_task/view.html.erb 1. Add a “Revision Planning” link for students to edit their revision plan. The link will lead students to the “Edit Revision Plan” page. The “Revision Planning” link will disappear from the assignment page if the checkbox is not checked. ” to enable the revision planning feature. Enable/Disable the “Revision Planning” link 1. After the instructor configures the assignment to include the revision planning feature, the “ Revision Planning ” link will appear on the student's assignment page but will remain disabled and only be enabled during each submission period after round 1. Therefore, to enable the link: 1.1. Login as instructor6. 1.2. Go to an assignment’s edit page. 3. In the new page, add two students, student8030 and student8031, so one student can create revision plan questions during the submission period while the other can respond to these questions during the review period. Functionalities Edit a Revision Plan 1. Login as student8030. 2. In the assignment page, click on the “ Revision Planning ” link. which redirects the user to a new page used to create a revision plan. Test retrieval of revision plan questions for a specific team 1. Login as student8030. 2. In the assignment page, click on the “ Revision Planning ” link after steps under Edit a Revision Plan have been done. The “ Revision Planning ” link should redirect the user to the Revision Planning edit page that is populated with previously saved questions. Check the Revision Plan questions in the questionnaire. Go to the only other team’s review page and check if the questions are properly displayed under the “Revision Planning” subheader. Check responses to the Revision Plan questions 1. Login again as student8030. 2. In the assignment page, click on the “ Alternative View ” link, and see if student8030 gets responses for both the original rubric questions as well as its revision plan questions.","The document describes the project well in narrative fashion.  It seems to suggest that revisions can be solicited after any round, not just after Round 1.  I don't think that's consistent with the code.  There are at least two points where notes about the project are in brackets in the design doc.  These should have been removed for the final version.  I don't think that the code modifications, especially the ones to controllers, are adequately described.  They are just listed, with no explanation of why the change was needed.  Similarly, the testing plan should explain what is tested."
E1685,"A student user can see all the reviews of his/her team’s project. The instructor can see all the reviews of everyone’s project. The instructor also has access to a Review report, which shows, for each reviewer, all the reviews that (s)he wrote. Both score report and review report use different code so UI is non-orthogonal, it would be great if we can follow same UI structure for both score and review report which also reduce the DRY problems. There is no functionality for user to search between reviews of particular project, such a functionality will help user to search through all reviews for specific problem they are trying to focus on. The project requires completion of the following tasks: 1. A single way of displaying reviews that would be visible to students (reviews that they did, and reviews that their team received), and instructors (reviews that each team received, sorted by team; and reviews that each student did, sorted by student) For student view the UI is consistent in displaying reviews they have done and reviews they have received but for instructor's view the review report follows different UI and have different code. To make the UI consistent we have decided to choose the UI design of student view as the base and modify the UI design for review report in instructor's view. Previous View: <image> Updated View: <image> Implementation: Review report view is rendered in app/views/popup/team_users_popup.html.haml. In this view, we populate table by iterating over each question under each round. In student view,for a particular assignment, the UI has show review button for each review in a round. Adding a single button will help student view all the review of a round with single click. Previous View: <image> Updated View: <image> Implementation: Review view is rendered in app/views/grades/_reviews.html.erb. In this view, we added show all reviews and hide all reviews buttons which when clicked call toggleAllElement function and displays all the reviews of a round. 1. Create a tabbed view for each review view type : Statistic, Reviews and Alternate Views tabs. The review report will need to be modified to have the addition of the Statistic, Reviews and Alternate Views tabs at the top of the page. It will default to the Statistics tab which should look something like: <image> And the Reviews tab should produce a view like: <image> The Alternate View tab should produce a view like: <image>. The Review tab was created by pulling up the rendering of the review partial out of the participant partial. This just needed to point the local variables to variables that were in this View. The Alternate View tab was a bit tricky since it was it's on view (view_team). So what was done was creating a partial named _view_team and moving all of the code that was in that view the partial and rendering the partial in the view_team view. So we decided that we could just keep the existing scores Review layout with the changes of toggling whether to hide or show the reviews. Make sure that each tab gives you a similar view as described above. 1. Make review feedback more readable by changing UI or background color. 2. Option to toggle review question or score or answers. The existing review also has this behavior. Previous View: <image> Update View: <image> Implementation: The implementation of this functionality is similar to Task 2. A review is rendered in app/models/response.rb. We added toggle questions, toggle score and toggle answers button in a review view, which when clicked calls toggleAllElement function in app/assets/javascripts/tableactions.js that toggles respective view. When scores are view in alternate view(Heat map) it displays score received for each review in tabular format when we click on any review hyperlink it invokes view method of response controller which render unnecessary elements like submission content, upload file button,etc along with review and feedback, instead it should just show review and feedback. So we created a new view to implement this functionality and removed other unrequired elements. <image>. 1. Log-in as student. 2. Go to particular assignment 3. Select alternative view 4. Click on any review hyperlink, to see reviews. 1. Add search box to search between reviews for particular string for a specific project(Student's view) or for specific user(Instructor's view). This functionality will help user to readily access the required content within the reviews. 1. To Test UI for student View 1.1. Log-in as Student. 1.2. Go to Assignment 1.3. Click Your scores 1.4. Click show reviews 1. To Test UI for instructor View 1.1. Log-in as Instructor. 1.2. Go to Manage Assignments 1.3. Click on review report of a particular assignment 1.4. Click on any item in team reviewed tab, to see reviews.",The document has everything that we asked for. LGTM!
E1465,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link>. Expertiza<ref name=""expertiza> Expertiza <link> </ref> is a web application available to both students and professors. More information on Expertiza can be found <link> . The source code can be forked and cloned for making modifications. This wiki provides an insight into our contributions to the Open Source Software project 'Expertiza' by Refactoring the Users Controller. The Users Controller deals with managing activities peripheral to the User registered with Expertiza. The Manage Users module can be accessed by roles other than the student. It provides users with the functionality to search other users based on keywords like username, email, etc. New user can be created and existing user information and role can be updated. Classes : users_controller.rb What it does : Manage Users i.e.search and list users, create new user, edit/update existing users, delete users. What has to be changed : 1. Modify methods to conform to RESTful style 2. Reducing the number of instance variables per action to one 3. Code cleanup by using string interpolation instead of concatenation, replacing '==' with eql? and :key =>'value' with key: 'value', modifying declarations of Arrays and Hashes and removing commented out code 4. Use of routing helpers instead of hardcoded URLs 5. Replace find_by with where to follow Rails 4.0 conventions Follow the steps below to access the view for UsersController. <image> 2. Hover over the ""Manage"" menu option and click on ""Users"". <image> 3. The view rendered is the index view for UsersControllers. <image>. 1. Modifications to users_controller.rb : The purpose of the index method in Users Controller is to list all registered users. The list method was called from the index method to list all users. Hence, we refactored the list method in users controller to index. Further, we refactored all the references of list method in UserControllers, Users views, Users tests and routes.rb to the index method. Before Refactoring : <code> After Refactoring : <code>. It is a bad practice to have more than one instance variables in a controller's method as it indicates increased coupling. Coupling must be as less as possible and the view should have direct access to as few instance variables as possible. Helper methods should be defined in controllers through which the view can access variables of the controller class. The code has been refactored to make use of helper methods for the instance variables in index action. Before Refactoring users_controller.rb <code> show.html.erb <code> After Refactoring users_controller.rb <code> show.html.erb <code> Similar approach for reduction of instance variables has been implemented in other methods like index, show_selection, etc. Code cleanup in the controller so that the code conforms closely to Rails conventions and further enhances the readability of the code. 1. Replaced String concats with #{} in paginate_list Before Refactoring : <code> After Refactoring : <code> 1. Replaced '==' with eql? Before Refactoring : <code> After Refactoring : <code> 1. Replaced :key =>'value' with key: 'value' Before Refactoring : <code> After Refactoring : <code> 1. Modified declarations of Arrays and Hashes Before Refactoring : <code> After Refactoring : <code> 1. Removed unused methods like self.participants_in and commented out code. Before Refactoring: <code> After Refactoring <code>. The code has been refactored to replace the usages of find_by.. with where(). Before Refactoring <code> After Refactoring <code>. Major refactoring revolved around moving lines of codes between methods, modifying array and hash declarations, using helper methods for avoiding multiple instance variables in controller methods and implementing Ruby Conventions. 1. Lines of Code Original : 248 Post Refactoring : 224 1. Code Complexity (Compared on Code Climate) Original UsersController<ref name=""originaluserscontroller> Original UsersController <link> </ref> <image> Refactored UsersController<ref name=""refactoreduserscontroller> Refactored UsersController <link> </ref> <image>. 1. <link> 2. <link> 3. <link>.","About half of the report is screenshots of existing functionality.  Only a few stylistic changes seem to have been made.  Style is now better, but these are not real refactorings."
E1852.2,"The objective for this project is to write unit tests using Rspec for participant.rb model, which is used to prepare data for participants enrolled in each course/assignment. By editing the participant_spct.rb, all class and instance methods are tested, and the path coverage is above 90% with all 97 lines covered. In software engineering, behavior-driven development (BDD) is a software development process that emerged from test-driven development(TDD). The behavior-driven development combines the general techniques and principles of TDD with ideas from domain-driven design and object-oriented analysis and design to provide software development and management teams with shared tools and a shared process to collaborate on software development. RSpec is a 'Domain Specific Language' (DSL) testing tool written in Ruby to test Ruby code. It is a behavior-driven development (BDD) framework which is extensively used in the production applications. The basic idea behind this concept is that of Test Driven Development (TDD) where the tests are written first and the development is based on writing just enough code that will fulfill those tests followed by refactoring. The initial unit tests’ path coverage is only 36.08% with 35 lines covered and 62 lines missed for participant.rb, which are not enough. The unit test should be improved by making the path coverage of more than 90% and achieve the highest possible branch coverage. A test file and two model files were modified for this project: spec/models/participant_spec.rb app/models/participant.rb app/models/assignment_participant.rb. participant_spec.rb participant_spec.rb is the file that test should be written in. participant.rb participant.rb is used to preparing data for participants enrolled in each course/assignment. It allows the user to review some information relate to the current course/assignment and execute operations such as sorting participant by their names and removing a current participant from the team. assignment_participant.rb assignment_participant.rb is a model file related to participant.rb. AssignmentParticipant is a subclass of Participant class, and it overrides some methods of its superclass, which affects the process of writing test code. 1. The email method in app/models/participant.rb uses ""assignment_id"" which is not correct and causes the test cannot pass. 2. Since AssignmentParticipant is a subclass of Participant class, and it overrides team method and score method of its superclass, the test cannot access the methods in the superclass. As a result, those two methods were removed to make the test pass. All of the mock instances are listed at the beginning of the test file. <code>. This case tests that all of the responses of the current user received show up when responses method is called. <code>. This case is given by the initial test file. <code>. This case is given by the initial test file. <code>. This case tests that the permission of whether the current user can review others' work should be returned when able_to_reveiw method is called. <code>. This case tests that an email about assignment registration will be sent to the current user when email method is called. <code>. Two cases are designed for testing this method. When the topic_name method is called, the dash (-) should show up when there is no such topic or the topic name is empty, or the topic name should appear. <code> <code>. This case tests that a list of users' names should show up alphabetical when email method is called. <code>. Two cases are designed for testing this method. <code> <code>. Four cases are designed for testing this method. The authorization of the current user is identified before returning the permissions this user has. <code> <code> <code> <code>. This test is a reverse version of get_permissions. <code> <code> <code> <code>. Two cases are designed for testing this method. When the handle method is called, 'handle' should be returned if the anonymized view is turned on, or the handle of the current participant should be returned <code> <code>. Three cases are designed for testing this method. When the delete method is called, it will check whether it is a force delete first. If it is a force delete, current participant, related response maps, teams, and team users will be deleted. <code> <code> <code>. Three cases are designed for testing this method. When the force_delete method is called, the current participant, as well as the team, should be deleted when the user is the only member. Or the other teammate should be removed from that team. If the current participant does not have a team, it should be deleted directly. <code> <code> <code>. With all class and instance methods tested, the path coverage is 100% with all 97 lines covered. Full video of running the test can be found at <link> .","Would have been helpful to describe why those mock instances were created (why 2 participants, for example).  The individual get_permission and get_authorization contexts should be explained.  Otherwise, the descriptions are quite good."
E1919,"It is an Open source platform which is based on Ruby with Rails. The existing code of ""Expertiza"" has many code smells which are not in compliance with the best practices of Ruby Rails. These smells were detected by CodeClimate. Code climate is a command line interface for the Code Climate analysis platform. It allows you to run Code Climate engines on your local machine inside of Docker containers. It provides automated code review for test coverage and maintainability. We were assigned the task to resolve code climate issues in models with names beginning with ‘H’ thru ‘Sc’. As per instructions, we were to fix all the issues detected by code climate except for below. Fix all code smells except 1. Assignment Branch Condition size for [method name] is too high 2. Perceived complexity for [method name] is too high. 3. Cyclomatic complexity for [method name] is too high. 4. Method [method name] has a Cognitive Complexity of XX (exceeds 5 allowed). Consider refactoring. 5. File [file name] has XXX lines of code (exceeds 250 allowed). Consider refactoring. 6. Class [class name] has XX methods (exceeds 20 allowed). Consider refactoring. 7. Method [method name] has XX lines of code (exceeds 25 allowed). Consider refactoring. <code> 2. Use ""analyze"" command. We have used ""analyze"" command of Code Climate to find out the code smells. Analyze command lets you pass file paths as arguments to the codeclimate and also lets you specify engine options with -e or --engine. <code> 3. We have also used Rubocop documentation for resolving issues. RuboCop is a Ruby static code analyzer (a.k.a. linter) and code formatter. 4. Issue related to method names starting with get_ are ignored because it requires refactoring across multiple files in the project, which would in turn break existing functionalities. 5. some issues are ignored as they were breaking the rspec tests. e.g. 1. mass assignment : It is used to create an instance using multiple parameters 2. In some test files instance were created with multiple parameter along with the primary id. But in mass assignment primary id is dangerous if allowed in mass assignment. 1. mass assignment <code> We assign multiple values to attributes via a single assignment operator. It is implemented using attr_accessible method. All other attributes will be protected. <image> <image> 1. Active Record Associations : Adding ""inverse_of"" option. When you have two models in a has_many, has_one or belongs_to association, the :inverse_of option in Rails tells ActiveRecord that they're two sides of the same association. Knowing the other side of the same association Rails can optimize object loading. It lets you reference the same object in memory, instead of loading another copy of the same record. <image> 1. Add dependent property In the file roles.rb we have has_many :users We need to specify ""dependent"" option here. With associations of Active Record , we can make transitions smooth of such operations(relationships) by telling Rails that there is a connection between the two models. It would make more sense here if we add ""dependent :destroy"" option for users. <code> <code> <image> 1. useless assignment of a variable In the file role.rb, we have The variable e is not being used anywhere. Such values are assigned to ""_"" or rather do not assign them to any variable, so that it doesn't get assigned to a variable and uses space. <code> <image> 1. Using snake case for method names In file roles.rb, we have <image> A standard good practice is to follow snake cases for naming methods. 1. Use find_by instead of where.first In file scored_question.rb, we have <image> Rails prefers ""find_by"" over ""where"" as ""find_by"" returns a single record as result, whereas ""where"" returns an array of record, to which we need to append ""first"" or ""each"" to get single record out of it. <code> 1. Nested ternary operators Ternary operators must not be nested. <image> And, there were many more code smells which needed a fix. 1. 162 issues resolved 2. 42 Files changed 3. 215 additions 4. 163 Deletions 5. Travis CI build passed 6. No merge conflicts 7. coveralls : <code> 1. codeclimate bot <code> 1. travis-ci <code>. 1. ta.rb <image> 1. response.html.erb <image> 1. spec/models/scale_spec.rb <image>. 42 Files changed 215 additions 163 Deletions. 1. Pull Request: <link> 2. Files: <link> 3. Codeclimate analysis: <link> 4. Travis CI: <link>.","Good description of the changes made, and the rationale for them.  You attempted to summarize how many issues were resolved.  A textual summary of the most common would also have been helpful."
E1869,"After an instructor gave a grade to an assignment, there is no way to track who gave the grade. A grading audit trail must be created and the following information needs to be stored: 1. When a grade is assigned by an instructor, there needs to be an indication of who did it and when it was done. 2. Comments previously provided by other instructors must also be preserved. This information needs to be stored every time an instructor edits a grade/comment and clicks the save button. Currently, there are two places need to add grading audit trail: 1. Review grade : Log in as instructor -> Manage -> Assignments -> View Review Report 2. Submission grade : Log in as instructor -> Manage -> Assignments -> View submissions. We will create a database called grading_history in the system contains elements of instructor id, assignment id, grade type, student id, grade, comment, and timestamp. We will use MVC design to create a model, a controller, and a view for both of Review Grade and Submission Grade . Model: grading_history.rb. Has a list of attributes contains instructor id, assignment id, grade type, student id, grade, comment, and timestamp. Controller: grading_history_controller.rb. Saves a new entry into the database every time a review grade or submission grade is saved View: index_html.erb. Displays current submission or review's grading history. An existing example of this is a submission record in the system. We also need to modified grades controller, so that every time, a grade is submitted or edited, grading_history_controller.rb will call a method to create an entry saves into the database. <image>. <image>. <image>. Functional testing: 1. Test if SubmissionGradeHistory.create is being called when a submission grade is changed. <code> 2. Test if ReviewGradeHistory.create is being called when a submission grade is changed. <code> 3. Test if GradeHistory.where is being called when grading history button is clicked. <code>. <image>. <image>. <image>. 1. app/controllers/grades_controller.rb <link> <code> 1. app/controllers/review_mapping_controller.rb <link> <code> 1. app/views/assignments/list_submissions.html.erb <link> <code> 1. app/views/review_mapping/_review_report.html.erb <link> <code>. 1. app/controllers/grading_histories_controller.rb <link> <code> 1. app/models/grading_history.rb <link> <code> 1. app/models/review_grading_history.rb <link> <code> 1. app/models/submission_grading_history.rb <link> <code> 1. app/views/grading_history/index_html.erb <link> <code>. <link> <link> <link> <link>.","This design doc does not really say much about how the proposed solution is implemented.  There are no references to the code.  The need tor a new grading_history_controller is not established.  It would be better to include references to the changed code on Github and describe the changes that were made.  Also, the screenshots should be smaller, so that one does not need to zoom way out."
E1462,"Expertiza<ref name=""expertiza> Expertiza <link> </ref> is an open source web portal for the use of both students and professors. It is developed on Ruby on Rails platform. More information on Expertiza can be found <link> . The source code has been forked and cloned for making modifications to the to survey responses controller. This wiki provides an insight into our contributions to the OSS Expertiza application, focusing on Refactoring the SurveyResponses Controller. <image> <table> Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.1.6. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link>. Refactoring helps to<ref> <link> </ref> 1. Understand what led to poor code design 2. Fix code which is difficult to understand 3. Express each idea “once and only once” 4. Recognize missing or inadequately formed classes 5. Simplify overly complex relationships between classes 6. Achieve the right balance of responsibilities among objects 7. Make code easier to test and more maintainable. We identified the following categories of code smells in the helper module: 1. Fat Classes : No class should be fat. 1. Bad Class names : A good class name is expected to adhere to the Ruby style and design style guidelines. 1. Duplicated Code : These are those pieces of code that does almost the same functionality of some other piece of code leading to a bad design style. There are many documented refactoring techniques, and a few common ones are below.<ref> <link> </ref> 1. Rename Class : Controllers as per Ruby conventions should be plural. 2. Using Helper classes : No class should be containing lot of code, a better practice is to have all active record queries with in the model and in order to keep as much as Ruby code out of the views, helpers are used. Helpers are the only methods you can access, other than instance methods for an instance you have access to. 3. Extract Method : It consists of breaking up long methods by shifting overly complex chunks of code into new methods which have very descriptive identifiers. This class creates surveys and records the responses which can be viewed. On submitting the responses, the scores and comments are posted. Classes : SurveyResponsesController.rb What it does : Creates surveys, submitting surveys, views responses, posts scores and comments. What has to be changed : 1. Pluralize the class SurveyResponseController to SurveyResponsesController 2. Changing declarations of Arrays and Hashes,removing commented out code 3. Use of routing helpers instead of hardcoded URLs 4. Move active record queries to the model or another class 5. Reducing the number of instance variables per action to one. 1. A new survey_responses_controller.rb file is added : As per Ruby on Rails convention, controller names get pluralized while model names are singular. 1. Modified declarations of Arrays and Hashes Before Refactoring : survey_responses_controller.rb <code> After Refactoring : <code>. A bunch of Active Record queries that existed in survey_responses_controller have been moved to SurveyResponse model. Before Refactoring: survey_responses_controller.rb <code> After Refactoring: survey_responses_controller.rb SurveyResponse.get_survey_list and SurveyResponse.get_survey_list_with_deploy_id methods have been created in SurveyResponse model for active record operations. <code>. It desirable not to have more than one instance variables in a controller action as it indicates increased coupling. Our goal should be reducing coupling as much as possible and view should have direct access to as few instance variables as possible. Here persist_survey method has been created in the SurveyResponseHelper to minimize instance variables. Before Refactoring: survey_responses_controller.rb <code> After Refactoring: survey_responses_controller.rb <code>. resources :survey_response do <code> The resourceful routes generated the helpers given below: <code> <code> <code>. Comments and extra spaces have been removed and conventions have been followed to enhance readability of the code. Testing was performed by running 2 different VCL instances one with the original code and the other with the re-factored code. <table>. 1. <link> 2. <link>. <references/>.","Writeup clearly explains what was changed, but not how it was changed.  For example a number of instance variables were removed and replaced by a call to get_assigned_surveys, but get_assigned_surveys is not described.  Design principles are mentioned, but no mention of design patterns."
E1690,"This wiki page is for the description of changes made under E1690 FinalProject for Fall 2016, CSC/ECE 517. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.2. <link> 1.1.1. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.4. <link>. Our final project consists of two cases of the password recovery process. Use case 1, Currently, when a user forgets his/her password and wants to reset the password, Expertiza system randomly generates a new password and sends the password as plain text in a email. We are replacing this practice by sending a reset password link that expires after a certain amount of time. Use case 2 deals with when a user enters wrong credentials. Currently, the login page simply shows an error. Irrespective of the number of times that a user enters wrong login credentials, the system produces a general error message. We are going to be replacing this system by using the alternative 2, using a captcha to verify that the user is indeed a human and not a bot trying to run a brute force attack on the system. Below are more details of our implementation. We have implemented the new password recovery system by sending a reset password link to the user's email. This link will be comprised of a generated path to a newly created view for resetting the password with a uniquely randomly generated token. This parameter will be a string attribute of a new model reset_password. This link will expire after a given amount of time. Using logic to compare the createdAt timestamp as well as the current time, the application would decide if the token is expired or not. We are also implementing a backoff system that will require the user to complete a smart captcha after 3 failed attempts. This smart captcha will be generated through Recaptcha gem and the user will then be redirected to the login page after successfully changing the password. This will ensure that the system is not vulnerable to Brute Force attacks as well as bots. Model: password_reset.rb Attributes 1. -id(autogenerated) -integer 2. -unique_tokenhash -String 3. -createdAt (autogenerated) -timestamp 4. -user_email -string Model Details When the user clicks on reset password, it will redirect to a view that has an input to enter the email address of the user. Reset password button will generate a random token (Long string) which will be hashed and saved in the database of the model reset_password. An expiration date will be generated and saved along with the user_id by looking up the user table using email id. The unhashed Token value will be appended on the url emailed to the user for the password reset page. Before redirecting , the controller checks the parameters in the link (username and token) and makes sure that token username pair exists and not expired. Token from the params will be hashed again and checked with the DB. This prevents an attacker who has read access to the database from making a token for some other user, reading the value that was sent in the email, then sending the same value himself. Once the controller completes all the necessary checks, it will redirect to a reset password page for that specific user (based on the user_id / username) Each Email Address can have only one active token saved in the database. Every time a new token is generated, it will replace the existing one which ensures that only one reset link is available. The project will be using reCAPTCHA gem. This kind of service is important for websites or web applications with lots of user generated content. After 3 failed Login attempts, a captcha would appear to make sure that a bot or a malicious software is not trying to attempt login using brute force. Adding this line to the Gem file allows us to have access to the recaptcha gem. <code>. To let reCAPTCHA work normally, we need to register the domains that the project will be deployed on [reCAPTCHA official website] <link> . Currently, we can use it on expertiza.com, 0.0.0.0, and localhost. <code>. The variable @@attempts acts as a counter to track the amount of invalid login attempts a user makes. Once the attempts variable is greater than or equal to 3 we then force the user to use the recaptcha question in addition to their correct logic credentials. Once the new requirements to login are satisfied the user is redirected to the password retrieval, otherwise they are redirected to the root screen with the captcha question. <code>. To run the Rspecs test cases: <code> To test from UI: <code> Here is a short <link> demonstrating the same.","The most important limitation is that it doesn't really describe how the code structure has been changed.  It shows a couple of UML diagrams, but doesn't explain them.  Your slide show was quite helpful; would be good to link the design doc to it."
E1718,"The main focus of this topic is the thresholds that guide which submissions a student can review as well as how many they need to review, and can review. A review can either be assigned to a student by the instructor, or it can be requested directly by the student. When the student handles it they can choose to be assigned a random submission, or they can choose the topic which they wish to review. Assignments can be set up so that each student must review a minimum number of submissions, with the choice of extra credit for completing up to a maximum number of reviews. When review topics are chosen, Expertiza sets it up so that the student can only choose a topic that has a low enough number of other reviews. The threshold itself is the acceptable range for the number of reviews a topic has compared to the least reviewed topic. Blue has had 1 review, Red has had 2 reviews, and Green has had 3 reviews. If the threshold is set to 0, then the only topic that can be chosen for review is Blue. As currently set up, if a student has already reviewed all assignments within the minimum threshold, they will be unable to request another review. To solve this, when a student has reviewed all submissions within threshold k, the system should increase the threshold by m so that the student can review all submissions within threshold k+m. The current version of Expertiza also fails to show a student what the minimum number of reviews they must complete is, as well as the upper limit of reviews allowed. This will be fixed in this project so that an instructor can set the minimum and maximum number of reviews from the Review Strategy tab, and those limits show up on the student's end when viewing Others' Work. A previous issue that has since been solved was that a student was allowed to review their own submission. 228: Increase the threshold for a student who has already completed reviews for all submissions with the minimum number. 402: Write automated tests to check if a student can review a topic only they have submitted on. Make it settable from the Review Strategy tab (see Issue 417) and viewable when a student clicks on “Others’ work”. Reviewers who have already reviewed the submission with the fewest reviews should be able to review the submission with the next fewest reviews, regardless of what the threshold is. If topic x and topic y has two reviews each and topic z has no reviews, the reviewer is allowed to review topic z, as it has the least number of reviews. He is not allowed anymore reviews until topic z catches up with x and y. Then, if the reviewer has done any other reviews before, such reviews are filtered out. Then the review pool is combed for submissions with least reviews and the minimum reviews count is obtained. It conducts tests to ensure that a student may not review a topic in which their submission is the only one. This case did not trigger a warning and the student was correctly assigned the submission. The second test checks to see if a student can choose a topic in which their assignment is the only submission. This was the main focus of issue 402. When choosing a topic the student must select a radio button for that topic and then request a review. Consequentially, this prevented the student from reaching the error message described in issue 402 ""There are no more submissions to review on that topic."" By this way, the instructor can allow students to review as many submission as possible but grading only required number of reviews. Validations are done by checking whether the number of reviews required is less than number of reviews allowed. 228 1. Log in as instructor(user:instructor6) and create a new assignment and add four students to the assignment(user:student360,student361,student362,student364). 2. Log in as student, submit an artifact. (e.g:a test link) 3. Log in as second student and submit an artifact. 4. Log in as first student and review an artifact, since there is only one other submission at this point, second student's submission is up for review. 5. Log in as second student and review an artifact. 6. Now, log in as third student, submit an artifact and also do two reviews, naturally you would be reviewing first and second student's submissions. 7. At this point, first and second students' submission has two reviews and third student's submission has zero review. 8. Now, log in as the fourth student and review, you should be allowed to review all three artifacts instead of just the one with least reviews. 402 1. Log in with an instructor. 3. Log in with a student. 5. Submit an assignment for that topic. 7. Attempt to select that topic for review -OR- Check the box for ""I Don't Care"" 8. Attempt to request review 417 1. Log in as an instructor 2. go to edit page of an assignment and navigate to Review Strategy tab. 6. Sign in as a student who has enrolled for that particular assignment.","Code snippets are shown, but only the new code, not the old code that was modified.  In the introduction, the description of what is done when the current reviewer has reviewed the least-reviewed submission is wrong; it says that the threshold is increased by m.  In fact, only the threshold for the current reviewer is increased.  This is clarified later in the writeup.  Good description of what the code changes do."
E2056,"When they are requested, the super-admin receives an email, and can go and approve or reject the request. The implementation is tedious to use, since all account requests since the beginning of time appear on the request page, and the super-admin needs to scroll to the bottom to find the current request. The requests can be approved/rejected only one at a time due to form design which can be improved. The steps to reach the Pending Account Request Page is as follows: 1. Log in as an admin or superadmin. <code> 2. Select Administration->show, which will bring up a list of features. 3. Click on “Pending Requests” from among the list of features to open the page containing requests from instructor/students. The admin or super admin can see a list of requests made by students and instructor in chronological order which means that the recent requests are at the bottom of the page. This makes the process cumbersome because any operation on newly created requests would be at the bottom of the page. Also requests can be handled only one at a time due to radio button forms format. 2. Commenting on the method foreign to explain the purpose of this method. 1. Split the page into two components - a. Current(by default) b. History(Processed requests) <code> 2. Collapse all self introductions in requests to display them in one line and expand them on click for easier interaction. 3. Paginate the list to display only 10 results per page. 1. Beside ""Home"", click ""Administration"", then click ""Show"" and in Show click ""Pending Requests"". 2. Two tabs named Current and History are present. 3. Click on tab named ""Current"". It displays all the requests which are ""Under Review"" status and needs to be approved or rejected. 4. A checkbox is present right beside every request and you can select either all the requests which need to be accepted or all the requests which need to be rejected and click on ""accept"" or ""reject"" button. When you click on ""Accept"" button, all the requests selected will be accepted and will be moved from Current tab to History tab. Chicking ""Reject"" button, rejects all the requests selected and will move in a similar fashion. 5. Select tab named ""History"". It displays all the requests which are ""Approved"" or ""Rejected"" in reverse chronological order. First, we modified method named ""request_new"" to ""new"" which creates a new request. <image> <image> <image>. <image> <image>. The task was to design a logic to the existing code such that the administrator would be able to see requests in two different views as in 'Under Review' or 'Approved/Rejected'. An additional function 'list_pending_request_finalized' was added that would filter the requests into 'Approved/Rejected' and the original 'list_pending_request' that filters the requests with 'Under Review' status. By default the requests are ordered in descending order with respect to updated_time with the status - 'Under Review'. <image> <image>. <image>. <image>. The method named ""Foreign"" is ambiguous and Method commenting is done describing the function and its parameters. <image>. The method action_allowed? <image>. The initial query receives all the requests from the database containing AccountRequest table without any form of order. This query that is being passed the list of requests has been modified in order to receive list in descending order of timestamp for updated_at field to show the recently changed requests at the top of list. The gem 'will_paginate' is used to access pagination features in pending request page in order to display only specific number of requests at a time for ease of navigation. Using the method ""paginate"", the number of results per page can be set. Also the corresponding paginate tab is added in the html page for navigating between pages. <image>. <image>. <image>. We can see that we have two tabs named Current and History and in Current we can see all the requests which are in ""Under Review"" status and which needs to be either Approved or Rejected. It only displays 10 requests on each page for readability. <image> <image> All the check boxes which needs to be approved can be selected at once and get approved after clicking the approve button. <image> All the files which got approved are displayed above and gets moved to History tab. Same happens with Rejecting requests. <image> In the history tab, All the files which got approved are added to the previous requests which got approved or rejected. It only displays 10 requests on each page for readability. <image> In the requests table the column Self Introduction has a ""more"" link that lets the user expand the column to view overall content inside it and a ""less"" to collapse it back to original. <image>.","The document is not very readable.  The test plan precedes the outline of the solution.  The solution has 8 subsections, which is too many, and also, the outline is not clear.  That is the most serious issue. Too much of the formatting is ad hoc.  They number their lists manually, and not always with the same leader."
E2003,"The software allows the instructor and students with the following privileges,. 1. Create new assignments 2. Customize new or existing assignments 3. Create a list of topics that students can sign up for 4. Give grades/reviews for the students' submissions. The assessment_360 controller is designed to gather data from all stakeholders about the performance of a student in a course. At present, the controller provides only two top-level functions where each of them gives a list of students in the class. 1. all_students_all_reviews contains teammate and meta-review scores received by students for all assignments in the course 2. course_student_grade_summary gives a listing of students and what topic they worked on and what grade they received on each assignment during the semester. It calculates, (a) The average score for each assignment for each course (b) The overall review grade for each assignment for all the students who have taken the course Passing the average score calculated from (a) checks if the student has teammates which could result in not having an average teammate_review_score. It was hard to check if each of the keys were present or not. The current implementation of the method throws a nil error at the moment on the following line, <code> This is rectified by introducing, <code>. The functionality that the methods shared was that, both of them checked if there were course participants who had taken a particular course. This occupied 4 lines of code in both the functions. So, this is defined in a separate function called insure_existence_of and called from the two functions. <code>. It finds the list of all students and assignments pertaining to the course. This data is then used to compute the metareview and teammate review scores for each student. The code before refactoring had 64 lines of code as shown below, <code> To calculate the average grade for each student on all assignments in this course that a student has taken in this course is refactoring in the base code by adding the avg_review_calc_per_student method. <code> To avoid a divide by zero error that is thrown when we try to calculate the average grade when a student has no teammate is handled by the overall_review_count method. <code> After refactoring <code>. This method finds the list of all students and assignments pertaining to the course. The data obtained is then used to compute the instructor assigned grade and peer review scores. It was the secong biggest method in the assessment360_controller.rb controller file. The code before refactoring is shown below, <code> In this function, all the functionalities pertaining to a course participant - student in this case, in a given assignment is invoked by introducing a new method called assignment_grade_summary. This method checks if a topic exists and if it does, it passes the final grade that is calculated for that student in that course. <code> After refactoring <code>. Ideally the name of a variable or method should be enough to identify it's function in the class. This is because assessment_360 controller, of course is an exception and does explain what each of the functions do on their function names, 1. all_students_all_reviews - Find the list of all students and assignments pertaining to the course. This data is used to compute the metareview and teammate review scores. 2. avg_review_calc_per_student - Calculate the overall average review grade that a student has gotten from their teammate(s) and instructor(s) 3. overall_review_count - To avoid divide by zero error 4. course_student_grade_summary - Find the list of all students and assignments pertaining to the course. This data is used to compute the instructor assigned grade and peer review scores. 5. assignment_grade_summary - To pull information about the student's grades for particular assignment 6. insure_existence_of - To make sure there are participants for the course 7. calc_overall_review_info - The function populates the hash value for all students for all the reviews that they have gotten. I.e., Teammate and Meta for each of the assignments that they have taken. The following test cases were made for the major methods added to the Assessment 360 Controller: 1. insure_existence_of - Checking if the course participants are empty - Check if function redirects to back - Check if function flashes an error if it's not present - When method is called, it should check if there are course participants and redirects to back and flashes error if there are no participants 1. assignment_grade_summary - Checking if the course participants are empty - Check if function redirects to back - Check if function flashes an error if it's not present - When method is called, it should check if there are course participants. 4. Scroll down to find the respective course, and select the brown menu icon. The changes made to the code is present on this <link> .","They do a reasonably good job of describing the changes, but (1) they show the old and new versions sequentially, rather than in Github diff view, which makes the changes much more difficult to understand, and (2) in view of the lack of comments in some snippets of code shown on the wiki page, the documentation should have contained further detail on what the code does.  Would have been good for the test plan to give an overview of the testing code."
E1668,"Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.5. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.1.6. <link> 1.1.4. <link> 1.6. <link> 1.7. <link>. <link> is a peer review system where the students can submit their work and do reviews on fellow students’ work. Expertiza is an open source project and is based on <link> framework. There are various ways to use e-mail functionality in the Expertiza. To name a few examples: users should get welcome emails once they register successfully, they should get reminder emails if they missed deadline of submission of their works, they should receive notification emails when other users review their homework, or others finish reviewing one of their reviews. We will write feature test to check the e-mailling functionality, RSpec will be used as the testing framework. We will also use <link> to interacting with the Expertise. Basically, we can add a new gem in the gem file, like this: <code>. Capybara is a tool which help to test web application by simulating how you can interact with you app. We will use it to test how we can set the emailing function on the web. We can include Capybara by first adding a gem file: <code> And then include it in the rails_helper.rb: <code>. These are required before we do emailing testing: <code>. T1: Test users can edit their email addresses in the email option field under profile page. T2: Test you can set emailing functionality for users under profile page. T3: Test after resetting password email can be sent to users. T4: Test after signing-up emails can be sent to users. T5: Test after updating homework emails can be sent to reviewers. T6: Test emails can be sent to users after their work get reviewed. Testing email address can be edited successfully in the profile tab. Users can update their email addresses anytime by clicking the profile button in the header after they log in. We test if new address can be filled in successfully by using Capybara: <code>. Testing email option can be checked successfully in the profile tab. These boolean values can be reset in the profile page under E-mail options checkbox can be checked/unchecked can be checked/unchecked successfully. 1) We first test that if the 'When someone else reviews my work' checkbox by using Capybara: <code> 2) Test that if the 'When someone else submits work I am assigned to review' checkbox can be checked/unchecked successfully: <code> 3) Test that if the ""When someone else reviews one of my reviews (metareviews my work)"" checkbox can be checked/unchecked successfully: <code> 4) Test that if the ""Send me copies of emails sent for assignments"" checkbox can be checked/unchecked successfully: <code> Below are the tests located in the email_notification_spec.rb file, we use a gem named 'capybara-email' to open the email we intend to send and check for the content for related mailing task: <code>. Testing email can be sent to users successfully if they reset their password. Users can reset their password if they forget about their previous ones. They can get a new password in email sent by the Expertiza system. We use capybara to test and check for password-reset content: <code> <code>. Testing welcome email can be sent to users successfully if they sign up successfully. Users will get welcome email once they get new accounts in the Expertiza, we use capybara to test and check for welcome email content: <code> <code>. Testing email notification can be sent to the users successfully once their assigned homework get updated. We use capybara and check for the content for update email: <code> <code>. Testing email can be sent to the users successfully once their work get reviewed. Once a user's assignment get reviewed by a reviewer, a notification email will be sent to the user to check for the content of the review. We use capybara to test and check for the content for review email: <code> <code>. <code> The results of our work shows below: <image> <image> <image>. According to our test, the emailing functionality works well under various scenarios. 1. <link> 2. <link> 3. <link>.",Good job of explaining the tests that were included.  Perhaps should have explained in some more detail how the tests work.
E2004,"Current implementation of create method has too many assignments and multiple layers of if conditions. <link> has identified following issues with the method: <code> We extracted a method called assignment_form_save_handler from the code to handle the case when assignment_form is saved. This allowed in reducing the number of lines in the create method from 33 to 15. Assignment Branch Condition size was also reduced from 56.37 to less than 15. <image> Following methods were extracted from assignment_form_save_handler : 1. fix_assignment_missing_path - to handle non existent directory path 2. update_assignment_form - to update assignment due dates, and questionnaire array in assignment form <image>. <link> shows following issue: <code> <image> This method had assignments and method calls that could be consolidated. By removing and grouping assignments and method calls into helper methods, we can still use them and reduce the branch condition size. 1. update_due_date contains the loop that adjusts due dates for an assignment. <image> <image> <image>. <link> shows following issue: <code> The branch size of the copy method was inflated due to: 1. Assigning (old_assign and new_assign) things that are only used once or not all 2. Calling methods to assign values only used once <image> To reduce the branch size: 1. Group assignments into a helper method which reduces the assignment and method call count We created helper methods update_copy_session and check_same_directory? 1. update_copy_session contains assignments unused in the copy method, but relevant to the program 2. check_same_directory compares directories for two assignment IDs, consolidating the conditional used in the copy method. <image>. The current implementation of the empty_rubrics_list method has many different branches of the code that could be executed. <link> identified Assignment Branch Condition size to be too high. We extracted code to remove questionnaire types from the rubric list that are already in existing assignment questionnaires into a method named remove_existing_questionnaire . <image>. <image>. The current implementation of the create method has a high cognitive complexity because there are nested iteration blocks. <link> shows following issue: <code> There are two .each blocks, which are used to update assignment_questionnaire and due_date . The current implementation of the empty_rubrics_list method has a high cognitive complexity due to there being nested iteration blocks. <image>. RSpect tests exist for the main methods used in the assignments controller: 1. action_allowed? 1.1. when params action is edit or update 1.1.1. when the role name of current user is super admin or admin 1.1.2. when current user is the instructor of current assignment 1.1.3. when current user is the ta of the course which current assignment belongs to 1.1.4. when current user is a ta but not the ta of the course which current assignment belongs to 1.1.5. when current user is the instructor of the course which current assignment belongs to 1.1.6. when current user is an instructor but not the instructor of current course or current assignment 1.2. when params action is not edit and update 1.3. when the role current user is super admin/admin/instructor/ta 1.4. when the role current user is student 2. new 1.1. creates a new AssignmentForm object and renders assignment#new page 3. create 1.1. when assignment_form is saved successfully 1.2. when assignment_form is not saved 4. edit 1.1. when assignment has staggered deadlines 1.2. As value errors should be covered in the ability to make assignments, the only test needed for this is when deadlines are staggered. 5. update 1.1. when params does not have key :assignment_form 1.1.1. when assignment is saved successfully 1.1.2. when assignment is not saved successfully 1.2. when params has key :assignment_form 1.1.1. when the timezone preference of current user is nil and assignment form updates attributes successfully 1.1.2. when the timezone preference of current user is not nil and assignment form updates attributes successfully 6. show 1.1. renders assignments#show page 7. copy 1.1. when new assignment id fetches successfully 1.2. when new assignment directory is same as old 1.3. when new assignment id does not fetch successfully 8. delete 1.1. when assignment is deleted successfully 1.2. when assignment is not deleted successfully These tests were included and not added to because they cover all the instances that the methods would be used under. Our additions to the code, helper methods, do not have tests as they are used in the main methods and do not need their own tests. The helper methods did not change any functionality. <link>.","Good writeup. They have added code in the form of screenshots but this makes it very easy to understand the difference between the old code and the new code. Each issue is separately addressed. Some descriptions could have been more specific, e.g., ""check_same_directory compares directories for two assignment IDs, consolidating the conditional used in the copy method..""  I wonder what ""consolidating the conditional"" means. "
E1555,"For users intending to view the deployed Expertiza associated with this assignment, the credentials are below: 1. Instructor login: username -> instructor6, password -> password 2. Student login: username -> student5762, password -> password 3. Student login: username -> student5763, password -> password 4. Student login: username -> student5764, password -> password Please make note that new accounts and password resets are disabled on the Expertiza deployment; That functionality is outside the scope of the assignment, and it is unnecessary to review that functionality. Expertiza supports team based assignments, student and instructor roles, allocation of assignments to students (e.g. For this assignment, 7 Work Items were assigned, requiring the modification and testing of the Expertiza Ruby on Rails code. Of the 7 Work Items in the scope of our assignment: 3 of the Work Items involved making code changes to Expertiza, 3 other Work Items involved testing those changes, and one final Work Item had a deliverable of a recorded online video. Below is a list of the Work Items in scope, each with a ""WI#"" identifier, which will be used henceforth to reference the respective Work Item. 2. WI2 : Write test cases for the remaining generate _team_name() method. 2. WI4 : Write tests for team exporting and importing for both assignment team and course team. 3. WI5 : Record a video which demos team exporting and importing, submit it to youtube and submit the youtube link to Expertiza. 1. WI6 : In add_member method, testing if the team can have more members (using “can_add_member” as flag variable) should be extracted to a single method. 2. WI7 : Write tests for adding members when both the team is full and not. Please note that below sections discuss the work done within the scope of each Work Item, but Work Item WI5 is not discussed. Please view the link in the submitted Expertiza assignment. 1. Work Item 1 ( WI1 ): The generate_team_name() method was removed from the <link> file. This method was removed because, during analysis and testing it was found that the Generate_team_name method (line 159) in the <link> model file was being executed. 1. Work Item 3 ( WI3 ): In the <link> file, updated the export function (line 39) to export the team members' names consecutively instead of with a space in between them. 1. Work Item 6 ( WI6 ): In the <link> , the add_member method (line 69) was refactored to check if the team can have more members. method (line 60) was customized such that it was more useful. The <link> controller-file was modified to add additional checks for handling the case of sending a team request to a team which is already full. (line 50). 1. Work Item 2 ( WI2 ): The <link> file was added, and the included test cases tested the generate_team_name() method functionality. 1. Work Item 4 ( WI4 ): The <link> file was updated to cover more test cases. The <link> and <link> fixture files were added for better support. 1. Work Item 7 ( WI7 ): the <link> file was added, and the enclosed test cases tested the functionality of attempting to add members to a team, and whether the process was successful or not. The following list of fixture files were also added to assist in testing: <link> , <link> , <link> , <link> , <link> , <link> . The test cases test for successful member adds, failed member adds, and participant and non-participant adds. This <link> , which was created as one of the deliverables of the assignment, provides a good instruction to the forms and pages associated with the functionality in scope. To test the functionality under WI1 : log in as admin or instructor, navigate to Manage Courses, tab to assignments, for an existing assignment choose the icon to the right which navigates to creating and managing teams. Click 'Create Team'. To test the functionality under WI3 , please view the video above. To test the functionality under WI6 , log in as admin or instructor, click on the Assignments tab in Manage Content, for an existing assignment choose the icon to the right which navigates to creating teams. Or, consider more clear functionality on how to go about getting to the Team functionality. 5. The two below scenarios result in errors: Scenario 1: Assignment Teams Login as instructor -> Click Assignments Tab -> For some assignment, click Create Team button on the right Here adding a non participant to a team results in a flash message. Scenario 2: Course Teams Login as instructor -> Click Courses Tab -> For some course, click Create Team button on the right Here most of the functionalities seem to be broken. Here clicking the ""Create team"" option results in a crash. Adding members to existing teams also does not work.","If your charge was to create a two-page writeup, you did an excellent job.  Most of the reviewers asked for more detail, and we think that more detail should have been provided too.  Also, we suggest that the use of ""Garbage"" for team and course names conveys disdain for the project."
E1829,"<link> is an open source project based on <link> framework. The Expertiza project is a software that creates reusable learning objects through peer review. It is a web application where students can submit and peer-review learning objects (articles, code, websites, etc). It is used in some courses at NC State University and by professors at several other universities. It supports team projects, and the submission of almost any document type, including URLs and wiki pages. Expertiza enables the instructor to create new and customize existing assignments. It also enables the instructor to create a list of topics the students can sign up for as part of a project. Students can form teams in Expertiza to work on various projects and assignments. Expertiza supports submission across various document types, including the URLs and wiki pages. The import feature is the most helpful feature for instructors to set up assignments. The instructors usually have a list of students, teams, etc. from their learning management system. Being able to import these into expertiza saves a lot of time when setting up an assignment. Rename existing team when there is a conflict ->When importing teams there are different options to handle conflicting team names. We added an option rename EXISTING team when a conflict exists. <image>. Merge teams when there is a conflict ->When importing teams, and a conflict exists there is an option to merge the two teams by inserting the new members into an existing team. <image>. Validate file when importing participants If one attempts to import users or participants, and does not specify the file to import from, a NoMethodError error occurs. ->The error has been handled by validating the file before importing the teams, thus the file needs to mandatorily be uploaded in order to import team. <image>. Import of topics chokes on special characters It seems that non-ASCII characters in the description (e.g., a curly apostrophe, and perhaps also an en-dash) caused a SQL error in inserting the description string into the database. ->While importing the participants, the user can include special characters in the project description and is successfully stored in the database: <image>. Count of fields wrong in import When importing participants (or users), it is typical not to specify a password, but rather to have the system generate it. But if you do that, Expertiza reports that each record in the file you are importing does not have enough records. ->When the user tries to upload the file to import participants, password record should be made optional and let the user upload without password record: <image>. <image>. 1. We search the database to see if there is an existing team with the same name. In such a case we save the old team in the ‘team’ variable and set the team_exists flag to true. 2. We then cal the handle_dups method which handles the case if value chosen by the user is ‘insert into existing team’, inside the code this value is represented as ‘insert’. 3. Then the import_team_members function is called 4. We get the user through his/her name 5. If a user isn’t registered, we get a nil object and raise an ImportError 6. Else we add the user to the team if he/she isn’t already in the team 7. The add_member function only works till the team isn’t filled to its maximum capacity In file app/models/team.rb <code>. 1. We included a new option in the duplicate handler field. 2. We added a new handler in the handleDuplicates method to handle the given option as shown in the below screenshot. 3. We leveraged the existing generateTeam() method and sent the existing team id to this method and replaced the existing team’s team name as follows: In file app/models/team.rb <code>. 1. We validate the file before importing the teams. Thus, the file needs to mandatorily be uploaded in order to import team. 1. In the import method in user.rb file, there is a validation to check if the record length is less than 3 which is exclusive of password 2. If the record length is greater than 3, it indicates that there is a password in the record and we save the password in the database 3. If the length is equal to 3 then new system password is generated and saved for the user In file app/models/user.rb <code>. 1. Sql allows unicode values to be stored in the database. 1. <link> 2. <link> 3. <link>.","There are good and bad aspects to this document.  On the good side, it has a description of what has been done to fix each issue.  The description is very clear.  On the bad side, the section on some issues says nothing about what was changed in the code."
E1959,"When an instructor or a TA logs in to expertiza, s(he) can see a list of assignments under the assignment tab. An instructor or a TA can copy an assignment to use the same event in another course or as another assignment. When the user copies the assignment, the assignment is being copied without providing required flexibility to the users. Issue 1: While copying an assignment, the user (instructor or TA) is not asked whether they wants to copy the topics along with the assignment or not. Currently, it is copying the topics, without providing any choice for user to not have the topics. Issue 2: While copying an assignment, the teams/students assigned to each topic are not getting copied. The user might want to copy the teams/students mapped to the topics as well. (Hover on Manage Tab -> Click on Assignments) 3) Copy the assignment of your choice by clicking copy icon located on the right side of the specific assignment. Above steps copy the assignment. 1) Topics linked to assignment. Present system copies the topics but doesn't copy the students, even if you don't want it this way. Our implementation is to provide the user with the functionality to choose to copy/not copy topics linked to an assignment and students/teams linked to each topic. To solve the issue, we have created a new web page that is triggered on clicking the copy icon for the assignment. This page asks the user to select from 3 options, which are: 1. Copy without Topics. (Blank Assignment) 2. Copy with Topics. (Assignment with only topics) 3. Copy with Topics and Teams. (Assignment with topics and teams) Based on the option chosen by the user, this option is passed by the def copy in controllers/assignments_controller.rb to def self.copy in models/assignment_form.rb. <code> <code> The def self.copy in models/assignment_form.rb now receives this value and creates a duplicate of the assignment without copying the teams and topics originally. If the user chosen the option to just copy a blank assignment (i.e. without the topics or teams, the execution does not enter into any of the if conditions. If the user wants to copy the assignment with only the topics (but not the teams), then it goes into the first if (Line 330 [refer code below]) and copies the topics as well but does not enter the next if (Line 335 [refer code below]). If the user wants to copy the assignment with the topics as well as the teams, the code will enter the first as well as the second if condition and copy the topics as well as the teams. By following the below stated process, you can test the implementation that we worked on, which is: Target 1: Provide the user with the option to select copy/not copy topics linked to an assignment. Target 2: Provide the user with the option to select copy/not copy students/teams linked to a topic. Step 3 : Choose an assignment that you want to copy. We would recommend you choosing a robust assignment that has Topics and students/teams associated with topics. [Please make sure that you are under the Assignments tab or select the assignment besides the course] If you want to check and see if an assignment has topics or not, click on Edit (pencil icon) on the right. - If this assignment has topics, you will see a tab named Topics on the right of General tab. If there are no topics, you won't see Topics tab. - On clicking the Topics tab, you can see the list of topics. If you don't see any such, it means that teams/students are not assigned to topics. Step 4 : After you chose the assignment that you want to copy, click on the copy icon on the right of the corresponding assignment. Where is the copy button located? <image> Step 5 : Clicking the copy button will take you to copy options page, where you can select the options for copying. Now the assignment shall be copied with the options you provided. In step 6, if you chose to - copy without topics: You won't see 'Topics' tab near General tab. - copy with topics: You will see 'Topics' tab near General tab(As shown in image below). Navigate to Topics tab where you can see and check that the respective topics have been copied. You won't see students under each topic in 'Topic Name(s)' column(If there are topics under Topics tab in original assignment from which you created this copy). - copy with topics and students: You will see 'Topics' tab near General tab(As shown in image below). Navigate to Topics tab where you can see and check that the respective topics have been copied. You will see students under each topic in 'Topic Name(s)' column(If there are topics and students under Topics tab in original assignment from which you created this copy).","""-The team has  done a great job on the writeup of the project.
-The screenshots of code are useful, but the changes could have been shown more concisely with Github diff view.
-All the required subheadings have been covered in the writeup.
-They also added a section on """"Our Recommendation for a Separate Issue (For Instructors only)"""", which includes the issue that the team feels should be addressed on priority. 
-They have also added enough information on how to precisely test their added feature which is great. 
-Explained the test plans 
"
E1552,"Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.5. <link> 1.6. <link> 1.7. <link> 1.8. <link> 1.9. <link> 1.10. <link>. Types of Reviewing Strategies in Expertiza - 1. Instructor Selected Reviewing - Using this strategy the instructor assigns reviews to all participants of the assignment. After selecting this strategy the instructor has the following two options - 1.1. Set number of reviews done by each student. 1.2. Set minimum number of reviews done for each submission. <image> Instructor selected Reviewing 1. Auto Selected Reviewing - If the instructor selects this strategy, students need to select reviews themselves. Either the student is given a list of topics to choose from and he selects which topic he wants to review, or he checks “I don’t care which topic I review” and he/she will be randomly assigned a topic to review. The instructor can also specify two parameters after selecting this strategy - 1.1. Review topic threshold: - Let us assume Topic 1 has a submission than has not been reviewed. Topic 2 has submissions that has been reviewed atleast 2 times and k is set 2. Then the student will not be able to select topic 2 until all of topic 1’s submission has been reviewed atleast 2 times. 1.2. Maximum number of reviews per submission: - This specifies the maximum number of times a particular top can be reviewed. <image> Auto selected Reviewing 1. Student Selected Reviewing - In this strategy the student selects a particular submission to review instead of a particular topic. 1. <link> 2. <link> 3. <link> (For Instructor - username: instructor6, password: password. For student - username: student5700, password: password). <code>. dynamic_review_assignment_helper.rb allows the system choose a team to review when a student chooses a topic to review. It helps the code choose topics that have submissions with fewer reviews than other topics. A threshold k is used to decide whether a particular topic can be chosen. If, e.g., Topic 1 has a submission that has not yet been reviewed, and Topic 2 has no submission that has been reviewed by fewer than 3 reviewers, then the incoming reviewer can only choose Topic 2 if k ≥ 3. This class does not actually decide what is reviewable, but it does make up a sorted list of the submissions by the number of the reviews they have. 1. Keep only ""auto selected"" and ""instructor selected reviewing"". While making changes to the helper classes to remove student selected reviewing, a commit was made to the expertiza repository which deleted the page for student selected reviewing. <link> In student-selected reviewing, a student was allowed to review a particular submission and not just a particular topic.The functionality for “student-selected” reviewing was never implemented successfully. 1. The article was not written by the potential reviewer. The potential reviewer should not be able to review its own submission and hence a check for this condition is required. 1. The article was not already reviewed by the potential reviewer. The potential reviewer should not be able to review a topic which is already reviewed by him/her. 1. The article is not on the same topic as the potential reviewer has previously written about. The reviewer should not be able to review on the same topic that he/she submitted as the reviewer could give biased reviews to make his/her own submission seem better. Implementation : <code> 1. The article does not already have the maximum number of potential reviews in progress. The reviewer should only be able to review topics that have not reached the maximum number of reviews. 1. The article has the minimum number of reviews for that assignment. <code> Also, this was the only call being made to dynamic_review_assignment_helper.rb and this helper is not used in instructor selected and auto selected reviewing strategies. The project involved refactoring code which was used for student selected reviewing. 4. Check “Allow reviewer to choose which topic to review” and “Enable authors to review others working on same topic” in the same tab. 5. Choose the review strategy as Auto-Selected in Review Strategy tab. 2. Sign up for a topic. Validation Criteria: 1. You should not be able to review your own submission 2. You can review other submissions of the topic if you have checked “Enable authors to review others working on the same topic” while creating the assignment. 3. You should not be able to review a submission which has already been reviewed by you. 4. You should not be able to review a submission which has reached maximum number of potential reviews.","Your writeup mentions changes to self.find_submissions_in_current_cycle.  As far as we can tell, this method was removed from the code."
E1507,"<link> is a <link> <link> application where students can submit and peer-review learning objects (articles, code, web sites, etc). This Open Source application can be cloned from <link> , the latest active branch is <link> . There are 5 major goals for this project: 1. Fix Bug #483<ref> <link> </ref>, which causes some error and prevent users to get access to the submitted_content page. 2.Break up the complex methods such as get_comments , show_code_file_diff . Anything that can be modularized should be modularized (Single Responsibility) 3.While breaking up the complex methods, look out for possible helper functions. If there are any, move them to the review_files_helper.rb 4.Remove commented out code from the controller 5.Refactor the file based on Global Rules<ref> <link> </ref>. In ""Your works"" view, students can only submit links but no files. <image> This is caused by commit <link> where the line 13 in <link> was commented out. <code> But after uncommented line 13 in submitted_content/_main.html.erb and refresh the page, the Rails Server stopped responding. This <link> is responsible for handling the review files of the participants. This controller helps in uploading newer versions of reviews for an assignment and also in displaying all the versions (and diff between versions/code) with the help of <link> . There are quite a few complex functions inside these controllers. These functions can easily be broken up into much more smaller methods with specific functionalities. They also need to be refactored to meet the <link> . 1. review_files_controller.rb 2. submitted_content_controller.rb 3. review_files_helper.rb 4. review_comments_helper.rb 5. submitted_content/_main.html.erb 6. model/assignment.rb. Git log can be viewed in commit <link> 1. In submitted_content_controller.rb , line 19. <code> This else if must be a mistake, so we changed it to: <code> 2. In model/assignment.rb , line 489. <code> The Course model doesn't have an attribute called get_path , it should be directory_path , so we changed it to <code> 3. In submitted_content/_main.html.erb , line 18. <code> As in this page there doesn't have a parameter called assignment_participant , as it need to get the participant's id, so we changed this line to: <code> 4. In config/routes.rb . Added one more routes <code>. 1. Changed and and or to && and || to meet the requirements in the <link> . 2. In def get_comments , deleted unused variable: <code> 3. In def show_all_submitted_files , deleted unused variable: <code> 4. In def show_all_submitted_files , deleted unused variable: <code> 5. The method def get_comments is too complex, so we modularized part of its code in review_comments_helper.rb , we created a new method: def self.populate_comments , which returns handle, comment, authorflag these three variables. <code> 6. Rewrited all :key => value to key: value format according to the requirements in the Global Rules <ref> <link> </ref>. 7. The method def show_code_files_diffIn is too complex, we created a new method: def self.populate_shareObj in review_files_helper.rb to perform part of the show_code_files_diff . <code> 8. In review_files_helper.rb , created a new method: def self.find_review_files , which contains some statements in def show_all_submitted_files . <code> 9. In review_files_helper.rb , created a new method: def self.find_review_versions , which contains some statements in def show_all_submitted_files . <code>. 1. Changed and and or to && and || to meet the requirements in the <link> . 2. Rewrited all :key => value to key: value format . 3. Rewrited all param['string'] to params[:string]. 4. Added one more routes post :folder_action to config/routes.rb 5. Changed all array.size == 0 to array.zero? 6. Changed all find_by_x(val) and where(""x=val"") to where(x: val) 7. In def remove_hyperlink , deleted redundant line: <code> 8. In def download , deleted commented line: <code>. After fixing the bug #483, now the submit files function works. <image> The file is stored at: <image>. <references/>.","Writeup is too hard to follow.  It starts off with a bug description and does not say what role this played in the project.  In general, there is a lot of code and screenshots, but little prose tying them together."
E2110,"While setting up an assignment, the instructor will be asked to choose different kinds of rubrics. Any of these rubrics can later be edited or changed to a different rubric. A problem arises when an assignment is underway (students have already started reviewing) and a rubric is edited or changed. Some students started reviewing with the old rubric and the rest of the students who had not started a review will be presented with the updated rubric. 1. Additions: 1.1. Added more extensive comments to all added functions and lines of code for better readability 1.2. Added a popup confirmation message when deleting a question during active period similar to when adding a question to ensure instructor wants to delete all responses 1.3. Destroy response object instead of individual answers when editing a questionnaire during active period to return all students who submitted reviews to the 'begin' stage rather than 'edit' and give them a fresh questionnaire 1. Refactoring: 1.1. Split complicated functions from previous team, such as delete_existing_responses(), into more manageable and modular functions which only complete 1 main task 1.2. Fixed email formatting for email sent to users when questionnaire is edited 1.3. find_review_period() now uses find_due_dates() to search for assignment due dates. The main actions this project affects are adding and removing questions from a questionnaire. This popup works the same as the ""Add"" popup. Here is a list of files and the functions that were added or edited, excluding rspec files. Helper module containing important functions for deletion of responses and answers when editing a questionnaire during review period. 1. delete_existing_responses(question_ids, questionnaire_id) <image> Calls log_answer_responses and log_answer_info to store responses users made to the questionnaire. 1. log_answer_responses(question_ids, questionnaire_id) Given a list of question_ids and a questionnaire_id, gathers reponse_ids for all users responses to the questionnaire. 1. log_response_info(response_ids) Given a list of response_ids, gathers users responses to a questionnaire and records their comments in a hash along with their name, email, and the assignment name. Sometimes these review comments are sent to users in an email, and sometimes they are not. 1. review_mailer(email, answers, name, assignment_name) Given an email, answer list, name, and assignment name, calls notify_review_rubric_change() to send given information about previous review submission to user at given email. 1. in_active_period(questionnaire_id, answer=nil) Given a questionnaire and possibly an answer, determine the assignment and round number. Use these to determine if the assignment is in a review period. Return true if in active period, false if not. 1. add_new_questions Added call to in_active_period. If in active period, call delete_existing_responses(). 1. destroy Added call to in_active_period. If in active period, call delete_existing_responses(). Calls mail() to send email to desired user. 1. find_review_period(round) Determines the start and end dates of the rounds of an assignment and returns them. 1. get_latest_assignment(questionnaire_id) Given questionnaire_id, returns assignment and round where questionnaire is used (if multiple questionnaires are used in an assignment). 1. Added in_active_period() call to display warning about edited questionnaire during active period 2. Added confirm: to submit_tag 'Add' to display confirmation popup when adding a question during active period 3. Added script to catch <a> tag redirects with [data-method=""delete""] to display popup when removing a question. Script only active if in active period. <image> <image> 1. New file containing email layout used when emailing students their answers after questionnaire is edited during active period. Tests are created in the following files: 1. spec/controllers/questionnaires_controller_spec.rb 2. spec/models/assignment_spec.rb 3. spec/controllers/questions_controller_spec.rb 4. spec/helpers/answer_helper_spec.rb These tests cover the following cases: 1. Adding questions to a questionnaire during the review period 2. Adding questions to a questionnaire outside the review period 3. Determining if an assignment is in the review period 4. Determining if an assignment is outside the review period 5. Finding the start and end dates for a specific review period of an assignment 6. Finding the start and end dates for all review periods of an assignment 7. Deleting existing responses resulting from changes made to questionnaires during the review period 8. Deleting questions The same cases were also tested manually through the Expertiza UI, as shown in the demo video.","There are many diagrams to explain the flow. I would have liked to see more explanation of why all the files were changed.  Just saying ""Here is a list ..."" isn't very reassuring; it would have been better to see something like, ""If a question is added or deleted, that affects the question itself and the questionnaire. When a reviewer needs to be sent a copy of a rubric, this means that content needs to be copied out of answer objects ...""  That would explain how the pieces fit together.  I also think that the test plan should have described what was done in the tests for each class."
E2067,"The student_teams_controller.rb controller used in Expertiza to manipulate teams that are created for assignments. Primary functions that this controller provides is create a new team, update team name and delete members from a team. The motivation of our work is to improve the maintainability and readability of student_teams_controller.rb Controller. Furthermore, we also fix several occasions where the student_teams_controller.rb contains code snippets that actually belongs to the model classes. This will help enforce single responsibility principle and model-view-controller pattern. 1. Move return unless current_user_id? student.user_id into action_allowed method 2. Refactor code from view function into may or may not be necessary to add a method to the DueDates class 3. Remove variable current_team 4. Add comment for @users_on_waiting_list and also simplify the condition 5. Refactor @teammate_review_allowed into due_date.rb 6. Rename existing_assignments? to existing_teams 7. Add method comment for the update method 8. Change (matching_teams[0].name <=> team.name).zero? to (matching_teams[0].name == team.name)? 9. Add method comment for Advertise_for_partners and remove_advertisement 10. Rename sign_up into signup 11. Refactor code from remove_participant into waitlist.rb 12. Add method comment for the review method. 1. /controllers/student_teams_controller.rb 2. /models/waitlist.rb 3. /models/due_date.rb. The purpose of this section is to provide the before and after change comparison so the developer can perform code review to ensure the correctness of the change. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. File: spec/controllers/student_teams_controller_spec.rb <code>. 1. In the update method of student_teams_controller.rb, the 'elsif' needs a comment to explain its purpose. It is unclear as to why this conditional is present. 2. For student_teams_controller update method, simplify the condition logic by combining elsif and else into a single statement.","Document looks good with relevant details and screenshot of the before and after code provided. Some of the section headings are hard to parse, e.g., ""Refactor code from view function into may or may not be necessary to add a method to the DueDates class"".  However, the descriptions of code changes are clear.  In the test plan they have just attached screenshot of the original rspec file without any explanation. They have mentioned potential refactorings in the ""Future Work"" section and for this controller file"
E1783,"A feature that integrates Github metrics into Expertiza to help instructors grade the projects by providing more information of the workload of individuals and could do early detection on failing projects based on groups’ working pattern. Convolutional data extraction from Github integrates Github metrics into 'Expertiza'- an Open source project in order to help instructors grade the projects by providing more information of the workload of individuals and could do early detection on failing projects based on groups’ working pattern. By convolutional data, here we refer to the fields of the dataset which cannot be extracted directly, such as the working pattern, which is the amount of commits/code/files the pull request added/modified/deleted on each day during the whole project period. The project period is a range of days that can be tracked on Expertiza. For metrics we have considered following : o Number of commits everyday throughout the project’ s period. o Number of files changed everyday throughout the project’ s period. o Lines of code changed everyday throughout the project’ s period. Docker: The Docker has been set up on a Windows PC and steps are given below: Start Docker on Windows docker run --expose 3000 -p 3000:3000 -v //c//Users//Srikar//Expertiza://c//Users//Srikar//Expertiza -it winbobob/expertiza-fall2016 /etc/init.d/mysql start mysql -uroot -p show databases; quit git clone <link> cd expertiza cp config/database.yml.example config/database.yml cp config/secrets.yml.example config/secrets.yml bundle install rake db:migrate sudo apt-get install npm npm install -g bower On a Local Machine: We have used MacOS, so the following steps are in regard to MacOS. The following steps will help you set up Expertiza project in your local machine. The order we followed: 1. Fork the git repository mentioned above 1. Clone the repository to your local machine Install <link> 1. Install RBENV brew update brew install rbenv brew install ruby-build 1. Install dependencies brew install aspell gcc47 libxml2 libxslt graphviz 1. Install gems export JAVA_HOME=/etc/alternatives/java_sdk bundle install 1. Change yml files 1. Go to expertiza/config and rename secrets.yml.example to secrets.yml 1. Go to expertiza/config and rename database.yml.example to database.yml 1. Edit database.yml to include the root password for your local MySQL in the “password” field 1. Install mysql ( <link> ) 1. Log into MySql as root (mysql is generally present in /usr/local/mysql/bin/) mysql -uroot -p 1. Create expertiza user create user expertiza@localhost; 1. Create the databases create database pg_development; create database pg_test; 1. Set privileges for expertiza user grant all on pg_development.to expertiza@localhost; grant all on pg_test.to expertiza@localhost; 1. Install javascript libraries sudo apt-get install npm sudo npm install bower bower install 1. Download the expertiza scrubbed library ( <link> ) 1. Load this sql file into pg_development database created using the method mentioned here. 1. Open browser and test localhost:3000 1. Login credentials Username - instructor6 Password - password sudo rm /usr/bin/node sudo ln –s /usr/bin/nodejs /usr/bin/node bower install --allow-root thin start. pull request number and sha for commit is needs to fetch pull/commit specific data. <image> o git_datum.rb This is a model corresponding to our git_data table which have following attributes 1. pull request number. 2. author, who committed in that pull request. 3. Number of commit done by that author in the pull request. 4. number of files changed by that author in the pull request. 5. number of lines added by that author in the pull request. 6. number of lines deleted by that author in the pull request. 7. number of lines modified by that author in the pull request. 8. data when the pull request was created. The model has a static method called update_git_data which is responsible to update the data in the table for the active submission record. The method calls the methods on git_data_helper to make the GitHub api calls, manipulate the data that is returned from the service and then push the data in the table. PS - Everytime the method is called it just process the delta (changes for the pull request since the last time this method was called). This makes sure that the updates are faster and avoid data redundancy. <image>. <link> <link>.","The flow is reasonable and the writing is quite good, though there are occasional grammatical errors.  It's nonstandard to use all caps in Wikimedia section headers.  The code is pretty readable, but it is also very large, so it's hard to get much context on a single page.  Could it be shrunk?  Ditto for the screenshot.  Please use standard github itemization instead of ""o""s at the beginning of each item."
E1729,"This project is an addendum to the bigger Expertiza project. The Expertiza project is software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. The requirement for this OSS project was to ' Export Scores In Detail'. <link>. The branch on which we developed this project on is called <link>. Expertiza provides a the ability for an instructor to export scores for an assignment. Whenever a user fills out teammate reviews, peer reviews, feedback reviews, and etc. the scores for each question on those reviews are stored in the database. Currently however Expertiza only exports a csv with aggregated scores which are computed as weighted averages of the scores given in reviews. This is not the most helpful for visualizing the score data by question, individual team/user, reviewer. So that is why our assignment is to implement the ability to export a more detailed csv that contained all the scores for each question for each review and review type within a specific assignment. After talking with our project contact, Ferry, it was decided that the csv would be organized by round and within each round by response type. Part of the implementation was to also include the ability to choose the delimiter for the csv and specify which columns they wanted to include. So the reason we implemented our feature a certain way is because there was already previous code for exporting an aggregate csv so we designed our feature in the same fashion. An export controller already existed so we added a new method in that for exporting details and modeled it based on the already existing export method. Assignment.rb already had the methods for setting columns/fields and getting aggregate export info so we added our implementations corresponding methods in that class as well. For the view, we simply added our code, that linked to the new controller method, in the same view where the other csv feature was implemented. No specific design pattern was used, but our feature was simply modeled after previously existing similar features. 1. app/controllers/export_file_controller.rb 2. app/models/assignment.rb 3. app/views/export_file/start.html.erb. 1. app/views/export_file/_export_details.html.erb 2. spec/controllers/export_file_controller_spec.rb 3. spec/features/assignment_export_details/expected_details_csv.txt. 1. export_file_controller_spec.rb This method is called when the 'Export Details' button is clicked and selects the delimiter and generates the csv with selected columns. It then passes the CSV into the assignment models method to populate it. <code> 1. app/models/assignment.rb This method is called to populate it the csv and is where the majority of our implementation lies. It finds all the ResponseMaps associated with this assignment, then finds all the Responses associated with that each ResponseMap. Then for each response it saves the Answer objects associated with it into an array that is stored in a hash that is indexed by round and response type (teammate review/feedback review/etc). <code> This method checks nil while populating a csv field headers to only add headers which the user selected from the checkboxes. <code> This method generates a CSV row by looping through the answers. <code> This method generates a hash of answers, which is used to populate the CSV. <code> This method checks for number of answers in a particular round/response type and returns nil if there are none since the csv doesn't need to output any header for this round/response type. If this round has some answers then the round number header is generated along with the response type. If the round number is nil, then we simply make the header say 'Round Nill' instead. <code> This method is called by the controller to set the columns in the csv. <code> This method is called by the controller to set the headers in the csv (including Assignment Name and Instructor) <code>. Flow Chart When exporting a detailed CSV, an instructor can choose to include all, some, or none of the headers and the assignment may or may not include answers. The chart below details possible scenarios. <image> <table>.","The test plan is outstanding. very detailed and logically structured. It could be improved by comparing the #of active records with #of lines in the CSV. or if all student participants in the CSV, etc. It's a shame that the design desc has too many code snippet, copied pasted from the source code, which I could have checked directly in GitHub. I would expect a more high level pseudocode / UML diagram for the documentation. "
E1659,"For users intending to view the deployed Expertiza associated with this assignment, the credentials are below: 1. Instructor login: username -> instructor6, password -> password 2. Student login: username -> student5431, password -> password 3. Student login: username -> student5427, password -> password. It also allows students to review each other’s work and improve their work upon this feedback. We worked on a module named on_the_fly_calc in this Expertiza based OSS project. We focussed on refactoring some methods which were very complex and also modified the language of the module to make it more ruby-istic. We also worked on refactoring the code to reduce redundancy. On_the_fly_calc is a module that is included in assignment.rb. What this module does is that it calculates the score for both students and instructors. E.g., when a student clicks “view my score”, Expertiza calculates the review scores for each review. This is called “on the fly” because expertiza stores the review scores based on each question (in answers table), but does not store the total score that a reviewer gives to a reviewee. It directly calculates the total review score for each review, using the score values in the answer table during run-time. So only these points are stored in the database and when a reviewee clicks to see the score given by this particular reviewer, on_the_fly_calc module helps calculate the total score i.e. We worked on the following work items(WIs) in order to refactor the module: WI1 : Refactor ‘Similar Code’ in lines 34-42 and 62-70 in on_the_fly_calc.rb WI2 : Prefer ‘each’ over every instance of ‘for loop’ WI3 : Refactor ‘scores’ method to reduce ABC (assignment, branch and condition) size WI4 : Refactor ‘compute_reviews_hash’ method to reduce ABC (assignment, branch and condition) size WI5 : Refactor ‘compute_avg_and_ranges_hash’ method to reduce ABC (assignment, branch and condition) size. Lines 34-42 and 62-70 were similar in compute_reviews_hash method. Hence, a dedicated method ‘calc_review_score’ was defined and this method was called in the both instances inside compute_reviews_hash. Lines 34-42 in compute_reviews_hash: <image> Similar code in Lines 62-70: <image> Refactored method 'calc_review_score' for the two similar codes: <image>. In every instance where ‘for’ loops were used in on_the_fly_calc module, ‘each…do’ was replaced instead. This significantly reduced the Cyclomatic complexity of the code. The following screen shows the instances where for loops where replaced: <image>. 1. a) Method ‘scores’ was very complex, performing too many functions within a single method. This significantly reduced the Assignment, Branch, Condition size for ‘scores’ method. <code> b) The following 4 methods were created after splitting the first method i. participant_score <code> ii. assess <code> iii. calculate_score <code> iv. For example, the unless condition in Lines 132-134 was refactored to Line 127. This reduced the Perceived Complexity of 'scores' method. <image> 2. a) We also refactored method ‘compute_reviews_hash’ which was very complex and modularized individual functionalities into 2 separate methods. b) The following 2 methods were created and called after refactoring: i. scores_varying_rubrics ii. scores_non_varying_rubrics 3. Similarly, method ‘compute_avg_and_ranges_hash’ was also refactored and a seperate method calc_contri_score was defined to calculate contributor’s score. This method was then called from ‘compute_avg_and_ranges_hash’. <image> <code> <image> <code>. 1. Login into Expertiza as a student or an instructor. (You can use the student ids in the peer review section above) 2. Go to an assignment which has some prior reviews for a previous project and click on view scores. 3. The total score for a review is calculated on the fly using this module. We created unit tests as well to check that the module performs as it did earlier before we refactored it. There were no pre-existing test cases for this module. We first had to create a dummy class to test the module. <image> <code>.","Generally good job of describing changes.  In places, there is too much code and not enough explanation (e.g., for the methods following scores).  Screenshot from Code Climate is gigantic."
E2060,"Expertiza <link> is an open-source web application to create re-usable learning objects through peer-reviews to facilitate incremental learning. Students can submit learning objects such as articles, wiki pages, repository links and with the help of peer reviews, improve them. The project has been developed using the Ruby on Rails <link> framework and is supported by the <link> . Expertiza assignments are based on a peer review system where the instructor creates rubrics for an assignment through questionnaires which students use to review other students' submissions. The author of the submission is given an opportunity to provide feedback about these reviews. Expertiza displays reviews (i) to the team who was reviewed, and (ii) to the reviewer. A student user can see all the reviews of his/her team’s project. The instructor can see all the reviews of everyone’s project. The instructor also has access to a Review report, which shows, for each reviewer, all the reviews that (s)he wrote. The score report and review report use different code so UI is non-orthogonal, it would be great if we can follow same UI structure for score and review report which also reduce the DRY problems. Exact issue on Github - <link>. 1. Currently Review report uses its own code to display reviews. This a pretty basic view, and it does not interpret HTML codes. It should be changed so that it calls the usual code that is used for displaying reviews, that gives the circle with the score inside. Currently, if you pull up a review report, and then click on one of the teams reviewed, e.g., the first one, you get a report that looks like this: <image> We need to change the views to existing templates in view_my_scores pages. For student view the UI is consistent in displaying reviews they have done and reviews they have received but for instructor's view the review report follows different UI and have different code. To make the UI consistent we have decided to choose the UI design of student view as the base and modify the UI design for review report in instructor's view. This will allow us to use the same code in both views, thereby following DRY principle. Updated View: <image>. 1. <link> 2. Code for displaying a review is essentially copied instead of parametrized and reused, violating the DRY principle. 3. No new tests added although they do have a well detailed manual test plan. 4. HTML codes [Breaks] are left visible in the view. 1. app/view/pop_up/team_users_popup.html.haml 2. app/view/pop_up/team_users_popup.html.erb 3. app/controllers/popup_controller.rb [Hot Fix] The previous implementation involved having a haml file with bare HTML. [app/view/pop_up/team_users_popup.html.haml] <code> We replaced this with an existing view following the DRY principle [app/view/pop_up/team_users_popup.html.erb] <code>. 1. Expertiza on test VCL instance - <link> <image>. Our test plan are mostly manual. There are two reasons why we choose UI testing: 1. As we only change the layout of several views. We can only test them from UI testing. 2. The existing templates view_my_score are also tested with UI, without any Rspec testing. There are two test cases for UI testing. 1. To Test UI for student View 1.1. Log-in as Student. 1.2. Go to Assignment 1.3. Click Your scores 1.4. Click show reviews 1. To Test UI for instructor View 1.1. Log-in as Instructor. 1.2. Go to Manage Assignments 1.3. Click on review report of a particular assignment 1.4. Click on any of the links from **Team reviewed** Rspec testing: Added the following test to the ~/expertiza/spec/controllers/popup_controller_spec.rb <code> Since the modifications are mostly on a view, a simple test would suffice. 1. <link> 2. <link> 3. <link>. 1. <link> 2. <link> 3. <link> 4. <link>.","The section on ""Issues with previous pull"" is not explained.  It is not clear why the previous implementation needs to be described in the document for the new implementation.  Normally I don't like raw code dumped into the documentation, but here you are just doing it to show how bad the previous implementation was.  So I wouldn't complain about that, except that you really only need to document the changes you made, not the bad changes made by the previous team.  It would be good if the test plan included some screenshots."
E1784,"Expertiza allows the instructor to create new assignments and customize new or existing assignments. Mass Assignment is the name Rails gives to the act of constructing your object with a parameters hash. It is ""mass assignment"" in that you are assigning multiple values to attributes via a single assignment operator. The following snippets perform mass assignment of the name and topic attribute of the Post model: 1. Post.new(:name => ""John"", :topic => ""Something"") 1. Post.create(:name => ""John"", :topic => ""Something"") 1. Post.update_attributes(:name => ""John"", :topic => ""Something"") Without the convenience of mass assignment, we'd have to write an assignment statement for each attribute to achieve the same result. Here's an example: 1. attrs = { :name => ""John"", :topic => ""Something"" } 1. post = Post.new 1. post.name = attrs[:name] 1. post.topic = attrs[:topic] Obviously, this can get tedious and painful; so we bow at the feet of laziness and say, yes yes, mass assignment is a good thing. With the help of mass assignment, when we create or update certain object, we do not need to write an assignment statement for each attribute. But mass assignment could cause security vulnerabilities. Hackers could add other parameters to do some bad things. How to Deal With Mass Assignment? In models, we need to add ""attr_accessible"" to implement the whitelist. For controllers, Rails 4 introduces strong parameters, which is a new approach to protect mass assignment. So our group needs to resolve all these ""Unprotected mass assignment"" issues according to <link> . In models, we need to protect all attributes that we allow to be mass-assigned using ""attr_accessible"". Previously, we just removed all attributes after ""attr_accessible"" which fixed ""Unprotected mass assignment"" but would lead to failure when creating and updating models. So the testes could not pass. Therefore, we added all attributes after ""attr_accessible"" and tests passed. However, this time, Brakeman would report ""Potentially dangerous attribute available for mass assignment"". In order to solve ""Unprotected mass assignment"" and ensure that tests can pass, this is the best we can do. If there was no protection at all in the model file. We added ""attr_accessible"" and all attributes that we allow to be mass-assigned after it. <image>. processing the mass assignment parameters with a function without changing them directly. Fix unprotected mass assignment in update <image> Fix unprotected mass assignment in new <image>. If the parameters come from requests, we can directly use ""params.permit()"" to implement a whitelist. However, if the parameters come from values of other objects, we cannot directly call that built-in function. Firstly, we need to build a hash with those values and pass the hash into ""params"". And then we can filter the parameters using permit(). Fix unprotected mass assignment in create <image> Fix unprotected mass assignment in new <image>. <image>. After modifying over 140 files, we want to make sure these tests could still pass. It turns out all tests could pass except models/tag_prompt_spec.rb. <image> In tag_prompt_spec.rb, we will create an instance of Criterion and specify the type of it. However, type is a reserved word for ActiveRecord. When we use type as a reserved word, it specifies the name of a model class. 1. (1)If we add :type after attr_accessible in Question(Superclass of Criterion) model Because you add it after attr_accessible, it will allow you to set the value of type. So, the code in tag_prompt_spec.rb above will try to create an instance of ""Criterion"" or ""Checkbox"" or ""Text"" which should be the subclass of Criterion. However, there are no such subclasses Checkbox and Text. Therefore, the test would fail. <image> 1. (2)If we do not add :type after attr_accessible in Question(Superclass of Criterion) model In this situation, when creating Criterion, the information (""Criterion"" or ""Checkbox"" or ""Text"") of type will be ignored. All three instances are created with type ""Criterion"" which is subclass of Criterion(itself). However, in the last test, ""expect(tp.html_control(tag_dep, an_long_text)).to eql("""")"" will check the type these three instances. Because the type of last two instances are actually ""Criterion"", not ""Checkbox"" or ""Text"", the test would fail. <image>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.","This is very readable writeup, and could be used by someone to learn about this security vulnerability in general.  It lacks a summary, which would have been useful, but other than that, it is one of the best."
E1853.3,"Contents 1.1. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.4. <link> 1.5. <link> 1.1.1. <link> 1.1.2. <link> 1.6. <link> 1.1.1. <link> 1.1.2. <link>. 1. Node 1.1. Node#setup - Node#setup appropriately sets a Node's parent_id, name, id, and label to those of the MenuItem passed to it as an argument. 1.2. Node#setup - When MenuItem has a ControllerAction, Node#setup(MenuItem) makes Node's controller_action_id becomes that ControllerAction's id. 1.3. Node#setup - When MenuItem has a ControllerAction, Node#setup(MenuItem) makes Node's url become ControllerAction's url_to_use. 1.4. Node#setup - When MenuItem's ControllerAction has a Controller, Node#setup(MenuItem) makes Node's site_controller_id equal to Controller's id. 1.5. Node#setup - When MenuItem's ControllerAction has no url_to_use, Node#setup(MenuItem) makes Node's url equal to ""/#{controller.name}/#{controller_action.name}"", the controller_action's name appended to the controller's name. 1.6. Node#setup - When MenuItem has a ContentPage, Node#setup(MenuItem) makes Node's content_page_id equal to ContentPage's id. 1.7. Node#setup - When MenuItem has a ContentPage, Node#setup(MenuItem) makes Node's url equal to ContentPage's name. 1.8. Node#site_controller - #site_controller sets the @site_controller instance variable. 1.9. Node#controller_action - #controller_action sets the @controller_action instance variable. 1.10. Node#content_page - #content_page sets the @content_page instance variable. 1.11. Node#add_child - #add_child updates Node's children 1.12. Node#add_child - #add_child adds multiple children to Node's children. 2. Menu 1.1. Menu#select - it returns if select(name) is not in @by_name 1.2. Menu#select - when name is in @by_name, Menu.selected is equal to name, @crumbs ends with the lowest level node and begins with the highest level node, and #selected? returns true for all nodes from the selected node to the root. 1.3. Menu#get_item - returns nil when id is not in @by_id 1.4. Menu#get_item - returns the equivalent item when id is in @by_id (item is not identical, but all components of item are the same). 1.5. Menu#get_menu - returns nil if level has no children. 1.6. Menu#get_menu - return children of a level if level has children. 1.7. Menu#get_menu - return all nodes except root if level is root. 1.8. Menu#selected - returns root if nothing has been selected. 1.9. Menu#selected - returns the name of the last selected menu_item. 1.10. Menu#selected? - if nothing has been selected, selected? 1.11. Menu#selected? - if a node has been selected, selected? returns true for selected node and all its parents. 1.12. Menu#selected? - if there are no menu items corresponding to the permission's of the role provided to menu, selected? does not return true. 1.13. Menu#selected? - if MenuItem returns an empty array, selected? 1.14. Menu#crumbs - When top-level menu item is selected, crumbs has length one. 1.15. Menu#crumbs - When top-level menu item is selected, crumbs has the root node's id. 1.16. Menu#crumbs - When bottom-level menu item is selected, crumbs has two crumbs (assuming lowest level is two). 1.17. Menu#crumbs - When bottom-level menu item is selected, crumbs are ordered from child to parent and all are present up to root. That being said, the Menu model is highly compositional, and it touches on MenuItem, ControllerAction, Controller, ContentPage, and Role (in addition to Node, which is in the same model). Contains the menu class and the node class. 2. menu_spec.rb - the spec file for menu. <link>.","Some of the tests are described very well, explaining what they test and what the outcomes are.  Other tests have little description.  Tests like the one for topic_name are long, so the various steps should be explained."
E1990,"3. The Instructor is facilitated with metrics such as average volume and total volume of the content of the reviews provided by a student. In order to achieve this, we need to identify the suggestions in the review comments as a way of determining how useful a review would be. 2. We would want the instructor of the course to be able to view how many constructive reviews were provided by a reviewer in comparison to the average number of constructive reviews provided by the other reviewers of the course. 3. To detect the number of suggestions in a text, there is a web service in place, developed previously by some contributors. 1. The suggestion detection algorithm was expected to identify the number of suggestions in the review comments given by a reviewer. To mock this number, we used a random number generator. Now we expect to receive a value between 0-10 as the number of suggestions provided by the student in one round of review. 2. To achieve this, we have included the following in an alert when the reviewer clicks on ""Save"" or ""Submit"": 1.1. 1. The number of suggestions in the review comments provided by the reviewer for that round 1.2. 2. The average number of suggestions in the review comments provided by all reviewers of the class (Again, for the purpose of demonstration, we have used values from the random number generator mentioned above.). 1. We wish to present the instructor with comparison of the number of suggestions present in the review comments provided by a student and the average number of suggestions typically provided by the class. This visualization adheres to the pattern of visualization which was present on this page for volume of review comments and average volume of review comments. The PeerLogic web service will send back the output(number of suggestions in the review comments) which will then be displayed in an alert to the student. 1.2. avg_num_suggestions_per_round(assignment_id, round_id, type) - as the name suggests, the goal is to obtain the average number of suggestions provided by the class in each review round of the assignment. 1.3. num_suggestions_per_student_per_round(response_maps, round_id) - the goal is to obtain the average number of suggestions provided by the student in each review round of the assignment. Currently, we use this function to simulate the number of suggestions in each comment, using a random number generator. 1.9. initialize_suggestion_chart_elements(reviewer) - this method computes the number of suggestions provided by the student in each round, the average number of suggestions provided by the student in all rounds, the average number of suggestions provided by the class in each round and the average number of suggestions provided by the class in all rounds. <code> 2. Changes made to initialize all the metrics and get all their values from the web service / random number generator when the instructor views the Review Report. <code> 3. Changes made to call the web service (currently commented out since the service is not up) / random number generator. We call the function to get number of suggestions for the reviewer per round per team and for the class as a whole to calculate the average. <code>. 1. review_assignment_spec.rb: Tests have been added to test the feature of identifying the number of suggestions in a given review. 1.1. Check whether the student is able to see a suggestion score for his/her review - on clicking save 1.2. Check whether the student is able to see the average number of suggestions given by the class - on clicking save 1.3. Check whether the student is able to see a suggestion score for his/her review - on clicking submit 1.4. Check whether the student is able to see the average number of suggestions given by the class - on clicking submit 1.5. Check whether the number of suggestions displayed is in the valid range of numbers - on clicking save and submit 1.6. Check whether the the average number of suggestions given by the class is in the valid range of numbers - on clicking save and submit 1. review_mapping_helper_spec.rb : Test have been added to check whether the new legends for metric is now part of the ""Review reports"" page. Review reports page as visible to the Instructor, after the above mentioned changes. <code> Suggestion metrics as visible to the reviewer when saving the review. <code> Suggestion metrics as visible to the reviewer when submitting the review. <code>. <code> <code>. <code>. 1. Whether the alert renders the number of suggestions for a reviewee on save/submit. 2. Whether the alert renders the average number of suggestions in a class for a reviewee on save/submit. 3. Whether the function returns the number of suggestions in correct bounds and returns an Integer value. 4. Whether the function returns the average number of suggestions in correct bounds and returns an Integer value. Whether the review report has the modified legend metrics.","I would have liked a more complete description of what suggestion detection is supposed to do.  You did describe it, but so tersely that I think readers would have had dififculty grasping the approach.

You have a good overview of code changes, but then you just dump the changes into the document without an explanation of how each piece of code works.  It is good that you listed what the automated tests do.  The screenshots stand by themselves, though; it would've been more useful to weave them into the document wherever they applied."
E1818,"These roles can be better named as duties, corresponding to the duty of a team member in a particular project. The user table is used for both the instructor and the student. 1.1. Each instructor can have multiple roles that he can choose from for a particular assignment/questionnaire. 1.2. Each student can have 0 or 1 role for a particular project. The value of the duty for that project team is stored in TeamUsers. 2. AssignmentsDutyMapping stores the value for all duties applicable to a particular assignment, hence it is an aggregation of the duties for an assignment. 4. StudentTeams uses the AssignmentDutyMapping to table to find available duties for a particular assignment to allow teammates to select. The project introduces changes from the instructor view and the student view. The changes are as follow: 1. Create Duties table: This table stores all the duties created by any instructor. <code> 1. Create assignments_duty_mappings table: If an instructor wants to add multiple duties for an assignment, storing it in the duty table will cause the duty to be overwritten. Thus we have created a table which maps an assignment and all its duties. <code> 1. Create assignment_duty_questionnaire_mappings table : This table is created to store the questionnaire for team-mate review rubrics and the corresponding duty id. This field saves the status of the role based review check box. 3. Added a column entry named ""Duties"" to the Users table of type string. This field saves the duty that a student would select if role based reviews are enabled. 1. For a particular assignment, in the 'Review Strategy' tab of edit assignment, a check box called ""Allow role based review?"" is created. This allows an instructor to enable a role based team-mate review for a particular assignment. This takes us to the create method of Duties controller where an instructor can add new duties. <image> 1. The instructor can select from the dropdown of duties. We have allowed multiple duties to be selected at once.The duties created by an instructor are unique for that instructor and are not displayed for any other instructor. <image> 1. An instructor can decide the number of duties for a particular assignment. 2. When the assignment is saved, the duty_id is saved to the assignment_duty_mappings table and thus it is associated with that assignment. 3. The instructor can create Team-mate review Questionnaires for the different duties he created or can use any from the existing list of questionnaires. <image> 1. In order to do this, the instructor has to go to the Rubrics tab of edit assignment. There, if the assignment is role-based, a drop down menu displays the list of all the duties selected for an assignment. 2. When the assignment is saved, the questionnaire_id is stored in the assignment_duty_questionnaire_mappings table. 1. When a student goes to “Your team”, they can see the team members, their selected duties and the option to review if these are enabled. Students will either see ""Review"" link to start the teammate review or a message that says that ""Teammate has not selected a duty."" <image> 1. The student can select their duty from a particular set of duties created by the instructor for that particular assignment. Upon clicking ""Select"" option in the Duty column, they are redirected to a new page where all the duties appear as radio-buttons and the student can select one of these. This occurs only if role based reviewing is permitted for that particular assignment. <image> 1. A student can only select one duty. <image> 1. A team member cannot change their role after the assignment submission deadline. 1. When a student selects a particular duty , it is stored in the database table of that user. Thus when a team-mate reviews that student , they will see a questionnaire corresponding to the duty of that student. 1. Instructor tests <code> 1. 1.1. While creating an assignment, in the Review Strategy tab, check the box for role based reviewing and expect the 'role_based_review' column of Assignments table to be true. 1.2. Ability to add new duties from the Review Strategy tab. This new added duty will now be displayed in the Review Strategy tab if the role-based-review option is selected. 1.3. Select from already existing and newly added duties for a particular assignment. 1. Student (team member) tests <code> 1. 1.1. When a student visits 'Your Team' link, if the option of role based review is selected while creating the assignment, a link 'Select' should appear which enables the student to select the duty. 1.2. In the 'Your Team' tab, after clicking the 'Select' link, the student should be able to select one duty (radio button). This selected duty should now be visible on the 'Your Team' page.",Logical organization.  Good description of how the code works in most places.  Test plan has been added with an appropriate level of detail.
E1631,"On Expertiza, the bidding interface allows students to sort topics by preference. This phenomena causes various problems when running the topic assignment algorithm. We built an interface in sign up sheet that would allow students to drag and drop the topics into the priority table. Where this priority table will be used to run the selection algorithm with ease. This interface would help avoid the errors caused by the previous interface. But we can avoid these errors by only giving the users to order their topics by topic name and expertiza code can assign required priority numbers internally. <image> Old Signup Table. If no desired topics are selected, then the user will be assigned some topic depending on the heuristics used inside the selection algorithm. There exists a serious user interface problem with the previous design. Note when a user is scanning through a hugh list of the topics, he/she might want to choose the topic as they are reading the project description. In order to achieve it, they will have to remember the priorities of the less desired topics, thus they will have to constantly updating their priorities for other topics. 1. Improve the user interface 2. Allow the user to set their priorities based on the position of the topic in the selection list 3. Do not allow the user to set duplicate priorities. We proposed sortable list interface to solve the problem associated with the old interface. New interface has two tables. First table holds all the topic lists and second table holds all the chose user priorities. User can select the topic by moving the item from Topics table to Selection table. Users can also resort already selected topics. System also provides the ability to remove already selected topic from the selection by just moving it back to the topic selection table. <image> New Signup Table. These are the set of operations a user can perform on this signup page using the cursor: 1) The user can drag the topics from topics table on the left into the selection table on the right. As a result, the topics are moved from one table to another. 2) The user can rearrange the already added topics in the selection table. As a result, the topics can be moved up and down within this table. The order of topics in selection table on the right, from top to bottom, are taken in the order of high to low priorities. Then this list of prioritized topics are used to run the intelligent bidding algorithm. intelligent_topic_selection.html.erb This file has code to display Topics and selection table. Both topics and selection tables are assigned same class name ""connectedSortable"". <code> _suggested_topic.html.erb Instructor can allow students to suggest new topic. New interface makes use of the same code. This callback function is called when the user drags and drops the topic. This post method sends topic id of all the selected topics as a list to the controller. Previous interface used to call set_priority method to set the manually entered priority of each topic. But the new interface should calculate the priority of each topic based on the order of selected topic list. This method receives the topic as an array and updates the priority of each topic based on the received order. <code> In the previous interface, list method used to display all topics in some random order irrespective of chosen topics priority. But with the new interface, expertiza displays selected topics in Selection table based on the indicated priority and remaining unselected topics in the Topics table. Seggregation of topics into separate tables and ordering of topics happens in list method. This method displays new view only if the instructor created assignment with bidding topic selection option. <code> view/sign_up_sheet/list.html.erb This view holds the code to display manual FCFS (First Come First Serve) style topic selection. This code also had code to display suggested topic list. New interface makes use of suggested topic list code. So we refactored suggested topic code into separate partial and we replaced that code block with single render method. These columns doesn't give any useful information to students in bidding topic assignment because topic assignment happens at some predetermined time. We removed these columns from sortable topic list. Only FCFS style topic selection or Instructor/TA/Admin interface display's this information. 1. You can access the deployment here <link> 2. Login as student : user name: student5432, password: password 3. Navigate to <link> 4. Topics table contains all the topics available for this assignment 5. Selection table contains all the selected topics. First topic indicates highest priority. Last topic in this table indicates least priority 6. Drag and drop the topics from Topics table to Selection table to bid for the topic. 7. You can also remove perticular topic from your selection by moving the topic back to Topics table from Selection table 8. This feature is already merged to expertiza master repository few days back. You already used this interface to select 2nd OSS project topics. Enabling the interface to use keyboard to select topics and drag them into the selection table. This will make the selection very intuitive.","Design doc is mostly screenshots of code, which don't explain enough about why the project was coded the way it was. ""There are too many checks of """"reviews_is_team"""".
Login issue with action_allowed as pointed out during demo. 
There are too many screenshots of the code changed in the design doc."""
E1968,"This project fixed several bugs related to Assignment teams. Expertiza has Assignment objects, which represent an assignment usually assigned by an in structor for a course. If the instructor allowe teams for the assignment, the participants in that course can create teams with each other. Also, the instructor can create teams or add team membert to a exsiting team. Our project is focused on fixing bugs related to these functionalities. In this project we fixed three problems, the problems and the way to reproduce them is shown below. 1. Adding a member from the UI (typing the ID into the textbox) raises an error. <code> 2. Impersonating a student who has an assignment without affiliating to any course will cause an error. <code> 3. Creating a team by uploading a file. <code>. 1. The reason for the first problem was actually due to a key error. In teams_users_controller.rb line 35, 'assignment_id' was used to find AssignmentParticipant. But in the model of AssignmentParticipant, the foreign key name is acctually 'parent_id'. So, by changing it, problem solved. <image> 2. After our inspection into the file of ""expertiza/app/controllers/student_task_controller.rb"", we found the reason for the second problem was that before we used t.assignment.course.instructor_id, we had to confirm that t.assignment.course was not equal to nil. If there existed an assignment without being subject to any course, when this assignment was assigned to a specific student, it would raise an error when it came to showing the tasks of the student. Thus, in order to show student tasks correctly, we changed the code to at first checking whether the t.assignment.course was nil. If t.assignment was not nil, we could use t.assignment.course.instructor_id to retrieve data needed from the database, otherwise, we used t.assignment.instructor_id directly to retrieve data needed. <image> 3. The third one works fine. For each of the problems, we did feature tests with Rspec. They all follows the reproduction steps decribed above. 1. Problem 1: assignment_team_member_spec.rb Following steps needs to be performed to test this code: 1. Login as instructor. 2. Create a course and an assignment under that course. 2. Add at least two students as participants to the assignment. 3. Create a team for the assignment. 4. Add a participant to the team. 5. Check if the student is a team member of that team. 1. Problem 2: impersonate_student_spec.rb Following steps needs to be performed to test this code: 1. Create data for the test including an instructor, a student and an assignment without being subject to any course. 2. Log in as instructor. 3. Add the student as the participant of the assignment created. 4. Impersonate the student from the instructor account. 5. Check if the page of displaying tasks of the student is correctly shown. 1. Problem 3: assignment_team_import_spec.rb Following steps needs to be performed to test this code: 1. Login as instructor. 2. Create a course and an assignment under that course. 3. Create teams for the assignment by importing a file. 4. Check if these teams belongs to the assignment. Run the test locally: 1. Problem 1: The snapshot of results in the console when running rspec spec/features/assignment_team_member_spec.rb <image> 1. Problem 2: The snapshot of results in the console when running rspec spec/features/impersonate_student_spec.rb <image> According to above snapshot, after we applied changes in original code, the test was able to passed. Besides, we confirmed that our changes were successful by taking the same actions in our browser. 1. Problem 3:The snapshot of results in the console when running rspec spec/features/assignment_team_import_spec.rb <image>.","1) Clearly explained what their task was and how they resolved the issue.
2) Showed before and after code snippets side by side.  This can also be done with Github diff view.
3) Could have added test-case code snippets as well as explaining their test cases. 
4) The formatting is very basic, and consequently the various text elements are not well set off from each other.  Mediawiki markup (https://www.mediawiki.org/wiki/Help:Formatting) can be used to make it easier to read."
E1563,"<link> is a peer review based system which provides incremental learning from the class. Expertiza allows the instructor to create, edit and delete assignments, create new assignment topics, assign them to a particular class or selected students, have students work on teams and then review each other's assignments at the end. For the students, they can signup for topics, form teams, and submit their projects and assignments. Students then review the work done by other students and give suggestions to improve. Teams after reviews are allotted scores and they can refer to the peer comments to further improve their work. Refactoring <ref>Refactoring <link> </ref> is restructuring of code without the need of changing any external behavior. Some common techniques to refactor are: 1. Moving methods to appropriate modules 2. Breaking methods into more meaningful functionality 3. Creating more generalized code. 4. Renaming methods and variable. Refactor AssignmentParticipant model which is a subclass of Participant model. 1. Refactor scores method to smaller methods. 2. In set_handle method, there is no need for a separate ELSEIF statement. Club the ELSEIF statement into IF statement as an another OR condition. 3. Remove methods like compute_quiz_scores(scores) , average_score_per_assignment(assignment_id) which are not being used. 4. Method cycle_deviation_score(cycle) is also present in CollusionCycle, remove it from this class. 5. Methods related to reviews like teammate_reviews, bookmark_reviews do not belong to AssignmentParticipant model. Move them to the appropriate class. 6. Methods related to files and directories like files(directory) should not be present in AssignmentParticipant model, move them to FileHelper module. The method scores has been converted to smaller methods scores , assignment_questionnaires , merge_scores , calculate_scores . <table>. The set_handle method had an unncessary ELSIF statement which was performing the same action self.handle = self.user.name . This has been clubbed as an OR condition to the IF statement and the first ELSIF statement has been removed. <table>. The files and directory methods from AssignmentParticipant model have been moved to the FileHelper module. The methods files , submitted_files and dir_path are appropriate for the FileHelper' module and hence been moved there. The below line was added to the AssignmentParticipant model. include FileHelper The AssignmentParticipant class would look like <code> Methods moved to FileHelper: 1. submitted_files <code> 1. files(directory) <code> <code> 1. submitted_files() <code> 1. dir_path <code>. The following methods have been removed as they were not being used by the application. def average_score_per_assignment(assignment_id) <code> <code> <code> <code> def quiz_taken_by? (contributor, reviewer) <code> def has_quiz? <code> def reviewees <code> <code> def two_node_cycles <code> def three_node_cycles <code> def four_node_cycles <code> def cycle_similarity_score(cycle) <code> <code> <code> def cycle_deviation_score(cycle) <code> <code> <code> def compute_quiz_scores(scores) <code> def review_response_maps <code> def members <code> def get_hash(time_stamp) <code> <code>. 1. The bookmark_reviews() method from AssignmentParticipant was being called once in get_assessments_for method of BookmarkRatingQuestionnaire class. It has been replaced by the method statement directly since it only had a single line of code. <table> 1. The teammate_reviews() method from AssignmentParticipant was being called once in get_assessments_for method of TeammateReviewQuestionnaire class. It has been replaced by the method statement directly since it only had a single line of code. <table>. Please follow the below instruction to test UI: 1. Login to Expertiza on <link> . 3. You can select a previous assignment 'shivam test' or 'Pankti test'. The same can be checked by running Rspec spec The participant is able to log in to the system, view the assignments, submit links and files in assignment submission, view the scores, review peers, etc. Below are some of the execution screenshots after the refactoring of the model. The Expertiza Login Screen <image> User can see all the assignments as below. <image> View team members for the assignment selected. <image> View the submission page to upload the assignment. <image> View the scores of an assignment. <image>. 1. Expertiza Github repository<ref>Expertiza Github repository <link> </ref> 2. Our Github repository<ref>Our Github Repository <link> ]</ref>.","Writeup is fairly readable.  Has a nice table at the beginning.  Showed only ""after"" code; did not compare ""before"" with ""after""."
E1997,"Hence, existing code won't work. 2) On the Due Date tab, the instructor can select if (s)he wants to have meta-reviews done for the assignment, by clicking on the “Use meta-review deadline” checkbox and setting a meta-review deadline below. checkbox. Issue Description For an assignment, when 'Use Metareview Deadline' is unchecked, it means meta-reviews are not enabled for that assignment. Solution and Code Modification for Issue 3 As the checkbox and the content to be displayed on clicking the checkbox are located on different pages we cannot use the regular checkbox logic, so we used the concept of local storage and event listener. The code snippet below shows the existing code: <image> The 'removeOrAddMetareview()' is called on click of the 'Use metareview deadline' checkbox. This can be seen in the below code snippet <image> Now on clicking the 'Use metareview deadline' checkbox, the new code will invoke the 'removeOrAddMetareview()' function which indirectly invokes the two new functions. Now let us look at the implementation of the two new functions, we used a local storage variable called 'meta'.So based on the status of the checkbox a value is assigned to the local storage variable. For example, if the 'Use metareview deadline' checkbox is checked then the local storage variable is initialized with the value 'show' and if the 'Use metareview deadline' checkbox is Unchecked we assign with the value 'hide' to the local storage variable. Now after storing the respective values for the local storage variable, the storage event is triggered by these functions. checkbox is changed to false. The below code snippet shows the modifications made: <image> we wrote a javascript code that handles the event triggered when the 'Use metareview deadline' checkbox has been checked or unchecked. In this 'onStorageEvent' function we check the value in the local storage variable and based on that value we change the status of the display for the table row with id 'meta'. <image> Finally, the null value to the 'Has Meta-review Limit?' 2. Ensure that the meta-review fields in the review strategy tab are visible only when 'Use metareview deadline' is enabled in the Due dates tab. <image>. 2) On the Due Date tab, the instructor can select if (s)he wants to have meta-reviews done for the assignment, by clicking on the “Use meta-review deadline” checkbox and setting a meta-review deadline below. checkbox. For an assignment, when 'Use Metareview Deadline' is unchecked, it means meta-reviews are not enabled for that assignment. As the checkbox and the content to be displayed on clicking the checkbox are located on different pages we cannot use the regular checkbox logic, so we used the concept of local storage and event listener. The code snippet below shows the existing code: <image> The 'removeOrAddMetareview()' is called on click of the 'Use metareview deadline' checkbox. This can be seen in the below code snippet <image> Now on clicking the 'Use metareview deadline' checkbox, the new code will invoke the 'removeOrAddMetareview()' function which indirectly invokes the two new functions. Now let us look at the implementation of the two new functions, we used a local storage variable called 'meta'.So based on the status of the checkbox a value is assigned to the local storage variable. For example, if the 'Use metareview deadline' checkbox is checked then the local storage variable is initialized with the value 'show' and if the 'Use metareview deadline' checkbox is Unchecked we assign with the value 'hide' to the local storage variable. Now after storing the respective values for the local storage variable, the storage event is triggered by these functions. The below code snippet shows the implementation of the two new functions: <image> In _review_strategy.html.erb file: Small modifications have been made to the existing code that is the display of the table row with id 'meta' is given 'none' by default and also the status of the 'Has Meta-review Limit?' checkbox is changed to false. The below code snippet shows the modifications made: <image> we wrote a javascript code that handles the event triggered when the 'Use metareview deadline' checkbox has been checked or unchecked. In this 'onStorageEvent' function we check the value in the local storage variable and based on that value we change the status of the display for the table row with id 'meta'. <image> Finally, the null value to the 'Has Meta-review Limit?' 2. Ensure that the meta-review fields in the review strategy tab are visible only when 'Use metareview deadline' is enabled in the Due dates tab.",Very good description of the issues and how you fixed them.  Test plan needs to be better documented.
E2075,"Expertiza is an open source project based on Ruby on Rails framework, created and maintained by the joint efforts of students and faculty at North Carolina State University. It allows the instructors to create new assignments and customize new or existing assignments. Expertiza also allows an instructor to create a list of topics the students can sign up for. Students can form teams on the web application to work on various projects and assignments together. Additionally, students can peer review each other's submissions allowing them to improve upon their work. Expertiza supports submission across various document types, including the URLs and wiki pages. The Expertiza project allows ""calibration assignments"" to be performed where students are asked to review work that has also been reviewed by a member of the course staff. Calibration is the term used for rectifying, or checking or determining something. In the context of this project, a 'Calibrated review' is one which is performed by a student, so that (s)he can verify their work by comparing it with the instructor's response for the same assignment. If the student’s review “resembles” the staff-member’s review, then the student is presumed to be a competent reviewer. Since calibration reviews are meant as reference for better performance of peer reviews (which are performed later), they are not graded. Calibration submissions should be copied along with calibration assignments. On creating a copy of a previous assignment, say for example Design Exercise, Fall '20 for the Fall '21 semester - the calibration assignments associated with it are not copied over. The instructor is required to impersonate extra participants, and submit work on behalf of each of the extra participants. This is obviously extra trouble, and it would be a lot more convenient if an instructor didn’t have to resubmit the same calibration submissions over and over, every semester. The following steps were taken to test the aforementioned issues: Step 1: On copying the Design exercise assignment <image> Step 2: The original file contains the following calibration reviews <image> Step 3: However, the copy doesn't contain any of the calibrated reviews <image>. The project is implemented in Ruby on Rails that uses MVC architecture. We have three separate modules namely User Interface, Database Model and Control Flow (Model, View and Controller). We tend to reuse the already existing functionalities and data to our design. The calibration reviews that are present in the previous exercise will be copied into the newly created exercise which would prevent the instructor from performing additional tasks of performing reviews repeatedly. This would also prevent code duplication and additional memory usage. The following must be added to the current implementation: 1. Participants with 'View' and 'Edit' actions in the calibration tab are copied over to the new version, as they are considered calibration submissions 2. All hyperlinks and files associated with the above mentioned participants are copied over as well 3. Participants with the 'Begin' action are not copied over 4. A check is put in place to make sure that these steps are taken only for copying assignments with calibration reviews. This is signified by a calibration tab in the tool bar, on the edit page. <image>. <image>. 1. app/models/assignment_form.rb 2. app/views/assignments/edit/_calibration.html.erb 3. db/schema.rb. All changes mentioned below have been made in app/models/assignment_form.rb <image> <image> <image> <image> <image> <image> <image> <image>. 1. To check if the UI is working as expected [No broken links] 2. The submissions [Files and Hyperlinks] are copied when an assignment for calibration is copied. The following steps must be performed to test the project UI: Step 1: Log in as an Instructor, with Username - instructor6, Password - password <image> Step 2: Find an assignment with calibration submissions present, which is represented by a calibration tab on the editing page. In this case, the assignment chosen is called ""Design exercise"" <image> <image> Step 3: Copy the assignment, by selecting the icon shown below <image> Step 4: On inspection of the copied assignment, it is observed that the calibration assignments have been copied over. <image> Step 5: In the similar way, if the calibration tab has any files attached by the reviewers, then the files would get copied along with the participant details. Below is an assignment in which one participant has submitted a file named review1.txt in calibration. <image> Step 6: As the assignment has a file in calibration tab, even the copy of the assignment will have the same file with same content copied over to the calibration tab. Below is the copied assignment's calibration tab containing review1.txt created by the participant in original design exercise <image>. <link>. Below are the rspec testcases used to test the application. <image> <image> <image>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","Code changes are merely pasted into the document without any description.  This doesn't add much value over looking at a diff in Github.  This also applies to the test cases.  OTOH, the discussion of manual testing has screenshots that clearly illustrate the process."
E2020,"The purpose of this project is to allow instructors or teaching assistants who are participants of an assignment to be able to review (before the last due date of the specific assignment) any team that has submitted the assignment. Beyond this general endeavor, there is also the condition that team members of the assignment should be able to view reviews done by the course staff that can be identified in an aesthetically pleasing manner. As an added feature, reviewers should see how their reviews differ from those done by the course staff. There are two main issues: 1. Allow the instructor and teaching assistants to review teams that have submitted assignments. 2. Allow authors to visually identify reviews done by the course staff. 1. A star icon will be used to distinguish whether a review was done by a course staff and will appear below the 'Review #' heading. 2. Add helper class grades_helper.rb to handle check to determine whether review was done by course staff based on the boolean flag attached to a response. 3. Change will be made in view_team.html.erb such that after verifying that a response was done by a course staff via identity_helper.rb, a star is displayed below the 'Review #' heading. Note: Previously, a review that was done by a course staff would not be visually recognizable by an author of the particular reviewed assignment. With the following changes, however, authors will be able to recognize reviews done under the ""Summary Report for assignment"" page, as reviews done by course staff will have a black star located immediately below the ""Review #"" header. A boolean check is done in the review_done_by_course_staff? method and used in view_team.html.erb to display a black star below a particular review if and only if review_done_by_course_staff? Changed files: app/helpers/grades_helper.rb <code> app/views/grades/view_team.html.erb <code> Pull request can be found <link> 1. A staff user (Instructor, TA, Admin) will see the star for reviews done by another staff member as well as the names of all the reviewers. <image> 1. A student will still see the star for reviews done by a staff member but all names are anonymous. <image>. While students must submit reviews in the review stage, instructors/TA's can submit reviews any time before the final deadline. In order to submit reviews, the instructor/TA must be added as a participant to the assignment. Then, they will go to ""View Submissions"" on the Manage Assignments page. If the final deadline for the assignment has passed, they will see an ""Assign Grade"" link next to each submission. Otherwise, they will see a ""Perform Review"" link if a review has not been submitted yet or an ""Edit Review"" link if a review has been submitted already. Students can view only the reviews they have performed and the reviews of their work, while instructors/TA's can see all reviews for the assignment. Reviews done by course staff will be marked with a star to distinguish them from students' reviews. <image>. It holds the user ID of the User (user.rb) who reviewed the assignment, from which we will determine the user's role: Instructor, TA, or student. It also contains the ID of the Assignment (assignment.rb) being reviewed. Additionally, the Questionnaire (questionnaire.rb) can be located by its ID defined in AssignmentQuestionnaire and consists of the Questions (question.rb) users use to review the assignment. 2. Verify that assignment reviews can be submitted by users with an Instructor, TA, or Student role assigned. 3. Verify if a instructor is not a participant, an ""Assign Grade"" is visible. 4. Verify if an assignment's deadline is passed and the instructor is a participant, an ""Assign Grade"" is visible. 5. Verify if an assignment's deadline is not passed and the instructor is a participant, a ""Perform Review"" link is visible. 6. Verify if a review has already been submitted by an instructor, a new ReviewResponseMap will not be created for the instructor when they load the list_submissions view. 7. Verify a star icon appears next to only reviews done by instructors/TAs in the responses view. This should be visible to both staff and students. UI Testing 1. Login as an instructor 1.1. Username: instructor6 1.2. Password: password 2. As this test is an extension of the one conducted in Part 1, impersonate the student who the instructor performed a review for. Go to Manage -> Impersonate User and enter the student's user name. 4. You should now be in the ""Summary Report for assignment"" page. Below whichever review that the instructor submitted, there will be a black star. spec/helpers/grades_helper_spec.rb <code> <code> <code> <code> <code>.","In showing your code, it would be much more helpful if you show the changes you made and describe them.  In some cases you do, but for ""View changes"" and ""Changed files:"" below that, you just show the code."
E1848.2,"Assignment_team.rb in Expertiza provides a method for student to assign a team and finish one assignment. Features come at the cost of complexity; this project is focused on creating the test methods to ensure that user interaction with the assignment interface remains stable and reliable. 1. The forked git repository for this project can be found <link> 2. The pull request link can be found <link>. We use 'let' to define a memoized helper method. The value will be cached across multiple calls in the same example but not across examples. <code>. There are some examples for how this project create test methods for assignment_team.rb. The assignment_team.rb offers a method that could save files in one directory <code> Based on the above code, the test case can be created: <code>. The assignment_team.rb offers a method that could export the fields <code> Based on the above code, the test case can be created: <code>. Our test cases has coverage: 100% There are in total 127 relevant lines, and all of them get passed. The testing framework in the assignment_team_spec.rb used unit tests to test the functionality of each action in the class. The mock instances are created at the beginning of the file, so that during each test they don't need to be constructed again. In order to test each unit case without depending on other functionalities, the mocked actions, as well as the desired returns are built inside different test cases, depending on the need of the case. In building the test framework, the key is to understand the input, output and the desired action of each function that we want to test. The Rspec test format also has a steep learning curve, but the test shows stable and robust result on the assignment_team.rb.","The beginning of this document is quite readable.  The description of the ""Help Method"" should be expanded to explain why these objects are being created.  Later on, the prose description of test cases could be expanded to explain how the tests are being carried out.  It seems like the team may have run out of time, after starting very strong."
E1791,"To track the review time that each student spend on each submitted resources is meaningful to instructors to study and improve the teach experience. In this project, our team is going to solve this problem as well as improving previous time tracking methods using mature third-party APIs to record link review time more accurately. Our team is going to solve the submission review time tracking by attempting to open the downloaded files inside popup windows of the web browser in order to record the time on the client side. Strategy In this project, for each review page, we need to deal with different type of links. For online links, such as github repo, youtube link, etc, we use javascript to open a new window detect time when the window is closed. For other files that need to be download and open locally, we can only make approximation for review time. For this project, we need to design a database table to store all the time that we need to record for each review submission event. For each review, when the reviewer click on one link of the submitted files, we create an entry to the table review_time, we will write a function to record current time to the database. For how to determine time when the reviewer complete with the opened link, there are different cases. If the reviewer click on save or submit button, close the page, or logout, we need to write to all open entry (without end_at) respect to this review and save current time to end_at. But for how to decide when the review close the opened link is a little complicated. For the other files that need to be downloaded, we can only make an approximation by record the time when the reviewer click on the link until the time he/she enter the reviews. For each task, reviewer might open each link several times, might also save the review process and restart it some times later, so we will have multiple records for each link. Every time the student click on the link, a new record is created and then the time in all records will be summed up to total time for every link and displayed on instructor page. After we record start_at and end_at time for each piece of review, we need to display time that each reviewer spent on each link. Because the reviewer may save the review and start again in the future, so for each link there might be several entries, we need to sum them together. 1. When user click on save or submit the review without closing opened windows, the system will search all records of response time for the reviewer and reviewee where end time is NULL, and update it with current time. 2. If the reviewer opens the reference links or download files, but leave them open and turn to focus other unrelated stuff, the review page will send a popup alert dialog to confirm if the review is still in review mode. If not, it will close these windows and save the time as approximation of end time. For the cases described, shut down computer etc., there will be records written in data base with end time NULL, next time when the reviewer restart the review, the system will just drop all the records with NULL end time and start a new query. Also if reviewer does not interact with the review page for a long time, it will pause the timer and commit all existing related time record in database. The time limit is now 2 minutes. We will test the following cases during our development 1. When we work the review, if we click on GitHub link, GitHub pull request link, check whether the system record review time correctly. 2. When we work the review, if we click on doc, pdf, image link, check whether system open submitted files in views/response/_submitted_files.html.erb and recore the review time correctly. Test of new model and function will be written and tested during project development: 1. Test the success of a review time record given valid start and end time; describe ResponseTimesController do <code> 1. Test whether the start time is updated to the end time last saved in the database when the user resumes a review; <code> 1. Test whether the end time is updated as the current time when the review is saved to the database. However, due to the complexity of the Expertiza system and limited time period, there are still several points to improve in the future: 1. Improve the accuracy of review time record. To record the exact time that the user spends on each link or file, it is more accurate to track the active time of each new window or tab of these links or online files. 2. Notify the user when no response on the review page. Occasionally the user may open the review page to do the review, but is interrupted to focus on other applications. In this case, we stopped the time recording but try to alert the user that if he wants to continue the review. However, this notice cannot show in time if the user is not focusing on that review page. So a global alert is necessary to save the time and provide notice on time.","A number of reviewers commented on weaknesses in the test plan, but it appears that has been addressed,  Generally a good description of work to be done."
E2102,"In order for students to write effective reviews, they need to understand the work that they are reviewing. Expertiza can allow authors to create a quiz over their work. If an assignment is set up to use quizzes, then a reviewer must take the quiz over the author’s work before reviewing it. Then, based on how the reviewer scores on that quiz, Expertiza can weight that author’s scores accordingly in calculating a peer grade. Thus, reviewers who understand the author’s work better have more say in determining the author’s (peer) grade. quiz_questionnaires_controller , naturally, is the controller that administers a quiz. A quiz_questionnaire is a kind (subclass) of questionnaire in Expertiza. A questionnaire consists of a number of questions (or “items”) that the reviewer needs to answer. This questionnaire contains many violations of good programming practices. E2102 deals with refactoring the code inside quiz_questionnaires_controller.rb so that it is clear and conforms to DRY principles. Note: The majority of the issues listed in the previous section were solved simply by adding descriptive comments/messages or improving existing ones to clarify behavior, so those will not be shown in this section. Prior to changes, the code in the action_allowed? method had some repeated code. <code> This can be solved by using the authorization helper methods described in <link> . <code>. Some logic inside the new function of the controller is technically correct... <code> ...but can be improved by making better use of Ruby keywords. <code>. Within the save_choices function of the controller, there is an if-statement that determines what function to use when saving a question of a certain type, which can be either true/false or multiple choice. <code> We can make this more readable by substituting this structure with a function call to a newly defined factory method called question_factory ... <code> ...which contains the refactored if-else structure and saves questions of the appropriate type. <code> Code improvements can be viewed in much more detail in the E2102 pull request <link> . Coverage testing was disabled on our PR like many others so the most recent coverage is not available. However, the only change we had to make to a rspec file in our project was for the issue of *Line 31: Change message to, “This assignment is not configured to use quizzes.” . You can see in our file changes we simply fixed the expectations of the test case and the build passed for our controller file. Note: Our project is a refactoring of existing controller code. It cleaned up the controller and therefore does not really have anything to test besides if the app is still working. Steps: 1) Visit our hosted website (until the end of April 2021) at <link> 2) Login with the username instructor6 and password password 3) Click assignments at the top (to the right of ""Courses"" under ""Manage Content"") 4) For ""773HimesMakthalTest"" click the edit pencil icon <image> 5) Note that Has Quiz? is enabled and it has due dates and is assigned to student7366 6) At the top, go to Manage > Impersonate User > student7366 7) Under assignments, click the 773HimesMakthalTest assignment 8) Click ""Your work"" > Click ""Create a quiz"" if no quiz has been made yet 9) You can fill in the new quiz or edit an existing one. Also you can view the quiz. <image> Again, this all worked before we made any changes. Our project was just refactoring.","Very good point-by-point description of what was done.  Good to link to project board (but all issues have been resolved) and repo to view changes.  In Section 5, section headers are two-line sentences; a pithier heading should have been added."
E2072,"There were no existing test cases for the controller. WI3: Refactor copy method name WI4: Refactor assign_quiz WI5: Refactor Review Score WI6: Rewrite Score calculation within the scores method WI7: Refactor Volume - # Distinct Words in a Review WI8: Provide documentation for Compute_Assignment_Score. sort_review_by_review_volume_desc loop re-implementation: <image> Initialize_chart_elements loop re-implementation: <image> <image> Display_volume_metric removal: <image> Rewrite Scores Method The scores method returns the scores that a specific assignment_participant has received Originally, the scores method contained several convoluted method calls with some unused and commented out code. The following changes were made to accomplish this task: 1. Removed topic_total_scores (score calculations for a microtask) and moved it into the scores method, since this method was only called once and wasn't used anywhere else. I also removed the associated tests. <image> 2. Removed calculate_scores method and refactored the code into the scores method, since this method was only called once and wasn't used anywhere else. I also removed the associated tests. <image> 3. Refactored the merge_scores method which is called by Scores. 1. DRYed out the code by adding a new update_min_or_max method that dynamically sets the min or max <image> 1. Refactored merge_scores to use update_min_or_max method. <image> 1. Added 6 RSPEC tests for this new update_min_or_max method 4. Added comments for the scores method and merge_scores method <Image Here> Refactor assign_quiz Method The assign_quiz method was originally located in the assignment_participant.rb file and was requested to be moved into quiz_questionnaire.rb. 4. Because CollusionCycle is unused, we deemed it appropriate to make the following changes: 1. Removed the method definition from assignment_participant.rb <image> 1. Removed the rspec test for this method <image> Refactor copy Method Name The copy method was determined to have a misleading name for a method that copies a participant to a course. As a result, the copy method name was refactored into 'copy_participant'. The issue originally stated that the method should be able to determine the review score for any round of review. The original method returned the first round (index position 0) review score. We made the following determinations: 1. The review_score method only returns the first round review score which is from index position 0: <image> 2. We determined that review_score method is only being called in collusion_cycle.rb, which is no longer used in the Expertiza application. <image>. We also made changes to the RSpec tests for these methods, which will be discussed in the Rspec Testing Section below. For testing our changes, we focused on updating and designing new automated RSpec tests for every method. Refactor assign_quiz Method Removed assign_quiz spec test from assignment_participant_spec.rb to correlate with the deletion of the assign_quiz method itself. <image> Refactor copy Method Name Refactored copy to copy_participant in all spec test instances (assignment_participant_spec.rb). <image> Refactor self.grant_publishing_rights to assign_copyright Following refactor, a new spec test needed to be built for the modified assign_copyright method in assignment_participant_spec.rb. 3. Tests if key matches using assign_copyright <image> In this test, we created a new RSA key pair in order to effectively test the functionality of the assign_copyright method. We then call the assign_copyright and pass the private key to this method. Rewrite Scores Method As described in the previous section, during the rewrite of the scores method our team cleaned up the merge scores method as well, by creating a new update_max_or_min method and abstracting/DRYing out the code. We wanted to make sure to thoroughly test this new method by adding the following rspec tests: 1. Removed topic_total_scores tests 2. Removed calculate_scores tests <image> We verified that the current scores tests were testing the functionality well and no changes were made to these tests. 3. We added 6 new tests to the rspec file to test the new methods for update_max_or_min. <image> Reviews_by_reviewer Method Since we decided to remove this method because it is unused in the application (besides Collusion_cycle.rb), we removed the associated rspec tests as well: <image> Review Score We also removed the Rspec tests for review_score method which we removed as stated in the previous section. <image>. <image>.","The URL does not contain the name of the project as required.  I didn't want to copy the whole page, but I did add the project title to the first line of the page.  The description of changes made is quite readable, but you simply boldfaced the names of the changes.  If you had made them section headers in Mediawiki markdown, they would have appeared in the table of contents, making it much easier to see at a glance what had been done.  Unlike the description of the refactorings, the description of the tests is not as detailed.  More prose describing how they would would have been helpful."
E1796,"Expertiza enables the instructor to create new and customize existing assignments. In the Expertiza portal presently when an instructor wants to create a new assignment then as he selects a new assignment option only a few metrics are asked for while for mentioning the other metrics the professor needs to edit assignment and then under that he is shown the options to edit all the other metrics. Issue1: Here we will be unifying the edit assignment view and new assignment view and for that we had to understand how the page requests are being sent on the background on the edit assignment page and accordingly change and implement the changes on the new assignment view. So incase of new assignment page we have to avoid doing that since we wont be having an assignment id yet to update the values. Specific Improvements to assignment creation by navigating the user for creating a new assignment to edit assignment page(view/assignment/edit_assignment). Making sure the edit assignment has blank fields in case of new assignment and saved fields in case of editing. When an Instructor creates a new assignment, he should be able to see a table to set DueDates, Review Strategy options and Rubrics associated with the assignments. These options are currently available to the instructor while editing an assignment. We will be adding options to be set during creation of new assignment. Fields to add suggested topics will be excluded for new assignment creation. <image>. <image> While under Edit assignment the professor can now mention all the various metrics regarding the assignment on this page. So, in this case when we have to save a view for a assignment page, we cannot actually do that because on every tab or every change of tab it needs an assignment id. But in case of new assignment page, we do not have an assignment id yet and we did not create the assignment. New assignment creation form will render forms to set Due Dates, Review Strategy and Rubrics as a table. In the improved view of New Assignment instructor will be able to specify details under four tabs as shown in the below screenshots <image> In the General tab the instructor is now able to see all the options from the old view. This tab allows the instructor to select the various rubrics for the new assignment. <image> In the improved view, there will be an additional new tab titled ""Review Strategy"". This tab allows the instructor to set the various policies for review of the new assignment. <image> The new view also renders tab a titled ""Due Dates"" where the instructor can select the deadlines for various rounds of the selected rubrics. This tab also allows the instructor to select the late penalty policy The instructor can also choose to make a new late policy instead of selecting an existing policy created by the same instructor. As an Instructor, clicking on Manage->Assignments->new public assignment,will redirected to ""Create New Public Assignment"" Page. As an Instructor, clicking on Manage->Assignments->new private assignment,will redirected to ""Create New Private Assignment"" Page. As an Instructor, clicking on Manage->Assignments->new public/private assignment, ""Create New Public/Private Assignment"" should render a table with tabs ""General"", ""Rubrics, ""Review Strategy"", ""Due Dates"". As an Instructor, clicking on ""Rubrics"" tab from ""Create New Public/Private Assignment"" page, the tab should display table to select Questionnaire, menu type, display style, weight and notification limit. As an Instructor, select Review Strategy from drop down on ""Rubrics"" tab from ""Create New Public/Private Assignment"". As an Instructor, set number of reviews done by each student on ""Review Strategy"" tab from ""Create New Public/Private Assignment"". As an Instructor, Set minimum number of reviews done for each submission on ""Review Strategy"" tab from ""Create New Public/Private Assignment"". As an Instructor, Set both calibrated and uncalibrated artifacts on ""Review Strategy"" tab. As an Instructor, select Anonymous Review option on ""Review Strategy"" tab. As an Instructor, select allow self review on ""Review Strategy"" tab. As an Instructor, set due dates on ""Due Date"" tab from ""Create New Public/Private Assignment"". As an Instructor, set number of submissions allowed on ""Due Date"" tab from ""Create New Public/Private Assignment"". As an Instructor, set number of reviews allowed on ""Due Date"" tab from ""Create New Public/Private Assignment"". As an Instructor, set number of teammate review allowed on ""Due Date"" tab from ""Create New Public/Private Assignment"". As an Instructor, after updating the fields on all tabs and clicking on save should create an assignment form in database. As an Instructor, after saving the new assignment, redirect to edit page to update Signup topics. As an instructor, save should not reload the page while creating a new assignment. Test when instructor creates a empty template for assignment form. Test when name of the assignment is not unique. Test when late policy is not created for instructor, and instructor tries to create a new assignment. As an instructor, delete an assignment.","When you say ""metrics"", you mean ""settings"",  The prose is rather difficult to read, perhaps because it does not provide enough context.  The ""code changes"" section should be matched up with the rationale for the changes, perhaps by linking back to previous sections.  This should be a single narrative, rather than a set of independent descriptions of changes, so everything should be linked together in the prose."
E1769,"Expertiza is a web application where students can submit and peer-review learning objects (articles, codes, websites, etc). Instructors add and edit assignments to Expertiza. Students can be assigned in teams based on their selection of the topics. The task of the project is to refactor assignment_form.rb and write unit tests for it. assignment_form.rb is a fairly complex file. It contains a lot of methods that are long and hard to understand. These methods need to be broken down into simpler and more specific methods that are easier to read/understand. Also, the few instances of code duplication that exist should be removed. 1. Refactor `add_to_delayed_queue` method 2. Rename method `is_calibrated` to `calibrated?` and all other places it is used 3. Use `find_by` instead of `where.first` 4. Complete pending tests in sign_up_sheet_controller.rb. 1. Refactor the assignment.rb 2. Refactor the assignment_form.rb 3. Complete relating tests in assignment_form_rspec.rb and assignment.rb 4. Complete tests in sign_up_sheet_controller_rspec.rb. `add_to_delayed_queue` is a long method with some duplicate codes and hard to understand. In order to encourage code reuse and make it easier to understand semantics of the function, we split it into three methods, name the added two as `get_diff_from_now` and `add_delayed_job`. The changes are displayed below, Original Code: <code> Modified Code: <code> <code> <code>. In Ruby, the common naming pattern for a method which return a boolean value is an adjective followed by '?', so the method name 'is_calibrated?' is bad and a preferable one should be directly 'calibrated?'. We refactorer this method by using 'Refactor' operation in RubyMine. We renamed it to 'calibrated?' and RubyMine found all place it appeared then changed them. Before: <code> After: <code>. If we use 'where' and then use 'first' method to return the first record matches the condition, the application will find all eligable records and return the first one. However, 'find_by' method will return a record once it find one and then terminate itself. Therefore, conpared with 'where.first' method, 'find_by' is much more efficient. That's why we use 'find_by' instead of 'where.first'. Before: <code> After: <code>. We write rspec test for relating methods in assignment_form_spec.rb. We test `add_to_delayed_queue` method <code> <code> Next we test `change_item_type` method <code> We also add test for `calibrated?` methods. <code> <code> We also completed remaining tests in `sign_up_sheet_controller_spec.rb`. There are a lot of methods in `sign_up_sheet_controller.rb`, and it can be executed by 'rspec spec/controllers/sign_up_sheet_controllers_spec.rb' <code>. Youtube: <link>.","The motivation for the refactorings is described well.  There is a good beginning at describing the refactorings themselves, but I think it would have been helpful to describe the changes in more detail.  The tests, on the other hand, are not described in prose.  The reader is asked to read the code, which is harder to do."
E2105,"Currently in Expertiza, students complete peer review questionnaires during the many rounds of an assignment. The instructor can view these reviews on the ""Review Reports"" screen. Once the page has loaded, clicking the ""View"" button while ""Review Reports"" is selected in the dropdown will open the reports. This project was created to give the instructors more information about how students complete reviews, specifically the time they spend on a review. This ""review time"" metric should be broken down by each link in a submission. With the general functionality outline by previous groups, our team was asked to: 1. Design a database schema for logging time a reviewer spends on a submission 2. Modify the Review Report to show the time spent on each submission 3. Add tests for the code written. When the reviewer navigates to a page from the expertiza review page a submission_viewing_event is created for that url and a start time is saved. Once the reviewer closes this page an end time is saved in that same submission_viewing_event, a total time is calculated and this is saved to local storage using pstore. As the reviewer navigates to different links from the review page, submission_viewing_events are created for each link accessed and these accumulate a total time spent with the link open. Once the reviewer saves or submits their review, these events are saved to the database from local storage, and deleted from local storage. If the user is returning to finish a saved review, these rows are pulled from the database, added to as stated above, and saved to local storage again until saved or submitted. When the instructor goes to view the ""Review Report"", each row from that students review is pulled for display as seen here: <image> The pop-up shows: 1. Percentage of total review for each link in a pie chart 2. The time the reviewer spent on each link 3. The total time spent on the review 4. The average times spent on each link for this submission by all reviewers 5. The average time spent reviewing this submission by all reviewers 6. Class statistics including: 1.1. Average review time for all submissions 1.2. Median review time 1.3. Standard deviation for review times. Our Pull Request can be found <link>. Our list of tasks included: 1. Review and understand previous teams code 2. Refactor and comment usable code from previous groups (Added after reviewing previous code) 3. Create new UI for viewing data 4. Improve current database schema to hold the total time spent on a review 5. Add tests. Upon reviewing all the previous groups code, it seemed that E2080 (our previous group) had the best starting point for our project having improved their previous groups code. They had a way of tracking the time spent on a review, storing it in a local file, saving this file to the database, and displaying the data. 1. Most of the client side javascript is now located in <link> and <link> 2. Functionality like calculating time between entries is now done in <link> using functions from <link> to assist with any math. We did this using simple javascript calls in <link> to get the relevant information using the controller and moved much of the formatting to <link> . The schema as it stands only recorded start time and end time for accessing a link. New Submission_Viewing_Event Database Schema: <image>. Select this to get to the review page. 5. Select the available submission and begin the review 6. Now you should be taken tot he questionnaire for that assignment. Conduct the review however you like. 1.1. Note: You must open the teams submitted links and files from the review page for it to be timed 1.2. Note: If you have a link open, you will not be able to open it again 7. Once complete, submit the review 8. You can now ""Revert"" back to your instructor account using the button in the Expertiza site heading 9. Navigate to the ""Review Report"" page as outlined in the Background section of this site 10. Find the student account you used and there will be an R1 or R2 next to your review. Click on these to see the breakdown of your review times for that respective round. Rspec file: <link> <code>. Rspec file: <link> <code>. Rspec file: <link> <code>. Added Files or Changes: 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. <link> 9. <link> 10. <link> 11. <link> 12. <link> Refactored Changes: 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. <link> 9. <link> 10. <link> 11. <link> Untouched Changes by Previous Teams: 1. <link> 2. <link> 3. <link> 4. <link>.","This page is very good, except that it does not show any of the changes to the code or explain them.  The high-level description is good, but the reader should be provided some insight into how the code was changed."
E1401,"Assignments in Expertiza have many components--due dates and topics, for example. Due dates and topics are objects in their own right (DueDate, SignupTopic); we need a way to have sets of due dates and topics associated with an assignment. There are also separate forms to create and edit an Assignment and its components (Topics, Due Dates), these forms should be unified into one form for every component of an Assignment. Also, it'd be nice if we could sort assignment due dates in order of next due. 1. Remove the separate New and Edit forms for assignment 2. Create a form object to encapsulate the creation and editing of Assignments, Due Dates, and Topics 3. Add the ability to sort Due Dates. 1. All CUD (Create, Update, Delete) operations on Assignments, Due Dates, and Topics should be performed through an AssignmentFormObject 2. Assignment, Due Date, and Topic views and controllers should be subsumed into a combined AssignmentFormObject view and controller. As a bit of background, form objects<ref> <link> </ref> could be thought of as a fake model that is not itself persisted but persists all its component models. The name comes from the idea that in many cases forms require information for several models at a time, rather than just one. Creating a series of forms to work with each model at a time is tedious and frustrating, both for the coder and for the end user. A form object fixes this problem by acting like a model. It can have validations, persistence strategies, and a save method that returns the object if and when it is saved, just like a model. Our design uses one form object, AssignmentFormObject, to store data about the base Assignment model, Due Date, and Topic models associated to that Assignment. In this way we can achieve both objectives, utilizing the form object to create, update, and delete Assignments and associated Due Date and Topics without having to have separate controllers and views for each. The form object inherits from ActiveRecord (though is not a subclass of) in order to be able to mass-assign attributes and create custom validations and Virtus<ref> <link> </ref> to handle attributes like a normal model. We need these custom validations because the attributes of the form object include arrays of attributes for models, something the default validations cannot handle on their own. In addition, we need to run validations on the parameters passed in for each of the models contained within the form object, again something that the default validations cannot do. The logic behind persisting a form object is somewhat more complicated than a normal model (in which you very rarely have to override the default save operation). This is because form objects must persist several models at once, as shown below. <code> The form object starts a transaction (in order to guarantee that either everything or nothing is saved) then attempts to create (or update) the Assignment. If this succeeds, it moves on to the components of the Assignment, doing the same. If any one of these operations fails (for instance, if a topic is not able to be saved), the entire operation is rolled back, removing all of the partially saved changes and reverting to before the form object attempted to persist. In this way we make sure that the save operation is atomic like a normal model's save operation. Because the form object can be treated like a model, writing a controller to populate views with it is just as easy as with a normal model, as shown. <code>. Basically, we have added the ability to add most of the same attributes to a new assignment as when editing an existing assignment. Previously, you could only provide an assignment name, then you had to add due dates, etc. There are still some limitations to this process due to the complicated relationships between models. The addition of Rubrics and Review Strategies is currently not implemented for new assignments, and this should be addressed in future works. In addition, you may only add one topic to a new assignment, then you must add more topics at the edit page. The addition of due dates uses a partial view that is in need of refactoring. In addition some validation is necessary for date times. For submission due dates and review due dates, please provide a date time. With the use of a form object there are side benefits that we can take advantage of with more effort that we just didn't have time for. 1. Ability to add multiple sign up topics from a new form 2. Ability to add rubric details from a new form 3. Redo the due dates partial to be more readable and use rails conventions rather than JavaScript 4. Redo the due dates partial in general, it is very messy and difficult to work with 5. Relocate JavaScript scripts to another.js resource file rather than in-line in the html 6. Eliminate the need to have multiple calls to the same controller methods for every table entry for due dates on the edit pages.","Very intuitive description of what was done.  Howeer, they don't indicate what changes were made to existing code, and don't show what functionality ended up in which classes."
E1928,"A similar review bidding feature was implemented in the previous semester, by making use of the Top Trading Cycles (TTC) algorithm. Solution: We implmented the color coding feature in our bidding list and the selection list. 1. There is only one list while topic bidding interface has two lists, one for the the available list of topics and the other list for topics that are selected for the bidding. Solution: We have implemented the two lists as seen below: <code> <image> <image> 1. There was no ""add link to submission"" in the bidding list. Students currently are able to ""bid"" for topics that they want to do as an assignment. We plan to implement the same bidding feature for reviewing others' work, which is currently assigned on a ""first-come-first-serve"" basis. By letting the students bid on topics they're interested in, the reviews are assigned more efficiently based on user interest. It should be noted here that this is an implementation of the bidding feature for assignment topics. <image> 1. When an assignment is released, an instance of Assignment is created and corresponding topic instances of SignUpTopics are also imported, indicating that different topics are available for students to choose from within this assignment. 2. Students are assigned as instances of AssignmentParticipant to this assignment and form up their teams (Model Team). After topics bidding, some of the candidate teams become an official signed-up team of a particular topic. 4. After assignment submission, participants choose their preferred topics and response mappings between assignment (reviewed object), assignment team (reviewee) and assignment participant (reviewer) are created. <image>. Currently, Expertiza employs FIFO strategy on review assignment. When it's done, a new mapping is created, that is why review assignment is in FIFO style. To understand the basic workflow of bidding on topics, we can look at the LotteryController: Firstly, teams have different preferences towards available topics. For example, let's say there are three topics within an assignment, namely A, B and C and there are 4 teams W, X, Y, Z. The peerlogic service runs top_trading_cycles algorithm to let the teams have a fair bidding over the topics. Now, consider a similar bidding approach to peer review assignment. The following diagram illustrates the similarity of the two bidding model. <image> As for topics bidding, a few available slots of a particular topic are open for teams contending. 2. The size of bidding data is different, since the number of teams are usually 1/2, 1/3 or 1/4 of the participants. 3. The policy of bidding may be slightly different. Participants are not allowed to review a response submitted by themselves. However, the topic bidding doesn't have this constraint. Each student has a priority list. The algorithm terminates when all students are assigned a seat. As part of this assignment, we have to analyse the implementation of the stable marriage problem which is a stable sorting algorithm. Based on this approach, in the existing implementation of Expertiza, we have match_new_teams_to_topics method in the lottery_controller that performs this stable sorting algorithm for teams that have bid for an assignment. Our objective would be to implement a similar strategy, but we would use students instead of teams since there are no ""team reviews"". Every student selects their own assignment to review. Almost all of the functionality for our project has already been implemented in the review portion of the Expertiza system - where the teams are allowed to bid on topics they want to work for their project. We plan to reuse the code to keep the implementation DRY but we need to add some additional features to make it work for the review bidding functionality. <image>. The bidding interface for reviews is followed from <link> implementation for topic bidding. We need to modify the code to implement the heat-map showing us the demand density for each project to be reviewed, the list of all available topics to review and the list of topics selected already. Color Coding Scheme: The color coding scheme would range from Red for the most in-demand topics to green for the least contested topics. After we allow the student users to bid for their topic of interest we need to provide access to instructors to start the bidding algorithm. To maintain the original functionality of Expertiza as well as to add review bidding, a new model to handle bidding data called ReviewBid is created. ReviewBid contains bidding assignment information, its biddable topics as well as the participants' preference. ReviewBid is served as the input of the bidding algorithm. We decided to let participants bid on assignment teams rather than topics for simplicity. Allow Instructor to set review strategy to bidding : <image> After setting the review strategy to bidding , participants are assigned a default bidding list, ordered by topic's name. <image> Instructors can start bidding by clicking the following icon. <image> After the bidding is done, participants can login and see what they are assigned with. <image>.","For design doc: You did quite a good job describing how your tests work; unfortunately you did not do the same for the code.  The ""Decisions"" section does that to some extent, but it would be more useful if it structured in terms of what code files were changed.  Simply listing the files to be changed is not very helpful; it asks the reader to figure out for himself (her) what has been done."
E1982,"1. When a rubric is replaced or the items/questions attached to it are changed, all the active students’ responses object to that rubric will be deleted are created again, that means students need to redo the reviews if they have already done. 2. The system will email the students who have done reviews to notify a redo request after deleting the response object and all associated answer objects. 3. The “active” in the first goal means the replacement action happened during the task duration and the student responses have done in the task duration before the replacing rubric action. An instructor replaces the rubric on Sep.12th, when 60 of 100 students have already finished their reviews. Then the response objects will be deleted and re-created to be new objects in the system, and students need to redo their reviews based on the new rubric. If the instructor does edit or change a rubric of the assignment while an assignment is in review progress, it will make previous review record make no sense. So it is supposed to delete previous response and notify all those students who have submitted review before to re-submit a response of new rubric. The function classification change as two kinds: Minor change & Major change. 1. Minor Change defined as the change makes no difference to reviewings so that we could also use reviewing before change made.(e.g. 2. Major Change include situation as below: 1.1. add a new question which not mentioned before, which make previous response lack of sone answer. 1.2. Any question is edited to a different question, which make previous response make no sense. 1.3. rubric is replaced by a different rubric, so everyone should re-submit a response on new rubric. Since Minor Change still could be used to scoring so that we could also use reviewing before change made.(e.g. And major change has some questions cant be found in previous rubric, system would delete all related reviewing records and email those reviewers to redone reviewing in such situations. 1. In Practice, after rubric is replaced or rubric is edited, doing such process: 1.1. give a confirmation to client to verify change 1.2. make sure it is a rubric of assignment which in reviewing period 1.3. sending e-mail to who has already submit review 1.4. deleting previous responses of such rubric 1.5. update the rubric formal in database. <image>. <image> The main goal of the code is to edit the rubric. We classify these actions into two types: major change and minor change. You have to delete the old question and add a new one. Minor change: Edit questions. Major change: Add/Delete questions. In this case, we have to check if there are any reviews done by students in the active period, i.e. the period of time when students can submit reviews. If there are any, we have to notify the affected students by email asking them to re-submit a review using the updated rubric, and delete their old reviews. Major or minor? 2. Check if the change to the rubric is made during the task duration (or if there is any active response?). 3. Process updates when a major change is made. After a change is made, the system will check if the date is during the task duration to determine whether it needs to update existing response objects. If the change is not during an active task duration, then nothing further needs to be done. If the change is during an active task duration, then the system will do the following work. Changes are categorized to be major or minor. Minor changes affects only the wording of a particular rubric item. Major changes involves rubric replacing and changing items/questions. To tell a major change, the params passed to the controller includes a tag/identifier that indicates if a new question was added, hence a major change. If the previous process returns that a major change has been made, the system deletes existing response objects and re-creates new updated object in database when a student press on “review”. As for minor changes, updates affects only the objects that created after the change. Once controller notice instructor makes a major change of the rubric, and some students have begun the peer review, email notification module is initiated. When students receive the email and update their review, the questions now correspond to the new rubric. <image> <image>. <image> <image> The answer_helper.rb helps questionnaire controller check period conditions, send email to the according reviewers, and delete existing responses. When the current time is not in the review active time period, this method returns false. When the current time is in the review active time period, the in_active_period returns true. <image> Deleting a question from a questionnaire is now considered a major change, so we added active period condition check in question_controller.rb. <image>.","Good description of the project, except ... it is not clear how you tell whether the wording of a question has been modified, or the question has been replaced by another question.  I also don't understand what ""task duration"" is.  Is that the same as the active period?  Description of what the code does is good."
E1576,"It handles the display, submission, deletion of hyperlinks and files by the teams. The submitted hyperlinks and files are stored in participants table, which means they are associated with individuals instead of team. Currently, when a team member wants to see all the submitted hyperlinks of his team, Expertiza needs to load all the submitted hyperlinks from each participant in this team and merge them all before display. Similar overhead happens when a team member wants to delete a submitted hyperlink. Also, the directory_num field needs to be moved from the participants table to the teams table. It signifies the sub-directory which stores all the files submitted by this team. 1. Create a new column hyperlinks in the teams table. 2. Write db migration, move all the participants’ submitted hyperlinks from participants table into teams table. 3. Write db migration, remove the hyperlinks field from participants table. If so, instead, it should just check the directory_num from teams table. 10. Write test cases to test student-submitted hyperlinks and files. This project can be divided into four major work items: 1. Moving the hyperlinks field from the participants table to the teams table. 2. Moving the directory_num field from the participants table to the teams table. It just needs to check directory_num from the team table. 4. Write test cases to verify student-submitted hyperlinks and files. Since there is no existing correlation between teams and submitted content, we will first need to look up the participants in the team using the teams_users table. Instead, if the hyperlinks data were available in teams table, we could directly access all the submitted content for a team in one shot, making it much more streamlined. Finally, the refactoring needs to be thoroughly tested by writing test cases for student-submitted hyperlinks and files by making sure that: 1. the submitted hyperlinks and files are correctly displayed on the submitted content page. 2. the reviewer can see the submitted content from the reviewees. 3. the instructor can see the submitted content from the reviewees. Use Case 1: Submit hyperlink for an assignment by student. Description: A student who is an assignment participant should be able to submit hyperlink on the “Your work” section of an assignment. Postconditions: The submitted hyperlink should be stored in the teams table of the database. 2. All other team members should be able to view the submitted hyperlink. 3. A reviewer should be able to see the submitted hyperlink. 4. An instructor should be able to see the submitted hyperlink. Use Case 2: Submit file for an assignment by student. Postconditions: The directory_num field which stores the directory number of the directory storing all the submitted files for a team should be stored in the teams table of the database. 2. All other team members should be able to view the submitted file. 3. A reviewer should be able to see the submitted file. 4. An instructor should be able to see the submitted file. Use Case 3: Delete hyperlink for an assignment by student. Description: A student who is an assignment participant should be able to delete submitted hyperlink on the “Your work” section of an assignment. Postconditions: The deleted hyperlink should be removed from the teams table in DB. 2. All other team members should not see the deleted hyperlink. 3. A reviewer should not be able to see the deleted hyperlink. 4. An instructor should not be able to see the deleted hyperlink. 6. Rewriting the corresponding views to read directory_num from the teams table instead of the participants table. 9. Our test suite included the following tests: 1.1. Testing submission of a hyperlink by one student - Check the count of submmited hyperlinks, verify that the hyperlink is stored properly in the database and displayed correctly from the UI. 1.2. Testing submission of two hyperlinks by two students in a team - Check the count of submmited hyperlinks, verify that the hyperlink is stored properly in the database and displayed correctly from the UI. 1.3. Testing submission of the same hyperlink by two students in a team - Check that the duplicate hyperlinks does not get stored. 1.4. Testing deletion of a hyperlink - Check the count of submmited hyperlinks and the updated list is displayed correctly from the UI. 1.5. Testing submission of one file by one student - Check the submission of a file and check the updated count of submitted files. 1.6. Testing deletion of one file by one student - Check the deletion of a submitted file and check the updated count of submitted files. 1.7. Testing submission of multiple files by multiple students - Check the submission of multiple files and check the updated count of submitted files. 1.8. Testing deletion of multiple files by multiple students - Check the deletion of multiple submitted files and check the updated count of submitted files.",They didn't fix the db like we told them to; otherwise they'd have gotten 95 or so.
E1858,"Expertiza provides Teammate Reviews under View Scores functionality for each assignment. Purpose of this project is to augment existing assignment submissions with data that can give a more realistic view of the work contribution of every team member using external tools like GitHub. This external data may include: number of commits, number of lines of code modified, number of lines added, number of lines deleted from each group’s submitted repository link from GitHub. 1. Teammate Reviews functionality in the View Scores page gauges teammate views on how much other team members contributed to the project. New metrics will be appended under each student data under the same functionality. 2. Github Metrics under View Submissions page should include a bar chart that shows number of commits by the team throughout the assignment timeline. <image> Previously, view submission does not show work contribution per teammate. Actors: 1. Instructor: This actor is responsible for viewing GitHub metrics of teams and team members of an assignment. Pre-Conditions: 1. The Team should have submitted the assignment with a PR link or GitHub repository. These are what the solution supports: 1.1. Number of commits per user and total per team. 1.2. Lines of Code added 1.3. Lines of code deleted. So we end up hitting GitHub API anyway. 1. With respect to showing GitHub metrics in the View scores page, it would have been very difficult to map Expertiza users and their names to public GitHub profiles as students may use a different name. So instead of appending GitHub data to Teammate reviews table, we will be showing a new table below it to display the metrics. This will allow the instructor full view of how teammate rated each other and how that maps to factual information from GitHub. 1. The Github metrics that need to be integrated with Expertiza were finalized as below. 1.2. Lines of Code added 1.3. Lines of code deleted. 1.4. Pull Request Status ( includes code climate and Travis CI Build status) 1.5. User Github metrics: 1.1.1. Committer ID 1.1.2. Committer Name 1.1.3. Committer email ID 1. A new link ""Github Metrics"" is provided under “View Submissions” for an assignment in the instructor view.This link opens a new tab and shows a stacked bar chart for number of commits per user vs submission timeline from assignment creation date to the deadline. 2. In ""View Scores"" for an assignment in the instructor view, under Teammate Reviews tab, a new table for Github Metrics is added, which shows following Github metrics per user: Student Name/ID, Email ID, lines of code added, lines of code deleted, number of commits 1. For GitHub integration, we have used GitHub GraphQL API v4. We have used github-omniauth gem for authentication/authorization purposes. 1. We also show the status of check runs in the View Github metrics view to help instructors view the status of various tools on the repos/PRs without having to go to the actual GitHub page. 1. A new table ""Github Metrics"" is added under Manage-> Assignments -> View Scores -> Teammate Reviews. <image> The GitHub metrics table shows results for each team member. 1. The second change is in the View Submissions page, where we have added a link ""Github Metrics"" to a new page. <image> At present, view submission shows group assignments are submitted as a single submission and 'view github metric' link shows work contribution per teammate. 1. The new page appears after clicking on the link ""Github metrics"", that shows bar chart for # of commits per day. We have also added other relevant information about Pull Request, such as total commits, lines of code added, lines of code modified, PR merge status, check status. <image> The bar chart <image> The Github summary. 1. Added below new functions to implement Github Integration in View Submission page <code>. Change 1: GitHub metrics in teammate reviews 1) Log in as an instructor (instructor6/password) 2) Navigate to assignments through Manage --> Assignments 3) Select ""View scores"" icon for the assignment of your choice 4) Select the team for which you wish to view scores 5) Go to ""Teammate Reviews"" tab 6) View data per team member based on different GitHub metrics (e.g. Change 2: Bar chart for # of commits changed by the overall team 1) Log in as an instructor (instructor6/password) 2) Navigate to assignments through Manage --> Assignments 3) Select ""View submissions"" icon for the assignment of your choice 4) Click on the ""Github metrics"" link for the team whose metrics you wish to view 5) A new page opens and shows # of commits changed per team member since the start of the assignment, also bottom of the page shows summary from Github submissions.","The document contains quite a good discussion of the problem to be solved and the tradeoffs made in solving it.  It shows the visualizations that were implemented.  The weak part is that the code is simply pasted in with no explanation.  No one is going to read the code in this format.  They will look at it on Github.  It would have been much better just to include a link to a diff in Github.  Also, the code shown has a complete lack of comments, which is unconscionable."
E1985,"3. Thirdly, we implemented an additional feature that allows the instructor/TA to add himself as a participant while creating/editing an Assignment (This way seemed to be more convenient rather than going to the “Add Participant” page and adding themselves as a participant.). Note 2: To be able to perform a review, the user has to be a participant of that assignment. 4. Finally, after the assignment deadline passes, the assignment goes into the “Finished” stage. Current scenario The instructor/TA will be able to perform student reviews (after implementation of Part 1) for the assignment, only when he is a participant of the same assignment. Thus, every time he creates an assignment and wants to add himself as a participant in order to perform student reviews, he is supposed to do the following Go to list of assignments -> Find the required assignment -> Click on add participant -> Type user Id -> Click on add The same flow is as shown below where the instructor/TA has created a new assignment say “Program 1 Github” wherein he wants himself as a participant to be able to perform student reviews : To overcome the hassle, we added a check box through which the instructor/TA will get an option to add himself as a participant while creating the assignment. Also, he will be able to add/remove himself as a participant while editing the assignment. It is added as follows: <image> If the instructor/TA selects the box while creating the assignment, then he will be added as a participant for the same assignment. Thus, instructor being a participant allows him to perform reviews for the students for this assignment. Also, while editing the assignment, he will be able to add/remove himself as a participant for this assignment. returns true if the instructor is already a participant for the assignment, else returns false. This method is required to verify that the instructor/TA is not a participant of the assignment, and thus he can be added as a participant if the checkbox has been selected. Also, during editing the assignment, we need to show checkbox being selected if the instructor is a participant and vice versa. It checks if the ""Add yourself as participant"" checkbox is selected for the currently created/edited assignment. If it is selected during creation or editing, then the instructor is added as a participant to the currently created/edited assignment. <code> The method ""delete_instructor_as_participant"" removes instructor as a participant for the assignment when the checkbox is unchecked during the editing of the assignment. “Add participants” <image> c. “View Submissions” <image> 4. Now add the instructor as a participant (3.b). again. Edge Cases: 1. If the user is not a participant of the current assignment, they are shown a list of all submissions made by all teams of the current assignment. Here the assignment chosen is Final project (and design doc). <image> Part 3: Add instructor/TA as a participant while creating the assignment UI Testing 5.1. Login in as an instructor. 5.1.1. Username: instructor6 5.1.2. Password: password 5.2. Go to Manage-> Assignments 5.3. Click on add assignment 5.4. Enter the required details- Assignment name, course etc 5.5. To add instructor/TA as a participant, go to Review Tab and select the ""Add yourself as a participant?"" checkbox. 5.6. Click on Save The assignment has been created and the instructor/TA is added as a participant to the assignment. Edge Cases : 5.1. If the instructor/TA does not select the ""Add yourself as a participant?"" checkbox while creating the assignment, then he is not added as a participant 5.2. If the instructor/TA selects the ""Add yourself as a participant?"" checkbox while editing the assignment, then he is added as a participant 5.3. If the instructor/TA unchecks the ""Add yourself as a participant?"" 1.1. Username: instructor6 1.2. Password: password 2. Go to Manage-> Assignments 3. Click on add assignment 4. Enter the required details- Assignment name, course etc 5. To add instructor/TA as a participant, go to Review Tab and select the ""Add yourself as a participant?"" checkbox. 6. Click on Save The assignment has been created and the instructor/TA is added as a participant to the assignment. Edge Cases : 1. If the instructor/TA does not select the ""Add yourself as a participant?"" checkbox while creating the assignment, then he is not added as a participant 2. If the instructor/TA selects the ""Add yourself as a participant?"" checkbox while editing the assignment, then he is added as a participant 3. If the instructor/TA unchecks the ""Add yourself as a participant?"" checkbox while editing the assignment, then he is removed as a participant Rspec Testing : <code>.","On the code you displayed, yes, it does contain comments that the reader could peruse to understand the code.  But the reader could gain the same info just by reading the code from the repo.  What would be useful is prose explaining what changes were made and why.  Just like you did later in Part 3.  But then when you wrote about automated tests, you just pasted in the code again."
E1571,"This project in particular intends that the students collaborate with each other and work on making enhancements to the code base by applying the concepts of Rails,RSpec, DRY code,Test driven development etc. Currently, the Assignment controller holds methods which are deprecated and also has a few lines code in its Edit and Update methods which could be removed to make the code DRY. In addition to that, it houses a few actions where the code could be refactored to make it DRY and follow the Ruby style guide and Rails 4 syntax. 1. Refactor edit and update method 2. Remove irrelevant comments from the create action. 4. Change to new redirect method rather using controller and action explicitly. using the DRY principle 6. Refactor code to follow ruby style guide and Rails4 syntax. Edit function contains many manipulations that need be refactored into separate functions. <code> This part of the code is moved into a separate function. <code> There are lots of redundant code in the following snippet.And, constants are hard coded inside the code rather than defining constants. <code> Redundant code is removed and made it more efficient and understandable. <code> <code> Hard coded constants are removed and necessary constants are defined in the deadline_helper.rb helper file. <code> <code> <code> <code> The following snippet constructs a string that need to be shown to the user when rubrics are not set by the instructor. <code> Adding code such as above directly into the controller action made the edit function bulkier. The above snippet is also refactored into a separate function. <code> Refactoring out into separate functions makes the code more readable and understandable. Update function of the Assignment controller helps in updating the resources after editing it. The following code retrieves the data of the user logged in. Explicit URL creation using controller name and controller action is refactored in such a way that helper functions create the URL when required. <code>. The Create action has a few comments which are irrelevant and make the method bulky. These could be safely removed from the code. The action logic could be moved to Model by passing the current user object to the corresponding method we create in the Model. The method in the model would then return a list of courses which would be used in the View corresponding to this action. Inside controller action, <code> Inside model, <code>. There is a need to create a method in the Model with the same name and then pass an assignment object. All operations can be performed inside this method and then the user can be redirected back to the assignment list page. Inside controller action, <code> Inside model, <code>. According to Ruby style guidelines explicit use of action and controller in redirect calls should be avoided. This helps in easy refactoring in case action names are changed in future. All the redirect calls in assignment controller have been modified to use url path helpers. In controller assignment and action toggle_access, redirect call has been changes as follows <code>. There exist variables which are declared and initialized but are not used in any part of the code. Such variables could be safely removed without impacting the functionality of the action. The same piece of code is used at various points of code making it redundant and hence can be converted to a method. There exist dead code which tries to remove due_dates not in update or new list from database. There can never be such a case, so the code can be safely removed. 3. Removal of existing code does not lead to reduced/loss of functionality. <code>. It allows user to record edit and debug test cases. Major test cases identified are following 1. Loading assignments 2. Creating assignments 3. Editing assignments 4. Updating due dates for assignments 5. Associating assignments to a course 6. Deleting assignments The test cases were manually run and recorded once. Then the test cases were re run with changed parameters on the deployed version of the application. Test scripts can be found <link> . Follow the instructions below to test the application using selenium IDE 1. Install Selenium IDE plugin for Firefox. 3. Download the test scripts from <link> 4. Open the test script from Selenium IDE. File -> open -> select test script html file 5. Set the testing speed to slow on the speed slidebar, otherwise test may fail due to slow page response 6. Run the script from Selenium IDE using 'Play current test case' icon. To add a new assignment or topic and to remove an assignment or topic, we need to change the script every time to avoid duplicate record IDs. When we run the same script more than once, the test case will fail. Thus, we haven't provided test case for those scenarios. 1. There exists lot of redundant code which code be refactored into methods. 2. Unused variables and deprecated methods could be ridden off from the code base. 3. The test cases are written only for the methods that came under the scope of this project. But there is room for implementing test cases for the other actions too.",Very well written!  Only weakness is that it could have identified the changed code more explicitly.
E1524,"It is the advanced planning of these deadlines that makes them ""staggered deadlines"" rather than extensions<ref> <link> </ref>. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.4. <link> 1.5. <link> 1.6. <link> 1.7. <link> 1.8. <link> 1.9. <link> 1.10. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.11. <link> 1.12. <link>. Controller 1. <link> 2. <link> Model 1. <link> 2. <link> View 1. <link> 2. <link> 3. <link>. This raises the idea of a staggered-deadline assignment , where different topics have different submission and review deadlines, rather than all topics having the same deadline. And with staggered-deadline assignment, we can distribute less time on them. 1. In production version, instructor can set Submission deadline , Review deadline and Metareview deadline for each topic. <image> Set different deadline for each topic 1. Also, instructor can set the dependencies of different topics. <image> Dependency graph for all topics. 1.1.2. Instructor creates a new staggered-deadline assignment. 1.1.2. Hand in assignment. 1.1.3. Peer review. 1.1.2. Work on assignment. 1.1.3. Peer review. 1. First, login expertiza, in the ""Manage Content"" page, create a new assignment. Then, as shown below, choose the ""pencil"" icon to edit the assignment. <image> Assignment panel 1 1. Check""Has topics?"" and ""Staggered deadline assignment?"" two checkbox, and create new topics in ""Topics"" panel, click ""save"". 1. After discussing with professor, the ""sign up sheet"" icon in assignment pop up panel should be moved. Because that icon has the same functionality as ""topic"" panel in assignment edit window. These work has already done by <link> . So we have to move all the staggered-deadline realted code to the <link> and <link> . The function is used to display a page that lists all the available topics for a staggered-deadline assignment. It only stores the deadline for a single assignment. [Professor] In a staggered-deadline assignment, there is one submission deadline and one review deadline per round. If the view currently works (and I think it might), as soon as you make an assignment a staggered-deadline assignment, the Signup Sheet (Topics) page will have a link at the bottom to show deadlines for each topic. 1. If staggered-deadline of one assignment is even later than the second-round review, is it means that that assignment do not need peer review and go directly into meta-review stage? [Professor] No, there are also separate meta-review deadlines for a staggered-deadline assignment. I think in the current implementation, only submission deadlines, review deadlines, and meta-review deadlines vary by topic. 1. When to set staggered-deadline assignments? Create assignment or Before submission? [Professor] Basically, the staggered-deadline is set at the same time when an assignment is created. [Professor] The dependencies of topics means one topic cannot start until another topic finishes. In edit signup sheet for assignment, we want to save topic dependency and show the depandency graph, as show below: <image> Assignment panel 1 In order to show the dependency graph, we must first save topics dependency and save the topic dependency graph under public/assets/staggered_deadline_assignment_graph path. <code> Then, after we click the Save dependency button, and click show dependency graph button, the dependency graph is shown below: <image> Assignment panel 2. Since we have done several modifications to the Expertiza program, some new tests are needed to test the features. 1. Test the staggered assignment <code> 1. Test the dependency graph. It is recommended to use <link> . 2. An <link> , slightly dated, showing how to create and deploy an assignment 3. A guide for <link> 4. For students, a <link> or <link> presentation explaining how to submit and review an assignment with Expertiza. 5. For students, a <link> showing how to use the system to submit and review an assignment. 6. For students, a <link> or <link> presentation explaining how to submit and review wiki pages with Expertiza. 7. For students, a <link> or <link> presentation explaining how to form teams and sign up for topics<ref> <link> </ref>.","They have a good collection of screenshots from the affected portions of Expertiza.  It shows that they have the old code mostly working. Explained the user flow in good detail. The description of staggered deadlines is wrong in the intro, though it has been corrected later in the doc. They mention calibration, but that's not part of their project. The design doc does not seem to be properly organized.
"
E2005,"3. ""View bookmarks"" link on student_task/view breaks if the student has not selected a topic yet. Get the bookmark questionnaire functioning and add to the bookmark list page. 6. Add a number next to/inside the icon with the number of current bookmark in order to make it clear whether a bookmark exists for a topic. 7. Add a ""View bookmarks"" link to the assignment view page for easier access. 10. Add URL to bookmark list for assignment topic on the assignment page, to make viewing bookmarks easier. 11. Instructors cannot currently see bookmarks (gets an error message saying instructors cannot create bookmarks). 12. ""Back"" button from Bookmarks list is broken. 16. Students can add/view bookmarks when ""Allow participants to create bookmarks?"" <image> Changed files: app/views/bookmarks/list.html.erb <code> Pull request can be found <link> Users cannot rate bookmarks they've uploaded. We wanted to make sure that users cannot rate bookmarks that they uploaded. Changed files: app/views/bookmarks/list.html.erb <code> Pull request can be found <link> Users cannot review bookmarks they've uploaded using the questionnaire. We also wanted to make sure that users cannot review bookmarks that they uploaded using the questionnaires. Changed files: app/views/bookmarks/list.html.erb <code> Pull request can be found <link> Users should be able to see the number of bookmarks from the topics list. Previously, users could add bookmarks, but could not tell how many bookmarks were provided for each topic (if any) without clicking the ""View bookmarks"" icon. This UI change displays the number of bookmarks for the topic inside the view bookmarks icon from the topic list view so that users don't need to click through each topic individually. <image> Changed files: app/views/sign_up_sheet/_actions.html.erb <code> Pull request can be found <link> UI changes to make finding your bookmarks easier: We added a ""View Bookmarks"" link to the student task view, that takes the student directly to the bookmarks that have been submitted for their topic. This code was then modified such that the link is greyed out if the student does not have a topic, and is hidden if bookmarks are not enabled for the assignment. Changed files: app/controllers/student_task_controller.rb <code> app/views/student_task/view.html.erb <code> Relevant commits can be found <link> <link> and <link> Grey out add/view bookmarks link on the topic page if bookmarks are not enabled. Previously, students could submit and view bookmarks even if bookmarks were disabled for the assignment. Bookmarks should be deletable by the user who created the bookmark, a teammate of the user who provided the bookmark, and the instructor. Instructors should have a way to view all the responses to the bookmark questionnaires so that can see which bookmarks provided were deemed useful. 7. Click 'Save bookmark rating questionnaire'. 2. Choose an assignment that will be used for testing and have bookmarks enabled and select the edit icon under Actions. 3. Under Topics Tab select 'Allow participants to create bookmarks?'. 4. Go to Rubrics tab, under 'Bookmark Rating' select the Bookmark review questionnaire that was previously created to use for reviewing the bookmarks. 1. Add a Bookmark to a Topic 1. Log in as a student who is a participant of the assignment with bookmarks enabled and select that assignment. 3. Choose a topic and select the 'Add bookmark to topic' icon from the Bookmarks column. The 'Add bookmark to topic' icon has a '+' sign. 5. You should now see a page listing all bookmarks for this topic. 1. Viewing all Bookmarks for a Topic 1. Log in as a student who is a participant of the assignment with bookmarks enabled (or an instructor) and select that assignment. 3. The number of bookmarks for each topic should be displayed visually inside the 'View topic bookmarks' icon in the bookmarks column. 4. Click the 'View topic bookmarks icon' to see a list of all bookmarks for this topic. 1. Editing and Destroying Bookmarks for a Topic 1. Perform this test with each of the following users: an instructor, a user who is assigned to the topic, and a teammate of the user who is assigned to the topic. 1.1. Log in with the user and select the assignment with bookmarks enabled. 1.3. Click the 'View topic bookmarks icon' to see a list of all bookmarks for this topic. 1.4. The user should see links to 'Edit Bookmark' and 'Destroy Bookmark' next to a bookmark only if the user is an instructor, the user submitted the bookmark, or the user is a teammate of the user who submitted the bookmark.","The document starts out with a list of 16 fixes that are needed, but the description of the changes is in a completely different order, and it's not clear how the ordering was devised. The changes are described with varying degrees of detail.  Some are explained well, while others have just a line or two saying what they do.  A DB diagram is shown, but its relation to the project is unclear.  There is a good manual test plan, but automated tests are not mentioned."
E1669,"Expertiza has been developed as an Open Source Software (OSS) on Ruby on Rails framework. Expertiza open source development program has fetched many contributions from faculties and students of different universities and thus, it incorporates a wide variety of Ruby coding styles, and this has been a reason why Expertiza project is kept as CSC/ECE 517 OSS project. The opportunity to work on an OSS project like Expertiza is also expected to provide student an introductory experience of understanding larger programs and making required contributions to them. The writing assignment along with programming assignment is expected to provide project documentation experience to students. The code works perfectly fine but lacks unit tests for its methods. The project requires contributors to write specification based unit tests. There are more than one ways to write unit tests in Ruby on Rails which includes writing test methods under test directory which requires writing fixtures and makes use of 'test_helper'. It is Rails' default way to prepare and use test data. The work around is creating factories which creates data for tests whenever it is needed to create. Factories generate data which is used to test the functionality of code. Factory Girl for rails is a gem for creating factories and it is also supported by open source development. For this project, factories were created using Factory Girl. One of the examples of factory girl being used in the project is shown in the following piece of code. <code> The above factory is a contribution through the project. Writing specifications is a way of behavior driven development approach to program which means that the specifications describes the behavior of the code. The specifications acts as tests and there are a number of tools, such as <link> and <link> with <link> , present to support this approach of development. For this project, RSpec was used and a part of reason for using RSpec is that it is included in the CSC/ECE517 coursework. Apart from the examples given above, a number of test cases were written as unit tests for classes which inherits from ResponseMap class, namely ReviewResponseMap, TeammateReviewResponseMap, FeedbackResponseMap, QuizResponseMap, BookmarkRatingResponseMap, MetareviewResponseMap and SelfReviewResponseMap. Though all the methods were not tested in the test cases but the basic methods like object creation, object id and their respective titles were tested to be as assigned in the instance. Example of test cases implemented for basic methods are shown below. <code> <code> <code> The first line of above code block is specifying the 'rails_helper' which is needed to write the specifications here. The test has been written for ReviewResponseMap class and 'reviewresponsemap', 'response' and 'participant' are instances of ReviewResponseMap, Response and Participant. The 'new' specification test block is just making sure that the created instances are of respective class types and is not a much required test. Apart from basic methods, some important methods were tested for classes which inherits more from ResponseMap as compared to other classes, example being ReviewResponseMap, FeedbackResponseMap and QuizResponseMap classes. Some examples are given below as pieces of code. <code> The above method is part of ReviewResponseMap and thus by Rails convention, the files containing above code is review_response_map_spec.rb. Similarly, for QuizResponseMap class, the sample of test is as below. <code> The above two methods are part of QuizResponseMap and thus by Rails convention, the files containing above code is quiz_response_map_spec.rb. All the test cases which have been implemented are working without an error, however, the tests hasn't been written for the some of the methods which call functions from inherited and related classes and the method chain calls a number of classes across the project which adds up to the complexity. For example, 'contributor' method from ReviewResponseMap class is a single line function but it calls method from ResponseMap which calls method from RevieResponseMap and then Participant and so on and it creates a complexity of creating instances of all these classes interlinking with each other with correct 'id'. The project is concluded with all the simple test cases and some complex test cases in the classes which are close to the ResponseMap hierarchy. After setting up expertiza, following RSpec commands can be used to invoke method testing. The project didn't make any changes in the development or production domain and only contributed to the testing domain. Also, RSpec tests are not tested with the running application in production or development, it's a part of testing which can be tested on console. So, no need of deployment was found for this project. All the methods have not been covered which leaves the scope of writing more tests to increase coverage on ResponseMap class and it's child classes. After getting enough coverage on ResponseMap and child classes, the closely related models like Participant and Assignment can be considered for unit testing. 1. <link> 2. <link> 3. <link> 4. <link>.","This is a pretty good description of the work that was done.  I would move the description of the code snippets to above the code snippets, but other than that, it seems quite adequate."
E1696,"Expertiza is an online system that is used by students to view/submit assignments and review others' work. 1. One can view the peer-reviews done only upon the completion of his/her self-review. 2. The final score of the self-review depends on the agreement of the self-review scores with peer-review scores. 3. While comparing the self-review scores with peer-review scores, more weight must be given to the instructor-score. 4. While considering the reviews done by others in the class, the average must be used. 6. Self-reviews are done individually and not as a team. 7. The self-review scores of each member of a team does not affect the self-review scores of the other members in the team. Student has the task of performing review of others' work as well as self review. Every team gets their review from peers and at present the composite score is the average of all the review scores that they have received. Added to this score, the self review score is also calculated for each team member, based on its closeness to the peer reviewed score. To implement this, the student needs to review his own work based on the same rubrics used for peer review and only after completion of the self review, their peer review scores will be visible. The composite score is calculated by the sum of the peer review average score and 100 minus the difference between self and peer review score. The self review score is displayed adjacent to the peer review score. As the composite score is based on the individual self reviews, they vary for each member of the team unlike the peer review score which is the same. In case of Self-Review, an Observer can be used to tell the system that the reviewer is now open to reviewing the works of his peers. <image> <image>. Here and everywhere else in this document, 'Raw Self-Review' score indicates the score assigned by the participants assessing one's own work. Self-Review score is a metric used to measure the extent of agreement between the Raw Self-Review score and the Average Peer-Review score. The highlighted portion of the screenshot below shows how the Self-Review score is obtained from the Raw Self-Review score. <image>. In accordance with the design paradigm of Expertiza, we developed a chart (or a circle) to represent the Self-Review Score (Again, remember that this is not the Raw Self-Review score. The Raw Self-Review score is of no use to the participants because it was, in fact, their opinion of the work done. The computed Self-Review score, on the other hand, is more useful as it depicts the level of agreement between the opinions of the participant and the reviewers.). We also ensured that the circle is colored similar to the other charts in the page (other than the final score chart, which was deliberately designed to be bright and unique). The following screenshot of a code snippet shows the creation of the circle for Self-Review score. Self-Review score cannot be a major part of the Final score. On the other hand, the Peer-Review scores must be the dominant component of Final score. After consulting with the Professor, we decided to give a 10% weightage to the Self-Review score and a 90% weightage to the Peer-Review score. The highlighted portion of the following screenshot shows the composition of the Final score. One sensible requirement of the project was to ensure every participant of an assignment evaluates one's own work before looking into the scores assigned by others. This is done to avoid an explicit or implicit comparison of the raw self-review score to the peer-review scores. By ensuring that every participant performs the self-review before looking into the scores assigned to his/her work, we also ensure that the raw self-review score is an honest indication of what the participant thinks about one's own work. 1. Juxtaposing Peer and Self-Review Scores - From the Assignment Home Page, click on 'Your Scores' to view both Average Peer-Review, Self-Review and Final Scores. 2. Combine Self and Peer-Reviews into a Composite Score - From the Assignment Home Page, click on 'Your Scores' to view the Composite Score assigned to you based on the closeness of your Self-Review score with the Average Peer-Review Score. 3. Complete Self-Review before checking Peer-Review Scores - From the Assignment Home Page, click on 'Others' Work' to try to submit Peer-Reviews for the projects submitted by others. However, this should be forbidden unless you have submitted a Self-Review of your project. 1. The words used in the self-reviews can be used to judge the seriousness of the reviews. 2. The changes in the scores of the self-reviews can be used to judge whether teams have worked to their own expectations. 3. In order to establish a common standard in the reviewing system, the absolute change in the review scores can be used to judge an individual.","Overall, it's a good doc. It contains all information about the project. However, the structure of doc could be improved. First state the requirements, your design approach, then the implementation. (instead of problems, implemetation, then the design). There are some small grammar error in the doc e.g., ""you will (be) shown"" ."
E2002,"<link> is an open-source project based on <link> framework. Expertiza is a complete instructor-student usage website where the instructor can assign assignments, deadlines, grades, etc that is required for the course. Similarly, the students can use this website to perform the tasks required as part of the course like project or assignments submission, forming groups and collaborating with them, as well as reviewing projects and teammates. This project focuses on a specific feature of expertiza which allows administrators, instructors or teaching assistants to impersonate another user (like a student) and access their account. The demonstration for the feature is as shown below. <image> figure 1 <image> figure 2 <image> figure 3. The aim of the project is to refactor the impersonate controller. The pre-existing code had the following major issues. 1. All functions related to impersonate controller were present in a single method ( from figure 4a and 4b) 2. Presence of repetitive code ( from figure 4a and 4b) 3. 3 levels of block nesting (from figure 5) 4. Too many return statements (from figure 6) <image> figure 4a <image> figure 4b <image> figure 5 <image> figure 6 This project is focused on resolving the issues mentioned above. Expertiza allows the administrators, instructors or teaching assistants to impersonate another user (like a student) and access their account. For example, an instructor impersonating a student’s account can view their assignments, stage deadlines, peer reviews and anything else that the student can view. One thing to be noted is that most of these users can only impersonate users for whom they are a parent. For example, instructor6 is a parent of student3841 and not student3836; as a result, instructor6 can impersonate only 3841. 1. Instructor login: username -> instructor6, password -> password when logged in as an instructor, under the manage option in the ribbon as in Figure 1, select impersonate user. Upon redirected to impersonate page, enter the account which needs to be impersonated. It impersonates that user provided that user can be impersonated. Now a new button called revert appears on the ribbon as in figure 3, this can be used to revert the impersonation and return to the instructor profile. The above-mentioned issues have been tackled by refactoring the impersonate controller by splitting into many smaller methods which are later called by the main impersonate controller. The following are the refactored new methods that help in tackling the issue1 apart from each being specifically for some issue rectification: 1. check_if_user_impersonateable 2. display_error_msg 3. overwrite_session 4. check_if_special_char 5. do_main_operartion. This method plays the main role in tackling issue3 - 3 levels of block nesting apart from issue1. Intial Code <code> After recfactoring - Moved to separate method <code>. This method is used to tackle issues1, 2 and 4. All the error message related code is moved to this method. <code>. This method reduces the number of return statements used in impersonate controller, apart from reducing the size of the controller. <code>. <code>. This code is used to reduce one functionality performed under the impersonate controller. This method checks to see if the given username is acceptable. <code>. This like an adapter method that is used to interface the impersonate method with display_error_msg and check_if_user_impersonatable. One main purpose to do this is to make the methods flexible for change apart from reducing the number of lines from the impersonate controller. <code>. The project can be tested from the UI as follows. Checking if impersonating a user is working <code> <image> figure 7 <image> figure 8 <image> figure 9 <code> <image> figure 10 <image> figure 11 <code> <image> figure 12 <image> figure 13 <code> <image> figure 14 <image> figure 15.","Issues are specified clearly and the changes that they made to tackle each issue is also very clear. The changes made in the code are correctly reflected in the document. But I think that the changes could have been described in more detail.  Instead of a statement like, ""Moved to a separate method and accessed through the adapter method do_main_operation"", I would have liked to see an explanation of the three branches of if statements in the coe for this method.  And instead of ""This method checks to see if the given username is acceptable."", I would have liked to know HOW the method checks for acceptability.  They have also tested various scenarios and displayed the results on the Wiki page. However, an automated test plan is missing.  Some screenshots are a bit blurry."
E2057,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.1.1. <link> 1.1.1.1.2. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.1.1. <link> 1.1.1.1.2. <link> 1.1.5. <link>. You can review the deployed link here: 1. <link> Credentials for accessing the student who is also a TA are: 1. Username: student12 2. Password: testabcd. If a person is listed as a TA in one course and as a student in another course, then if they navigate to the ""Your scores"" page of one of the assignments in which they are participating as a student, they can see a TA's view of that page - effectively allowing them to assign their own grade! The below screenshot shows the TA view for the course he is added as the TA: <image> As evident from the screenshot, the user, ""student003"" is assigned as a TA for CSC502. The user, ""student003"" is also a student in the course, CSC501: <image> The issue here is that this user, ""student003"" who is a TA in one course is able to alter the grades for his assignments in other courses he is taking in the semester: <image>. Once TA clicks on Assignment > view scores, they will no longer be able to see the form to add/edit the grade and comment for the course in which they are participating as a student. Files modified: view_team.html We are rendering the TA view (to grade and comment) only if the TA ID has an entry in the ta_mapping table. This ensures that the TA will be able modify the grades for courses for which they are assigned as TA. 1. Get the course ID for the course which the student is currently viewing. 2. Get the user ID, which will be the teacher ID as well 3. Using these two fields we are restricting the access for the student to modify the grades. Only for the courses for which a user is a TA, he will be able to see 'TA Grade-Comment:' section under Assignment > view scores <image> The green-highlighted lines indicate the changes. Below is the screenshot which indicates the TA view for which the user is registered as a student: <image>. 1. view_team.html.erb <code> <code>. The test plan is set to have an automated testing to ensure that the application is still working after we added our code. We are using RSpec for automated testing and show you the steps we did to test the UI. In the subsections below you can view the code snippets added to ensure that the TA is not able to change their own grade. In order to ensure that the TA is blocked from changing his own grade for the courses he/she is a student, we made the grade assigning section hidden. The test case assumes the role of a TA who is also a student in one of the courses. The student is allowed to complete one of the assignments in the course and when the student views the ""View scores"" page, he is prevented from updating the grades for the assignment. 1. grades_controller_spec.rb <code>. A student can upload files with their submission. What’s wrong with it: As there is no restriction on the files being uploaded, this is a security issue in Expertiza. Large files should be restricted. A student may also upload malware into the system affecting expertiza. 1. Problem 1 : No file size restriction while uploading files. 2. Solution : <code> <code> 1. Problem 2 : No file type restriction while uploading files. The existing method get_file_type only checks the extension of the file name. It is easy for users to bypass the validation. <code> 1. Solution : We use MimeMagic to detect the mime type of a file by its content. <code> <code>. Since the existing tests didn't cover the type and size validation while submitting the files. Our plan was to write the validation tests to cover these cases using RSpec. In order to ensure the functionality of validation, we carefully developed our code and used MimeMagic to detect the MIME type of submission. It prevents someone from uploading a fake file. We modify the original tests and add the following tests to ensure the validation works. <code> <code>. 1. <link> 2. <link> 3. <link>.","The problem is described clearly, although it is really that the TA can both view and alter the grades for course(s) where (s)he has been a TA.  Not only alteration is a problem.  The ""code addition"" for view_team.html.erb should have prose describing what is done and why.  Most of the other changes and tests are better described."
E1691,"This a page to describe a final project for ECE517. In this project we will be converting Assignment creation form to ReactJS. It allows the instructor to create assignments as well as modify existing assignments. Students can signup for topics in an assignment and can submit articles, codes, web-sites etc. It is a web application built on Ruby on Rails framework. It also allows students to review the submissions that have been made other students. ReactJS is an open source JavaScript library, used to provide a view for data rendered as HTML.It is maintained by Facebook, Instagram and a community of individual developers and corporations. React was created by Jordan Walke, a software engineer at Facebook. He was influenced by XHP, an HTML component framework for PHP. This render function basically implements html divs . 3. React can be rendered on the server-side. 6. It can be used with any framework such as Backbone.js, Angular.js, as it is only a view layer. A client-side dynamic web page processes the web page using HTML scripting running in the browser as it loads. JavaScript and other scripting languages determine the way the HTML in the received page is parsed into the Document Object Model, or DOM, that represents the loaded web page. The same client-side techniques can then dynamically update or change the DOM in the same way. Shown below is an example of a dynamically rendered webpage. The user is able to enter values, which are reflected in the view immediately after submission, without any redirection or reloading of the webpage. You can also see the timer running on the page, which demonstrates the ability to dynamically update variable values inside the view. <image>. The assignment creation view is currently implemented mostly in HTML and some data validations are done using JQuery. This implementation does not support dynamic view rendering which is essential to improving the user interface and contributing to the fluidity of the overall experience. For example, If the user wants to create a new assignment, clicking the new assignment link will generate a server request and the new view is rendered (url is changed). After filling up all the details required for the assignment creation, save link will again generate a server request which will make the database entry and again render a new view. <image> <image>. In the revised implementation, clicking on the New Assignment link generates a drop-down window, which contains the form for creating a new assignment. This form contains the same fields as the original form. In addition, we have added data validations for two fields. The name of the assignment cannot be left blank, and the 'submission directory' field cannot be left blank or contain any special characters. Furthermore, these validations are done in the client-side itself, removing the need for a server request to validate the data. Submitting the form will create a database entry and close the form. <image>. 1. apps/assets/javascripts/tree_display.jsx.erb 2. apps/controllers/assignments_controller.rb 3. apps/controllers/tree_display_controller.rb. We created a new React class NewAssignmentForm which dynamically creates and displays the form for New assignment. This class the following methods: <code> <code> <code> <code> <code> In assignment_controller.rb we edited create method: <code> In tree_display_controller.rb we added new method: <code>. 1. Log in as an instructor and check that creating a new assignment works as expected 2. Log in as an instructor and check that the assignment could be created successfully and all the entered options have been preserved. Similar to New assignment creation page Edit page does not support dynamic view rendering which is essential to improving the user interface and contributing to the fluidity of the overall experience. For example, If the user wants to edit the name of the assignment or change number of slots they have to click edit button. It will generate a server request and the new view is rendered (url is changed). After filling out all the details that changed, save link will again generate a server request which will make the database entry and again render a new view. <image> <image> </br>. In the revised implementation, as the edit button is clicked a dynamic drop down form will be displayed. Saving the details will make the database entry. Except for the database update, all the processing is done on the client side itself, leading to a decrease in the number of server requests. <image>. 1. apps/views/tree_display/list.html.erb 2. apps/views/assignments/edit.html.erb 3. apps/views/assignments/edit/_general.html.erb. 1. Log in as an instructor and check that editing an assignment works as expected 2. Log in as an instructor and check that an assignment could be successfully edited and all the existing functionality is preserved. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.",A very good job of synopsizing the changes you planned to make.  Would be good to update to reflect the changes that were actually made.
E1471,"Contents 1.1. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.4. <link> 1.1.1. <link> 1.1.1.1. <link> 1.5. <link> 1.6. <link> 1.7. <link> 1.8. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.9. <link>. Our contribution in this project would be to improve the display of questionnaires for all the instructors and also integrating a previous project which provides a new dashboard for students to view and compare their performance of each assignment. 3. The current student dashboard provides the average score and range of the student’s assignment, review and final score. 4. The system has a limitation where in a student/instructor cannot view and compare the student scores based on the class performance. 2. A project from last year has the implementation for the new student dashboard. 3. This new dashboard gives the students a comparative statistics for that particular assignment for the entire class. 5. Other features were part of the project were to show the number of reviews and metareviews he/she has done for this assignment and also based on a threshold what are the number of reviews/metareviews the student still needs to do. 6. A histogram distribution of the scores of the class (all teams) for that assignment would also shown as a part of the dashboard. The features required for the dashboard for students project have already been implemented. The current code is able to display the maximum scores, average scores, number of reviews and distribution charts. Name : Students viewing scores for the assignment Actor : Student Other Participants : None Precondition : Statistics have been recorded for average high and low scores. Primary Sequence: 1. Log in to Expertiza 2. Select an assignment 3. Select Your Scores 4. Click on the link for view class scores for this assignment. 5. View the average, high and low class score for that particular assignment Name : Students viewing graphical output for scores for the assignment Actor : Student Other Participants : None Precondition : Statistics have been recorded for average high and low scores. Primary Sequence: 1. Log in to Expertiza 2. Select an assignment 3. Select Your Scores 4. Click on the link for view class scores for this assignment. 5. View the graphical output for average, high and low class score for that particular assignment Name : Students viewing number of reviews done by him/her Actor : Student Other Participants: None Precondition : Statistics have been recorded for number of reviews done by the student. Primary Sequence: 1. Log in to Expertiza 2. Select an assignment 3. Select Your Scores 4. Click on the link for my reviews for this assignment. 5. View the number of reviews the student has done for that particular assignment and also the number of reviews he still has to do to reach the threshold. Name : Students viewing number of metareviews done by him/her Actor : Student Other Participants: None Precondition : Statistics have been recorded for number of metareviews done by the student. Primary Sequence: 1. Log in to Expertiza 2. Select an assignment 3. Select Your Scores 4. Click on the link for my metareviews for this assignment. 5. View the number of metareviews the student has done for that particular assignment and also the number of metareviews he still has to do to reach the threshold. Name : Students viewing average number of class reviews for the assignment Actor : Student Other Participants: None Precondition : Statistics have been recorded for class reviews for that assignment. Primary Sequence: 1. Log in to Expertiza 2. Select an assignment 3. Select Your Scores 4. Click on the link for view class reviews for this assignment. 5. View the average number of class reviews for that particular assignment Name : Students viewing average number of class metareviews for the assignment Actor : Student Other Participants: None Precondition : Statistics have been recorded for class metareviews for that assignment. Primary Sequence: 1. Log in to Expertiza 2. Select an assignment 3. Select Your Scores 4. Click on the link for view class metareviews for this assignment. 5. View the average number of class metareviews for that particular assignment <image> <image>. Following is class diagram for Assignment display module. <image>. 1. Log-in to Expertiza as an student (Username: user480, Password: password). 2. Click on 'Program 1: BackChannel' assignment. 3. Click on the option 'Your Scores'. 4. The dashboard is then displayed with the class statistics along with the new graph added.","This is a project on information display, and yet the design doc doesn't have a single mockup of a screen, even after I asked for it.  It also is not clear that the team has looked through the files they were to merge in much detail (though they have mentioned the main purpose of each file).  Also, as several reviewers have mentioned, there is no mention of design principles or practices in the design doc."
E1506,"RSpec is a <link> (BDD) framework for the <link> , inspired by JBehave. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.2. <link> 1.3. <link> 1.4. <link> 1.1.1. <link> 1.1.2. <link> 1.5. <link> 1.6. <link> 1.1.1. <link> 1.7. <link> 1.1.1. <link> 1.1.2. <link> 1.8. <link> 1.1.1. <link> 1.1.2. <link> 1.9. <link>. 1. <link> 2. <link> (Username: user6, no password) 3. <link> 4. <link> 5. <link>. The search method should be in model and the paginating method should be in the controller. [done] 4. New feature: delete users 1.1. A user can be deleted if (s)he has not participated in an assignment. [done] 1.2. If the user is participating in an assignment, the system will ask, “User is participating in k assignments. Delete as a participant in these assignment(s)?” [done] 1.3. If the user has submitted or reviewed in any of these assignments, the system will say the user cannot be deleted, but offer to rename the user account to <current_account_name>_hidden. 1.1.1. rename (javascript calling update method in users_controller.rb) [done] 1.1.2. different users have different delete methods. [done] 1.4. If the person trying to delete does not want to rename the account, the system will just say that the user can’t be deleted. [done] 5. Testing feature: search for users 1.1. In rails 4 branch, admins can search for the users with 1) users’ login names 2) users’ last or first names and 3) users’ emails. Here's the function: <code>. It will be called if you do search in Manage->Users page. It has two components: search for users, paginate the results. So we would like to refactor this method by seperating it into search method and paginating method. The search method is in model and the paginating method is still in controller. The code below is the ""paginate_list"" method in official Expertiza: <code> From the code we can see that the search method needs four parameters: 1. role: user can only search users below his role 2. user_id: current user id 3. letter: keyword in search 4. search_by: search by user name, full name or email Base on this, we implemented the search method in ""user.rb"": <code> And the original ""paginate_list"" method is modified as: <code>. At the very beginning, we decide to use ""Cascading Delete"" to delete users. Because there are many relationship between different users. So, we divide all users into two set, one is new user without any relationship, the other is the old user with some relationships. When deleting old users, we find some problems. Because old users may be a reviewer before and score some assignments. If we delete some old users, the assignments' review scores will be a mess. <image> Confirm box flow diagram 1. A user can be deleted if (s)he has not participated in an assignment; 2. If the user is participating in an assignment, the system will ask, “User is participating in k assignments. Delete as a participant in these assignment(s)?”; <image> Delete confirm box 1. If the user has submitted or reviewed in any of these assignments, the system will say the user cannot be deleted, but offer to rename the user account to <current_account_name>_hidden; <image> Rename confirm box 1. Rename (javascript calling update method in users_controller.rb); <image> Rename success 1. If the person trying to delete does not want to rename the account, the system will just say that the user can’t be deleted. <image> Cannot delete. So when deleting the old users, Expertiza uses the functionality and customed confirm box we define; when deleting the new users, Expertiza will use the default confirm box. <code>. We write some features test to test ""search for users"" functionality. <code> <code> <code> 1. Instructor searches users by login names. <code> 1. Instructor searches users by first name or last name. <code> 1. Instructor searches users by email. <code> 1. Instructor deletes new users. <code>. <code> <image> Rspec feature test pass.","Generally good, but certain sections, e.g., Implementation, need more prose to be easily understood.


Writeup has an overall description of the project, but not what was done by this team.  They have showed code, but haven't said how it related to the changes they made.  Nor do we have a prose description of what they did.
This is a good description of some of the changes that the team made.  The initial description of Sahana could be shortened, given that anyone who was going to extend this project would already be familiar with Sahana.  The ending is very abrupt, without any indication of how they had improved functionality, or how their changes could be built upon."
E1553,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link> 1.1.9. <link>. <link> is an open source project based on <link> framework. 5. Prevented displaying of all versions for all users and tables when a user views the index page. 6. Added missing CRUD methods to Versions Controller 7. Added RSPEC testcases for testing changes done in Versions Controller. This class manages different versions of reviews. Sometimes it’s necessary to find the current version of a review; sometimes it’s necessary to find all versions. Similarly, a user may want to delete the current version of a review, or all versions of a review. Pagination of versions helps the user to view a subset of versions at a time. Considering the huge number of versions in the system, it is very useful to have a pagination mechanism and a filtering mechanism which can be applied on the whole set of versions. 1. Any user irrespective of his/ her privileges can view all the versions. The versions which a particular user can view should be restricted based on the privileges of the user. For instance, only a user with Administrator privileges should be able to view all the versions in the system. Every user can view all the versions irrespective of whether the user is a student or an administrator. 1. Any user can delete any version The versions which a particular user can delete should be restricted based on the privileges of the user. For instance, a student should not be allowed to delete any version. According to the current implementation any user can delete any version in the system. 1. Filtering of versions were restricted to the current user The filtering options on versions were restricted to the current user. Sometimes a user might want to view versions associated with other users. For instance, an instructor might want to view the list of versions created by a particular student. This is not possible with the current implementation. The method paginate_list was building a complex search criteria based on the input params, getting the list of versions from the Database matching this search criteria and then calling the Page API. <code> 1. Solution : The implementation has been changed in such a way that the versions which a user is allowed to see depends on the privileges of the user. The approach we have taken is as follows: 1.1. An administrator can see all the versions 1.2. An instructor can see all the versions created by him and other users who are in his course or are participants in the assignments he creates. 1.3. A TA can see all the versions created by him and other users who are in the course for which he/ she assists. 1.4. A Student can see all the versions created by him/ her. 2. Problem 2 : The search criteria created in the method paginate_list was difficult to comprehend. A student is not allowed to delete any versions now. Other types of users, for instance administrators, instructors and TAs are allowed to delete only the versions they are authorized to view. For instance, the UsersController has to paginate the list of users. The current user can now choose as part of the version search filter any user from a list of users if the current user is authorized to see the versions created by that user. 1.1. BuildSearchCriteria – as the name suggests the sole purpose of this method is to build a search criteria based on the input search filters when the current user initiates a search in versions. First the search criteria is built, then the criteria is applied to versions in the database to get all versions which matches the criteria and then the retrieved versions are paginated. The pagination algorithm for VersionsController displays at most 25 versions in a page. The purpose of this method is to determine whether the user who is triggering a CRUD operation is allowed to do so. So when the current user invokes a CRUD operation, the action_allowed? method is invoked first and if the method returns true the CRUD operation is triggered or else the user is intimated with a message and gracefully exited. <code>. The current version of expertiza did not have any test for VersionsController. These actions are not allowed to any of the users. Try searching for a user's versions and see if the results are paginated or not. Search here: <code> 4. Visit the same URL as step 3, you should see only the students under that instructor in the users dropdown. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. Clean Code: A handbook of agile software craftsmanship.",Good job of explaining changes!
E1958,"Expertiza has Assignment objects, which represent an assignment that is done by some number of users. An instructor or a TA can perform several kinds of operations on assignments, such as, ”Add participants”, “Create teams”, and “View scores”. These operations can be seen: First, on the homepage, under the “Actions” column in assignment list when a user (instructor or TA or admin) logs in and navigates to Manage -> Assignments. Second, when editing an assignment (by clicking on edit logo above), on the tab called “Other stuff”. Contents 1.1. <link> 1.1.1. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.3. <link> 1.4. <link> 1.5. <link>. The following tasks were accomplished in this project: 1. Issue 1384: Implement a setting in the user’s (instructor/ TA) profile, from where the user can choose whether to see these actions on the homepage or in a tab associated with each assignment. 1. Issue 1430: Under the “General” tab of the assignment edit page, an instructor or a TA can change the course of an assignment. What is wrong: A TA or an instructor can assign any course to an assignment even when they don't have access to the course. TAs can unassign an assignment from the course, and if they do so, they lose access to the assignment. What needs to be done: Only those courses should be shown in the dropdown list of courses, the assignment is part of and the instructor or TA has access to. Instructors, but not TAs, would then be allowed to change an assignment to be part of no course. Also, change the name of the tab from “Other stuff” to “Etc.”. 1. Implement a setting in the user’s (instructor/ TA) profile, from where the user can choose whether to see these actions on the homepage or in a tab associated with each assignment. Two new flags in the user database namely preference_home_flag and preference_edit_flag were created which were initialized to be true and the user would see a checkbox for both of his preference in the profile page which would both be initially checked to be true. Now user can uncheck this to see where he/she wants to see the operations. We implemented them both on local. We tried to use one of the flags as a text box and tried to insert text values in the profile page and could not accomplish the expected output as the flag was not updating. app/controllers/users_controller.rb. <code>. <code>. app/views/users/_editpreference.html.erb <code> db/migrate/20191028210443_add_preference_edit_flag_to_users.rb <code> <code> app/views/profile/edit.html.erb <code>. 1. Under the “General” tab of the assignment edit page, an instructor or a TA can change the course of an assignment. Only those courses are shown in the dropdown list of courses, the assignment is part of and the instructor or TA has access to. Instructors, but not TAs, would be allowed to change an assignment to be part of no course. Also, changed the name of the tab from “Other stuff” to “Etc.”. app/helpers/assignment_helper.rb. <code>. <code> app/views/assignments/edit.html.erb <code>. Travis-CI Build Testing Travis-CI Build Test of the beta branch after a refactored function is merged in the beta branch. <image> <image>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.","In the problem statement, the first two paragraphs of prose apply to Issue 1430, but that is not clear from the formatting.  A heading needs to be added.  Actually, I just did that for you.  BTW, there should be a space between ""Issue"" and the issue number, e.g., ""Issue 1430"".  I added the space too.

I'm not sure what it means to say, ""We implemented them both on local.""

When you show before and after views of code, it would be much clearer to use the Github diff view.

No screen shot of either of the two issue fixes.
No instruction on how to manually test.
No detail about issue #1384 fix (just code changes)
No reference links for thier work."
E1476,"According to the existing code workflow, the assignment of topics to teams are based on FCFS (first come first serve) basis, where a team which first signs up for a topic gets the topic while other teams are waitlisted on the same topic. 3. The current system fails to resolve the problem when many teams bid for handful of topics(among many topics) causing unnecessary additions to the waitlist. Factors such as team size are not considered which are important while assigning a topic to the team and potentially can reduce many issues faced by the current system. 1. One student can sign up only for a single topic. In cases where many topics are available, a student is forced to choose a single topic among many available topics which can be a difficult task. To select a single topic which best fits his/her choice among many available topics requires a pre-study of all topics prior to the sign up process. 3. If all the teams choose a handful of topics among many topics, it would also result in unnecessary additions in the waitlist queue for those few topics resulting in a situation where all the topics are not uniformly distributed among all the teams 4. Before, signing up, if more than one student forms a team and if each student belonging to the same team tries to sign up for different topics, than those topics are allotted to individual students resulting in a situation where a team can hold more than one topic. The algorithm works by considering every team as strength of 1, representing the student in the team. After sign up the topic would be allotted to the team based on a lottery system where a team is randomly selected for every topic. the intelligent assignment of teams. This approach is based on two important factors: 1. Team strength 2. Priority order of the topics submitted by the team. An added advantage of this approach is that, unlike the previous system, the intelligent team assignment system allows each team to bid for multiple topics which increases the chance of every team getting at least one topic that they placed their bid on. Each team can place their bids in priority order, the priority of the bids are also considered while assigning topics to the teams. For example: If TeamA is up to its maximum strength and bids for Topic1 , Topic2 , Topic3 where Topic1 has the maximum priority then TeamA has larger chance of being assigned Topic1 , but if Topic1 is already assigned (to a different team which had equal probability of getting the same topic based on team strength and bid priority) then Topic2 would be considered for assignment followed by Topic3 . Thus the priority mentioned by each team is also an important factor for assigning topics to teams. Before the sign up process takes place, students can merge their teams to form a larger team. 1. Every team is allowed x bids that they can use during the sign up process to select the topics of their choice. [The value of x is decided by the instructor using class strength, number of topics created for an assignment and maximum team strength allowed for that assignment.] 2. During the sign up process, the team can place x bids on x topics of their choice in a priority order. 1. As each team can place their bids on the available topics based on topic priority. Hence every team gets to choose more than one topic of their choice. 2. The teams are assigned topics based on modified <link> <ref> <link> </ref> algorithm which considers factors such as team size and priority ensuring that the topics are no longer assigned based on FCFS basis. This approach addresses the most important issue where a topic is not assigned to the team just because the team was late to sign up for the topic as compared to the other teams. This flow chart illustrates the ""modified stable matching"" algorithm used to assign topics to teams based on the strength of the teams(bidder) and the priority in which they bid for the topic. This algorithm takes two parameters as input 1. A list of teams which are un-assigned any topic 2. A hash of team and topics which were assigned Algorithm 1. Sort the list of teams in descending order of team size 2. For each team a.Get the team_size and topics that the team placed their bid on b.Arrange the topics according to the priority order mentioned by the team i. For each of the topic, check which team is assigned this topic and store its team strength in assigned_team_size ii. If the team which is assigned this topic is not up to maximum strength and if the ( team_size + assigned_team_size <= max_strength allowed for each team) then assign this team the topic. This would in turn start assigning teams with topics based on their bid preferences. The table bid is supposed to store all the bids on the topics with their priority. When the instructor starts the intelligent assignment of topics to teams, IntelligentAssignmentController triggers the assignment algorithm. The students interact with AssignmentTopicView which lists down all the topics for the assignment and allows students to bid for topics with priority.","Generally good description of what is to be done.  However, the changes made to each review strategy could be enumerated more prominently  And the document ends pretty abruptly.  However, there are no mentions of principles or patterns to be used."
E1828,"This page provides a description of the Expertiza based OSS project. Expertiza is an open source project based on Ruby on Rails framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. In Expertiza, students usually review several projects during a given time frame. We felt that since each reviewer would have multiple projects to review and some project may be updated without his/her knowledge it would be more convenient to the reviewer if he/she gets to know the status of the review without opening the project to be reviewed everytime. This helps the reviewer quickly identify submissions which need immediate attention. The reviewer should be able to know the status of any review he/she is doing. This can be done in UI of the reviewer’s page. The submissions can be color-coded using a scheme similar to the one used in the “Review Report” page for the instructor in expertiza. The color coding scheme implemented by us is: Red – If the review has not been started Orange – If the review was started, but not completed Brown – Submission has been reviewed Since the functionality for the links of “View”,”Begin”,”Update”,”Edit” are already present, the 'Begin' link is visible only when the review has not started, so the link is 'Red' to indicate review has not yet been started. Similarly the 'Edit' and 'Update' links are visible only after the reviewer has opened the project to be reviewed at least once. So both these links can be colored 'Orange' to indicate that the review was started but not yet completed. The 'View' link is visible only after the review was submitted, so the link can be coloured 'Brown' indicating that no further action is required on the reviewers behalf and the submission has been reviewed. Hence, by just colouring the links displayed to the reviewer, we are able to indicate the status of the review. The lines in bold in the below snippet are the colour codes we added which will add button colour in the review page. Changes: <code>. app/views/student_review/_responses.html.erb. 1. Open expertiza (link is provided) 2. Login as student: student5408/password 3. Go to 'Assignments' 4. Select any assignment 5. Select Other's work 6. You are in the reviews page where you can see the buttons and their respective colours. As discussed thoroughly with our mentor and professor, the implementation is a UI change with CSS styling and colour tags added. Hence, testing the buttons on review page is beyond the scope of our project. The colour change will not impact the functionality of the buttons in any way. Hence, unit tests are not required. Colour for View Buttons: <image> Colour for Begin Button: <image> Colour for Edit Button: <image>. <link>.",Problem statement does not clearly explain what the issue is. The document could have been broken down into sections more clearly - text and headings are not clearly distinguishable. Does not explain changes made to schema.rb
E1501,"This page is about an open source project based on Expertiza OSS. This project aims to refactor assignment.rb which is the largest class in Expertiza. It also aims to refactor other snippets which does not follow the Ruby style guidelines. <ref> <link> </ref> Refactoring is a technique to alter the internal structure of the code without affecting the external behaviour. It is used for: 1. Programs that are difficult to read; 2. Programs that does not follow the language specific guidelines; 3. Programs that has high coupling;. <ref> <link> </ref>Expertiza is an open source project developed using the <link> platform. The code can be cloned and modified from <link> . Assignment.rb is the largest class in Expertiza, comprising 1105 lines of code which contains the assignment model and the related functionalities. It also contains the score module which is refactored to make the file more clean and easy to read. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.4. <link> 1.5. <link> 1.6. <link>. Classes involved: <code> What they do Assignment.rb along with the controller file is responsible for creating and editing the assignments. The file also contains methods which calculates the student scores. What needs to be done: 1. The assignment model needs refactoring as it contains some modules which are responsible for generating assignment scores; 2. Moreover, the querying module is database dependent which should be made database independent; 3. There are many function names and code lines which does not follow the ruby guidelines. They should be changed to more ruby like coding style;. <ref> <link> </ref>ActiveRecord concern is a pattern introduced in Rails 4.1 to separate the heavy loading done by models. Methods which can be logically put together are added in a <ref> <link> </ref> module/mixin. This mixin is then included in the main model. The mixin can be reused by any other model if required. This makes the code align with Rails philosophy of DRY. In this case all methods related to 'scores' were collaborated together and put inside the mixin scorable. There are many methods which are not directly related to assignments. These methods are responsible for generating the scores and related functions. These methods are: 1. get_scores; 2. get_max_score_possible; 3. compute_reviews_hash; 4. get_average_score; All these methods are taken out of assignment.rb and pushed into a new file ""scorable.rb"". This made score generation a separate module and the dependency of scores on assignments reduced significantly. The pull request can be viewed <link> . There were many instances where the coding was not like ruby like. The ruby community believes in small and well readable code. The code was refactored to be more readable. Many changes were done to the structure of the code to make it more Ruby like. It also introduces more Ruby style terms like select and processes like piping instructions. Before Change <code> After Change <code> Before Change <code> After Change <code>. ActiveRecord provides a layer on top database. Hence if no MYSQL specific query is used in the code it very simple to change the database without changing the code. Using Ruby hash for query rather than raw SQL also helps in keeping the code clean. The queries where changed to function more like active record query. This made the queries database independent and more user friendly. Before Change <code> After Change <code>. <ref> <link> </ref>`Rubocop` was used to check the ruby style guide violations. Most of the Ruby style guide violations in assignment.rb class were fixed. 1. Version of gem ""EventMachine"" was updated as earlier version was incompatible with ruby version 2.2.0. The version was changed from 1.0.3 to 1.0.7.; 2. One more gem <ref> <link> </ref> ""quite_assets"" was added to avoid unnecessary log creation of the asset request. ; 1. Clean up tests: Few of the controller tests were not in the correct order. We changed them to the right order. 1. Feature change was not in the scope of the project. The changes are checking bad code smells and fixing them. Also, please have a look at the pull request for all the refactor details. You can pull the code with refactored file <link> . 1. <link> 2. <link> 3. <link> 4. <link>.","The introduction is not very useful, but after that, it seems to be a good description of changes made.  Writeup is rather short, though.
"
E1554,"Expertiza <ref> <link> . expertiza project </ref> is a project built with <link> <ref> <link> </ref>.It is mainly used by an instructor to provide a peer reviewing systems among the students it also supports team projects submissions wikis etc. This class handle the basic creation and modification of student teams. There are also some complicated actions. E.g., if a team get destroyed (this may be caused by instructor force this team to be destroyed, the students all leave the team), the topic held by this team should be transferred to next team which is on the waiting list, if there is any. These are the scenarios where topic transferring may happen: 1. when instructor destroys a team 2. when the last person leave this team 3. when this team wants to switch topic 4. when instructor wants to increase the available slots for a topic. The same code for handling topic transferring used 3 times at the following places: <code>. 1. Make topic_transfering a function call, and make sure all those 4 scenario works. 2. Write tests for all those 4 scenarios. 3. Record a video for those 4 scenarios, submit it to YouTube and submit the YouTube link to Expertiza. 4. Delete method in teams_controller.rb is complicated, “@team.destroy” should be called latest after all the records related to this team can be deleted. 5. write tests for delete method. Before: Code repeated in teams_controller.rb, student_teams_controller.rb, SignUpTopic.rb <code> After: The repeated code implemented as a function in SignUpTopic.rb <code>. Rspec tests can be performed by using the following commands from expertiza directory in the terminal: <code>. 1. Login as instructor. 2. Create a course. 3. Create a assignment using the above course. 4. Create topics (two topics are sufficient, though one will be used). 5. Create Users (at least 4 for better understanding : User21, User22. User23, User24). 6. Add users as participants to the assignment. 7. Create teams (TeamX -> User21 , User22) and (TeamY -> User23 , User24). 8. Impersonate as user and choose the topic first, invite other user. Impersonate as other user, accept the invite. 9. Revert to instructor role after creating teams. Make sure you have the same setup as above before every scenario. Scenario 1: 1. Go to Manage Content > the assignment you created > select 'Create Team' icon > delete the first team. 2. There will be only one team now. 3. Go to Manage Content > the assignment you created > select 'Edit' icon > Topics Tab 4. The second team will have the topic on which it was wait listed. 5. Check 'Number of slots' , 'Available Slots','Number on Wait list'. Scenario 2: 1. Impersonate as user of the team which has the topic. 2. Leave from the team. 3. Impersonate as second user of the team which has the topic. 4. Leave from the team. 5. Revert to instructor role after creating teams. 6. Go to Manage Content > the assignment you created > select 'Edit' icon > Topics Tab 7. The second team will have the topic on which it was wait listed. 8. Check 'Number of slots' , 'Available Slots','Number on Wait list'. Scenario 4: 1. Go to Manage Content > the assignment you created > select 'Edit' icon > Topics Tab 2. Select 'Edit' icon for that topic. 3. Increase the number of slots to 2 or more. 4. The second team will have the topic on which it was wait listed. <link> Youtube video will guide you test functionality manually. <references />.","The writeup is a bit short.  Some of the parts (e.g., on deleting a team) show the code that was changed, but do not explain how it was changed.  "
E1684,"<link> is an open-source project on GitHub used by students to view/submit assignments and review others' work. Expertiza also provides tools to visualize the scores and gauge the improvements made during the course semester. It also facilitates and monitors team projects. It is targeted at educational and non-profit organizations. <link> is a hosted, distributed continuous integration service used to build and test software projects hosted at GitHub. Configuration: Travis CI is configured by adding a file named .travis.yml, which is a YAML format text file, to the root directory of the repository. This file specifies the programming language used, the desired building and testing environment (including dependencies which must be installed before the software can be built and tested), and various other parameters. Operation: When Travis CI has been activated for a given repository, GitHub will notify it whenever new commits are pushed to that repository or a pull request is submitted. It can also be configured to only run for specific branches, or branches whose names match a specific pattern. Travis CI will then check out the relevant branch and run the commands specified in .travis.yml, which usually build the software and run any automated tests. When that process has completed, Travis notifies the developer(s) in the way it has been configured to do so—for example, by sending an email containing the test results (showing success or failure), or by posting a message on an IRC channel. In the case of pull requests, the pull request will be annotated with the outcome and a link to the build log, using a GitHub integration. <link> supports selenium-webdriver, which is mostly used in web-based automation frameworks. It supports JavaScript, can access HTTP resources outside the application, and can also be setup for testing in headless mode which is especially useful for CI scenarios. Using Capybara with <link> : Load RSpec 2.x support by adding the following line(typically to the spec_helper.rb file): <code>. There should be a feature test for submission of the assignment by the student. Once the assignment is created by the instructor the only call to action for the student is assignment submission. The purpose of this project is to test whether the submission function could work properly under different scenarios. We will design multiple test cases to simulate different scenarios which the system could encounter. For example, how system respond when a user uploads an invalid URL. The following part will provide more and detailed information on test cases. When a user is attempting to submit an assignment, there are some possible cases need to be considered. 1. Upload single valid link: upload a valid link, the system should properly render the page and add this link into the database. We will use the following statements to simulate the submit action. <code> 2. Upload invalid link: upload an invalid link (e.g. a non-existing link), the system should detect the invalid link, reject the submission and cast corresponding error message. 3. Upload multiple links: upload multiple links, the system should properly render the page and add the new link into the database. We will use the following statement to check if the current page has the uploaded URL. <code> 4. Upload duplicated links: upload an link which has already been uploaded before, the system should detect this duplicated link, reject the submission and cast error message. 5. Upload empty link: upload an empty link, the system should reject the submission and cast corresponding error message. 6. Upload a valid file: upload a valid file, the system should properly render the page and add this file into the directory. We will use the following statements to simulation the submit action. <code> 7. Upload multiple files: upload multiple files, the system should properly render the page and add the new file into the directory. 8. Upload duplicated files: upload a file which has already been uploaded before, the system should update the existed file with new one. The test code will check whether the content of this specific file was successfully updated. 1. First, using <link> to create test data: create assignment, create topic, create participant. <code> 2. Mock the workflow of Assignment submission using Capybara. <image> 3. Check the result of the submission from both web page and database. In database level, the submission results are stored in the table: TEAMS. <image>.","The doc mentions the files that will be modified, but said little about the modifications that would be made.  Which methods will be modified?  What parameters will be passed?  Also, the testing plan is much too vague."
E17A0,"1. A new button to select Reviewers as a team will be provided at the Assignments Edit page in the Review Strategy tab for the instructors 2. Any member of a team should be able to select a review to be done by their team. 3. Team members should not be allowed to edit a review simultaneously. These changes include: 1. Providing the delete review logic in case the instructor decides to change the review strategy. 2. To track 20 mins of inactivity to auto-save the review in case when the user starts the review and forgets to save it. Say that the instructor decides to change the review strategy after the reviews have already started. <image> 1. Name: Teams submitting reviews for assignment or topic 2. Actor: Student (as member of a team) 3. Other Participants: Team Members 4. Precondition: Instructor has set up an assignment with review strategy as ""Team Reviews"". Thus, in the diagram above, the participant is a single member team. The student can request a review for the team from here. Depending on the number of reviews allowed and the number of reviews already performed by the team, they will be allotted a new review Begin the review. Only one member of the team can edit the review at an given time. Complete the review and Click Submit. Thus, when a team member is editing a review we lock the response using that team member's id. When locked the other team members can only view the review. Case 2: Scenario: The beginning of a review is a special case since when the begin button is clicked a review form is only rendered. Case 3: Scenario: If a team member forgets to save or submit a review and has not closed the browser window, then we automatically save the review after an inactivity timeout of 20 mins thus unlocking it for the other team members to edit. Case 4: Scenario: At a critical time, if a team is unable to contact the team member who has locked the review by closing the browser window without saving the review, the other team members can contact the instructor who has been provided an unlock button for such emergency situations. The instructor can now unlock that review and then the other team members can edit it. Case 5: Scenario: An instructor can delete completed review if he/she decides to change the review strategy for an assignment between team reviews and individual reviews. If a user is editing a review at the instant when instructor is deleting the reviews, upon pressing the save review or submit review button, the user is redirected to the student_review/list.html.erb page UI Changes 1. Currently there is no team reviewing in Expertiza. Thus, we will provide a check-box, in the review strategy tab of edit assignments, for the instructor. If the instructor changes the reviewers to teams, then each participant (who is member of some team), will request reviews on behalf of the entire team. method to check whether it denies certain action when the review is locked by a user other than current user. method to check whether it allows certain action when the review is locked by current user. 5. Test the reviewer_is_team_member method to check whether the current user is a member of the assignment review team. Thus, when a team member is editing a review we lock the response using that team member's id. It can only be unlocked when the review has been saved. When locked the other team members can only view the review. Case 2: Scenario: The beginning of a review is a special case since when the begin button is clicked a review form is only rendered. Case 3: Scenario: If a team member forgets to save or submit a review and has not closed the browser window, then we automatically save the review after an inactivity timeout of 20 mins thus unlocking it for the other team members to edit. Case 4: Scenario: At a critical time, if a team is unable to contact the team member who has locked the review by closing the browser window without saving the review, the other team members can contact the instructor who has been provided an unlock button for such emergency situations. The instructor can now unlock that review and then the other team members can edit it. Case 5: Scenario: An instructor can delete completed review if he/she decides to change the review strategy for an assignment between team reviews and individual reviews. If a user is editing a review at the instant when instructor is deleting the reviews, upon pressing the save review or submit review button, the user is redirected to the student_review/list.html.erb page. Thus, we will provide a check-box, in the review strategy tab of edit assignments, for the instructor. method to check whether it denies certain action when the review is locked by a user other than current user. method to check whether it allows certain action when the review is locked by current user. 5. Test the reviewer_is_team_member method to check whether the current user is a member of the assignment review team.","This is quite readable, except for the long paragraph in Step 2 of Approach, which should be broken up.  Some reviewers denigrated the test plan, but it seems reasonable now.  I would encourage you to make more use of Mediawiki markup instead of just putting numbers at the start of paragraphs."
E1759,"Expertiza is an open source project based on Ruby on Rails framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. One of several ways to set up the environment and the one we adopted is:- Ubuntu-Expertiza image (.OVA) [Recommended] This is the link for the image. ( <link> ) And you can install VirtualBox (free) and import this image into VirtualBox. Some machine may require you to enable virtualization and then run the following commands. <code> <code> <code> <code> 1. For logging in as an instructor:- Username: instructor6 Password: password. Expertiza should be able to distribute surveys to the users. The survey can be one of the following: 1. Course survey (all the participants of the course can take it). 2. Global survey (all the users in Expertiza can take it). The survey can also be targeted (the admin can specify a group of people who will receive this survey). The three kinds of surveys in this project are: 1. Assignment Survey questionnaire 2. Global survey questionnaire 3. Course evaluation questionnaire <image>. The following tasks were performed by us as part of our project: 1. Understood the flow of the survey creation and deployment function. 2. Updated the RSpec file in /spec/features/ folder. 3. Used fixtures to create the student record in test DB. 4. Used Capybara to write functional tests for: 1.1. Creating a new survey. 1.2. Creating different types of questions. 1.3. Editing different types of questions. 1.4. Deleting different types of questions. 1.5. Deploying survey. 5. Created multiple tests to check valid and invalid cases. For example, to test valid_start_end_time? by checking that if the start time is later than the end time, the test returns false. 1. spec/features/survey_spec.rb 2. spec/features/assignment_survey_spec.rb 3. spec/features/global_survey_spec.rb 4. spec/features/course_survey_spec.rb 5. spec/features/helpers/instructor_interface_helper.rb. Login as an instructor: 1. Use credentials username: instructor6, password: password. 2. Click on Manage -> Questionnaires-> Survey / Global Survey/ Course evaluation. 3. Create a new Survey/ Global Survey/ Course evaluation filling in the parameters asked for. 4. Test if the survey is created and deployed and the questions can be added, deleted and modified. <image>. The following test spec has been written to create an assignment survey. <code> The following test spec has been written to deploy an assignment survey. <code> The following test spec has been written to create a course survey. <code> The following test spec has been written to deploy a course survey. <code>. After completion of this project, the creation, deployment, and deletion of surveys will be fully tested.","The wiki is well organized, but is also quite short.  The class hierarchy diagram and screenshot are useful.  Each test is described with just one line of code.  It would be much more helpful to have the various steps in the tests described in prose."
E17A7,"The bidding ability is only for bidding for a topic for (teams of) students in a course. Then the bidding algorithm assigns the topics, particularly with the following features: 1. Students (not in a team) with close preferences are assigned to a project team, and the common preference is the project topic assigned to the team. Alternatively, for existing teams, the project topic is assigned as per the common project topic preference list 2. Each team is assigned only one topic 3. Each topic (if assigned) is assigned to a maximum of one team. This project is responsible for the bidding algorithm used in the conference, which is significantly different from the project bidding algorithm as explained above. For the purposes of the project, we assume that there are several reviewers in a conference who review papers which are proposed to be presented in the conference. 1. To take the existing bidding code in Expertiza (which is meant for students bidding for project topics) and make it callable either for bidding for topics or bidding for submissions to review. 1. To develop code such that both applications (bidding for project teams and bidding for conference paper reviews) use the same code 2. To improve the algorithm for calculating the score for a particular project topic/conference paper review assigned to a project team/conference reviewer 3. To ensure that the topic assignment algorithm assigns topics in a balanced manner in the case no reviewer has bid for any topic 4. To develop a variable name in the database so as to distinguish between a project topic and a reviewer topic We want to state here that we are not responsible for developing any conference features. Preference Lists can have minimum 0 topic and a maximum of L topics. Then the topics are allocated to teams such that each team gets a unique topic and each topic is assigned only to one team. We are trying to combine the code so that it can be used for both the project topic bidding as well as the conference paper review bidding. 2. For Bidding for Conference Paper Reviews, M >= 1 but P and R are generally greater then 1. The item to be bid on is the conference paper reviews. We also note that it simply cannot be used for conference paper review assignment. In this case, this change tries to ensure that every topic is assigned in such a way that there are more or less equal number of reviewers reviewing each topic. Actors: 1. Conference Reviewer: Submits a preference list of papers and reviews assigned papers 2. Conference Administrator: Responsible for the assignment of topics to the reviewers Scenario The case of reviewers submitting a list of preferred topics and the administrator running the assignment process. 1. Use Case Id: 1 2. Use Case Description: Participants choose the preference for conference review topics and submit it 3. Actors: Participants 4. Pre Conditions: Conference papers are presented and submitted, and the participants are eligible for reviewing 5. Post Conditions: Conference committee members can view participants preference and run bidding algorithm on it. 1. Use Case Id: 2 2. Use Case Description: bidding preferences and related participants information are processed and saved to database 3. Actors: None 4. Triggered by Use Case 1 5. Pre Conditions: participants preferences are submitted 6. Post Conditions: information can be retrieved and used by bidding algorithm. 1. Use Case Id: 3 2. Use Case Description: participants can view list of topic available for conference paper topic 3. Actors: Participants. 1. Use Case Id: 4 2. Use Case Description: Committee members can run bidding algorithm on application to help assigning the conference paper topics to participants 3. Actors: Conference Committee 4. Pre Conditions: preferences must be submitted by participants 5. Post Conditions: the bidding result can be used for paper assignment. 1. Use Case Id: 5 2. Use Case Description: System assigns participants to conference paper topics according to bidding result 3. Actors: None 4. Triggered by Use Case 4 5. Pre Conditions: bidding algorithm has run and result has been returned 6. Post Conditions: Participants can view topics been assigned to them. 1. Use Case Id: 6 2. Use Case Description: Conference committee members can change assignment result manually 3. Actors: Conference Committee 4. Pre Conditions: topic assignment has been done 5. Post Conditions: changes in bidding result is visible to participants and other committee members. The diagram shows the process of bidding algorithm that we proposed to use for conference paper review assignment. 1. This was discussed above 2. Basically, in the case none/some of the teams have no preferences, then these teams should be assigned topics such that each topic has more or less the same number of reviewers assigned. 2. No UI has been created been created for the conference paper review bidding. 1. Case 1: No reviewer submits a list of preferred topics to review : In this case all topics are assigned same bid score. 1. Case 3: Number of topics exceed the number of teams: Some topics may not be reviewed,depending on the limits put by the conference.","The description of what needs to be done is very clear.  The description of the current bidding code is not.  Some kind of itemized list would have helped.  In the new code, I don't understand what score calculation is about.  Is that perhaps bid priority?  The description of the test cases is very short and not specific; it would have to be elaborated considerably to be used as  blueprint for implementation."
E1629,"The purpose of this project is to improve the performance of the Course and Assignment listing page. This page lists all the courses that are created by the logged in user and also the public courses that are created by other users. The current implementation of the page is in ReactJS and takes a long time to load. The course assignment listing page has three tabs. These tabs are Courses , Assignments and Questionnaires . The courses tab lists all all the courses that the instructor/TA might be interested in. This includes all the courses that they created and also the public courses. Additionally in the courses page all the assignments related to each course is also loaded when the page is loaded. All assignments belonging to a course can be viewed by clicking on that course. On the listing page there exists a check-box which allows the user to select whether or not to display public projects. By default this option is selected and as a result all public and private courses are displayed. Similarly for the assignments page all the public as well as private assignments created by the user are loaded. Because of this the page takes a long time to load. The individual work items identified are as follows: 1. Include others' items check-box should be unchecked by default for both courses and assignments page. By default, the public courses should not be loaded. 2. Current implementation of the Course page makes separate REST calls to the controller for fetching assignments for each course. This is a bad design and it takes a while to load the whole page. we plan to modify such that the assignments are loaded only when a particular course is clicked. 3. List the courses in two different sections. One section should be to list all the courses that are created by the user. The other section should be to display all the public courses. This section should be displayed only if the check-box is selected. Searching for courses in the current single list implementation is difficult. Partitioning the list into two sections would greatly improve the usability of the page. 4. Similarly the assignments tab should be divided into two sections. The first section should list all the assignments that are created by the user and the next should list all the public assignments. In order to better understand the problem consider the following scenario: When logged in as an instructor(instructor6) the course page loads a total of 103 courses. Hence it will make 103 REST calls to fetch assignments for all these courses. Out of these 103 courses the signed in instructor is concerned with 25 courses. Assuming he checks the assignments to all of these courses it would result in a total of 25 REST calls to fetch assignments. The table that displays the course listing is a ReactJS component. Currently it loads both private and public courses in the same section by means of a single REST call. We intend to split this such that one rest call is made for public courses and one call is made for private courses. Files modified: 1. app/controllers/tree_display_controller.rb 2. app/assets/javascripts/tree_display.jsx 3. app/views/tree_display/actions/_courses_folder_actions.html.erb View of the Private Courses Section <image> View of the Public Courses Section <image>. Adding to the changes made in previous work item, load only the private section on page load. The public section is loaded only when the check-box to load public courses is selected. Each row in the course listing table represents a course. Each course has a sub section listing its assignment. Whenever a user clicks on a course a REST API call will be triggered and this will fetch the assignments, and a subsection will be added to the user interface. This project is involved with improving the performance of the Course and Assignment Listing page. We will update this section with a comparison of the page load time on completion of the project. Detailed steps are as follows: 1. Course listing is a view used by instructors & TAs to view courses. As the instructor & TAs login to expertiza, they would be directed to the course listing where they would see that checkbox (“include others’ items”) to include public courses by other members, in the listing is unchecked by default. Similar to course listing, there is an assignment listing as well to be tested. Also check to see that only private courses are loaded by default. 2. The logged in user’s courses and others’ public courses are listed in two different sections. One section for each type. Section listing others’ public courses are displayed only when user selects the checkbox “include others’ items. 3. Similarly, the logged in user’s assignments and others’ public assignments are listed in two different sections. Section listing public assignments are be displayed only when user selects the checkbox “include others’ items”. 4. Check that on clicking a particular course in the course-listing page, the assignments of that course are listed.","Limited tests done, but then, there wasn't much that could be easily tested.
Design doc is rather sparse, not including the screenshot of the different course types (which doesn't explain much about the project)."
E1683,"In Expertiza, students can review others’ work. However, currently all reviews are done by individuals, regardless of whether the assignment is assigned as individuals or teams. In team assignments, when the team member reviews an assignment, his/her review is independent from his/her teammates’ reviews. To encourage students to discuss together and review carefully, it is sometimes reasonable for students to submit their reviews as a team. And apparently, team-based reviewing can reduce the workload of each student. In a word, the main purpose of this project is to achieve the function of team-based reviewing and ensure that Expertiza works well with the change. <image>. Based on the design documents, the basic project design is proposed below. In Expertiza, we have ResponseMap , which is the object that records who reviews whom. In ResponseMap , there are two attributes: reviewer_id and reviewee_id . The reviewee_id is the ID of the Team , which indicates which team is being reviewed. And the reviewer_id is the ID of Participant , which specifies a user who is participating in this assignment. <image> To achieve function of team-based reviewing, a boolean field reviewer_is_team needs to be added to ResponseMap to determines whether the reviewer is a AssignmentParticipant or an AssignmentTeam . If reviewer_is_team is true, then the reviewer_id would refer to a record in the teams table, not a record in the participants table. <image> And a field reviewer_is_team is also need to be added to the assignments table as well to indicate the review of assignment is an individual-based reviewing or team-based reviewing. <image>. Several parts of the system need to work regardless of whether the reviewer is an individual or a team, like “View my scores” and “Alternative view”. The scores are given as team if the reviewing type is team-based. <code> For an Instructor to specify whether the reviewing is team-based or individual-based, we are intended to provide a dropdown on the Review Strategy tab of assignment creation. <code> <code> We set a lock in editing review, so that other team member cannot start to edit a review at the same time that one team member is editing it. The error message is considered to be displayed by flash[:alert] . <code>. RSpec is a testing framework for Rails, and is a Behavioral-Driven Development tool. It is a domain specific language(DSL). All the tests can be executed by rspec spec command, or can also be executed individually using the command ""rspec spec/models/assignment_team_spec.rb. We intend to write unit tests using RSpec for all the methods which we modified/created. We intend to write unit tests using RSpec for all the methods which we modified/created. And also the basic test case is proposed for UI test. <table>.","The documentation has everything that we asked for. it's well structured, contains a workflow diagram (it's not behaviour diagram. behaviour diagrams are use case, interaction, collaboration, state chart, and activity see UML 2.0). so I can skim it quite fast. the design of the UI with the pie chart is also nice. DB table is also explained well (Actually you could get ""round"" from the response table).  Well done!"
E2010,"Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can also peer review other students' submissions. The criterion.rb model consists of functions that decide what to display while creating, editing and viewing the questionnaires depending on whether the user is an instructor, a teaching assistant or a student. So, this file consists of a lot of HTML code that is rendered to the final questionnaire view. The current version of this controller has four methods, but two methods are very long and would require refactoring. The HTML code which is rendered to the final view is made up of concatenations. Another issue with the code is that the branch conditions size for the complete and the view_completed_question method is very high. Also, this controller has very few comments. The criterion.rb model consists of functions that decide what to display while creating, editing and viewing the questionnaires depending on whether the user is an instructor, a teaching assistant or a student. So this file consists of a lot of HTML code that is rendered to the final questionnaire view. Criterion is a question in questionnaire. Other type question in questionnaire include Drop down (multiple choice), Text box (short question), Text area (long question). They can be add in questionnaire. For this project, we have to deal with the following two methods: 1. The complete method, which is 104 lines long. this method returns the display for the students when they are filling the questionnaire. It includes the advice given for different questions, dropdown options to rate a project based on the question, a textarea to enter comments and so on. <code> 1. The view_completed_question method, which is 47 lies long. Thismethod is responsible to return the display if a student is viewingan already filled-out questionnaire. <code>. Our goal is to refactor the complete and view_completed_question method mainly by reducing the number of lines code for each function and also by introducing new methods to make the code more modular. We will also try to reduce the branch condition size wherever possible and hence reduce the cyclomatic complexity for these two functions. We also plan to introduce comments wherever needed to make the code more understandable. The main aim is to reduce the number of lines and make the code more compact without affecting the readability of the code. 1. High branch condition size problem: extracting three methods from method "" complete "" 1.1. Method "" dropdown_criterion_question "" return html when choosing dropdown options 1.2. Method "" scale_criterion_question "" return html when choosing scale options 1.3. Method "" advices_criterion_question "" return html about showing advice for each criterion question 2. Too long code 1.1. Combining the short HTML strings into longer ones but not too long 1.2. Using one readable line of code instead of three or more lines of if-else statements 3. Fix incomplete condition problem 4. Change the language to more Ruby friendly. The origin test about method ""complete"" didn't include the situation when the parameter ""answer"" isn't nil and the parameter ""dropdown_or_scale"" is ""dropdown"" or ""scale"". We added the test examples from 4 to 16 including the multiple for method ""complete"", ""dropdown_criterion_question"", ""scale_criterion_question"". 1. Test for method ""complete"" with or without answer and dorpdown_or_scale Origin test <code> New test <code> 1. Test for method ""dropdown_criterion_question"" with or without answer <code> 1. Test for method ""scale_criterion_question"" with or without answer <code> 1. All existing tests passed <image>. Test Log in Website url: <link> Log in: instructor6 Password: password Log in: student2064 Password: password Test criterion works well in questionnaire 1. After logging in as a student, click the ""Assignments"" 2. Choose an assignment, like ""Backchannel application review"" 3. You can choose ""Your scores"" to see the review results 4. Click Criterion 1, you can see all the reviews for this criterion. 5. Click ""toggle question list"", you can see all criterion questions. 6. After logging in as an instructor, choose ""Questionnaires"" tag 7. Click on the name Review: This should show a drop-down showing different reviews made. 8. Choose a review, select the edit icon to the right. 8. Change dropbox of question type to Criterion, select Add ""2"" more. 9. Edit question content: ""Test question Textarea"", ""Test question Criterion1"", and ""Test question Criterion2"" in that order. 10. You can also change the question content for exited criterion question These manual tests show criterion works well. Feel free to try your own test cases.","There are two kinds of changes described: changes to individual statements, or compound statements, and changes to methods. The changes to individual statements are described very clearly, but for changes to methods, usually the authors just dump the old code out, followed by the new code. That does not help the reader much. There are formatting glitches due to hundreds of single quotes throughout the document. One of them is not closed properly, and that causes the whole document, except for part of the table of contents, to be in italics. The overall impression is that this document is clearer than most.. The testing plan is very elaborate. Good Rspec tests are included."
E1463,"Expertiza<ref name=""expertiza> Expertiza <link> </ref> is an open source web portal for the use of both students and professors. It is developed on Ruby on Rails platform. More information on Expertiza can be found <link> . The source code has been forked and cloned for making modifications to the to survey responses controller. This wiki provides an insight into our contributions to the OSS Expertiza application, focusing on Refactoring the SurveyResponses Controller. <image> <table> Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.1.6. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link>. Refactoring helps to<ref> <link> </ref> 1. Understand what led to poor code design 2. Fix code which is difficult to understand 3. Express each idea “once and only once” 4. Recognize missing or inadequately formed classes 5. Simplify overly complex relationships between classes 6. Achieve the right balance of responsibilities among objects 7. Make code easier to test and more maintainable. We identified the following categories of code smells in the helper module: 1. Fat Classes : No class should be fat. 1. Bad Class names : A good class name is expected to adhere to the Ruby style and design style guidelines. 1. Duplicated Code : These are those pieces of code that does almost the same functionality of some other piece of code leading to a bad design style. There are many documented refactoring techniques, and a few common ones are below.<ref> <link> </ref> 1. Rename Class : Controllers as per Ruby conventions should be plural. 2. Using Helper classes : No class should be containing lot of code, a better practice is to have all active record queries with in the model and in order to keep as much as Ruby code out of the views, helpers are used. Helpers are the only methods you can access, other than instance methods for an instance you have access to. 3. Extract Method : It consists of breaking up long methods by shifting overly complex chunks of code into new methods which have very descriptive identifiers. This class creates surveys and records the responses which can be viewed. On submitting the responses, the scores and comments are posted. Classes : SurveyResponsesController.rb What it does : Creates surveys, submitting surveys, views responses, posts scores and comments. What has to be changed : 1. Pluralize the class SurveyResponseController to SurveyResponsesController 2. Changing declarations of Arrays and Hashes,removing commented out code 3. Use of routing helpers instead of hardcoded URLs 4. Move active record queries to the model or another class 5. Reducing the number of instance variables per action to one. 1. A new survey_responses_controller.rb file is added : As per Ruby on Rails convention, controller names get pluralized while model names are singular. 1. Modified declarations of Arrays and Hashes Before Refactoring : survey_responses_controller.rb <code> After Refactoring : <code>. A bunch of Active Record queries that existed in survey_responses_controller have been moved to SurveyResponse model. Before Refactoring: survey_responses_controller.rb <code> After Refactoring: survey_responses_controller.rb SurveyResponse.get_survey_list and SurveyResponse.get_survey_list_with_deploy_id methods have been created in SurveyResponse model for active record operations. <code>. It desirable not to have more than one instance variables in a controller action as it indicates increased coupling. Our goal should be reducing coupling as much as possible and view should have direct access to as few instance variables as possible. Here persist_survey method has been created in the SurveyResponseHelper to minimize instance variables. Before Refactoring: survey_responses_controller.rb <code> After Refactoring: survey_responses_controller.rb <code>. resources :survey_response do <code> The resourceful routes generated the helpers given below: <code> <code> <code>. Comments and extra spaces have been removed and conventions have been followed to enhance readability of the code. Testing was performed by running 2 different VCL instances one with the original code and the other with the re-factored code. <table>. 1. <link> 2. <link>. <references/>.","Writeup doesn't clearly indicate what changes were made. There is a tendency to show ""before"" and ""after"" versions without saying what is different between them.  It doesn't mention design principles, nor list any design patterns.  Reviewers had trouble understanding code."
E1868,"The basic functionality of this controller is to assign reviewers to review artefacts or submissions by other participants or teams. To summarize, the review_mapping_controller was modified by separating the report generation functionality into a new helper named report_formatter_helper. The reports and reviews are two different functionalities which should not be clubbed. The reports provide functionality such as presenting reviews for grading, showing author feedback (rejoinders), showing a table of all teammate reviews, showing a calibration report in an assignment where students rate the same work that has been previously rated by an instructor, and showing how many answers students have tagged. Every report boils down to one single idea i.e. In the current implementation, the reports are accessed by clicking on the “view review report” button in the buttons tray of an assignment, which leads into the review report page. This page contains a drop-down menu listing various reports to navigate to. This always forces the user to initially view the review report and only then choose the required report. We intend to modify this implementation such that the user is not forced to view the review report but can directly select the required report. Since the logic for report generation has been abstracted into a new controller, existing tests for report generation must be verified for regression and also check for improving the code coverage statistics. Currently, there are ten different reports 1. Review report 2. Author feedback report 3. Teammate review report 4. Aggregated comments by rubric question 5. Comment summary by reviewee (team) 6. Potential collusion report 7. Answer tagging report 8. Calibration report 9. Plagiarism checker report 10. Self review report The new implementation will have ReportFormatter module with following methods - ReviewReport - AuthorFeedbackReport - TeammateReviewReport - RubricQuestionReport - RevieweeCommentReport - CollusionReport - AnswerTagReport - CalibrationReport - PlagiarismCheckerReport - SelfReviewReport UML representation of the new module is provided below <image>. In order to avoid the user to be redirected to review reports page every time the user wants to view a specific report, the following changes have been made to the implementation: 1. The icon in view assignments page has been renamed from ""view review report"" to ""view reports"" to generalize. <image> 2. On clicking the ""view reports"" icon, the user is directed to a new page that has the drop-down to select the required report. <image>. The use case of reports gives a broad overview of the functionality. The details are as follows(sample reports screenshot included) 1. When the requested report type is ""SummaryByRevieweeAndCriteria"", we check that the corresponding data is rendered. This report should contain a summary, reviewers, average scores by reviewee, average score by round and average score by criterion. <image> 2. When the requested report type is ""SummaryByCriteria"", we check that the corresponding data is rendered. This report should include a summary, reviewers, average scores by reviewee, average score by round and average score by criterion. <image> 3. When the requested report type is ""ReviewResponseMap"", we check the corresponding report data is rendered. This reports participants, average and range. <image> 4A. When the requested report type is ""FeedbackResponseMap"" and assignment has varying rubrics by round feature, we check the corresponding participants' data related to feedback i.e. number of feedbacks done, last feedback status. When the requested report type is ""FeedbackResponseMap"" and when the assignment does not have varying rubrics by round feature, we check the corresponding participants' data related to feedback i.e. number of feedbacks done, last feedback status. <image> 5. When the requested report type is ""TeammateReviewResponseMap"", we check that there is a correct mapping between the participant and its response. The report must return participant information, the number of reviews completed, teammates reviewed, the last review status. <image> 6. When the requested report type is ""Calibration"" and participant is not empty we check if the correct report is rendered or not. The report must return the calibrated values of the participants' response to the given assignment. <image> 7. When the requested report type is ""AnswerTaggingReport"", we check if the correct report page is rendered or not. The report must render the participants' details, the number of taggable answers, the number of answers tagged, the number of answers not tagged and the percentage of answers tagged. <image> 8. When the requested report type is ""PlagiarismCheckerReport"", we check if the correct report page is rendered or not. 9. When the requested report type is ""CollusionReport"", we check if the correct report page is rendered or not. 10. When the requested report type is ""SelfReviewReport"", we check if the correct report page is rendered or not.","The work to be done is described well, and so is the test plan.  However the Implementation specfics contain only a list of reports to be created, and nothing about the structure of the code that creates them.  Reviewers gave this design doc high marks."
E17A6.2,"To register to use this website, one needs to be either a course TA or Instructor and send a request to expertiza administrator to get approved. The request function only serves TAs and Instructors, so students won't be able to register. A student account is created by instructors or TAs. A pending request page that displays all the requests should also be able to perform actions like approve or reject with an note. However, currently, all of these are done manually, which means no pending request page currently exists, no simple approve or reject action, and no user experience, and all users are added into the database through command line operations in the database(only instructor and TA roles which is acceptable currently but not when more other institutions try to user Expertiza). In addition, we also want users be able to add their institution if it does not show under the list provided by us. Overall Introduction Request account function is currently not working properly. A new user who tries to request an expertiza account can do so, but the instructor can see yet has no power to approve any request. The approval process is currently done manually, which is cumbersome. Our mission is to fix the request account functionality so that whoever requests for a new accounts can be approved by instructor clicking a button, and secondly, optimize the functionality to improve user experience. 1. Add institution <br\> -A registering user should be able to choose their institution from a drop-down menu, but they should also be able to add an institution if they couldn't find one. <br\> -The new institution should be saved as a new record into the institution table <br\> -New account request should be saved to requested_users table with correct institution id.<br\> 2.superadmin, admin should be able to approve/decline requests <br\> -add a new drop-down item under “Administration > Show…” so requests can be visually displayed and handled<br\> -enable the ""approve"" function for admin and superadmin<br\> -make clickable user email address so a conversation is possible<br\> 3. The record retain after admin's approval/rejection and an email will be sent to remind <br\> -an email should be sent when a request is approved or declined<br\> -all record should be kept on the page even it has been handled<br\>. <image>. - redesign the view shown in the previous section to include a field named institution in the current form to allow user to submit their institution if they couldn't find one in the list, and save it into the table corresponding to the form it submits to. - design a requested_user table to save all account requests. - to create an new view that can show all pending account requests and include actions like approve and reject to allow instructors to process requests on the same page - create corresponding new controller with methods corresponding to actions like reject, approve and index. <image>. - redesign the view and model to retain the request record after super-admin or admin approves the request. - add an email tag in the corresponding view, so there will be an email send to email address offered by requester after approval/rejection. 1. First of all, a new user need to click 'REQUEST ACCOUNT' to create a new account. <image> 2. In the 'request new' page, in the original version, the user can only choose an institution from the drop-down menu. After our modification, the user can choose the 'Not List' choice in the drop-down menu and type in an institution when (s)he is not able to find his(her) institution in the drop-down menu. <image> 3. After log in as an admin/super admin, the user can see a drop-down item under 'Administration->Show->Pending Users' to see all account requests. <image> ‎ 4. After clicking the 'Pending Users', the admin can see a list of new account requests and the emails are clickable to send email to the requesting user. Also, after the admin accepts the request, the record should retain in the view and an email informing the requestor will be sent to the requestors' given email address. <image> 5. After clicking the email address, the sending email page will pop up and admin can converse requestors. <image>. 1. a proper error message for improper information filled in, such as wrong email address format or existing account. 2. When a pending account gets approved or rejected, an email will be sent to the submitted email address. 3. A new item ""show"" should be added under administration and direct instructor to pending requests page when clicked 4. pending requests will have an email column that is clickable which allows instructor to send emails to applicants before a decision is made. 5. when a request is processed, its record is still kept with the status of processed.","The document is reasonably readable.  It explains the changes in functionality. The UI changes are described, but the code changes are not.  The test plan is not adequately described.  It should say what tests are to be performed, not just which functionality is to be tested.  It is reasonable to test the UI manually, but model and controller tests should be automated."
E1852.3,"Unit Tests are implemented to ensure proper independence and desired functionality of methods in a model. Unit Testing is an essential component for the following strategies: 1.1. Test Driven Development(TDD), where unit tests are used to drive the development of a product. In this project, RSpec testing models were used to satisfy the testing requirements of behavior driven development. The Participant model is used to prepare data for participants enrolled in each course or specific assignment. Participants are also assigned to various topics and assignments depending on the involvement of the participant's user. Functionality of the model allows the return of the participant's current team, his or her current responses, identifying attributes such as name and user handle, as well as the participant's role permissions and authorizations. Additional components allow for the generation of notification emails and the calculation of a participant's grade on an assignment. There are not enough unit tests for the Participant model of Expertiza. 1.1. Write unit tests using Rspec 1.2. Achieve a path coverage of more than 90% 1.3. Achieve a high branch coverage. To achieve a goal of more than 90% test coverage, our team completed the following test plan: 1.1. Obtain the appropriate testing environment via a provided virtual box image and RSPEC testing framework. 1.2. Acquire a deeper understanding of the Participant model, its functionalities and dependencies. 1.3. Create factories and doubles to assist in the testing of model methods. 1.5. Apply generated helper objects and mocks to achieve high test coverage of each method within the Participant model. Our approach to testing the Participant model involved simplistic use of helper objects and mocked message passing. The Participant model is a super class that encompasses various types of participants. The current factory file contains a default participant build that is associated with a subclass ""Assignment Participant"". In order to ensure the testing of the super class functions, we created a participant factory that is derived directly from the Participant model. <code>. The following variables were generated using the provided factory class to assist in the testing of the Participant model. <code>. 1. team : Returns the team associated with a participant. - mock simulates the find_by method in TeamsUser object and returns team_user <code> 1. response : Returns the response associated with a participant. - mock used to simulate the return of a response from the participant's response_map <code> 1. name : Returns the name of a participant. <code> 1. fullname : Returns the full name of a participant. <code> 1. handle : Returns the handle of a participant. <code> 1. delete : Deletes a participant according to the participant's current associations and the value passed to the variable 'force'. - mock to simulate the return of the participant team when asked - mock used in the testing of a forceful delete of a participant with a team association consisting of a single team user by simulating the return of team length to be one when asked <code> 1. force_delete : Method called inside #delete to remove the participant and all necessary associations. Testing of this method is covered through the testing of #delete. 2. topic_name : Returns the topic name associated with a participant. - mock used in the testing of an existing topic name by simulating the return of a participant's topic when asked <code> 1. able_to_review : Checks and returns the review rights of a participant. <code> 1. email : Sends an email to a participant, verifying an assignment registration. <code> 1. scores : Returns a hash of values that are applicable to a participant's assignment scores (i.e. <code> 1. get_permissions : Returns the permissions association with a participant based on participant type (i.e. participant, reader, reviewer, submitter). <code> 1. get_authorization : Returns the participant's authorization role based on its access rights (can_submit,can_review,can_take_quiz). <code> 1. sort_by_name : Returns the sorted array of participants by name. <code>. Run all Rspec tests from the terminal : <code> Run a specific Rspec test from the terminal : <code> Run Rspec tests from terminal with mutations to test quality of test cases : <code> 1.1. more information about mutation testing can be found in the link provided in the External Links section of this wiki. Through the implementation of quality unit tests, 100.00% path coverage was achieved. 1.1. <link> 1.1. <link>. Expertiza Github with implemented tests for Participant model : 1.1. <link> - tests can be found within rspec/models/participant_spec.rb Mutant gem description and use : 1.1. <link> Demo video can be found here: 1.1. <link> -This demo video involves an in depth walk through of the testing code 1.1. <link> -This demo video involves a short capture of the RSpec test run.","Excellent motivation of the tests, and good descriptions of what they return.  However, you did miss one place:  The Variables section contains a long list of objects.  It should be explained why those objects are needed."
E1464,"The requirements provided for the Open Source System project of Expertiza were as follows : The file refactored in this project is user.rb (295 lines) which is User Model class for expertiza project. This model helps the user log in and checks whether the user is a student, admin or a super admin. It helps reset passwords and assign instrcutors to the user. <link> is a project developed using <link> platform. This can be achieved by submitting code base, URL of hosted code on remote server and Wiki submissions. It is an open source application and the code can be cloned from <link> . 1. <link> 2. <link> 3. <link>. Any website that wants to provide content or features based on user preferences/roles needs to handle users. Expertiza does this with the help of the User Model(user.rb). Expertiza has multiple user roles like Student, Instructor, Admin, Super Admin and TA. User Model helps the user login and verify to access privileges for each user. The User Model(user.rb) also handles various other features like user access management (for example, Setting Instructors, TAs for a set of Students), user password management (for example, forgot password feature, generating random password) etc. We have identified quite a few issues in the User Model of the Expertiza project. Given below are the issues that we have identified (and fixed thereafter): 1. Inefficient boolean logic present at multiple lines in the code 2. Not using [ ] & { } instead of Array.new & Hash.new (for reasons like code hygiene and efficiency) 3. Using “key => value” instead of “key: value” 4. Not using in-built array functions such as one?, any?, zero?, first & last 5. Methods that were not being used 6. Methods that were just delegating their implementations to other functions in other classes. For each of the above stated issues, we have made the following changes to improve the code: Before Changes <code> After Changes <code>. For reasons like code hygiene and efficiency, we did the following changes: Before Changes <code> After Changes <code> Before Changes <code> After Changes <code>. Before Changes <code> After Changes <code> Before Changes <code> After Changes <code> Before Changes <code> After Changes <code> Before Changes <code> After Changes <code> Before Changes <code> Before Changes <code> After Changes <code> Before Changes <code> After Changes <code>. Before Changes <code> After Changes <code>. Before Changes <code> After Changes The function was commented out. <code>. Before Changes <code> After Changes The code was commented out and delegated using the code <code>. We have refactored the code for user.rb file (User Model File) for Expertiza project without changing the functionality of the expertiza project. As such there would be no changes in the functionality of the project, but inorder to verfiy the changes made please follow the below mentioned steps: 1. Go to <link> <image> 2. Enter Username as 'user2' OR 'user3' OR 'user4' and Password as 'password' where user2 is ADMIN and user3, user4 are STUDENT. For Example: Username: 'user3' and Password: 'user3' 5. You should be able to view the forgotten password page with message saying ""Incorrect Name/Password"" <image> 6. Moreover, the forgotten password page can also be accessed directly, by clicking on ""Forgotten your password?"" link in the <link> page <image>. The project had redundant code, multiple functionalities in a method and extra conditional statements in User Model file. Thus we refactored the User Model file according to global rules for Model class file and Rails 4.0 standard.","Report tends to be a listing of code changes, w/no description.  Except for style, there is no application of design principles."
E2104,"<link> is an open-source project developed using the Ruby on Rails framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. When an assignment or review approaches its deadline on Expertiza, students initially should receive deadline reminder emails at a specific time before the deadline that the instructor has preconfigured. Lack of this functionality sometimes results in students missing their assignment submission deadlines and thus losing marks. Students should receive this type of deadline reminder email. So this amendment to the project involves adding an asynchronous deadline reminder mailer to the application. Modified Files 1.1. app/models/due_date.rb 1.2. test/models/due_date.rb 1.3. db/migrate/20210319212323_create_delayed_jobs.rb Implementation approach 1) Reminder email sent when assignment or review is approaching deadline: In the due_date.rb file, whenever a new due date is created or an existing due date is updated, the 'start_reminder' method will be fired which will eventually be added to the delayed_job queue. This job will be executed at a preconfigured time before deadline, where it will fire the method 'reminder' which will be added to the delayed job queue by the handle_asynchronously method of gem 'delayed_job_active_record'. Inside the reminder method, we will fetch three attributes - assignment_id, deadline_type, due_at. These three attributes will be used to decide the deadline type ( submission or review or teammate review ), fetch the participant email for that assignment, fetch the deadline threshold and at the end send the email reminder at a specified threshold time before the deadline which will contain all the details such as assignment names link to assignment and assignment type ( submission or review or teammate review). Testing We have used Rspec for testing the delayed_job functionalities. Using the test-driven development (TDD) approach, we have added a Rspec test which checks whether the mail is enqueued upon the firing of the reminder method. We have used Rspec for testing the delayed_job functionalities. Using the test-driven development (TDD) approach, we have added a Rspec test which checks whether the call for reminder method is enqueued upon the firing of the start_reminder method, with the proper scheduled execution time. NOTE: All the reminder mails except the ones for the reviewer are sent to expertiza.development@gmail.com ,as this is already set in the development environment. Additional Links 1.1. Git pull link: <link> 1.2. VCL deployment: <link> References 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> Team <link> <link> <link>. 1. app/models/due_date.rb 2. test/models/due_date.rb 3. db/migrate/20210319212323_create_delayed_jobs.rb. 1) Reminder email sent when assignment or review is approaching deadline: In the due_date.rb file, whenever a new due date is created or an existing due date is updated, the 'start_reminder' method will be fired which will eventually be added to the delayed_job queue. This job will be executed at a preconfigured time before deadline, where it will fire the method 'reminder' which will be added to the delayed job queue by the handle_asynchronously method of gem 'delayed_job_active_record'. Inside the reminder method, we will fetch three attributes - assignment_id, deadline_type, due_at. These three attributes will be used to decide the deadline type ( submission or review or teammate review ), fetch the participant email for that assignment, fetch the deadline threshold and at the end send the email reminder at a specified threshold time before the deadline which will contain all the details such as assignment names link to assignment and assignment type ( submission or review or teammate review). We have used Rspec for testing the delayed_job functionalities. Using the test-driven development (TDD) approach, we have added a Rspec test which checks whether the mail is enqueued upon the firing of the reminder method. We have used Rspec for testing the delayed_job functionalities. Using the test-driven development (TDD) approach, we have added a Rspec test which checks whether the call for reminder method is enqueued upon the firing of the start_reminder method, with the proper scheduled execution time. NOTE: All the reminder mails except the ones for the reviewer are sent to expertiza.development@gmail.com ,as this is already set in the development environment. 1. Git pull link: <link> 2. VCL deployment: <link>. 1. <link> 2. <link> 3. <link> 4. <link>.","This page is very rudimentary.  It just gives the implementation approach, and does not show what changes have been made.  The Testing section has one paragraph repeated twice."
E2026,"This means that refactoring projects, testing projects, and Mozilla projects need to use the same rubric. The feature concluded with allowing 4 rubric scenarios for an assignment: 1. Rubric does not vary by round or by topic. 2. Rubric varies by round, but not by topic. 3. Rubric varies by topic, but not by round. 4. Rubric varies by both round and topic. Our proposed solution keeps the previous implementation, but changes rubric filtering to allow instructors/TAs to use filters that are not theirs. Following the <link> footsteps, this diagram depicts the interactions between an instructor and an assignment. Alongside editing topics and due dates, the instructor can edit what rubrics are assigned to an assignment. The topics tab allows instructors to specify which rubric associates with each topic while the rubrics tab lets the instructor determine if the assignment will vary by topic or not. <image>. Now find questionnaire by assignment questionnaire and type rather than assignment/type/round_number/topic_id. 1.3. assignment_participant.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1.4. feedback_response_map.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1.5. on_the_fly_calc.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1.6. self_review_response_map.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1.7. tag_prompt_deployment.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1. Views 1.1. edit/_rubrics.html.erb : Modify to set assignment vary by round/topic fields instead of non persisted flags 1. Helpers 1.1. assignment_helper.rb : Refactor by moving function to find questionnaire / assignment questionnaire to assignment_form.rb. 1.2. grades_helper.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1.3. summary_helper.rb : Refactor to use the persisted assignment fields for varying by topic/round instead of using methods 1. DB Migrate 1.1. XXXXXXXXX_add_vary_by_topic_to_assignments.rb : Migration to add “vary by topic” field to assignment 1.2. XXXXXXXXX_add_vary_by_round_to_assignments.rb : Migration to add “vary by round” field to assignment 1. All of the related test files to accommodate the above changes. <image> In addition to that, we will be adding two additional boolean fields to the assignment schema: vary_by_round and vary_by_topic . As discussed earlier, in the previous implementation, these were methods that were called to determine if an assignment varied by round/topic rather than a persisted value. It would always query for the AQs by assignment id, current round number, and current topic id. However, if the assignment did not have reviews that vary by round or topic, these values would be nil on the AQ, and the previous query would fail. To fix this, we modified the assignment_questionnaire function in the AssignmentForm model to check the Assignment's vary_by_round and vary_by_topic flags, and then add the corresponding fields to the query. This means that: 1. If an assignment does not vary by round or by topic, the query for AQs will be by assignment id only. 2. If the assignment varies by round but not topic, the query for AQs will be by assignment id and round number. <image>. Here we describe manual UI Testing steps to edit an existing assignment to allow it have to specialized rubrics for different topic types. Make sure Has topics? <image> 1. Click on Rubrics tab. You will see 2 checkboxes ( Review rubric varies by round? , Review rubric varies by topic? ) 2. Check the box for Review rubric varies by topic? 3. Go to Topics tab and verify that there is dropdown menu beside each Topic. 4. Select a rubric from dropdown menu, and click Save <image> 1. Go back to Home, and select the same assignment to edit. When you click on Topics tab, you should see the rubric you had selected. 1. This was due to how questionnaires were retrieved/found for an assignment. Staggered deadlines also rely on finding questionnaires using topic id, which isn't handled until after an assignment is made. 1. Unresolved Another quality of life improvement is that staggered deadlines and topics cannot be added to an assignment until after the assignment has been created and saved.","The explanations are reasonable at first glance, but I think they depend too much on being familiar with the E1936 design.  One example is the Database Flow section.  The statement, ""We will be re-adding the database flow that was added in the previous implementation, linking sign_up_topic to assignment_questionnaire via a topic_id field."" is not clear, and the table below does not help to elucidate it.  Then it discusses the vary_by_round and vary_by_topic fields, referrring the reader to the previous design doc.  It would be much better if this document were self-contained.  That said, though, other aspects are well written."
E2073,"Its purpose is to allow teachers and students an environment to enhance learning. For teachers, they can use this platform to create, edit, or grade assignments. Students are able to view assignments that teachers have posted, create teams for projects, and review other peers assignments. By having one platform for students and teachers to engage, students are able to stay on top of their tasks and teachers can monitor how well their students are learning the material. Courses are an essential part of Expertiza as students and teachers can be grouped together by a course. The course_controller has many important functionalities such as creating, modifying, and deleting courses. When the course_controller is called to create or modify a course, the course's name, institution ID, directory path, or info can be updated. Our task for this assignment is to refactor some of the code in the course_controller file. Why do we want to refactor course_controller? Refactoring is the process of restructuring existing code without changing its behavior. It is important to refactor to keep your code readable, understandable, and clean so that future developers can understand your code when they want to implement or change existing code. For the course_controller, we wanted to refactor it to courses_controller since the current convention of rails requires that controllers be plural. We also wanted to improve readability by removing redundant code in two functions and also fixing a warning message to be more understandable. Lastly we removed a function in course_controller that belonged in a model and not a controller. The following tasks were accomplished in this project: 1)The class should be named courses_controller.rb, to follow the current Rails convention that controllers should be named in the plural. 2)Edit the warning message in the copy function 3)Remove duplicate code in the create and update functions 4)Remove create_course_node function as it does not belong in a controller and move it to course_node.rb. Issue: The class should be named courses_controller.rb, to follow the current Rails convention that controllers should be named in the plural. Solution: By changing the name of the class from course_controller.rb to courses_controller.rb, we needed to go through all the files where Course was called and change it to Courses. <image> <image> <image> <image>. Issue: Edit the warning message in the copy function Solution: When a student submits a file it should be stored at the path that the teacher specifies. If a teacher specifies a path that already has a filed stored then we need to warn the student that the path is already in use and where they should go if they do not want to overwrite the current file. <image>. Issue: Remove duplicate code in the create and update functions Solution: In the first and second images below, we have removed the redundant code in the create and update functions. We replaced the redundant code with a function called set_courses_fields which we defined in the third image. <image> <image> <image>. Issue: Remove create_course_node function as it does not belong in a controller and move it to course_node.rb Solution: For the first image, we have removed the course_node function from the courses_controller.rb file. The second image we are in the models folder for course_node.rb and we have moved course_node from course_controller.rb into this file. <image> <image>. In the subsections below we are testing the create and update methods. File: courses_controller_spec.rb Command to run rspec on file: rspec spec/controllers/courses_controller_spec.rb <image> <image> <image>. <link> In order to manually test some of the functionalities after refactoring course_controller: 1. Login as instructor. 1. In order to create a course, there is a blue circle with a plus button on the right side of the page next to Actions 2. Click on the blue circle and it will lead you to the New Course Page 3. Fill in the information to create a new course 4. After filling in the course information, click create and it should take you back to tree_display/list page 5. The course you created should be listed at the top. 1. In order to update a course, go to a course that you want to modify 2. To the right of the course you have chosen there will be two rows of icons 3. On the first row there should be a pencil, red X, and a paper icon, if the pencil does not appear you may need to refresh the page 4. To edit click on the pencil icon, this will take you to the edit page 5. At the edit page you can edit whichever part of the course you want to change 6. After you make your edits, click update and it will take you back to tree_display/list page where the updates will display. 1. <link> 2. <link> 3. <link> 4. <link>.","Very good description of what you needed to do, and how you accomplished it.  Would have been improved if the Refactorings (""Refactors"") section titles had included what changes were made (""Rename to courses_controller""), rather than just saying ""Issue 1"", etc.  The test plan could have had more prose description, like your refactorings had."
E2103,"A response is the object that is created when someone fills out a review rubric, such as when one writes a review, gives feedback to a reviewer, or fills out a survey. Responses to the individual rubric items are kept in Answer objects; each Answer object has a response_id to say what Response it is part of. It is not the worst controller in the system, but it would be much clearer if its method names were more descriptive of what they do. 2. def scores This should be a model method (in response.rb)! 3. def new This method contains a complicated condition that determines whether the submission has been updated since the last time it was reviewed. If it has not, then the reviewer can edit his/her previous review. If there has been an update, then the reviewer gets a new review form to “update” the review. It would make sense to have a model method that tests whether there has been a review since the last file or link was submitted. Then the code here would just call that function. It would be a lot clearer what the new method is doing. Perhaps this method should also be included in the refactoring, for the sake of clarity of the resulting code. 6. def show_calibration_results_for_student This method makes about five db accesses. This method was poorly named and commented. This method was called within the controller methods Edit and New, and is used to set any instance variable objects that the controller will need during these actions. <image>. This method appears to have been created to replace the code at lines 71-74, however these particular lines of code are never repeated, and any calculation or business logic regarding scoresd should be (and is) in the model, the method scores is not necessary. The method scores was deleted as part of this refactor. <image>. The reason this method was complicated and needed refactoring was due to the fact that when a response is being created, that particular Response object must be created when the User first begins a new Response (so do the Answer object(s)). A new response also has to be created when there have not been any reviews for a particular current round, and also when a reviewee has updated their submission after the most recent review in the current round. So far, this method was refactored by moving much of the logic to the Response model in the method populate_new_response. In this method, references to a response map and the current round (if any) of a response are used to determine whether a previously-created or a new response object is used in this new review. <image> <image>. The main issue with this method was the naming and poorly commented code, making the purpose and functionality of the method obscure. This method is called whenever a user is editing or viewing a response - in this case, the controller already has access to the particular Response object in question and thus this method is used to get a reference to the questionnaire corresponding to the Response object and question id. Due to the functionality and because it requires access to a Response object already, this method was renamed to get_questionnaire_from_response. Comments were added to clarify its functionality. <image>. Again, the main issue with this method was the name and poorly commented code. This method has similar, but not the same, functionality as the set_questionnaire (get_questionnaire_from_response) method, except this method is called when a user is creating a new Response object, thus the controller does not have access to the Response object in question. In this case, it is possible to get a reference to the appropriate questionnaire by using the ResponseMap object instead of the Response object. This method was subsequently renamed to get_questionnaire_from_response_map and the code was commented to clarify its functionality. <image>. Therefore we created a method calibration_results_info Response.rb which would calculate the the required review_response_map, calibration_response_map , question objects keeping the logic and entire database access into the model. <image> <image>. Due to the size and structure of Expertiza, we thought it would be appropriate to provide some guidance on how to manually test the main refactors in this project, the new method and the show_calibration_results_for_student method. 1. def new In order to make a new response, we suggest logging in as (or impersonating) one of the following students: 1. student7602 1. student7605 1. student7607 Once signed in or impersonating one of the student accounts listed above, navigate to the Program 1 assignment, and click on it. Now, click on Others work, and request a new submission to review. From here, click begin to see that a new response form is generated. Again, click on Others work, and click on Show calibration results. Now, the calibration results for this review response will be visible to the user.","Very good description of what was done.  The paragraphs about each change are easily understandable.  I find the dark-background screenshots less readable than the default light-background changed code snippets from Github, but this is a minor issue.  The instructions on manual testing assume that the tester is using the anonymized db, which might not be true."
E1790,"For the next step, we would like to utilize this raw data for virtualized charts and grading metrics. Currently, there are three models created to store the raw data from metrics source. <image>. <image>. <image>. <image>. <image> The current framework only defined the schema, but the models are still empty, and the methods of the data parser have not been implemented yet. When new data is added to the database, developers don't have to change the metric_data_point_types and metric_data_points tables. The developers only need to add two methods to translate the data type to and from strings. Besides, we only have GitHub to be our data source currently. As a result, we also need to find other data sources to be one of the grading metrics. In schema metric_data_points, value has been defined as a string to accommodate different data type. But this requires the program to translate data into strings when storing the data and translating the string back to data when accessing it. To make it worse, using strings to store data types, such as float type or Time class, would either lose the precision or incur more abundant storage space. Our first and current source for grading metrics is GitHub, and Zach and Tyler have implemented the integration with GitHub API for fetching the commit data. However, the integration looks that it is still in the first stage; the app can fetch the data and store into the database. We don't have actual implementations of getting the valid data and the usage of this data to be one of the grading metrics yet. 1.Since each metric and metric_data_point_type could have many metric_data_points, we need to add has_many metric_data_points in those models. To make the database store different data types as they are, we can create a metric_data_value table for each data type. When storing data in the database, we can create the new data using the factory pattern as shown in the figure below, and the string parameter “type” could be used for specifying which type of data is created. Each metric_data_point_type and metric combination could only have one metric_data_point, so if it already exists, the new data will replace the old one. When querying data in the database, we can first utilize the has_many relationship between metric and metri_data_point to get all the metric_data_points. Finally use the value_id in metric_data_points table to find the data. <image> This design could solve the problem discussed above. Each data would be stored as their original data type. Thus, we do not need to convert data type to/from strings which lead to precision loss or space problem. Each time when we need to add a new datatype, we don’t need to modify the previous schema, we only need to add a new model and schema. For example, even if the new data type is an array, we could use the dimension field in metric_data_point_type to specify the length of the array, then use the value_id field in metric_data_point to specify the start id of the array, finally in the corresponding metric_data_value table we can use the start id and the dimension to get all the elements in the array. Secondly, the table of each data type would need to store the id, which costs extra space. 2. We also need to implement the data parser methods. The data parser methods will be implemented in the data source model class. We can utilize Ruby’s duck typing character to implement polymorphism, so when the application gets a data source object, it could invoke the parser method without knowing which type of data source it is. This ensures this program is closed to modification and the data source is open to extension. It allows further extension on new metric sources. <image> Each parser will parse the given data source and use the metric data factory to create model for each data then use these data to create the metric model. 1. Given a valid url of GitHub, the GitHub parser could correctly get all the data. 2. Given a valid url of Readability, the Readability parser could correctly get all the data. 3. Given a valid url of Trello, the Trello parser could correctly get all the data. 4. Test that the parser should correctly create metric_data_point_type if it doesn’t exist. 5. Test that the parser should be able to create the correct type of metric_data_value model according to the type specified by the metric_data_point_type. 6. Test that the parser should correctly create metric_data_value models if it doesn’t exist. 7. Test that the parser should correctly update metric_data_value models if it already exist. 8. Test that the metric_data_point_value could be correctly queried with the data from a given metric.","Reviewers generally liked it in the second round, and I think you've done a good job of describing what you would do in narrative form, which is the main point.  However, as noted by one reviewer, you could have done a better job of explaining the differences between your readability metrics.  Also, the huge model code detracts from readability; you'd have to zoom out to see it all.  The test plan is very sparse."
E2021,"The reviews performed by the students right now are being assigned on a first-come-first-serve basis. a team is assigned to a single topic, whereas the assignment of the reviews is many-many mapping with each review being assigned to different students and each student assigned to different reviews. For example, let us consider a situation where user 'A' wants the review assigned to user 'B' and user 'B' wants the review assigned to user 'A'. <image> Motivation From a set R of available review topics, the user u from set U have to be matched with a pre-configured number of topics r1,r2,r3.....rk. So,the idea is to record the user priority and time-stamp at which r is bid. Once the bidding timeline is past, the recorded information for each bis is then fed to the algorithm, which would then match user u to review r1,r2,r3...rk. How should the algorithm match students S to the Review set R ? <image> From the diagram we can see that the three users are represented as u1, u2, u3 and the the three reviews are r1,r2,r3. In phase 1 : All users want the review 1 so all of them point to r1 and we see r1 is owned by u1 and r2 is owned by u2 and r3 by u3. In phase 2 : u1 is assigned r1 and now u2 points to r3 which is now its highest priority because r1 is removed and similarly u3 points to r2. In phase 3 : r2 is assigned to u3 and and r3 is assigned to u2, thus satisfying all. The latest implementation of the problem was E1986 <link> <link> . 2. All of the implementation code was put in the controller which is inappropriate for a controller. The code should probably be in the corresponding model file. 3. The tests that they have written are not adequate. The part of the code that requires modification is- app/views/assignments/edit.html.erb <image> As we can see from the code attached we need to move this code away from the Review Strategy tab. <image> <image> We have also added a checkbox to check if the algorithm is run or not based on the value of the checkbox that is ticked. <image> Webservice : The previous team had not set up the web service as internet-facing. Various refactors on the code were also performed the changes are shown below. The first file where we want to apply the principle to is the: app/controllers/review_bidding_controller.rb The code is shown below: 1.1.Previous Implementation : <image> From this, we can see the entire method can be moved to the model to reduce the stress on the model. 1.2.Previous Implementation : <image> The implemented changes by moving the code to the model are shown in the code attached below. 1.3.Current Implementation : <image> 2.1.Previous Implementation : The other function that we choose to move to controller hence to make sure the computations are performed only the model side is first the reviewer_bidding_data. <image> 2.2.Previous Implementation : The function reviewer_self topic shown below was also moved. <image> 2.4.Current Implementation The reviewer_self_topic is used to get the necessary self topic that is been assigned to the reviewer and the values will be returned based on what is been assigned. <image> 3.2.Current Implementation This has been removed to assign the color directly in the view. It has been implemented as shown below. <image> This implementation has been modified after looking into the pull request <link> which involves a similar implementation for the bidding of the projects. Write suitable tests to ensure that the implementation is working. The previous implementation gave their try on implementing the required test but all of them are commented out. So, they are required to be redone during this implementation. Previous Implementation <image> Previous Implementation We can see that the previous implementation has all the tests removed, the changed test cases are shown in the testing subtopic. <image> Current Implementation The current testing implementation has been shown below, in the Plan for Testing section. Then the bidding algorithm should assign reviews randomly. Automatic testing : Few tests have been written for both the controller and the models : the file we can see that tests were written for the controller that checks if the web-service call is fine. <image> The screenshot of the passed tests are shown below : <image> The other tests that are written are for the model. <image> The other tests written checks if the assignment id is assigned right and if its an integer. <image> The screenshot of the passed tests are shown below : <image> In all of the above cases, all the projects have to be assigned to at least one reviewer so that every project has been peer-reviewed.","This is a well written description, but unfortunately it assumes that the reader is familiar with bidding for topics, which is not necessarily true.  You show ""before"" and ""after"" code sequences, but it would be much clearer if the changes were shown in Github diff view.  However, the descriptions of the changes are quite understandable.  Ditto for the tests."
E1848.3,An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. We fixed this error in our pull request.,"Description of mosts tests is very good. However, it's still a long list, and it would have been good if the tests were grouped, to bring some order to the description.  The scores(questions) test could be described in more detail by saying what objects are being created and why."
E2074,"LIVE LINK: <link> DEMO: <link> Currently, teammate review is just an extension of the project review feature. Although the features the project review function provides is adequate for team-to-team evaluations, it has been requested that the feature be extended specifically for teammate reviews. Some of theses critical features could greatly improve user experience, such as: 1. The ability to set a deadline on teammate reviews 2. The ability to check/verify who has completed a teammate review 3. The ability to create an assignment only involving a teammate review Implementing the third feature would also give the possibility of auto-grading for peer-reviews, vastly improving the UX for instructors. This would allow for deadline-based functionality on teammates review, satisfying the first feature requirement. 1.2. This would be added to the deadline_type model 1. Addition to Assignment.rb 1.1. A new function, participants_completed_teammate_review will be added to grab a list of participants that completed teammate reviews for a particular assignment 1.2. This will involve an innerjoin op on the ReviewMap , Assignment , and Participant table Frontend changes: 1. Modify Due Date tab functionality 1.1. Assignments will be allowed to have 0 rounds of reviews. 1.3. If there are no submission or review deadlines at all, ""Your Work"" and ""Others Work"" will not show on the participant's homepage for the assignment 1. Modify List Submissions page for assignments 1.1. In the Team members column, all the students who have not reviewed their teammates will show a red dot next to their name, indicating a missing review. [PLAN] : I propose a method that will achieve the following goals: 1. Add the ability on the front end to set a deadline on teammate reviews Below is a graphic showing the implementation on the website, under the due dates tab for an assignment. <image> A new button will be added, and after clicking the instructor can then add a deadline to the teammate review. 2. Ability to restrict when users do teammate reviews. Below is a graphic of the new behavior on the ""Your team"" page. When the deadline has passed for teammate reviews, the edit button will show inability to edit, as well as an informative graphic (the tooltip) <image> 3. Ability to quickly check which teammates have completed team reviews in the current UI. Below is a graphic of the changes to the instructor view for an assignment. It shows a red dot to signify the student has not finished a peer review. <image> 4. Ability to have a teammate review only assignment. Below is a graphic of the due dates tab for an assignment and the changes made. After selecting the new teammate review deadline, then a new row will appear. This allows the instructor to have an assignment that only features a teammate review. This allowed for differentiation between other deadline types. 2. Another checkbox was added to be conditionally displayed on the assignment edit page under the due-dates tab above the previous ""Team formation deadline"" checkbox. After being clicked, another row is added to the due date table itself for the use to select a teammate review deadline. In the screenshot below, note how the change now does an individual check across all deadline types for the current assignment instead of just one deadline type. This allows for instructors to have a singular assignment when the only purpose is to peer review teammates. After setting the assignment to 0 review rounds, the user can then add the teammate review deadline (or any other deadline type) and create an assignment strictly for that purpose. <image> ^After setting to 0 reviews, the other rows related to submissions disappear 5. Teammate review date restriction. Now teammate reviews can have a set deadline and can restrict the users based on preconfigured settings. When the deadline has passed, students will no longer see a button to edit or modify a previous teammate review. (lines 59-60 show the controller changes) <image> Changes to controller^ <image> ^^ ""Review"" and ""Edit"" button links are hidden past the due date 6. Extra conditional hiding values on the student task pages. When assignments only feature teammate reviews, the ""Your Work"" and ""Others's Work"" tabs are hidden on the student task page. (shown below, notice how there is only one task named ""Teammate Review Deadline"" and the hidden ""Your Work/Other's Work"" fields) <image> 7. Rspec testing. <image> 8. Quick view to see who has performed teammate reviews. In the example below, student 8597 is the only one who has completed ALL their teammate review. <image>. Rspec tests for the due date deadline type addition was added to the previous 'due_date_spec.rb' file. All the changes above where verified to work without bugs or errors (including all test cases of deadline's passing/being before today's date, the ability to make a teammate-review-only assignment, etc.).","Good job of motivating the changes, and describing them.  Not all of the code changes, e.g., assignment_helper, are covered in the document.  There is no plan for automated testing.  But the document is very clear."
E1525,"The main advantage of using Expertiza, in an educational environment, is for the instructor to introduce peer reviewing among the students. Expertiza allows the instructor to create and customize assignments, create a list of topics the students can sign up for, have students work on teams and then review each other's assignments at the end. Currently the teaming information is only accessible from specific assignment. Sometimes a course may require a student to work with at least, for example 5 other students. To check teaming information for a course, It would be helpful for a student to have a way in Expertiza to see how many other students (s)he has teamed with during a course, and who those students are. An instructor might also want to see this information for grading purposes. Similarly, instructors and students want to see scores that teammates have given them for contributions to their team projects. New features that will be added to the system will 1. Allow a student to see how many other students (s)he has teamed with during a course, and who those students are. 2. Allow students to see the review score that teammates have given them for contributions to their team projects. 3. Allow the instructor to be able to see the teaming information of all the students. 4. Prevent students from seeing individual review scores when the number of team members who reviewed the student is < k, where k should be settable by the instructor when editing an assignment. 1. <link> This view file displays various statistics related to review scores obtained by the student in different assignments. 1. Use Case 1: Allow a student to see how many other students (s)he has teamed with during a course, and who those students are. 1.1. Actor: Student 1.2. Actions: 1.1.1. Student logs in to Expertiza. 1. Use Case 2: Allow students to see the review score that teammates have given them for contributions to their team projects. 1.1. Actor: Student 1.2. Actions: 1.1.1. Student logs in to Expertiza. 1.1.2. Open any assignment on the “Assignments” page. 1.1.3. Open “Your Scores” to find the review scores given by teammates in the “Teammate review” column. We plan to use this section for allowing the students to see their review scores given by the team mates. 1. Use Case 3: Allow the instructor to be able to see the teaming information of all the students. 1.1. Actor: Instructor 1.2. Actions: 1.1.1. Instructor logs in to Expertiza. This would involve adding similar changes as allowing students to view their teammates in the Instructors views. 1. Use Case 4: Instructor decides whether a student would be able to view his teammate reviews for an assignment or not by checking an option while creating the assignment. 1.1. Actor: Instructor 1.2. Actions: 1.1.1. Instructor logs in to Expertiza. 1.3. Actor: Student 1.4. Actions: 1.1.1. Student logs in to Expertiza. 1.1.2. Students should be able to see individual review scores only when the instructor has checked the ""Show Teammate Reviews"" option. This can be achieved by adding an additional option to the ""Create Assignment"" page of the instructor. <image> Use Case Diagram. The instructor can look at the overview of the course by clicking on the ""360 assessment dashboard"" action of the particular course. Further upon clicking each assignment (""New Assignment"") in this case, the individual scores for each student will be seen in a table as shown below. <image>. Similarly, the instructor can look at the review and metareview scores for each student by clicking on the ""View aggregated team mate and metareviews"" action of the particular course. <image> Along with the aggregate scores for each student, this page also shows the class averages for each assignment as shown in the image below. <image>. To see the new functionality for student: Login to the Expertiza application using any student account like ‘user5403’, then select assignment. 1. The student should be able to see all the teammates he has teamed with in specific courses on the left panel. 2. To see the teammate review, select “your score” in one assignment, there is one column named “teammate review” showing the teammate review you got from your teammates for this assignment. To see the new functionality for instructor: Login to Expertiza as an instructor using username “user6”. 1. To see the fixed dashboard, click on the ""360 assessment dashboard"" action of some particular course. 2. To see the review and metareview scores for each student in one course, click on the ""View aggregated team mate and metareviews"" action of that particular course.","Good listing of use cases. Specs say that the # of teammates in the entire course should be shown.  Design doc says only the # of teammates in an assignment will be displayed. We changed the conditions under which teammates will see reviews.  This will be controlled by a checkbox on the General tab of assignment creation, not based on the number of teammates k.  This change is not reflected in the doc."
E1570,"Expertiza is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). The Expertiza project is supported by the National Science Foundation.<ref> <link> </ref><ref> <link> </ref>. Classes involved: <code> Controller Responsibilities: This controller deals with displaying “trees” of objects to the instructor. When an instructor logs in, (s)he is greeted with a homepage that lists questionnaires (rubrics, quizzes, surveys), courses, and assignments. These objects are displayed in a “tree,” allowing the user to click on the top-level object and see the objects beneath it. Bad practices followed: 1. Many Duplicate Methods. 2. Very Long Methods combining many Functionalities. 3. Redundant methods not being used anywhere. Refactoring to be done: 1. Split get_children_node_ng and get_children_node_2_ng into smaller methods and give reasonable names to them and make sure implement common code in a single method. 2. Merge all the repeating methods into a single method. 3. Write functional tests for the TreeDispayController. 4. Remove commented code in list method. We used the DRY principle while refactoring our code to remove duplicates in get_children_node_ng and get_children_node_2_ng methods. <table>. <table>. 1. Login in as an instructor or admin using credentials (admin with password: admin or instructor6 with password: password) 2. To check the changes made in go_to_menu_items method, hover over the Manage tab in the navigation bar on the top and click all the links and check whether they are being redirected to correct pages. For example, if Questionnaires is clicked, you should be | redirected directly to the page displaying all the questionnaires with its sub-categories like Reviews, Surveys etc. 3. To test the changes made in get_children_node_ng and get_children_node_2_ng methods, click on the sub categories under each of the parent tree displays (Courses, Assignments and Questionnaires) and all of them will further expand to show the details. (Click on the name of the Course/Asignment/Questionnaire to expand them). <image>. <image>. <image>. <table>. <table>. This is a new Common Method for both get_children_node_ng and get_children_node_2_ng that does the functionality of rendering a page with data from all nodes by calling another method populate_1_row(). There is another Method call that happens in this method which as a whole renders the List View. <code>. 'This is a new Method that is called from Method populate_row() and fetches all the child node names from respective Controller actions and then populates the tmpObject. <code>. This is also a common Method which integrates the rendering functionality of get_children_node_ng and get_children_node_2_ng making sure both levels are properly populated in the view.' <code>. There was a Method which dint have any Routes defined in the Routes.rb file and was not called in any of the Controller . After Careful analysis we descided to remove the method from the tree Display Controller. <code>. <table>. We have written Rspec tests for the tree_display_controller and have run the same with success. From the home directory of the application, run the test as ""rspec spec/controllers/tree_display_controller_spec.rb"" <code>. <references></references>.","Good description of the changes that have been made; however, for the tests, the code is just given, without any description of why they test what they test."
E1984,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.8. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link>. Currently, these self-review scores are not used to compute the final scores for the assignment. <image> The objectives we achieved for this project are as follows: 1. Provide a formula that takes both the peer review score and self-review score into account for calculating the composite score . 2. The composite score should get higher as the self-review score gets closer to the peer-review score . 3. Make sure that the peer-review scores are not visible before the self-review submission. 4. Display the composite score on the “View Scores” page. 5. Display the self-review scores in the ""View Scores"" page and in the ""Alternate"" (heat-map) view of the peer-reviews, highlighting them as a different type of review. According to self assessment rules: students get more points as their self-review get closer to the scores given by their peer reviewers. The following flowchart illustrates the proccess of how scores are retreived to implement the self-review score feature. Feel free to review all the code changes in Github by following the next link: <link> 1. grades_controller.rb <image> <image> 1. assignment_participant.rb <image> 1. response_map.rb <image> 1. vm_question_response.rb <image> <image>. Basically, we have two actors: on one side we have the Instructor which will create an assignment, add students to it and enable the self-review option. On the other side, students will be able not only to review their peers' work, but also will be required to review their own work in order to view their final scores, if the self-review option is enabled by the instructor. <image> <image> 1. Actors: 1. Instructor: This actor is responsible for creating assignments and adding students to the assignment. 1. Actions 1. Instructor: Create Assignment, Enable Self-Review. 2. Student: Login, Add work and Submit, Submit Self-Review, View Scores. <image> Currently, Expertiza allows students to submit an assignment and provides a link to self-review their work. Once the self-reviewing is done, the self-review score gets stored in the database and it is not further used in calculating the overall score of the assignment. Thus, students can score themselves higher than what they should actually get when considering the peer-review scores. So, to make a productive use of the self-review score and to help students learn self-evaluating themselves, we will make changes in the review score calculation, explained in the section below. We derived a formula that takes into account the self-review score and calculates a composite score , which will be the student's final score for a given assignment: <image> More information regarding the derivation of this formula can be obtain from the following document: <link>. <image> [ <link> ]. 4.1. Add student3000 and student4000 to the assignment. 6. Go to test assignment and click on work . 7. Click on Review my own work button and then the begin link to start the self review. Grade yourself accordingly and make sure to submit the self review when finished. 10. Sign in again as student4000 Go back to the assignment and click on Others work . Click on Request a new submission to review and review the student3000' s work. Don't forget to submit the review when done. Go to the assignment and click on Your Scores . Here you can see the final average peer review score, which is computed by using the proposed formula in this project. In the scores table, you can see your peer review score and self review score (cyan color) side by side. <image> <image>. Then by requirement of this project, and to make sure that every student submit their self review, the Your scores link will be disabled for the assignment. So students will only be able to review their scores after submitting their self review. <image>. 3. The composite scores are saved to the database. 4. Self-review scores are displayed with peer-review scores. 5. Student can only see their own self-review. <image>. 2. Implementing multiple score approaches. 3. Add scores from team evaluation (Your team -> Review) to the formula.","Very good job of describing the changes to be made.  Code changes are nicely diplayed.  One place for improvment: Along with the code changes, write a couple of sentences describing, for each file, the changes in that file.  "
E1797.1,"2. The student may also be able to give reviews to other works for a particular assignment. 3. There also exist timestamps for deadlines that have passed and that are upcoming for an assignment submission or a review to be done. 4. For the reviews that a student receives for his work, the student can give feedback to each of the reviews. With this, the student is able to view his entire submission history for an assignment in a convenient way. What needs to be visualized on the timeline: 1. Hyperlink submission record with timestamps 2. File upload record with timestamps 3. Due dates 4. Visualization of Peer review of others works, which includes: 1.1. A Review hyperlink that redirects to the review by clicking on it 1.2. The Round number (To be displayed only if the assignment has multiple rounds) 1.3. Timestamps 5. Visualization of Author feedback on others review, which includes: 1.1. A Feedback hyperlink that redirects to the feedback by clicking on it 1.2. Timestamps. Issue-1: Submission records with timestamps: A student can submit their work for an assignment using ""Your work"" button in the respective assignment page. Issue-2: Due dates: There are different due dates for every assignment like Round-1 submission, Round-2 submission, Round-1 review and Round-2 review Due Dates. Issue-3: Peer Review other's work: A student needs to review work of different teams during the course of the assignment. As of now in order to view the review, Expertiza requires the user to go to the ""other's work"" page in the assignment. This issue includes a timestamp, link to view review, review round number to be shown in the graph. Note: this review is the peer review given by this particular student to different teams as part of the assignment, not the reviews the student received. Issue-4: Author's feedback on other's Review A student can give feedback for the review he/she received for a specific assignment. It must be noted that the feedback here is not the feedback he got for review given by him/her but the feedback he/she gave for the reviews the had received. The assignment has several deadlines or due dates. There are due dates for Round 1 and Round 2 submissions for this particular assignment. There are also review deadlines for each of the rounds for the assignment. The student can give a peer review to other students' work on the assignment. The student is able to give feedback to the peer reviews that he received. We have used Orange color for a round's submission and review deadline and Green color for all hyperlink submissions, file submissions and Cream color for feedback, peer review, team review and self review submissions. So in summary, the following things have to be present on the timeline that are visualized as rectangular boxes on the timeline: 1. The submission hyperlink box with the hyperlink 2. The file upload box with a link to the uploaded file 3. The Round 1 peer review deadline 4. The Round 1 submission due date 5. The Round 2 peer review deadline 6. The Round 2 submission due date 7. The Peer Review that the student gave to other students 8. The feedback that the student gave to received reviews 9. A self-feedback that the student gave to himself 10. A team review that the student can give to his teammates 11. Additionally, all the rectangular boxed have timestamps that display when the submission was made or the due date of that task Apart from this, various buttons were also added to better interact with the timeline. Similarly, the reviews submitted by the student is linked by the hyperlink in the Peer review rectangular box on the timeline. The types of due dates included are Round submission or Round review due date. 3. You shall see a timeline with duedates 4. Click on your work, submit hyperlink/files, same will be displayed in that particular assignment home page(navigate to previous page) 5. Review teammates work/ give a peer review/ submit a self review/ submit feedback to review received, same will be reflected in respective assignment home page along with a hyperlink to the particular review given. 6. The submission along with the timestamps for each submission along with hyperlinks to each of student's work is displayed in timeline. Timeline behavior when the student opens the view page of a newly created assignment 1. When the user has not made any submissions, reviews or feedbacks to reviews to the assignment, the timeline must only display the due dates of the assignment. So only those submissions will be displayed on the timeline. In the peer review submission rectangular box displayed on the timeline after the student submits a peer review, instead of showing the label ""Review for [topic name]"", the label says ""Review"". Timeline behavior when a submitted hyperlink is removed 1. When a submitted hyperlink is removed, the submission must not be displayed on the timeline any more.","The reviewers complained about various diagrams being missing, but I liked the flow in general.  Except for the Program Design section, which had a lot of prose without any examples or diagrams to concretize what was being said, it was easy to read and easy to see what was meant.  The code snippets had narratives to explain what they were about, though a little more detail would have been helpful."
E1452,"The AssignmentTeam and CourseTeam models, as sibling subclasses of the Team model, tended to share certain functionality. This assignment called for refactoring those classes to make them better conform to ruby convention and to support the DRY (""Don't Repeat Yourself"")<ref> <link> </ref> principle of avoiding duplicate code. A quick skim of the code turned up a few places where the AssignmentTeam and CourseTeam models had similar functionality, as well as multiple methods and variables that needed better names. Some preliminary suggestions were run past the point of contact for this section of the codebase. They are summarized as follows: 1. The 'participants' and 'get_participants' methods in AssignmentTeam appear to have the same functionality, so these should be refactored into a single method. 2. The 'create_team_and_node' method will be renamed to 'create' to better follow accepted Ruby conventions. 1.1. A few other methods that could also be named better. For example, 'remove_team_by_id(id)' could be 'delete(id)'. 3. The 'includes?' method will be renamed to 'has_participant?' 4. There are some common responsibilities in both AssignmentTeam and CourseTeam, so that code will be pushed up into the superclass Team. This project took a two-stage approach. The first stage involved renaming methods and variables, but largely avoiding invasive code changes that could have an impact on the functionality. The second stage separately made changes like merging or removing duplicate functions. Several main goals were kept in mind throughout this process: 1. DRY 2. Ruby naming conventions 3. Project style conventions 4. Good design cosiderations, such as high cohesion and low coupling. <image>. 1. The import/export functionality for different team participants could be combined and simplified. This responsibility could probably be broken out into separate classes so that this responsiblity is encapsulated better. 2. Rather than extending the Team class to create separate classes to capture related functionality when teams are associated with assignments or courses, it might be better to just associate teams with courses or assignments directly and then delegate related functionality (like importing/exporting data) to separate helper classes. 1. The renaming and refactoring was performed as suggested in the given requirements. These changes helped enforce consistency and common conventions. 2. Some common functionality was combined to adhere to the DRY principle. 3. Methods were grouped and organized within their model classes to make them easier to read and mentally consume, and to suggest groups of responsibilities for potential future work. <references/>. 1. OSS - E1452 project on GitHub: <link> 2. Expertiza Project Documentation: <link> 3. Working Expertiza Site: <link> 4. Expertiza on GitHub: <link>.",Very clear.
E1859,"Expertiza is an online assignment grading platform. Instructors can create assignments and implement peer reviews for submitted assignments. This project concerns the creation of a system for visualizing student performance on those assignments, primarily as graded in peer reviews. Graphs will be made to show various rubric criteria and the class' performance on the criteria. If the criteria are the same for multiple stages of review, an instructor should be able to compare performance over time or between reviews. Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.5. <link> 1.1.1. <link> 1.6. <link> 1.7. <link> 1.8. <link> 1.9. <link> 1.1.1. <link> 1.1.2. <link> 1.10. <link>. Our task is to provide an interactive visualization or a table for instructors that shows how their class performed on selected rubric criteria. Such feature would be immensely helpful for instructors as it would assist them to identify what they need to focus more attention on. For example, creating a graph showing the average scores for all or a certain subset of main rubric criteria (questionnaire). If the average score of the class on selected criteria (question) is low means the instructor can emphasize more on the learning materials related to it. The visualizations will be implemented as either a single or stacked bar chart with a bar for each of the selected criteria to be observed. If a single bar, then the height of the bar will be the total class average, but a stacked bar chart may be better to show the percentage of the class that received each score. The changes made to the expertiza project will primarily include HTML/ERB changes to the view files to accommodate the added charts on the page and the necessary javascript to allow responsive design. Brief controller modifications will be made to facilitate database filtering to get the displayed data. 1. On clicking Manage and then on assignments, following page appears. <image> 2. Click on 'view score' icon of an assignment. The summary report page of the selected assignment comes up. <image> 3. Following are mockup screens which we wish to create: a) Instructor would select the round and rubric criteria of the assignment for which he/she wants to view the class performance. <image> b) The bar graph of the class performance for those criteria would be displayed. <image>. The flowchart representing graphical flow of an instructor visiting view scores under assignments is given below: <image>. We have used the lightweight <link> library for displaying the chart data on the page, with standard HTML for all of the options and dropdowns for option selection. The following graph shows the view of the 'view scores' page after the modifications. The instructor selects a subset of rubric criteria for which he/she wants to know how a class performed for a particular round. A bar graph of the average score of the class for that subset of criteria is displayed. <image> The above graph shows an average score of the class for 10 rubric criteria in Round 1 for assignment ""OSS project/Writing assignment 2"" selected by the instructor. A live demo with randomly generated data can be found on <link>. We have implemented a new partial file criteria_charts to the team_chart that display the bar graph with existing data collected by the grades controller methods to the view page. Modified files: <code>. <code>. <code>. The specification of the project does not require us to use automated tests. However, we have tested the existing tests after the addition of new features to the grades_controller. We have approached <link> testing framework. The UI feature tests are conducted manually. To validate all functionality of the chart when adding new features or fixing old ones, the following criteria were tested manually for expected functionality: 1. Chart is displaying correctly 1.1. Bars are showing up where expected 1.2. Bar annotations are showing the expected value 1.3. Criteria labels are for the correct bar and displaying correct values 1.4. Hover text is displaying the correct values 1.5. Null values are not present on the chart 1.6. Correct colors are used for the multi-round view 2. Show Labels checkbox works as expected 3. Round Criteria is displaying correctly 1.1. Round dropdown menu shows all rounds for the assignment 1.2. Selecting a round changes the criteria checkboxes 1.3. All checkboxes are displayed with appropriate text 1.4. Checkboxes correctly remove or add criterion bars to the chart. We have modified one of the existing tests for grades controller because the addition of new functionality broke that particular test. The added test handles the chart functionality correctly. <code>.","The documentation seems to show an outdated version of the screen that selects criteria to be shown.  The code has just been pasted in; there should be a description, and it would've been much better to give a link to Github, where the changes could be seen.  Some reviewers said that tests were not covered, but that deficiency has been fixed in the final version.  Would've liked to have seen some description of what the test does, however."
E1522,"Through the use of charts and graphs to enhance certain pages, such as the student's scores page and the instructor's scores page, and allow for the users to get an at-a-glance analysis of the data without having to dive into the tables. Our project video <link>. There are quite a few gems available to visualize data in Ruby on Rails, like Goolgecharts <ref> <link> </ref> and GoogleVisualr <ref> <link> </ref>. These gems makes use of Google Visualization API and wrap it to let users write ruby codes to present nice charts in their web pages instead of using Javascript. GoogleVisualr is a a wrapper around the Google Chart Tools<ref> <link> </ref> which allows users to create beautiful charts with just Ruby, instead of writing JavaScript if using the Google Chart Tools directly. Just include the following gem in the Gemfile. <code> And in the Rails layout, load Google Ajax API in the head tag, at the very top. <code>. 1. In your model or controller, write Ruby code to create your chart (e.g. Area Chart, Bar Chart, even Spark Lines etc). <code> 1. Configure your chart with any of the options as listed in Google Chart Tools' API Docs. <code> 1. In your view, invoke a chart.to_js(div_id) method and that will magically generate and insert JavaScript into the final HTML output. <code>. The following code presents the example of area chart. <code>. The following code presents the example of area chart. <code>. The following code presents the example of area chart. <code> The resulting chart looks like below. <image>. Googlecharts is a ruby gem implements a wrapper for Google Chart API. gchartrb<ref> <link> </ref> is a Ruby wrapper around the Google chart API<ref> <link> </ref>. In our project, we use gchartrb to generate all the bar charts in the visualization. <code>. The following example code would generate a bar chart. <code> The bar chart would look like below. <image>. The following example code would generate a line chart. <code> The bar chart would look like below. <image>. The 'Review Score' view of the assignments can be enhanced using these visualization. From a user experience perspective having a more prioritized view of the scores would be beneficial. <image> The above scoring which is in tabular form can be enhanced with charts. The scores page was augmented with bar graphs displaying the distributions of each column, as well as a circle icon for the average score for that column. <image>. We created a new view under the grades views, called participant_charts. This view is included as a partial in the grades/view_my_scores view. For the bar charts we constructed a method that, given the score and the type of bar chart, populates an instance variable that contains the charts. The code was included in the grades controller (grades_controller.rb file) and is shown below <code> The width of the bars is dependent on the number of scores to show. For the circle charts showing the averages of the columns we used a javascript library, circle.js. By simply passing the scores to the .js code in the grades view as shown in the code below. The circle is then rendered automatically in a div block elsewhere in the view named the same as the id: tag below <code>. Making use of an existing function, toggleElement, we added a link above the charts table that when clicked hides/shows the charts. The code to accomplish this is shown below <code>. Based on the uniformity of the review scores, we compiled a reliability metric. A good reliability score indicates that the grade given to the assignment by the reviewers is to be trusted, whereas a poor reliability score indicates that there was a high level of disagreement in the reviewers and the instructors should perhaps take a closer look at the participant's assignment. This reliability score is computed from the standard deviation of the review scores. A standard deviation that's less than 10 will award a good reliability score. A standard deviation between 10 and 20 will award a medium reliability score, whereas a standard deviation greater than 20 will give a poor reliability score. <image> The color of the three bars Icon, and the number of filled bars is representative of the reliability of the reviews. <image> <image> A similar method to the one used for the bar charts was used. In this case, a horizontal bar chart was created, and the data was dictated by the qualitative score that was passed into the method. This score could be 'good', 'medium' or 'bad'. <code>. In the instructor view of the assignment scores we added similar charts to the one shown for students. In this case we include a class average in the form of a circle chart, and a class distribution in the form of a bar chart. An example of this is shown below <image>.","Obvious that you invested some effort in thinking about how data was to be presented. Good visual design, and good mockups of the changes to be made. It's not clear what the three horizontal bars represent, nor is it clear how you are going to calculate reliability."
E1577,"The current version of The Expertiza Project has an automated meta-review system wherein the reviewer gets an e-mail containing various metrics of his review like relevance, plagiarism, number of words etc. , whenever a review is submitted. The purpose of this project is to give students some metrics on the content of the review when the automated meta reviews are disabled. submitting a review of an assignment or adding an assignment to a user profile. The project requires completion of the following tasks 1. create database table to record all the metrics 2. create code to calculate the values of the metrics and also ensure that the code runs fast enough (can give results within 5 seconds) as the current auto text metrics functionality is very slow and diminishes user experience. <image>. <image> The image shows the schema for the new table which will be created to store the calculated values of the metrics. 2. total_word_count: This attribute contains the total number of words for a particular review(response_id). 3. diff_word_count: This attribute contains the total number of different words for a particular review(response_id). 6. offensive_count: This attribute contains the number of comments containing offensive words. 1. View Reviews Text Metrics as Reviewer: As a reviewer, he/she can see the text metrics of individual reviews as well as aggregate metrics for all the reviews done for an assignment/project. 2. View Reviews Text Metrics as Instructor: As an instructor, he/she can see the text metrics of reviews received by any team for a particular project/assignment. The instructor can also see the text metrics of the reviews done by any reviewer. 1. For use case 1 , test whether the text metrics Db has entries populated for each type of metrics (no. of words, no. of offensive words, etc), once the reviewer submits any reviews. 2. For use case 2 , test if the instructor can see the text metrics of reviews received by each team for a project/assignment. Also, test if the instructor can see the text metrics done by any reviewer. <image>. review submitted. 1.3. A new row is updated in the table when a new review is saved or submitted and the respective row gets updated when an existing review is re-edited or submitted. <image> 2. Create code to calculate the values of the metrics and also ensure that the code runs fast enough (can give results within 5 seconds) as the current auto text metrics functionality is very slow and diminishes user experience. 1.3. The calculation code uses the Answer table to pull out the saved review content using the response_id of the review. It incorporates a set each for offensive words list, suggestive words list, and a list of problem pointing words. The function then calculates the following: 1.1.1. Total number of words in the review 1.1.2. Different number of words in the review 1.1.3. Number of offensive words in the review - the method uses a set of offensive words as a dictionary and compares this with each word in the review 1.1.4. Number of words which signals a suggestion in the review - the method uses a set of suggestive words as a dictionary and compares this with each word in the review 1.1.5. Number of words which signal a problem being pointed out in the review - the method uses a set of problem pointing words as a dictionary and compares this with each word in the review 1.1.6. Number of questions responded to with complete sentences - each sentence which has more than seven words qualify for a complete sentence <image> 3. Create partials for both students and instructors: 1.1. Views are created for both students and instructors to display the text metrics calculated for each review and assignment. These views are accessible through links in the student report page and instructor _review_report.html.erb page 1.2. The following are screenshots where the links are included in the above mentioned pages <image> <image> <image> 1.3. The following is a screenshot when a student saves or submits a review <image> 1.4. The following is a screenshot when the student clicks the View Text Metrics link <image> 1.5. The following is a screenshot when an instructor uses the View Review Report link at the assignments page for a given assignment <image> 1.6. The following is a screenshot when the instructor clicks the text metrics summary link <image> 1.7. The following is a screenshot when the instructor clicks the individual text metrics link <image> 4. Make the code work for an assignment with and without the ""vary rubric by rounds"" feat 1.1. The calculate_metric code works for each review submission in a way where it uses the response_id of each review saved/submitted to find the review text saved in Answer table. The entire review text is then thoroughly checked to calculate the required metrics. <image>.",It said that Expertiza was started by NSF; otherwise fine.
E1983,"Expertiza provides teammate reviews to gauge how much each team member contributed, but we would like to augment this data with data from external tools like Github (for example, number of commits, number of lines of code modified, number of lines added, number of lines deleted.) Overall data for the team, like the number of committers and number of commits may also help instructors to predict which projects are likely to be merged. Currently, Expertiza provides Teammate Reviews under View Scores functionality for each assignment. We need to augment this data with data from external tools like GitHub in order to validate that feedback. New metrics will be appended under each student data under the same functionality. 2. Github Metrics under View Submissions page should include a bar chart that shows the number of commits by the team throughout the assignment timeline. Overall data for the team, like the number of committers and number of commits may also help instructors to predict which projects are likely to be merged. For each participant, record should include at least: 1.1. Committer id 1.2. Total number of commits 1.3. Number of files changed 1.4. Lines of code changed 1.5. Lines of code added 1.6. Lines of code removed 1.7. Lines of code added that survived until final submission [if available from Github] 2. The code should sync the data with Github whenever someone (student or instructor) looks at a view that shows Github data. 3. The data for teams should be shown in the instructor’s View Scores window, in a new tab, probably between Reviews and Author Feedback. 1.1. Design a good view for showing data on individuals. The reason for this is that we’d like to see all the data on an individual in a single view. 4. Create a bar chart for the # of lines changed for each assignment team on “view_submissions” page. However, their work has been rejected with the feedback ""They have integrated the github metrics into expertiza to show the number of commits, pull requests status, etc against every project. They have also integrated it into the metrics. The GitHub commit data can be shown on a weekly basis instead of the current day wise. Showing the data day-wise does not add much for the instructor grading. A bar graph needs to be added to display data like no of commits, no of lines added and number of lines deleted by each user. 1. Old Graph Representation <image> 1. New Graph Representation The data is shown as a horizontal stacked graph grouped by the time range for eg: weekly or daily. The bar will show the no of commits, lines of code in a stacked manner. Actors: 1. Instructor: This actor is responsible for viewing GitHub metrics of teams and team members of an assignment. Pre-Conditions: 1. The Team should have submitted the assignment with a PR link or GitHub repository. Github Metrics Features can be accessed from manage content UI <image> Then click the 'view submissions' <image> Then we can see 'Github Metrics button' in each project submission <image> Below is the bar chart of the number of commits per week grouped by team members <image> Below is a drop-down menu that allows the instructor to change the graph to show either the number of commits, or the number of lines added or the number of lines deleted. <image> Below is a drop-down menu that allows the instructor to change the graph grouped by week or grouped by student <image> Below is view that shows overall Github metrics showing the whole team contribution. <image> Below is a pop-up preview of the Github metrics (number of lines added and deleted as well as the number of commits) of each member on each date. <image> Below is a pop-up preview of the Github metrics (number of lines added and deleted as well as the number of commits) of each member over the complete duration of the project. <image>. We intend to follow the same when implementing our end-point for pulling GitHub data. To get the data from Github we will use their query api. We will refactor their code and fix code smells with the help of the code climate platform. A bar graph needs to be added to display data like the number of commits, the number of lines of code added/removed per user basis. We tested all the existing functionality for the page where we are showing GitHub matrices. New Features which we tested are: Github Metrics By Week 1. Number Of Commits 2. Lines Added 3. Lines Deleted Github Metrics By Student 1. Number Of Commits 2. Lines Added 3. Lines Deleted ""get_chart_data"" function parses the input github data based on the type of the graph and timeline selected to the required data format required by the chartjs-ror ""horizontal_bar_chart"" function <code> Checking private method being called <code>.","I thought it would have been better to distill the reasons for rejection of last year's project, rather than just quote the feedback.  They did a very good job of showing the changes to the tables and graphs displayed in their reports.  However, there was hardly anything describing the code changes, and the tests were pasted in, with hardly any description of what they were doing."
E1929,"This <link> project, completed in the Spring of 2019, aimed to improve the charts instructors could view to see the grade statistics for a given assignment. Two charts already existed, one showing the grade distribution for all teams, and another simply showing the class average grade. Our goal for this project was to add a third chart, using <link> , which would show grade statistics for the various <link> grades within that assignment. The chart is interactive so the user (instructor) can toggle which rubric criteria, and which statistics, to display. Along with displaying the rubric criteria for a single assignment, we aimed to add a feature which would allow the comparison of compatible rubric grades from two different assignments. Contents 1.1. <link> 1.2. <link> 1.1.1. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.4. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.5. <link> 1.6. <link> 1.7. <link> 1.8. <link>. E1929 - Visualizations for Instructors - Class performance on specific rubrics An interactive visualization or table that shows how a class performed on selected rubric criteria would be immensely helpful. Webpage: login as instructor -> Manage -> Assignments -> View scores. <image> Figure 1: Existing assignment grade charts - The existing assignment grade charts show the average grade for the assignment and the grade distribution. During this project, we aimed to add a third chart which shows the distribution for specific rubric criteria within the assignment. We successfully executed all of the ideas we had during the planning phase: 1. Add new feature to show mean and median data for rubric criteria in a given assignment 2. Add new feature to show comparison 3. Performed UI testing to ensure features were operational, including edge cases 4. Added and ran RSpec and Capybara automated tests. <image> Figure 2: New Rubric Statistic Visualization - Added in the center of the existing two charts is an interactive chart the instructor can use to see the mean or median scores for whichever criteria they select. This is done on the ""Analyze Assignment"" tab, which is selected by default when the ""View Scores"" page is loaded. <image> Figure 3: New Rubric Cross-Assignment Comparison Visualization - The instructor can see a comparison between selected criteria between the current assignment and the selected assignment. The rubric criteria must be compatible in order for it to even show up in the selection list. This comparison visualization is done on the ""Compare Assignments"" tab which must be selected after the ""View Scores"" page has been loaded. 1. Refactored <link> partial view to use partials for each graphic. Previously both charts were defined together in _team_charts.html.erb, but now each graphic has its own partial view ( <link> , <link> , <link> ). In addition to the automated tests above we also performed manual testing of the newly added features to include: 1. The new feature properly initializes 1.1. Analyze Assignment tab is loaded by default 1.2. Chart is in between the other two existing charts 1.3. Round 1, all Criteria selected, and Mean are selected by default 2. Analyze Assignment tab operating correctly 1.1. Bars are showing up where expected 1.2. Bar annotations are showing the expected value 1.3. Criteria labels are for the correct bar and displaying correct values 1.4. Hover text is displaying the correct values 1.5. Null values are not present on the chart 1.6. Round dropdown menu shows all rounds for the assignment 1.7. Selecting a round changes the criteria checkboxes 1.8. All checkboxes are displayed with appropriate text 1.9. Checkboxes correctly remove or add criterion bars to the chart 3. Compare Assignments tab operating correctly 1.1. Compare Assignments tab is only displayed if compatible assignments exist 1.2. Clicking Compare Assignments tab loads that tab 1.3. (All tests from Analyze Assignment tab apply to this tab as well) 1.4. The two colors for assignment comparison are correct. The Development database shows the ScoreView as a view, but the Test database shows it as an table. 1. We were unable to find two compatible assignments in the Expertiza test database to fully test our Compare Assignments feature. 1. Put our new chart on the View Scores page, rather than on a new page 1. Since it was able to fit on the existing page while displaying all the necessary info, we figured it'd be beneficial to have all grade statistics charts together. <link> <link> <link> <link>.","For design doc: You did quite a good job describing how your tests work; unfortunately you did not do the same for the code.  The ""Decisions"" section does that to some extent, but it would be more useful if it structured in terms of what code files were changed.  Simply listing the files to be changed is not very helpful; it asks the reader to figure out for himself (her) what has been done."
E1785,"This page provides a description of the Expertiza based OSS project. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. 1. The following problems need to be handled in this project: Currently, when someone reviews a submission at the next review round (second or third review round), (s)he can't see when that submission was last updated. But a reviewer needs to know when a submission was last updated, because only submissions that are updated need to be re-reviewed.So, reviewers should be told the updated submissions and their latest submission time. 1. 1)app/controllers/student_review_controller.rb 2. 2)app/views/student_review/_responses.html.erb. In order to know whether someone's submission has been updated or not ,we need to acquire the last review time and the latest submission update time.If the submission time is later than the last review time ,it shows that the submission has been updated after previous review so we would show that submission time on the review page to notify reviewers about the update. In our case ,the submission update time includes link or file update time and Github update time. We found expertiza has a submission record which has the time of submitting and removing file or link so we could get link or file update time through submission record. Github update time is actually its latest commit time which can be acquired using OAuth token to access the github repository to get it.There's review timestamp in expertiza database ,every time you update (save or submit) a review, at that moment the time would be stored in database. We use updated_at method to get the latest review update time that is our last review time. 1. 1.get the last review time. (here sorted_reponse[0] is the last review ) <image> <image> 1. 2.Use OAuth token to access the github repositpry and get the latest commit time. <image> 1. 3.Compare Github update time with last review time <image> 1. 4.get link or file update time through submission record and compare the submission update time with last review time. <image> 1. 5.show update information on the reviewer page <image> 1. Screenshots Of The Implemented Features <image>. 1. <link> 2. <link>.","There is a prose description of one of the issues fixed.  It includes code. There's also a screenshot, but it shows only a line related to the Github functionality.  The role of Github could be more clearly explained."
E1658,"Expertiza is an educational web application created and maintained by the joint efforts of the students and the faculty at NCSU. It’s an open source project developed on Ruby on Rails platform and it’s code is available on Github. It allows students to review each other’s work and improve their work upon this feedback. The following is an Expertiza based OSS project which deals primarily with the lottery_controller.rb file. It focusses on refactoring some of the more complex methods, modifying some of the language to make it more Ruby friendly, removing some redundant code. The goal of this project is to attempt to make this part of the application easier to read and maintain. The lottery_controller contains all of the logic for running the lottery. Code climate is used in this project to detect various issues such as high cyclomatic complexity, bad naming, etc. Fix following issues mentioned below: 1. Cyclomatic complexity for run_intelligent_bid is too high. 2. Perceived complexity for run_intelligent_bid is too high. 3. Use snake_case for variable names. 4. Avoid more than 3 levels of block nesting. The code was refactored and its Code Climate rating improved from F to A. Before Refractoring: <image> After Refractoring: <image> 1. Cyclomatic complexity for run_intelligent_bid and other methods is greatly reduced. 2. Perceived complexity for run_intelligent_bid is also reduced. 3. snake_case are used for variable names. 4. More than 3 levels of block nesting is avoided. Before: <code> After: <code> Assignment using if condition was changed to conditional operator Before: <code> After: <code> Changed to find_by from find_by_id Before: <code> After: <code> Changed to the latest ruby convention for HashMaps Before: <code> After: <code> Removed unused variables Before: <code> After: <code> Changed find_by_id to find_by Before: <code> After: <code> Used snake case naming convention. Removed and condition inside if and converted it to nested if condition check. Replaced inject with each_with_obj. Before: <code> After: <code> Split the function into smaller pieces to keep up with coding conventions. Initially, the lottery controller had only one test case: for the action run_intelligent_bid. We added one more test case for run_intelligent_bid and also added test cases for all the other actions in the controller. 1. For the action run_intelligent_assignmnent, we have two test cases: 1. webservice call should be successful This is to check if the web service is getting called. But the URL given in the code is currently is of a web service that is currently down. Hence for testing purposes we have used a dummy URL. This can be replaced with the correct URL to the web service when it becomes available in the future. 1. should return json response This test case checks if the response from the web service is in JSON format or not. 2. For the action run_intelligent_bid, we have the following test cases: 1. should do intelligent assignment This was an already existing test case. It tests whether the assignment received is intelligent or not. 1. should exit gracefully when assignment not intelligent This checks if the control redirects to main page in case the assignment received is not intelligent. 3. For the action create_new_teams_for_bidding_response, we have the following test cases: 1. should create team and return teamid This test checks if the method is creating the team for bidding by taking in the assignment as parameter. 4. For the action auto_merge_teams, we have written the following test cases: 1. sorts the unassigned teams This test case checks whether the method is able to sort teams which have not been assigned to any assignments yet. As a result of our work, the code quality of the controller lottery_controller.rb has improved a lot. Code Climate has given it the highest possible rating. The original code had a code climate rating of F. We worked on all the issues pointed out by code climate and and improved the rating to A. Initially, there was only one test case and only one of the methods in the controller was covered. We have also added RSpec test cases for all the methods in the the controller and hence the test coverage has increased. This was a very good learning experience. We learnt how to write test cases in RSpec and got a chance to contribute to Open Source Software. Another major take away from the project was the chance that we got to read and understand code written by other people. This is very important skill to have when you work in the industry and can be sometimes more difficult than writing code from scratch.","The writeup is locally very good; it describes every change and gives the reason for it; ditto for tests.  What I'd like to see is a narrative overview of what was done, rather than just a bulleted list."
E1728,"This wiki provides details on the refactoring tasks that were undertaken as part of the continuous improvement to the Expertiza project. <link> is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). The Expertiza project is supported by the National Science Foundation. The application provides a complete system through which students and instructors collaborate on the learning objects as well as submit, review and grade assignments for the courses. By participating in the overall refactoring effort as part of the continuous improvement of Expertiza, students get an opportunity to work on a open source software project. This helps them gain exposure on the technologies used in the project as well as much needed experience in collaborating with peers as part of the software development process. The tasks involved as part of this refactoring effort were geared towards cleaning up the grade view logic. The initial set of tasks were: 1. For files: _scores_author_feedback.html.erb, _scores_metareview.html.erb, _scores_submitted_work.html.erb 1. Move javascript code to assets 1. For files: _scores_header.html.erb 1. Move logical code (such as L43-96) to helper file and assign self-explanatory method name 1. For files: _participant.html.erb, view_team.html.erb 1. Move javascript code to assets 2. Move logical code to helper file and assign self-explanatory method name 3. Such as L8-22 in _participant.html.erb 1. Create test file named grades_helper_spec.rb in spec/helpers 2. Write test cases for all methods in grades_helper.rb. On working with files _scores_author_feedback.html.erb, _scores_metareview.html.erb, _scores_submitted_work.html.erb, _scores_header.html.erb, the team came to find out that these files were not being used anymore in the application and the overall tasks were updated to the following: 1. Remove useless partials from grades view, such as _scores_author_feedback.html.erb, _scores_metareview.html.erb, _scores_submitted_work.html.erb, _scores_header.html.erb, etc. 2. For files _participant.html.erb, view_team.html.erb to grades_helper.rb 1. Move javascript code to assets 2. Move logical code to helper file and assign self-explanatory method name such as L8-22 in _participant.html.erb 1. Create test file named grades_helper_spec.rb in spec/helpers 2. Write test cases for all methods in grades_helper.rb by using factories. The named files were removed from the project and the deletions were committed to the repository. A new test file was created and added to the project: spec/helpers/grades_helper_spec.rb. Prior to this project, none of the existing methods in grades_helper.rb were tested using unit tests. The following unit tests were written and used to exercise the methods. An examination of the specific test cases is given below in the Test Plan section. The final two methods in this file are functional tests used to ensure all discrete functions perform normally when combined together. <code>. The main goal of testing was to ensure functionality was maintained after refactoring was completed. The following test cases exercise the functionality of the code sections which were refactored. Automated versions of these tests were written using RSpec/FactoryGirl/Selenium and appear in on the Github repository associated with this project. The functional tests may also be run manually per the descriptions below. <table>. Unit tests were required per the project assignment for helper methods which previously had no associated unit tests. These tests verified that each discrete method returned the proper values. The tests were written using RSpec/FactoryGirl and are listed in the code above. A summary of the test cases is given below. <table>.","This description will be hard to read, because long sequences of code are included without any narration, and without showing what was changed.  It would be better to use Github's diff feature to show deleted code with a red background and added code in green.  Or, if this would be too verbose, at least the difference between new and old should be described.  Test plan looks good."
E1782,"In Expertiza, students may submit links (which go into the Expertiza db) or files (which go into a directory in the Expertiza filespace). A persistent problem in Expertiza has been that instructors have created multiple assignments that had the same submission directory. In this case, the students’ submissions for one assignment went into the same directory as the submissions for another assignment, and reviewers who thought they were reviewing for one assignment were also presented with work submitted by a different student on another assignment. The basic problem has been fixed, but there are some special cases that need to be addressed, and tests need to be written. Issue #391: When an assignment is created, there needs to be a check that the submission directory is not the same as the submission directory for any other assignment. In Expertiza, the pathname for an assignment always has the instructor’s user-id (e.g., /efg) in the path, so it’s only necessary to check all assignments created by the current instructor to make sure that the specified directory path is not in use by another assignment. Make sure that the check is made correctly even if it is a TA who creates the assignment. There is a method for setting path of the submission in assignment.rb. Issue #404: When a previously created assignment is assigned to a course, any existing submissions need to be moved to a subdirectory of the course in the Expertiza filespace. (In Expertiza, an assignment can be created without being assigned to any course, and can later be assigned to a course.) Even the assigning the assignment to a course is implemented in assignment.rb. 1) assignment_controller.rb 2) assignment.rb 3) assignment/new.html.erb. -> When an instructor tries to create a new assignment with the storage directory similar to one of the other assignments or a sub-part of other pre-existing assignment the system would warn the instructor about this change and wouldn't save the assignment. -> The system once gets a create request compares the directory path to paths of all existing directories for similarity and sub-part check (sub part check is required because if not done a directory will have submission files of one assignment as well as a directory for some other assignment) and logs an error if similarity is found. -> If there errors they will be displayed in /assignment/new.html.erb Pseudo Code: <code>. When an instructor creates a new assignment, (s)he can do it without specifying the course to which assignment belongs. In this case, the directory path for the course is assigned as ""<instructor_username>/path/mentioned/while/creating/"" Eg. ""instructor6/assignment4/Java/"" However when later s(he) assigns a course to the assignment, the assignment directory path should change to ""<course_path>/>/path/mentioned/while/creating/"" Eg. ""CSC517/f17/assignment4/ruby"" Psuedo Code: Added the following logic in assignments_controller.rb update method <code>. Link to ScreenCast Bug #391 : <link> Link to ScreenCast Bug #404 : <link>. Steps to test Issue #391: 1) Login as Instructor 2) Click on Manage , select assignments. 3) New public assignment/ New private assignment 4) Fill in the details and remember the directory path 5) Save 6) Create New assignment 7) Fill in the details and keep the directory path same as the one before. 8) You will see an error displayed on top of the page. Steps to Test Issue #404: 1) Login as Instructor 2) Click on Manage , select assignments. 3) Find out an assignment which isn't assigned to a course. 4) Select assign to course badge 5) Select course from available radio button 6) Click Save 7) Now you will the updated path on assignment display list and instead of assign to course remove from course badge will be visible. Following RSPEC Code is added to assignment_spec.rb: 1) To check if the directory storage path specified by the user is a part of any other submissions directory we check if the assignment.directory_path is a part of any existing directory path: <code> 2) To check that an assignment object cannot be saved until a submission directory path is provided for that assignment: <code> 3) To check if after assigning course to an assignment is the directory path updated to contain the course path: <code> 1. 1.1. To test the changes clone the following repository <link> .","For Issue 391, a short explanation has been given along with pseudo-code.  Would be helpful to see how that relates to the actual code.  For Issue 404, no prose description has been given of the fix."
E2066,"The lottery controller assigns teams to topics based on the priorities the team gave to each signup topic during the bidding process. When the lottery controller is called to run its method run_intelligent_assignment, a web service is sent the bidding data from each team and returns a new list of teams, each of which is close to the maximum team size specified for the assignment. The web service coalesces teams that have similar bid data and then assigns those coalesced teams to topics, giving each team their top bid on a topic that hasn't been assigned yet. Teams with larger team sizes and more bids are assigned their topics first. This class contains logic to merge bids. It also contains code that creates teams, add and removes users from team. These methods are more suited to being model methods. The As much as possible, the controller should only contain standard crud actions. 1. Fix bug which created multiple bids with same topic, team and priority. 2. Call existing AssignmentTeam.rb method to create team and team node, instead of creating them separately. (DRY principle) 3. Call existing Team.rb method to add members in team. 4. Remove code that explicitly deletes dependents before deleting object and rely on dependent destroy instead. 5. Move logic to delete empty teams belonging to an assignment into assignment.rb. 6. Move logic for creation of team with members to Team.rb. 7. Move logic that merges bids of different users to Bid.rb. The parent objects being discussed here have association callbacks dependent destroy to correctly dispose dependents when it itself gets destroyed. We don't need to explicitly delete child objects before parent is deleted. <code> The function remove_user_from_previous_team explicitly deletes team_user_node before team_user is deleted. TeamUser contains code has_one :team_user_node, foreign_key: 'node_object_id', dependent: :destroy to destroy related node when team user is destroyed. <code>. <code> Team contains code has_one :team_node, foreign_key: :node_object_id, dependent: :destroy to destroy related node when team is destroyed. <code>. Controller should not contain code to generate new bids by calculate priorities of topics using previous individual bids of users. This kind of complex logic is suited to being a model method in Bid class. Create a class method merge_bids_from_different_users which accepts team id, signup topics and bids of users, and contains logic to create bids and get priorities for new bids. <link>. Expertiza already had well written test cases for lottery controller. While moving methods to model some of these test cases were moved as well. After refactoring the controller, it was tested manually and using previously written RSpec tests to ensure that no bugs were introduced. Note: Although there is a drop of 0.004% in coverage all the code that belongs to lottery_controller and which was moved to models has 100% test coverage. Test which belong to code that has been refactored have been refactored, most of the other test relating to lottery controller remain unchanged. The following commands can be run to test lottery controller and other functions that relate to E2066. <code>. <link> By following the steps below, you will be able to manually test Expertiza with E2066 fixes. 3. Scroll till you reach assignment named lottery . <image> 4. Click on the orange Intelligent Assignment button. Note: 1. If there are no non signed up teams that have bids for topics, then a 500 Internal Server Error is displayed. 2. When intelligent assignment finishes it disables bidding on topics, bidding on topics needs to be enabled to run intelligent assignment. Steps to create an assignment with topics: 1. Create a new assignment with Has teams? 2. Go back, and then edit assignment by clicking on the pencil icon. 3. Select Has topics? 4. Go to Topics tab and add a few of them. 5. Enable bidding for topics. 6. Go to Other stuff tab, select Add Participants and then Copy participants from course . Steps to signup students for topics: 1. Impersonate a participant. 2. Select assignment with topics. (for example lottery assignment) 3. Open Signup sheet . 4. Drag and drop topics under selection section. 1. app/controllers/lottery_controller.rb 2. app/models/assignment.rb 3. app/models/bid.rb 4. app/models/team.rb 5. spec/controllers/lottery_controller_spec.rb 6. spec/models/assignment_spec.rb 7. spec/models/assignment_team_spec.rb 8. spec/models/bid_spec.rb. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","Very good description of changes.  Where you titled subparts ""Example 1"" and ""Example 2"", you could have used more descriptive names.  Code sequences are shown in an easy-to-understand format, with irrelevant details elided."
E2111,"Github repository and pull request links are submitted as part of programming projects in several NC State CSC courses. As part of decoupling Github from the grades controller, we expect to decouple and revert tests for the grades controller such that the tests become independent, permitting the build to pass if our Github controller tests pass as expected. Also, some tests may need revision when code is moved from the Github Metrics controller into the new MVC architecture. This is how a user will view List Submissions when they are not yet authenticated to Github. This view is where an Instructor can login to Github via omniauth, and trigger queries to the Github API for the assignment submissions. The ""Github metrics"" link is only displayed when Github metrics are available for a submission. The updated chart view, which can be found via the ""Github Metrics"" link in the List Submissions view, displays all of the latest metrics from Github as of the page load. The Github API requires users to be authenticated to query the API. A user logs in and authorizes the oauth app for their Github account, then Github redirects the client back to Expertiza with an authentication token piggybacked. The token is then used for communication between the Expertiza server and Github. The reason ""github2021"" is used for new oauth apps is due to Github's 2021 updates to their security infrastructure -- our code handles ""github"" and ""github2021"" callbacks differently to match these security updates. We have a helper model called MetricsHelper, which contain helper methods for graphing: This method take parsed Github metrics data, authors in a PR, and dates of all commits as parameter. It Creates the bar graph for the Github metrics data. Links the authors with their Github data and assigns them a color. This method take parsed Github metrics data, authors in a PR, and dates of all commits as parameter. It Creates the pie chart for the Github metrics data. Links the authors with their Github data and assigns them a color. This method does not take any parameters. It defines the general settings of the Github metrics chart. This method does not take any parameters. It defines the labels and display of the data on the Github metrics chart. This is a new model that saves user's Github email as the identifier of their Github account. With this information, we can connect Github metrics with each students. This method takes a submitted Github pull request URL and a cursor for pagination in Github GraphQL API as parameter. It Formulate and return the actual query message to send over HTTP request to do the GraphQL query for a Github pull request. For more detailed information, check Github GraphQL API. This method takes a submitted Github repository URL, the date of the project starting date, and a cursor for pagination in Github GraphQL API as parameter. It Formulate and return the actual query message to send over HTTP request to do the GraphQL query for a Github repository. For more detailed information, check Github GraphQL API. The Metrics controller contains all the logics for querying Github metrics and present these metrics with the default show method. The default show method, which renders the html page that shows all Github metrics with a bar chart and a pie chart. This method redirect the user to Github authorization endpoint to authorize the current user. An authorized user can use the Github API with 5000 rate limits per hour. This method takes the participant id as parameter. It calls several helper methods to query Github metrics information from links that this team submitted and populate all related instance variable, which will be used in frontend presentation. This method call corresponding method to retrieve Github pull request metrics information or repository information base on different conditions. This method take all PR URLs that a team submitted and retrieve all Github metrics. This method takes all hyperlink_data includes pull request number, repository name, owner name of a single PR url as parameter and retrieve all Github metrics for a single PR. This method takes the Github metrics of a PR returned by the query as parameter, parse and store them into corresponding instance variable. This is done through Github REST API not GraphQL. This method take all repo URLs that a team submitted and retrieve all Github metrics. This method takes the Github metrics of a repo returned by the query as parameter, parse and store them into corresponding instance variable. This method does the accounting for each author in this PR. This method takes the query message as parameter and makes the actual Github api HTTP request with GraphQL and query message. This method takes the global GraphQL id of a PR object as parameter and make the actual Github api HTTP request to query the PR's status info. In addition to the changes mentioned above, we also added one authentication method, called custom_github_login in auth_controller.rb, which catches the returned 3-way handshake from the Github API when a new Github App is configured and authorized. This method creates the code used to populate, and set the coloring of, the heatgrid metrics table.","This design doc begins beautifully, describing the background, the reasons for the changes, and the implementation strategy.  It would be much better if it showed the changes to the various classes and methods and described why they were made.  Also, there should be more information on the tests, such as a list describing each test. "
E17A1.2,"The Expertiza project is software to create reusable learning objects through peer review. Expertiza enables the instructor to create new and customize existing assignments. 2. For student side, there is no way to notify for an author to tell that a particular review that they received was submitted by an expert. 3. Students are not able to see how an expert has rated the assignment, they can only see calibration results for calibrated assignments by clicking on the “Show calibration results” link. 1. Change in DB Schema 1.1. “is_calibrated” field in assignment table to “has_expert_review” 1.2. “calibrate_to” field in response_map table to “expert_review_to” 2. User interface changes 1.1. Original interface <image> <image> <image> 1. 1.1. Instructor side 1.1.1. In assignment setting page (“General” tab), change the checkbox title from “Calibrated peer-review for training?” to “Add expert peer review?” 1.1.2. When instructor clicks that checkbox, there will be a new tab named “Calibration”. Change the tab name from “Calibration” to “Expert review” on the assignment setting page <image> 1.2. Student side 1.1.1. Change the link title from “show calibration results” to “show expert peer-review results” <image> 1.1.2. Change the title in “response/show_calibration_results_for_student.html.erb” to start with “Expert review comparison report for” <image> 2. New features 1.1. Let expert review support the vary-rubric-by-round functionality 1.2. Support multiple expert reviews (Both TAs and instructors could do expert reviews) 3. Tests 1.1. Create expert_review_spec.rb file in spec/features folder 4. Additional minor changes 1.1. Reflect changes in DB schema at all places, including tests. 1.2. Change the partial file name from “_calibration.html.erb” to “_expert_review.html.erb” 1.3. Rename “response/show_calibration_results_for_student.html.erb” to “response/show_expert_review_results_for_student.html.erb” and also change other call sites 1.4. Change in database The following schema changes will be implemented using a new migration file: 1. “is_calibrated” field in assignment table to “has_expert_review” 2. “calibrate_to” field in response_map table to “expert_review_to” Change in User interface The following files will be edited to reflect the changes in user interface as mentioned in tasks: 1. #assignments/edit/_calibration.html.erb 2. #response/show_calibration_results_for_student.html.erb 3. #student_review/_responses.html.erb 4. #student_review/list.html.erb 5. #assignments/edit.html.erb. <image> 1. Instructor and TAs are the ""Experts"" that can review the assignment. 2. Multiple experts should be able to review the same assignment. 3. When a student views the review, student should understand whether the review was made by an expert or a student. 2. app/assignments/edit/_expert_review.html.erb 1.1. Showing multiple rounds of View/Begin review as per the current round and number of reviews already done by the expert (as it happens for students). 1. Existing tests should be changed according to changes in database schema and user interface. 2. A new test file expert_review_spec.rb will be created to unit test the changes with the following steps: 3. Log in using instructor's or teaching assistant's credentials. 4. General tab should have the checkbox titled 'Add expert peer review?' 6. There should be a tab ""Expert review"" on the assignment setting page. 7. Log out and log in back using student's credentials. 8. There should be a link titled 'show expert peer-review results' 9. Test multiple expert reviews by submitting multiple reviews when logged in as an instructor or TA for the same assignment. 10. Also test the vary-rubric-by-round functionality. New tests will be written to test the new features added, like : 1. assignment should support multiple expert review. 2. current assignment should support vary-rubric-by-round.","This document is rather short, but so are the requirements for this project.  As several reviewers note, the test plan is weak. The screenshots are too big and can't be seen without zooming out, but the same could be said of almost all other design docs."
E1996,"<image> 1. The ""Score awarded/average score"" column is supposed to report the score by the current student reviewer in the first round, the average score by all reviewers in the first round, and scores for the second round. 2. The scores in the ""Team Reviewed"" column would also be displayed with bar graphs, like in the ""Metrics"" column. 3. Column width should be adjusted intelligently. In the view shown, ""Reviewer"", ""Reviews done"", and ""Team reviewed"" are too wide, whereas ""Assign grade and write comments"" is too narrow. 5. Replace the team names with an anonymized version of them. 3. The width of column is set up in the _review_report.html.erb file from line 37 to line 43. Change the percentage distributed to every column to adjust the width. 4. Check the ""Score awarded/average score"" column to see if the scores are displayed. 5. Check the ""Reviewer"", ""Reviews done"", ""Team reviewed"", and ""Assign grade and write comments"" columns to see if they are adjusted as intended. 6. Check the ""Reviewer"" column to see if there is a index in each row. 7. Check the ""Team reviewed"" column to see if the team names are anonymized. <image> 1. Replace the reviewer name and team names with an anonymized version of them, as done on the main review-grader page. 3. Adjust column width intelligently. The “Comments” column is also too wide for easy reading. 4. Get rid of “Review: Round1”. It should be, “Review Round 1”. For the team names, replace the ""team.name"" with randomly generated team names. <image> 3. To adjust column width intelligently, we will change the preset width in /app/views/popup/view_review_scores_popup.html.erb. 5. Check if the reviewer names and team names are all anonymized. 7. Check if column widths are appropriate.. 8. Check if “Review: Round1” is changed to “Review Round 1”. The modification are mainly on 'Main review-grader' Page and 'Summary' page. 1. Fix the “Score awarded/average score” column so that it is populated with the correct numbers. The problem only occurs in the first round review for some teams. But these teams have review scores from some reviewers which means these teams should have reviews for them. Before Modification: <image> After Modification: <image> 2. Column width should be adjusted intelligently. In the view shown, ""Reviewer"", ""Reviews done"", and ""Team reviewed"" are too wide, whereas ""Assign grade and write comments"" is too narrow. Before Modification: <image> After Modification: <image> 3. Numbered the rows of the table (e.g., ""2. Student 8370"") so it is easy to count the lines. Before Modification: <image> After Modification: <image> 4. Replace the team names with an anonymized version of them. Before Modification: <image> After Modification: <image> 5. Adjust the bar chart. Before Modification: <image> After Modification: <image> 6. Adjust the size of text are in the comments column(last column), improve user experience. Before Modification: <image> After Modification: <image>. 1. Replace the name of the reviewer with the anonymized version, as done on the main review-grader page. Before Modification: <image> After Modification: <image> 2. The code can be located in /app/views/popup/view_review_scores_popup.html.erb. Before Modification: <image> After Modification: <image> 3. At first we removed the duplicated team name and reset the width of column. This can be implemented simply by change the width percentage of the column. Before Modification: <image> After Modification: <image> 4. We implemented our design by add a blank into the prepare_review_response function in review_response_map.rb. Before Modification: <image> After Modification: <image>. This test is for the score from reviewers. 2. In file ""spec/models/review_response_map_spec.rb"", change "".to eq(""review round1"": {questionnaire_id: 1, response_ids: [1]}, ""review round2"": {questionnaire_id: 1, response_ids: [2]})"" to "".to eq(""review round 1"": {questionnaire_id: 1, response_ids: [1]}, ""review round 2"": {questionnaire_id: 1, response_ids: [2]})"". This test is for the change that changes ""Review Round1"" to ""Review Round 1"".","There are a lot of good things about this design doc.  It itemizes the issues, and has screenshots showing exactly what has been changed.  There is enough here that the reader can easily understand what has been done.  However, the authors could have made it easier for the reader by inserting code snippets, rather than discussing code changes in long paragraphs of text.  They could have inserted paragraph breaks to make it easier to read."
E1562,"<link> is an <link> application where instructors and students can manage their course assignments. This page is for the explanation of refactoring Expertiza. Based on the DRY principle and Rails convention, we also need to rewrite some methods to adhere to the RESTful style. 1. setFlag() in due_date.rb is not adhere to Ruby on Rails naming conventions. 2. DueDate.assign_topic_deadline method is same as DeadlineHelper.create_topic_deadline. 3. The code to sort dates is duplicated in due_date.rb and response_controller.rb. 4. DeadlineHelper.set_start_due_date method is too long. 5. DueDate.default_permission needs to be refactored to get better performance. due_date.rb and deadline_helper.rb: due_date.rb is a model class to manage the deadlines of an assignment. It has methods for setting due dates for an assignment, copying due dates from one assignment to a new assignment etc. Files involved: <code> What it does: Manages the deadlines of an assignment, setting due dates for an assignment, copying due dates from one assignment to a new assignment etc. What's wrong with it: 1. It has methods making unnecessary DB calls. 2. It contains duplicated methods. What needs to be done: There are 5 major goals for this project: 1. Remove DueDate.assign_topic_deadline and use DeadlineHelper.create_topic_deadline method wherever possible. 2. Create a new method for sort in due_date.rb and invoke it from places used in due_date.rb and response_controller.rb . 3. Rename setFlag() to adhere to Rails naming conventions. 4. Refactor DueDate.default_permission . 5. Refactor DeadlineHelper.set_start_due_date method to smaller methods. DueDate.assign_topic_deadline method which is same as DeadlineHelper.create_topic_deadline method. <table> First remove the assign_topic_deadline method in due_date.rb , then use DeadlineHelper.create_topic_deadline in sign_up_sheet.rb instead. <table>. First, create a new class method in due_date.rb . <code> Then call the new method when we sort the deadline in in line number 104 of due_date.rb and in line number 61 of response_controller.rb . In due_date.rb: <table> In response_controller.rb: <table>. Find the method in due_date.rb and rename it to set_flag . <table> Then also change the method name where it is called. In background_email_reminder.rake : <table>. <table>. The set_start_due_date method in </code>deadline_helper.rb</code>is too long. First create a new method check_dependency . <code> Then call check_dependency method in the original set_start_due_date method. <table>. Log into the application with the user having an instructor's role. 1. Click on Assignments. 2. Click on Edit. 3. Click on Due dates. You will see the default of each deadline type in each row is ""Yes"", while the others are ""No"". <image>. Log into the application with the user having an instructor's role. 1. Go to Page: <link> (723 can be changed to the id of any assignments). 2. Click on Save dependencies. Successful loading of this page confirms the save dependency method. <image>. <references/>.","Writeup shows clearly the changes.  What is lacking is a prose description of the new, smaller methods, and how they accomplish the work of the old scores method."
E1969,"It is a platform which allows the instructor to create new assignments and customize new or existing assignments. Students can also peer review other students' submissions. It was reported by a student that an assignment was not able to be reviewed even though it was during the review period. That is, caused by a user navigating to the point where they should be able to conduct a review, but doing so in an indirect way. To begin our investigation of this bug, a flow chart showing most plausible user flow paths was created. This flow chart is found below: <image> <image> From this point, we began to manually test the user flow paths represented in our flow chart on our local development environment. We then set out to create an automated test suite that would test the user flow paths in a more quick and reliable way. The purpose of the following test is to iterate over a set of plausible user flow paths that terminate in being able to begin a review. The following flow paths are tested, where each step in the path is either a user clicking in the UI or navigating to a page directly using their browser: 1. Assignments -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin 2. Contact Us -> Assignments -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin 3. Home -> Assignments -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin 4. Profile -> Assignments -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin. 1. Assignments -> /student_task/view?id=3 -> Others' work -> Request a new submission to review -> Begin 2. Contact Us -> /student_task/view?id=3 -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin 3. Home -> /student_task/view?id=3 -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin 4. Profile -> /student_task/view?id=3 -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin. 1. Assignments -> /student_review/list?id=3 -> Request a new submission to review -> Begin 2. Contact Us-> /student_review/list?id=3 -> Request a new submission to review -> Begin 3. Home -> /student_review/list?id=3 -> Request a new submission to review -> Begin 4. Profile -> /student_review/list?id=3 -> Request a new submission to review -> Begin. 1. student_task/list -> ReviewTestAssignment -> /student_task/list -> ReviewTestAssignment -> Others' work -> Request a new submission to review -> Begin These test cases are implemented using the following code. <link> Review is not possible during resubmission period, even when explicitly enabled. Essentially, when a review period overlaps with the second submission period, the first review period is not available (the submission period takes priority). However, as soon as the review stage overlaps with the submission stage, you can no longer perform a review. You can simply just check to make sure that the current stage is a review stage, rather than a submission stage. This was done by changing the != to a == and the submission to a review. Now it no longer matters if it is within a submission window or not, as long as it is within the review stage. However, I added one more test within this spec file: <code> The theory behind this test is that currently, all review spec tests had the same deadlines for submission and review, so I staggered them similarly to how they were staggered in the issue documentation to ensure that the fix had been met. I also tested this manually on my local system, ensuring that I could review a test if I impersonated a user. 1. At first, create an assignment ""Test Demo Assignment"" by logging into Expertiza as an Instructor. <image> 1. Navigate to Manage->Assignments. <image> 1. Create a new assignment ""Test Demo Assignment"" and save it to ""Test_Demo"" directory. <image> 1. Set the rubrics. <image> 1. Set submission deadline to be 2 days from now. <image> 1. Set review deadline to be 4 days from now. <image> 1. Enable meta-review and reviews in both phases: submission and review. <image> 1. Add student user ""student2065"" as a participant on this assignment. <image> 1. Navigate to ""Test Demo Assignment"". Both the links, submission and review are accessible in the submission period itself. <image> 1. Click on ""Your Work"". The student can submit his work in submission period. <image> 1. Click on ""Others' Work"". The student can review other peers' work in the submission period. <image>.","The test plan for the first issue is very well explained.  However, the test code overflows the test box and is hard to read.  It could also benefit from comments.  
The second issue is well explained too, except that ""Varun's fix"" is not identified.  It should be mentioned that it is in Issue #1211, but actually, to keep the reader from having to consult other sources, some of the description of that issue could have been included in this wiki page.
The .png files are really very large, and that detracts from readability."
E1819,"In the current system, self-review scores are created and stored, but are not used afterwards. The main points of this project are as follows: 1. Create a method to calculate a derived score between self and peer-reviews. The closer the self-review is to the peer-review, the greater the score. Display this score on the ""View Scores"" page. Display the correct review scores accordingly. 3. Display the self-review scores in the ""View Scores"" and heat map of peer-reviews, denoting that they are a different type of review. Allow instructors to decide if students should be allowed to view peer-reviewers before completing their self-review. <image> When checked the system will check if a student has completed a self-review when they access the scores view. If they have not completed their self-review they will see a message indicating such. Find or create a function that will derive a score from self-reviews and peer-reviews. This score should be reflective of the difference between the students self-review score, and their peer's reviews. The purpose behind this score is to teach students to become better at reviewing their own work. By providing a score that reflects how similar their reviews are to their peer's reviews, students receive feedback on their self-assessment abilities. Create the different displays for self-reviews Instructors and students both have a heat-map view of scores from peer-reviews <image> (Instructor view pictured) student's self-review scores will be added to this view, but need to be denoted in a way that makes it easy to see this is a self-review not a peer-review. One potential option is to use an icon that shows this is a self-review score. <image> Which makes it simple for users to understand that particular column represents the scores from a self-review. blue), both denoting that the score comes from a self-review. Similar approaches can be taken to differentiate between self-review and peer-review scores in the regular ""view scores"" page. <image> (Student view pictured) The students can see their self review alongside the peer reviews. <image> The instructor has the option as described previously to limit students access to peer reviews until after they have submitted a self review. Students will see ""You have to submit self-review under 'Your work' before checking 'Your scores'."" next to ""Your scores"" until they submit a self review. There are many possible methods of deriving a score between self and peer-reviews. The simpler of approaches involves only the self and peer-review scores, and the more complex approaches may involve several other factors. The simplest approach is to simply take the difference between the average peer-review score, and the self-review score. A similar approach is utilized in several other systems, in which when a students self-review score is within 5% of their average peer-review score, they will receive the greater of the two grades. <image> A slight change to this approach is to take into account the peer score, so the greater your peers believe you performed, the greater your score is (proportional to the difference between reviews again). The self and peer-review derived grade should only be indicative of the students ability to self-review, not of the quality of the project. <image> Another approach is to derive the grade based on the percent difference between the self-review score, and the peer-review scores. However, at low scores students will see greater swings in this derived grade. <image> These previous approaches involve only the peer and self-review scores, and are the simple approaches to the problem, the following options involve greater complexity, but seek to better solve the problem at hand. The SPARK approach is discussed <link> Which results in a score that should accurately reflect the relation between self and peer scores. The scores here will need to be adjusted to match the grading scheme of the project, a score of 1 is equivalent to a 100%, and the difference between 1 and the score is representative of a lower grade, regardless of the score being above or below 1. This method also includes a second score titled SAPA, Self-Assessment to Peer-Assessment factor. This score requires teams to evaluate each team member on the same self-review rubric. After this is completed team member's self-review scores are divided by their average teammate-review score to create the SAPA. In the ranking approach, students are asked to rank their team, including themselves, from 1 to n (where n is equal to team size), where 1 is the highest score, and n is the lowest score. While the approach is very similar to the ranking approach there are important differences. 2. Implementing multiple score approaches, or hybridizing the approach. 3. The derived scores can be saved to the database. 4. Self-review scores are displayed with peer-review scores 5. Student can only see their own self-review.","A lot of the design doc relates to functionality that wasn't implemented.  My first review asked for an intuitive explanation of how the various metrics are calculated, and I still don't see one here.  In particular, I don't understand how the metrics are calculated, and since the files are .pngs and not spreadsheets, I can't look up the formulas.  Discussion of implementation is limited to a list of files modified, which will not be too helpful in understanding what is done, given that a diff in the pull request will give more info than that."
E1991,"The main idea of this project is to improve anonymized view in Expertiza. Currently, anonymized view is not implemented for students. Although, not directly required by students, instructors may want to use anonymized view when impersonating a student. In an anonymized view, instructors cannot impersonate a student because the username field has the anonymized name instead of their real name in the database. In order to be able to impersonate a student, we need to know their real names from database. In some places, anonymized names are not shown. For example, heatgrid view. We need to fix occurrences in different parts of the application where anonymized names are not shown. Use randomized American names for anonymized users. Instructors often use 'impersonate' functionality to use Expertiza as a different user. Sometimes they also need to use anonymized view while they are impersonating a student. Therefore, anonymized view needs to be extended to students as well. In order to extend Anonymized view for students, the first thing we need to do is extend the following function : <code> This function is responsible to switch back and forth between normal view and an anonymized view. When an instructor is already in Anonymized view and wants to impersonate a student, they have to quit the anonymized view and get the real username of that student. However, we want the instructor to be able to impersonate a student by using their anonymized names. The following function in impersonate_controller.rb is responsible to impersonate students. <code> user.rb This file is responsible to convert anonymized name to original name <code> impersonate_controller.rb this code is responsible to change original user name to anonymized user name <code> In the above snippet, we have omitted the irrelevant parts of code. The only change we need to do is the logic for User.find_by() function. We will add a condition to check whether the current view is anonymized or not. If anonymized mode is set, we will convert the anonymous name back to the original name of the student. We will then make 'find' query using the real name of the student instead of using their anonymized name. The procedure to do this would be opposite of what we do to get anonymized names in first place. See following code snippet : <code> The above snippet is an example of how anonymized names are generated. There are places in the application where Anonymized names are not shown even when mode is set. Here are some examples where anonymized names are not shown : 1. HeatGrid View : On 'view grades' page, there are different tabs where detailed scores, reviews, etc are displayed in a table. The table's column title use real names of the students even when Anonymized mode is set. 1. Grade Reports : Similarly, on grades page, we can see overall reports of student grades. When in Anonymized mode, the student names are not anonymized in reports. This errors are fixed by above code changes. Code change in user.rb and impersonate_controller.rb fix the issue regarding anonymized user name and team.rb fix the issue regarding the anonymized team name. Following cases are covered: 1. Instructor should be able to impersonate a user with their real name 2. Instructor should be able to impersonate a user with their anonymized name 3. Instructor should be able to impersonate a user while already impersonating a user impersonate_controller_spec.rb this code is responsible to test the functionality to switch to anonymized view for student describe ImpersonateController do <code> end. 1. Login as an instructor 2. Impersonate a student 3. Switch to Anonymized view as a student Edge cases : 1. Instructor impersonates Student1 , switches to Anonymized view, impersonates another student Student2 , the application still should be in Anonymized view. 2. Instructor switches the application into Anonymized view, impersonates a student Student1 , impersonates another student Student2 , returns back to their own account by disabling impersonate view, the app still should be in Anonymized view. users_controller_specs.rb is responsible to test functionality for student. <code>. 1. Login as an instructor 2. Switch to Anonymized view 3. Find a student from list of users 4. Assert that the student name is anonymized 5. Use the anonymized name to impersonate the real user behind anonymous entity Edge cases : 1. Impersonating Anonymized user, the application should preserve its Anonymized state even after impersonating the student. impersonate_controller_spec.rb this code is responsible to test the functionality to switch to anonymized view for student using anonymized name <code>. All the bugs related to anonymized view are covered by code code changes made in the Pull Request and corresponding test cases are in place hence no need to write any test case for this section.","This document has a good desciption of how the changes are to be made.  It describes at a high level what has been done to the code.  However, nothing is said about automized tests.
Nit: It says that the heatgrid view is not anonymized.  That is false.  However, it contains onymous names for team members. The description gives the impression that the problem is worse than it really is."
E1565,"[Expertiza] <link> is an open source project developed using the Ruby on Rails platform. It provides features like team assignments, peer review, submission of projects, grading etc. The code can be cloned and modified from GitHub. This application provides an efficient way to manage assignments, grades and reviews. Assignment.rb is the largest class in Expertiza, comprising 1105 lines of code which contains the assignment model and the related functionalities. It also contains the score module which is refactored to make the file more clean and easy to read. Files involved <code> What they do: The admin controller defines the changes that can be done on other types of users by super-admin and provides the view accordingly. What needs to be done: 1. The text field for adding a new admin/instructor has to be removed, leaving only the button. 2. When the button is clicked, it should be redirected to new user creation view making the role (super-admin, admin or instructor) selected as default. 3. Make sure that user creation works for super-admin/admin/instructor. 4. Associate the users with the institution table 5. Add a drop down to the view of creating users so that new account creator can select the institute and save it. <table>. <table>. <table>. <table>. The controller defines the changes that can be done on other types of users by super-admin and provides the view accordingly. The functionality to view the list of super-admins, admins and the instructors was added. Also changes were made to add_adminstrator method for adding a new administrator in a clean way. <code>. <code>. <code>. <code>. The user_param() method in user_controller did not have any facility to include the institution of the user. After doing a db migration and creating an institution_id in the user table, an institute can be selected while creating a new user. A mailer error is caused when a user/admin/instructor is created and the application crashes. But this is not because of an error with the functionality. Although, despite the error, one can check if the user has been created by going to Manage -> Users page in the user interface. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. In order to inspect the changes made, you can visit our deployed <link> and use the credentials mentioned at the top of the page. <image>. <image>. <image>.","""Very nice job of listing changes in an easy-to-read format.
Would be better to show before & after code side by side.
There should be some comments about why the changes were made (maybe just copy them from the tables, above)."""
E1853.2,"The Menu model is used to create the top bar menu in Expertiza. It does this by obtaining and organizing MenuItems based on the current user's Role. Before this project, there were no unit tests for menu.rb. This project seeks to bring the unit test coverage above 90%. The final result can be found at expertiza/spec/models/menu_spec.rb. This specific spec file can be run by calling the following in the expertiza directory: <code> The addition of the -fd argument will write out full descriptions of the tests and provide an easy look at the work we did. In total, we wrote 29 tests that covered all the functions in both Menu and its internal Node class. Using the given factories, we created 6 MenuItems (test1 to test6) to pass to the Menu as well as 1 Role used to test the Menu constructor. <code> We stubbed the MenuItem method, items_for_permissions, to return an array of the 6 test items that we created. <code> Other pieces of the code were stubbed because these pieces should be tested in other model specs and not Menu spec. The double 'temp' is created, which acts as a stand-in for some other class objects which interact with Menu, in order to only test the functionalities of Menu. Each method in menu.rb has at least two tests checking both a known success case and an edge case or potential failure. As an example, a detailed look at the tests for Menu#initialize is shown below. <code> This first test revealed an error in the existing menu.rb code in the line shown below. <code> The below line shows the change that we made. This allowed the code to be more robust and prevent NoMethodError from nilClass. Without this change, a menu created with a nil role will throw an error causing the program to fail unnecessarily. This is important because the default value of role is nil and that should not fail. <code> The second test covers the main use case of Menu. It is supplied with a role and assembles a menu. Only a single role is tested because further testing of roles and menus should instead be handled in integration tests. <code> The third test checks that when the menu is created with items, these items are put into nodes, arranged appropriately and contained within the menu. In this case, the children of root will contain a single item, the node with id 1, because this node has a nil parent. The other nodes all have non-nil parents. <code> The final test checks a menu without any nodes. While this case is unlikely in actual use, it is important that it can be handled without throwing any errors. When a menu without any items is created, the root will never have anything added to its children array so this array will be nil. <code> These 4 tests alone provide nearly 85% coverage of menu.rb because of how much they rely on a variety of other methods within the class. Many of the functions in menu.rb return a Menu::Node. The simplest, Menu#get_item, takes a Node id and returns the corresponding Node object. All following functions use this to test that the correct Node is returned. However to prevent circular logic, the Menu#get_item test only checks the id of the returned Node. Below is a list of the descriptions of all of the tests we wrote Menu::Node <code> <code> <code> <code> <code> <code> Menu <code> <code> <code> <code> <code> <code> <code>. The 29 tests provide 100% coverage of the lines in menu.rb. Before the project the coverage was only A video of all tests running can be seen <link> . The main repository can be found <link> The forked git repository for this project can be found <link> Below is a snapshot of the coverage of our tests. Full coverage can be found at expertiza/coverage/coverage.html. The specific coverage can be found in menu under the models tab. <image>.","I'm glad that you broke up the tests into two groups, but even 12 and 17 are pretty long lists, that would have been good to subdivide. It also seems that it would have been helpful to include or link to the code for more than two tests, though I will agree that you picked good examples.  Overall, I thnk you did a very good job of explaning what you did and how you did it."
E1655,"For users intending to view the deployed Expertiza associated with this assignment, the credentials are as follows: 1. Instructor Login: Username: instructor6 , password: password 2. Student Login: Username: student5432 , password: password We would request you to create at least 3-4 users more to test all the functionality pertaining to this project. This is because teams can be created and all the functionality with respect to email notifications can be tested. Expertiza allows the instructor to create and customize new or existing assignments and courses. It also allows the instructor to create a list of topics the students can sign up for, add users, add reviewers, add teams. Students can also peer review other student's submissions. The Mailer Helper in specific invokes methods which perform mailer related functions like sending email to newly created user, sending email to reviewer etc. Currently, the mailer notifies the students on their account creation and to the reviewer when a submission of work is done. 1. When students' accounts are created by importing a CSV file on the Users page, they receive e-mails with their user-ID and password. But if an account is created by adding them as participants to an assignment when they don't already have an account, e-mail is not sent. So, this issue is fixed by implementing the functionality of sending e-mail when account creation is done in this case. Now, e-mail is getting triggered to the concerned user whenever their account is created regardless of how their account is created. The listed files were manipulated for updating this functionality. Note that the e-mail is only triggered for a file submission and there is no mailer functionality in place for URL submission. Also, after the last round of review is completed, e-mail is no longer is getting triggered as desired. The listed files were updated or created to get the functionality working. 4.1 E-mail is triggered to an invitee whenever a participant sends out an invitation to another participant to join a team. The listed files were updated or created to get the functionality working. The controller and helper class are same as mentioned in the 4th point. New views are created for this functionality 1. app/views/mailer/partials/_team_accept_invite_html.html.erb 2. app/views/mailer/partials/_team_accept_invite_plain.html.erb 5. Mail is also getting triggered when a student responds to a teammate advertisement. The controller and helper class changed are same as mentioned in the 4th point. New views are created for this functionality. This controller derives from the Application Controller. It states the functionality of importing any kind of file like csv, xls, doc into the application. It also provides the functionality of specifying the delimiter in the file which is being imported. This controller also derives from the Application Controller. It states the CRUD operations on submitting the file or hyperlink for assignment. It provides functionality to download, create folder and delete folder after submission. It provides the functionality for submitting links and submitting hyperlinks separately. This controller also derives from the Application Controller. It states the CRUD as well as other basic operations when an invitation is sent by an user to any participant to join their team. It provides the functionality to send and accept invitations as well as to reject invitations and leave team. This is a helper file for the import_file_controller class which stores the attributes from the controller class as well as creates new users when user are created by importing a CSV file. This is a helper file for the participants_controller class. This helper file is for the mailer class. This will show all the email notifications that the user receives. 1. Login as instructor. Create a new course and assignment. 2. Add new participant not having expertiza account to an assignment using a import file option. 3. An e-mail is triggered for participant who do not have an expertiza account. 1. Login as student. Go to assignment and open your work page. 2. Upload a new file submission. If the submission is made in review stage, an e-mail is sent to a reviewer saying a new submission is available for a particular review round. 1. Login as student. Go to assignment page. 2. Go to your team and create an advertisement for this assignment. 3. Login as some other student who is the participant of the same assignment. Go to assignment page and open sign up sheet. 4. For the topic assigned to the student who created advertisement, an icon will appear in advertisement tab. 5. Clicking on this icon will redirect the student to page where student can request to join the team of students who created advertisement. 6. On click of request button, an e-mail of this response to the advertisement will be sent to the students who created advertisement. 1. An e-mail is being triggered only when a file is submitted for revision. But on the submission of a link, no such e-mail is sent.","This is a very useful description of what has been done and why.  The e-mails could be worded better (e.g., they should include the assignment name)."
E1600,"Developed by both students and faculty at <link> using <link> , <link> is a educational based web application that allows to students to peer review other student's work. Then assignments may become available to peer review by other members of the course, which provides a way to <link> grading on the work. Expertiza previously contained a self-review feature where student's were able to review their own work after submitting their assignments but it was removed due to the inconsistency with the other types of reviews. The self-review feature should allow students to review their own submission using the same rubric that was provided to other peer reviewers of the assignment. 3. Student shall do a self-review in the ""your work"" section. There should be a button called ""Review my own work"" (or ""our own work"" if it is a team assignment). A student may click the link and fill in the questionnaire just like how they would for a regular peer review. 6. If the self-review was completed in the last round and the current round uses a different questionnaire (using the vary_rubric_by_round feature), a link called ""update"" will appear, which brings students to a new page to fill in the new rubric for the new round. 8. In grades_controller.view_team, self-review responses shall be excluded. 9. In grades_controller.view, self-review responses shall be excluded. 10. The method called "" add_self_reviewer"" in ReviewMappingController , shall allow instructors to create self-review response maps. When creating a new assignment, an instructor will have an option to enable self-reviews. 1. During the beginning stages of an assignment under ""your work"" the User Interface will show a label called Self-Review and a button which reads ""Review my/our own work"" (depending on whether it is an individual or team assignment). 2. After selecting ""Review my/our own work"" the button will change to ""Begin"" (just like how a peer review works). 4. Similarly to a peer review, a user may either ""Save"" or ""Submit"" their self-review. 5. After a user saves a self-review, ""View"" and ""Edit"" links will appear. However, once a user submits their self-review, they will be unable to edit the peer review. 6. If there are multiple rounds of submissions and reviews, then in all following rounds an update link will appear to allow for students to update their self-review. 8. If a self-review is not submitted throughout the duration of the assignment then ""Work yet to be submitted"" will be shown. and hit 'Save' Now, as a student (part of this assignment) one gets a chance to perform self-review of their work. 1. Performing Self Review: 1. Login as Student and select the assignment you wish to self-review 2. In 'Your work' tab of the assignment, at the very bottom of the page you'll find an option to 'Review your work'. On clicking this button, you'll get an option to 'Begin' self-review 3. Similar to peer-reviews, you'll have questionnaire and options to 'Save' and 'Submit' your responses 4. If you select to 'Save' your response, in the 'Your work' tab, you'll find 'View' and 'Edit' links which will allow you to view and edit your response respectively 5. If you click 'Submit' and submit your response (Hit 'Ok' in the prompt), in the 'Your work' tab, you'll find 'View' link which will allow you to view your submitted response. The links changes per round of submission (if there are multiple rounds) 1. In submission stage, you are allowed to submit self-review and thus you can see 'Review your work button'. On successful submission of your response, you'll have 'View' option. On successfully saving a response, you'll have 'View' and 'Edit' 2. In review stage, you'll only have an option to 'View' your response 3. If there are multiple rounds of submissions, then you'll have a new 'Update' option to submit a new response for new/same questionnaire (similar to peer-reviews) for all upcoming rounds of submissions. 4. Finally, after the assignment is finished, you can 'View' your self-review. The self-review feature was implemented using the Model View Controller (MVC) pattern. The largest change to the codebase to accommodate for the new self-review feature was the addition of a new type of Response Map called ""SelfReviewResponseMap."" The following method was added to handle the creation of new self-review for team members. A live version of Expertiza, running with the self-review improvement, may be found at <link>. 1. <link> 2. <link> 3. <link> 4. <link>.","A lot of the wiki is simply a copy of the requirements doc.
They mentioned that they didn't use design patterns other than MVC, but they also didn't describe any principles they used, e.g., how they added the new rubric type into the existing types."
E1788,"It is a collaboration tool which lets users with different roles (student, instructor, teaching assistant) to collaborate on a course in an institution. A collaboration could be for an assignment where students teams up for an assignment and instructors grades them on the basis of their submission. Students could review other's works and give feedbacks as well. 1. <link>. 1. <link>. Heatgrid is the view which summarizes all the reviews given for the work of a participant (reviews, author feedbacks and meta reviews) on a singular web page so that an instructor can go through all the feedback given to a student and decide their grade. The columns are sortable by their score, criterion, average score for a criterion or a metric. app/views/grades/view_team.html.erb is a fairly complex for a view. It uses the concept of view models to generate the required tables. When multiple rounds of reviews are displayed on the heatgrid, a bug prevents the second round of the reviews from being sorted by their criteria, average score, or the metric mentioned above. Tables which shows each round's report were not getting sorted except the first. 1. Find out what’s preventing the reviews in the second round from being sorted by a criterion, average score or the metric even though same code is used for first and second round of the reviews. 1. Come up with a design that can be used for all the rounds of reviews and implement it. Previously, TA was also seeing instructor's course list in their home page. 1. TAs should only be able to view the heatgrid of students for the assignments in courses for which they’re TAs for. 1. Nor should a TA’s homepage list any courses (s)he is not a TA for. 1. Improve the Access Control and allow the TAs of that particular course to view the heatgrid for the participants of that particular course. 1. <link> 2. <link>. We found a discrepancy in the unique identifier property of HTML element which was causing a bug and other was related to adding a condition for populating items in the list to be returned. For Problem 1 & Problem 2 . File 1 . 1. app/assets/javascripts/view_team_in_grades.js File 2 . 1. app/views/grades/view_team.html.erb For Problem 3 . app/controllers/tree_display_controller.rb. For all the tables on the page which had each round's data, HTML component table was given same id which was only allowing only first table to have the sorting properties. We assigned a unique id to all tables based on the round number and included a class ""scoresTable"" for each table and initialised sorting features based on class. <code> <code> <image> <image>. We found that for a teaching assistant, if he/she is not a TA of a course, private field of tmp_object (already existing name) was assigned false value. So, by adding only true values in the resource object returned for the TA, ensured that only courses in which he/she is TA of will be sent back to the view. We did not change the variable name as it was out of scope of this change request. <code> <image>. We wrote tests to verify that the courses returned are only those which are specified in ta-mapping table. For that we considered 7 scenarios 1. When there is a mapping between the user and course but user is not a TA 2. When there is a mapping between TA and course - in this case the course mapped to TA should be returned 3. When there is no mapping - in this case, no course should be returned. 4. When TA is also a student of another course 5. When TA is also a student of the same course he is TA of 6. When there is mapping between TA and course - in this case TA should receive assignments which are for the mapped course 7. When there is mapping between TA and course and no assignments are linked to the course <image> Below is the test written: <code>. Based on the scenarios we added, code coverage increased by 0.2%. More report could be found from below link: 1. <link>. 1. Login as instructor/TA (who has the privilege to view summary of reviews for all rounds) 2. Choose an assignment and go to summary page You would see a page similar to below with sorting enabled on specific columns on the right side of name. <image>. Below are the screenshots displaying the fix : <image> <image> <image>. <image> <image> <image>. <image> <link> <image>. 1. Login as a TA. You would be directed to the hop page displaying all courses a TA has privilege to view. <image> Below is the db result which matches with the results displayed on the screen <image>. A video explaining the fix can be found at below location: <link>. Pull request link : 1. <link>.","The description is pretty readable, for the most part.  Toward the end, there are too few prose descriptions.  For example, about three screenfuls of code are displayed without any commentary (apart from comments in the code) describing what it does.  If you are just going to copy code, it would be more useful just to give a link to a file in the repo.  Also, below that, screenshots are juxtaposed without any indication of which screenshot shows what.  However, overall, the documentation will be helpful to future developers."
E1777,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.2. <link> 1.3. <link> 1.1.1. <link>. <link> is an open source project based on <link> framework. Students can also peer review other students' submissions. 2. The punctuation, syntax and capitalization of statements in the review strategy tab requires improvement. 3. Message to a reviewer regarding how many reviews they are required to and allowed to perform is not clear enough. 4. Reviewers are assigned new reviews based on number of previous reviews assigned for that submission, which is incorrect. Issue #402 : To allow reviewers a larger set of topics to choose from, the instructor can set the threshold (on the Review Strategy tab of assignment creation/editing) to some integer k > 0. Then any submission that has within k reviews of the fewest number can be chosen by a new reviewer. Let’s say that all submissions have at least 1 review. If k = 3, then the reviewer can choose any topic where there is a submission that has 4 or fewer reviews so far. Suppose that the minimum number of reviews for any submission is 2, but that I have reviewed all the submissions that have only 2 reviews. Then I’m not allowed to review at all (unless k > 0). The reviewer will get assigned a submission even if it has fulfilled the required number of reviews, to ensure that the reviewer always receives a new submission to review as long as it is not his own. Issue #969 : 1. a.The two statements ""Set Allowed Number of Reviews per reviewer"" and ""Set Required Number of Reviews per reviewer."" This modification is made in the app/views/assignments/edit/_review_strategy.html.erb <code> <image> <image> 1. b) When the number of allowed or required reviews is not set on the Review Strategy tab, the system does not have a message to display to a reviewer about how many submissions of work they are required to and allowed to review depending on the values set by the instructor in the ""allowed number of reviewers per reviewer"" field and the ""Set Required Number of Reviews per reviewer."" 1. Solution : This view has been implemented in the app/views/student_review/list.html.erb <code> 1. c)The capitalization and punctuation of statements such as ""Set Allowed Number of Reviews per reviewer"" and ""Set Required Number of Reviews per reviewer."" in review strategy tab are incorrect. The changes were made in the file : app/views/assignments/edit/_review_strategy.html.erb <code> 1. Issue #965 : The assignment of work to review to a reviewer depends on the number of reviews it has previously received, if that work has been assigned to a reviewer previously and its review has not been submitted then the system will still consider it such that it would not assign the same work to another reviewer if it has enough number of reviewers previously assigned to review it. This might lead to a scenario where that work was assigned to enough number of reviewers, but it does not receive enough reviews and cannot be assigned to any new reviewers either. The system now considers only the reviews that were submitted by the reviewers for that work so that every submission gets assigned to reviewers until it receives its allowed number of reviews. So when a student who has submitted oss2 tries to review others work he will not be able to select oos2 at all because he cannot review his own submission. When a person who has oss1 as topic goes to this page and he asks to get a new submission for review it will give another slot’s oss1. If he does it again it says there are no more submissions available to review for this topic. So if he has already reviewed all the other submissions of his topic oss1 and he requests for one more submission of oss1 , he will not get any more submission to review because the only one left is his own submission. Issue #969 :Set allowed number and required number of reviews per submission as 3 and 3 respectively. Now it will display ""you should perform exactly 3 reviews."" Maximum allowed reviews is 2 now. Previously for a submission after 2 people begin review its does not give any further submission to review to that user because it already reached the limit. <image> On changing the method, when we try to get a new submission we receive one. This is because the previous reviewers have only begun their reviews but have not submitted them yet. <image> Now when the previous two reviewers submit the reviews they began. Now the same new reviewer will not be able to submit his review <image>. 1. <link> 2. <link> 3. <link> 4. <link> 5. Clean Code: A handbook of agile software craftsmanship.","Generally pretty readable, but the changes to instructor and student view are not well differentiated.  Secreenshots tend to be segued together without transitions. It would also have been better to explain the changes in terms of the functionality provided, rather than the issues addressed (e.g., ""Issue #969"" is not a heading that will mean anything to the reader)."
E1722,"<link> is an open source project maintained by the students and faculty of <link> . It is a web application based on <link> that facilitates the submission and peer-review of course work. <link> is a program designed to help with testing web applications. It is able to simulate regular user interactions like clicking buttons and filling in forms. It supports a number of testing drivers, including <link> and <link> . Expertiza's heat map display is an alternative way to view assignment review scores. Instead of the standard list of reviews that are expanded one at a time, the heat map displays all reviews together in a table with scores both color coded and displayed numerically. This allows the user to quickly view all scores received and see an easily understood representation of how high or low they are. Scores show as green when they are high, and shift through shades of yellow down to red as they approach the minimum possible. The purpose of this assignment was to write functional tests for the heat map display, which it previously lacked entirely. Functional tests are a kind of block-box testing and allow the user experience to be simulated and tested. This ensures that features work as expected and meet design goals. With active development, having these tests in place ensures that any features that break due to future changes won't go unnoticed. Since our assignment was simply to implement functional tests for a small part of the Expertiza project and we only changed a single method, there wasn't an opportunity to implement any particular design pattern. We created a single file and didn't modify any existing ones. 1. heat_map_spec.rb. To run these test locally, run the following commands on a linux system <code> This will run the tests we wrote and you will be able to see the results displayed in the command prompt. For testing the heat map functionality, we used factories to create test users, groups, and assignments that reset prior to each test. <code> A test user was used to fill in and submit a review using capybara. This review then displays for the other test users. This is called to setup the review before the test is run for every case that requires a review to be present. <code> To begin testing, the test user is logged in after the first user creates the review and logs out. First, a test to verify that when no reviews are present for a user, the page does not display scores. <code> Second, the ability to view existing review scores in a heat map was tested. <code> This test checks that the user can click through to a specific reviewer to view the detailed feedback. <code> A list of the questions on the review assignment should be at the top of the screen, and should be expandable by the user. <code>. Here is a link to the <link> request we submitted.","Wrtieup should have the project number in the title.  This is a very straightforward description of all the tests.  It would really help to add a paragraph listing and summarizing the tests, so the reader could see at a glance what you have done."
E1652,"For users intending to view the deployed Expertiza associated with this assignment, the credentials are below: 1. Instructor login: username -> instructor6, password -> password 2. Student login: username -> student6420, password -> password 3. Student login: username -> student6361, password -> password. It allows students to suggest a topic for an assignment as well. Students can form teams and invite other students to join their team for various assignments. Moreover, students can post team advertisements and describe the qualities they are looking for in their team members and other students can respond to the same. In Expertiza, there are teammate advertisement, invitation and join team request features which facilitate students to form teams. Teammate advertisement works only for assignments with topics. The topic holders can create advertisement and a trumpet icon will show on the signup sheet page. If one respond to the advertisement, a join team request will be created and the topic holder can see it on “Your team” page. After a student get a team and the team is not full, (s)he should also be able to send invitations to others. When a student gets accepted by a team, all the other join team requests/pending invitations should be removed. Current Scenario : When a student gets accepted by a team, all other join team requests/pending invitations are still shown on his page and their corresponding entries in the database. When one respond to an advertisement, (s)he should only be able to respond once. Current scenario: A student can respond to an advertisement any number of times. we allow the student to save the join request to the database else we flash a note saying the student has already responded to this particular advertisement once. If the number of entries returned by this query is less than 1 means the student is requesting a join team request for the first time. If user A got a topic and user B got no topic, then A join B’s team, A’s topic be be dropped and A and B end up with a new team with no topic. Current Scenario: A student cannot create a team advertisement without a topic but can invite other students to join his/her team without a topic. But the team record should not be deleted if this team’s work has already got reviewed. Current Scenario: If the last member leaves a team, the entire team is destroyed and a destroy on team creates a ripple effect thus destroying all the work done by this team. The advertisement does not work properly when there are 2 teams posting advertisements on the same topic. Current Scenario: When 2 students post team advertisements for the same topic and a third student clicks on team advertisements, it shows both students' team advertisements. Step 1: Login as an instructor. Create a new assignment (Assignment1) and related sign up topics (Topic1, Topic2, Topic3) and add atleast 4 students as participants. (student1, student2, student3, student4) Step 2: Login as student1. Sign up for Topic1 for Assignment1. Create a team advertisement. Step 3: Login as student2. Sign up for Topic2 for Assignment1. Create a team advertisement. Step 4: Login as student3. Sign up for Topic3 for Assignment1. Invite student4 to join your team. Step 5: Login as student4 and respond to student1 and student2’s team advertisements. Step 6: Login as student1. Invite student4 from the response received to your team advertisement. Step 7: Login as student4. Accept student1 invitation. Outcome: This should delete pending team request send to student2 and delete the join team request sent by student3. Step 1: Login as an instructor and create a new assignment (Assignment1) and related sign up topics (Topic1,Topic2) and add students (student1,student2) as participants. Step 2: Login as student1 and sign up for Topic1 for Assignment1 and create a team advertisement for the same. Step 3: Login as student2 and respond to student1’s team advertisement for Assignment1. Step 4: Now as student2 again try to respond to student1’s team advertisement. Outcome: This should flash a message saying you have already responded to this team advertisement. Step 1: Login as an instructor and create a new assignment(Assignment1) and related sign up topics (Topic1,Topic2) and add students(student1,student2) as participants. Step 2: Login as student1 and before signing up for a topic go to your team’s page. Outcome: It shouldn’t allow you to invite other people to join your team or create advertisements unless you have a topic assigned to you. It cannot be tested from the UI as the team is not visible from the UI but still the entries in the databases are preserved if the team;s work is reviewed and the last member of the team leaves the team.",Good job of describing the changes made and the manual testing process.
E1607,"This page outlines the use tests for assignment creation using the Expertiza system Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link>. Assignment creation in Expertiza provides a large number of options for users. Features come at the cost of complexity; this project is focused on creating testing methods to ensure that user interaction with the assignment interface remains stable and reliable. Assignment creation is available from the Manage -> Assignments drop down on the expertiza site. Once an assignment is created it has 5 tabs for form entry. The remainder of this document will cover testing for each tab in more detail, the tabs are: 1. General 2. Topics 3. Rubrics 4. Review Strategy Check the panxing01/expertiza repository for the current development files. Currently all tests are run in two files: 1. <link> 2. <link>. The Assignment class has many questionnaires throught the AssignmentQuestionnairs class. The Questionnaire class inherits from ActiveRecord::Base and has 8 fields plus primary key and date entries. The fields are: 1. name: The name of the questionnaire row 2. instructor_id: The instuctor key linked to the row 3. private: True if private questionnaire 4. min_question_score 5. max_question_score 6. type: field showing subclass 7. display_type 8. instruction_loc: stores URL for questionnaire instruction The Questionnaire class has 11 sub-classes. They are: 1. Rubric 2. CourseEvaluationQuestionnaire 3. SurveyQuestionnaire 4. BookmarkRatingQuestionnaire 5. AuthorFeedbackQuestionnaire 6. QuizQuestionnaire 7. GlobalSurveyQuestionnaire 8. Metasurvey 9. ReviewQuestionnaire 10. MetareviewQuestionnaire 11. TeammateReviewQuestionnaire. To set up functionality testing of assignment creation feature we did the following steps: 1. Created RSpec file in /spec/features/ folder of <link> 2. Wrote functional tests using <link>. In this section, the functional test includes assignment name, course, submission directory, description URL, ""Has team?"", ""Has quiz?"" and ""Calibrated peer-review for training"". 1. assignment name <code> 1. course <code> 1. submission directory <code> 1. description URL <code> 1. ""Has team?"" <code> 1. ""Has quiz?"" <code> 1. ""Calibrated peer-review for training"" <code>. In this section, functionality of ""Edit topics"" is thoroughly tested. Below are some of the code snippets of this testing module: 1. Edit topics content <code> 1. Show/hide teams <code>. Rubrics are arranged into 3 rows of data named ""Review"", ""Author Feedback"", and ""Teammate Review"". Each row is handled under separate descriptions in order to allow quick and comprehensive testing for the seperate functions. Each row updates using a subclass of the Questionnaire class for dropdown values. Classes used are the ReviewQuestionnaire, AuthorFeedbackQuestionnaire, and the TeammateReviewQuestionnaire respectively. Testing required creation of the three questionnaire subclasses in order to populate the dropdowns. Basic code layout for testing each value change: <code>. In this module we have tested the functionality of the ""Teammate Review"" module. Some of the tests are given below: 1. Teammate Review <code> 1. Notification limit <code>. The tests can be run on the terminal using the command: <code> We can check if the functionality of the system is implemented properly seeing if the corresponding tests pass or fail.","The class hierarchy didn't need to be included in this document.  Not sure why it was.
The wiki is supposed to explain why you've written what you wrote.  But you seem to have copied the code and inserted only a line or two, not much more than in the comments in the code file."
E1770,"<link> is a peer review based system which provides incremental learning from the class. This project has been developed together by faculty and students using <link> framework. Expertiza allows the instructor to create, edit and delete assignments, create new assignment topics, assign them to a particular class or selected students, have students work on teams and then review each other's assignments at the end. Students then review the work done by other students and give suggestions to improve. Teams after reviews are allotted scores and they can refer to the peer comments to further improve their work. Code Refactoring <ref>Refactoring <link> </ref> is the process of restructuring existing computer code—changing the factoring—without changing its external behavior. Refactoring improves nonfunctional attributes of the software. Advantages include improved code readability and reduced complexity; these can improve source-code maintainability and create a more expressive internal architecture or object model to improve extensibility. Test-driven development (TDD) <ref>Test-driven development (TDD) <link> </ref> is a software development process that relies on the repetition of a very short development cycle: Requirements are turned into very specific test cases, then the software is improved to pass the new tests, only. This is opposed to software development that allows software to be added that is not proven to meet requirements. The followings are several benefits of Test-driven development (TDD). 4. Refactoring Encourages Improvements. RSpec <ref>RSpec <link> </ref> is a 'Domain Specific Language' (DSL) testing tool written in Ruby to test Ruby code. It is a behavior-driven development (BDD) framework which is extensively used in the production applications. The basic idea behind this concept is that of Test Driven Development(TDD) where the tests are written first and the development is based on writing just enough code that will fulfill those tests followed by refactoring. Refactor AssignmentParticipant model which is a subclass of Participant model. 1. Refactor scores method. 1.1. Write failing tests first. 1.3. Extract duplicated code into separate methods. 1.4. Replace the conditional with the relevant method calls. 1. Method files is exactly the same as assignment_team.rb L103. 1.1. Write failing tests first. 1.2. Solve the duplication, extract method to a new file or delete useless one. 1. Method self.import is exact the same as course_participant.rb L21. 1.1. Write failing tests first. 1.2. Solve the duplication, extract method to a new file or delete useless one. 1. Use find_by instead of dynamic method. 1.1. Write failing tests first. 1. Use find_by instead of where.first. 1.1. Write failing tests first. Because the project is aimed at using TFD(Test First Development) to refactor the AssignmentParticipant model. We wrote 38 test cases for 24 methods in assignment_participant_spec.rb first, with the RSpec tool. The introduction video to our project<ref>Introduction video to our project <link> </ref> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code>. The method scores has been converted to smaller methods scores , assignment_questionnaires , merge_scores , topic_total_scores , calculate_scores . <table>. The files method of AssignmentParticipant model is exactly the same as assignment_team.rb, L103 , so we move it to a module named Instance_method in lib/TFD1770_refactor.rb . The below two lines are added to the AssignmentParticipant model and AssignmentTeam model. require 'TFD1770_refactor' include Instance_method 1. module Instance_method <code> <code>. The self.import method of AssignmentParticipant model is exactly the same as course_participant.rb, L21 , so we move it to a module named Class_method in lib/TFD1770_refactor.rb . The below two lines are added to the AssignmentParticipant model and CourseParticipant model. require 'TFD1770_refactor' include Class_method <code> 1. module Class_method <code>. Use find_by instead of dynamic method <table> Use find_by instead of where.first <table>. 1. Expertiza Github repository<ref>Expertiza Github repository <link> </ref> 2. Our Github repository<ref>Our Github repository <link> </ref> 3. Our pull request<ref>Our pull request <link> </ref>.","You can assume that your readers know about Expertiza and RSpec.  You can launch right into the Project Description.  It's great that you wrote so many test cases, but just displaying them is not helpful.  It would be easier to read them in Github.  There should be a description of each test, and they should be organized in a way that is easy to comprehend."
E1964,"This page provides a description of the <link> project undertaken for OSS component in Object Oriented Design and Development. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link>. <link> is an Open Source project based on Ruby on Rails framework. It is a software to create renewable learning projects through peer reviews and continuous assessments. It enables group projects and project submissions via URLs and wiki pages as well. It is supported by the National Science Foundation. This project aims to easily handle review score exporting for instructor and TAs, when they try to export scores from Expertiza to <link> . Currently, no such option exists to export scores so that it can be later uploaded to WebAssign efficiently. All tasks pertaining to the completion of the project have been listed out here as follows: 1. A new button has been added to export scores. 2. All functionality to be handled will be taken care of using VanillaJS in the view of Review Report. 3. Tests have been written for the UI and CSV creation. 4. Files modified: <code>. Diagrammatic representation of the workflow of the project is shown as follows: <code> Screenshot of the Review Report page with the option to export scores (marked in red): <code> Code snippet of the added button: <code>. 1. <link> is the link to a screen recording on how to access the functionality and export the CSV file. We have written two methods inside _review_report.html.erb named exportTableToCSV and downloadCSV which are as follows: <code> <code> The output file has ""name"", ""unity_id"", ""email_id"", ""grade"" and ""comment"" fields from the Review Scores Report table. <image>. The code has been designed such that all the reviews completed by reviewers for a particular assignment can be seen, graded collected and stored easily by the click of a button. Thus, a good test case would be to check whether the required headers and data are getting stored and to check whether junk data gets stored in the csv if there are no reviews by reviewers. Newly created test cases include: 1. Test cases to check for the UI elements in Review Report html page. 2. Test case to check whether added button (""Export Review Scores To CSV File"") is actually rendered in the html page. <code> 1. Test case to see whether a simple CSV with the correct headers (Name, Unity ID, Email ID, Grade and Comments) is being created. <code>. <code>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","1) Concise and to the point wiki
2) Good architecture diagram and clear explanation of code changes
3) Tests are explained clearly
4) Only con is they have copy pasted the whole code, but since the code is well commented, it is still easy to understand.  Would have been much more readable if presented in Github diff view."
E1931,"It gives the link in raw HTML, but it should give it as a link associated with text, such as the text “this new review” linking to the page that shows the review.The email send to the instructor should also link to page that shows data on each of the reviews done on this team. Currently, this feature works as follows: <image> Whenever a new review is submitted, it is compared with the average of the previously submitted reviews. If the difference between the new submission and existing average is more than the threshold limit set, then a mail is sent to the instructor.With every review submitted for an assignment of a particular student, the average is updated.The mail sent to the instructor contains the links to the conflicted review and a summary of the reviews. Currently whenever the conflict happens,a summary link is sent to the instructor which contains the score of all the reviews but there is no view where the instructor can see all the conflicts and analyze them. <image> 1. Conflicting Review which triggered the mail <image>. The scope of this project is to send an email notification to instructor which will contain links to the conflicting review, summary link, and a link to report which can be used for analyzing. The new report will have the information like the Team(having conflicts), the standard deviation for the team review score and pictorial representation of all the review scores. The email sent to the instructor should link to a page that shows the data on each of the reviews done on this team: 1. The name of the team. 2. The members (user-IDs and/or names) 3. One line for each review received.In this line would be 1. The name of the person (or team) that submitted the review, which would be hyperlinked to the review itself 2. The score given for the review 3. A bar chart showing pictorial view 1. The average score received from reviewers. 2. The standard deviation of the score received from reviewers. 1. Feature 1: New page to show the conflict report A new view page of the report which will have the following information:- 1. The name of the team. 2. The members of the team. 3. The name of the reviewer which would be hyperlinked to the review itself. 4. The score given for the review. 5. A bar chart showing pictorial view of all the reviews for a particular team. 6. The average score received from reviewers. 7. The standard deviation of the score received from reviewers. This view have a report of all the teams on one page.This report link is added to the mail that is already being sent whenever some conflict happens.This report page will be also accessible from the reports drop-down in the instructor view. 1. A new partial is created for this view - <code> 1. Partial for the display for reviewers,scores and metrics <code> 1. Sample view of the new report - <image> 1. Method to get all the answers(scores) for a reviewee on an assignment for a particular round <code> 1. Method to get the maximum score for an assignment and for a particular round <code> 1. Method to create the bar chart showing the review scores per round <code> 1. Method to get the team members <code> 1. Method to find the standard deviation <code> 1. Method to find the average score per round per team <code> 1. Method to get the review score for each round of particular team <code> 1. Method to create a response map for the reviewers and reviewee as well as the teams and the reviewee_id <code> 1. Method to get the reviewers of a particular assignment and particular reviewee <code> 1. Feature 2: No hardcoded URLs Hardcoded URLs are be managed by the config file in order to make these links functional on every server running Expertiza and raw URLs will be given some meaningful names. 1. Code changed for removing the hardcoded URLs <image>. To test code implementation and correctness of the modified feature, we had done the following tests:- 1. Run and pass existing RSpec Tests 2. UI testing for the new functionality 3. Develop New RSpec Tests for the new code. Majority of the new functionality concerns with the new view,so we have mainly done the UI testing shown below.Some of the Rspec test added are shown below: 1. Rspec Tests for Answer Model <code> 1. Rspec Tests for Report Formatter Helper methods <code>. We have created a <link> showing the new functionality. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. <link> 9. <link> (New Created) 10. <link> (New Created) 11. <link> 12. <link> 13. <link> 14. <link> 15. <link>. 1. <link> 2. <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","It is good to show the code, but I would have preferred a full-color report from Github's diff function, like you did with Feature 2, No hardcoded URLs.  You could also have described the changes with more than a one-line bullet point."
E1846,"As part of the project we were given task to fix following two issues. 1. <link> : In the existing Expertiza setup, the database supports only UTF-8 characters. Hence, if a user enters a non UTF-8 character, the database throws an error. This further leads to loss of data while refreshing or going back to the input page as data wasn't saved in database, effectively leading to loss of entire review if there's even a single non UTF-8 character. 2. <link> : The existing expertiza stores the HTML formatting tags (Like <b> for bold) as a string. However, while rendering the string these tags are not escaped, resulting in no formatting. We need to solve the issue and display proper formatting. While trying to save utf8 chars the application was throwing up error as following <image>. If a user looks at the review score table, he/she can see html tags along with the review comments. There are other instances such as the self review page where the problem is repeated. However, while experimenting with the fix, we found out that not all tables support UTF8 formatting. <code> We changed the charset with the command: <code> Output of show create table now is <code> This solved the problem. <code> <code> If we want to fix this in all tables, we can do following for each database via script or add migration for each table. The HTML template issue was caused due to a security feature of Ruby , which by default does not evaluate strings. To resolve the HTML template issue, we used the sanitize() function. This strips all the tags that aren't whitelisted, thus ruby now renders the standard HTML tags. <link> We had to carefully test all flows where the html tags were getting rendered. However there were additional screens such as tooltip in grade scores which too were showing html tags. Therefore we added code to strip tags in html. For tooltip changes, sanitize does not work, therefore we escaped all html form the text. <code>. To check if our fix for rendering html tags works we relied on manual setup and verification. Enable “Use signup deadline” as well and set that date to day’s date 4. Save 5. Click on add participants, then import all participants from course (The following steps assume student7488 and student7489 were added to the course during this step. Double-check to make sure they were added, or use some other students that were added) 6. Login as student7488 – sign up for the first topic. 7. Login as student7489 – sign up for second topic. 8. Login as instructor6 – set signup date to yesterday’s date (so we are now past the sign up deadline) 9. Login as student7488, submit any example hyperlink for this assignment. Perform a self review under “Your scores” (Add bold, italics, lists etc.. in this review as well) 10. Do the same as student7489 11. Login as instructor6 – set submission date to yesterday’s date (so we are now past the submission deadline) 12. Login as student7488 – go to “Other’s work” and click “Request new submission for review”. Perform review. 13. Do the same as student7489. 14. Login as instructor6 – set review1 date to yesterday’s date 15. Navigate back to “Manage -> Assignments”. Click on “View review report”. Click on “View”. Click on student7488 in the “Self Review” column. You will not see HTML tags if you had entered them in step 9 instead appropriate html will be rendered. Video of running output is available here: <link> -- As you can see in the later part of the video, HTML tags have been rendered correctly. 1. Repeat 1-8, create assignments and add reviewers 2. Login as student2 and give review that contains html tags, logout 3. Login as student1 and check reviews After the fix ( refer to section 3.2 ) Following is the output with html escaped. 1. Edit any text field and enter a supported UTF8 character. 2. Save. Earlier, this step was failing as it tried entering UTF8 character to the versions table which did not support UTF8. After the fix, editing it works as seen here: <link>. We have added Rspec tests to test that the given non-UTF8 character is removed and a valid UTF-8 character is not removed. The video is available here: <link> Both the Rspec tests pass: <image>. 1. GitHub pull request: <link> 2. Video Issue 1: Non-UTF8 character removal test + Rspec runs: <link> 3. Video Issue 1: UTF-8 character support : <link> 4. Video Issue 2: Rendering HTML : <link>.","Most reviewers think the writeup was good.

The document is well-structured. The issues to be fixed, the approach and the test plan have all been clearly mentioned. Links to videos are also included."
E1963,"1. E1963 This project aims to enable the instructor to change the role of an assignment participant. There are two ways to add a new assignment participant, first being through the Add button on the assignment participant page. The motivation of E1963 was to enable the instructors adding these users using either of the methods mentioned above to change these users' role. A user can have one of the following roles - participant, reader, reviewer, submitter. 1. The existing UI had the a dropdown that displayed the role of the user: submitter, reviewer, quiz-taker, or ""participant"" (a ""participant"" can perform all three roles). We have added a Submit button below each dropdown to enable the instructor to change the role of the user. On clicking the submit button, the role associated with that user is changed in the persistent storage. We have also added a flash message which confirms the change to the user. The following issues were targeted in this project: 1. #1: The instructor does not have the option to change the role of the user, once he/she has been added to the assignment. Thus, if the instructor wishes to change the role of a user from say a reviewer to a submitter, he/she is not able to save the changes. 2. #2: With the changes made for the issue mentioned above, the instructor will be able to save the changes manually. Upon creating a new user using an Excel import, the user should have the role of a participant by default. An instructor was then unable to change the role of the assignment participant. For each of the assignment participant record, there is a dropdown which contains the role of the participant. When the instructor attempts to change the value in the dropdown, it is not reflected in the backend, as there is no call associated with it, to submit the changes. By default, the user is assigned the role of a participant in any assignment. Thus, the goal is to modify these flags and save them in the database when the role of the assignment participant is changed, so that it is a persistent change. (Submit button now resolves this issue.) (Flash message now lets the user know about the change.). 1. As an Instructor, go to Manage Assignments <image> 1. Click on add participant <image> 1. Note that the user on the first record is currently a ""Reader"" <image> 1. Change the role of the ""Reader"" to say ""Submitter"" <image> 1. Refresh or re-navigate to this page and note that the changes are reverted <image>. Changes are made in the partial for participants ""_participant.rb"", so that the submit button is rendered on the view. Upon changing the selected value for the user role, 'update_authorizations' method is called from participants controller which passes the participant id as a parameter to the method to change its role in the database. Implementing the above mentioned changes, allows the instructor to change the value of role in the dropdown which retains the corresponding record on tap of the Submit button. The instructor will be presented with a success message on changing the role of the selected participant, on clicking submit. Both the problems listed above are taken care of such as the instructor is facilitated with an option to change the participant, as well as knows that the change made will be durable. 1. Submit button has been added to each row of assignment participants <image> 1. Change the ""Reader"" to ""Submitter"", on the first record and click on submit. Flash message confirmation is also provided to the Instructor to let him/her know of the change. <image>. The view before change: <image> The view after change: <image> 3. Missing Handle: Assignment Participant on adding a new Assignment Participant: We observed that when a new assignment participant is created, if a user already exists with the username, the existing user is added to that Assignment and his existing handle attribute in Users table is mapped to the handle attribute in Participants table. However, if a new user is added not currently in the Users table, a new entry is created first in the Users table and is then replicated in the Participants table. 4. Import Assignment Participants was not working - It is expected that if a user does not exist in the system, on importing assignment participants, a user will be created and he/she will be added to the assignment as a participant. 5. The role in the Assignment Participant view doesn't have a header unlike all the other attributes on the view. The required changes are made in the partial ""_user_list.html"" The view before change: <image> The view after change: <image> 6. The role in the Course Participant view doesn't have a header unlike all the other attributes on the view. The required changes are made in the partial ""_user_list.html"" The view before change: <image> The view after change: <image>. The test verifies the change of flags mentioned above as per the authorization of the user.","The documentation looks very good. The team has not only added the probelm statement but also identified few issues that existed in the system. 
The team has clearly explained the code changes.

The only suggestion I would make for improvement is that the team could have included the code changes, e.g., in Github's diff view.  Oh, and the tests in the test plan were not described as well as the other chnages.  Would be good to explain how they work."
E1936,"2. Rubric varies by round, but not by topic. 3. Rubric varies by topic, but not by round. 4. Rubric varies by both round and topic. 1. In assignment#edit page ""Rubrics"" tab, add a checkbox to specify whether rubric should vary by topic. 2. In assignment#edit page ""Topics"" tab, add dropdown(s) next to each topic to specify which rubric(s) are associated with the topic. 1.1. The dropdown(s) should appear only if rubric should vary by topic, per the Rubrics tab. 1.2. The topic should have a multiple dropdowns (one for each round) only if rubrics vary by round, per the Rubrics tab. Before: (Rubrics tab for an Assignment) <image> Before: (Topics tab for an Assignment) <image> After: (Rubrics tab for an Assignment) <image> After: (Topics tab for an Assignment) <image>. For example, each project topic may have various rubrics depending on the round it is used (e.g., for round 1, topic may have one rubric; but for round 2, the same topic may have different rubric) 1.3. Proposed previous migration changes would break DB design and would not allow to store correctly topic and its associated rubric per different round. This requirement was not met and Vary rubric by topic checkbox in the Rubrics tab was not implemented. Particularly, the rubric for each assignment and newly added Review rubric varies by topic checkbox with which instructor may choose to vary assignment by topic or not, by checking and unchecking the checkbox is displayed in the Rubrics tab. Similarly, Topics tab of assignments has additional Questionnaires column for each topic, where instructor may specify which rubric associates with which topic. 2. Rubric varies by round, but not by topic. 3. Rubric varies by topic, but not by round. 4. Rubric varies by both round and topic. 1. Assignment 1 does not vary by round or by topic. 2. Assignment 2 varies by round, but not by topic. 3. Assignment 3 varies by topic, but not by round. 4. Assignment 4 varies by both round and topic. 1. Allow an instructor to indicate that rubric should vary by topic 1.1. PROBLEM: There is no way for an instructor to indicate that an assignments' rubric should vary by topic 1.1.1. SOLUTION: Add a new checkbox in the edit assignment Rubrics tab to indicate this preference 1.1.2. FILE: app/views/assignments/edit/_rubrics.html.erb 1.2. PROBLEM: If the user changes the ""Review rubric varies by round?"" or ""Review rubric varies by topic?"" 2. Q: How will the ""Rubric varies by topic"" selection be stored? 3. Q: What will happen if an instructor selects ""Rubric varies by topic"", makes selections on the ""Topics"" tab, and then deselects ""Rubric varies by topic""? 4. Q: What will happen after an instructor selects ""Rubric varies by topic""? These rubrics will default to those shown on the Rubrics tab. 2. Click the Rubrics tab. 3. Check the ""Review rubric varies by topic?"" After checking the ""Review rubric varies by topic?"" 1. Go to Rubrics tab and verify that both ""Review rubric varies by round?"" and ""Review rubric varies by topic?"" 1. Go to Rubrics tab and verify that ""Review rubric varies by round?"" is checked and ""Review rubric varies by topic?"" 1. Go to Rubrics tab and verify that ""Review rubric varies by round?"" is unchecked and ""Review rubric varies by topic?"" 1. Go to Rubrics tab and verify that both ""Review rubric varies by round?"" and ""Review rubric varies by topic?"" 2. Go to Topics tab and verify that there is 1 dropdown menu per round for each Topic. 1. Go to Rubrics tab and check the ""Review rubric varies by topic?"" 3. Go to Topics tab and verify that checking the ""Review rubric varies by topic?"" 2. Rubric varies by round, but not by topic. 3. Rubric varies by topic, but not by round. 4. Rubric varies by both round and topic. The instructor may use the Rubrics tab of the assignments edit page to make changes to the ""Review rubric varies by round?"" and ""Review rubric varies by topic?"" The instructor may then use the Topics tab to select the appropriate rubric(s) for every topic in the assignment. 1. Reduce the delay between changing the state of the ""Review rubric varies by topic?"" checkbox on the Rubrics tab, and the show / hide of rubric drop-downs on the Topics tab.","This is an excellent design doc, especially in the way that it explains the rationale for change and why some design options were chosen over others.  The problem/solution format to the Implementation section and the Q&A are practically unique for this project, and they are very helpful.  I still have some suggestions: The Selected Modified Code section could have used a larger font and had more comments about what the code was doing.  I also find the Github diff display more readable, like your screenshot of adding topic_id to AssignmentsQuestionnaires."
E1568,"Expertiza is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. This page provides a description of the Expertiza based on OSS project. As the project, our team members successfully removed the answer controller, split confusing methods and provided all unit test in the Answer model. Changes can be found in the Answer.rb file which locates in expertiza/app/models/. There is a answer.rb file which handle all methods related to answer calculations. But there is no related view file related to AnswerController. All methods in it are show,action_allowed? and calculate_all_penalties. It is obvious that calculate_all_penalties method has already been deployed in GradesController. So we can get rid of calculate_all_penalties in AnswersController. Action_allowed? method is used to set the access authorization for different users. Because there is not show view page related to show method. So we can remove AnswerController. This can be checked in the controllers folder. As described in OSS project, the self.compute_scores method is complex. Followed the principle that one method only do one thing, we split the the self.compute_scores by adding a method called self.compute_stat to take on some responsibilities from the self.compute_scores method, namely, computing the current score. Specific changes before and after are shown below: <code>. <code>. <code>. We found some parts of codes in the 'self.submission_valid?' method can be taken out as a individual method. To fulfill the function which calculates the latest review phase start time, we named this method as 'latest_review_deadline"". See the changes below: <code>. <code>. <code>. Line 89 SQL query uses 'find_by_sql' which is not in accord with Rails 4 format and we substituted it with 'where'; which can be reflected in Line 93 in our case. Since Line 89 SQL is too long, which violates the rule that code should be readable; thus we take the following measures: <code>. There are six methods in the new version of answer.rb; so we performed six unit tests. The test file for Answer model is answer_spec.rb which can be found in the directory: expertiza/spec/models/ . Below is the unit test code: <code>. To verify that our code did not break the original functions. Sign in as instructor6 with password of 'password' and go to 'Assignments' then pick an assignment; and check scores. The result remains same. 1. <link> 2. <link> 3. <link> 4. <link>.",Too little explanation; code sequences too long (test sequence is much too long)
E1841,"In Expertiza, instructors (also admin, super admin and TAs) can create rubrics (they are called questionnaires in DB, there are different types like review rubric, teammate review rubric, etc. If an instructor has created an assignment with specific review rubric and reviews have been performed using the same rubric. An instructor should be warned about changing the rubric if there are outstanding reviews. If you try to select ""Manage > Questionnaires > Review rubrics"", it should pull up a list of review rubrics. But actually, it just takes you to the main Questionnaires page. Current Functionality Instructor able to create an Assignment but once participants have started reviews, changing the rubrics doesn't update the score. Instructor able to populate an Assignment with multiple rubrics Display of the Main tabs Instructor able to navigate between tabs(Courses, Assignments and Questionnaires), but Manage menu selection doesn't work. Solutions Issue #1186 When one tries to select ""Manage > Questionnaires > Review rubrics"" , it just takes back to the Questionnaires Main page rather than displaying the Review rubrics page. componentDidMount: function() . For example , if the Questionnaires tab is opened then a value of 3 will be assigned to the last_opened_tab parameter as the position of the Questionnaires tab is 3 on the web page.This function also handles the direction of the control from Questionnaires tab to the Review Rubrics Tab when Review Rubrics tab is clicked. We also alert the instructor about the above happening and they may choose not to update the rubric. The following functions were updated: edit, update 1.1. The edit function was updated to- store the current(before edit) rubric values in session. store the current assignment in session. <code> 1.1. The update function was updated to- call the private handle_rubric_modification function. 1.1. The rubrics_before_edit function is used to store the values of rubrics on an assignment before the users tries to update them. <code> 1.1. The handle_rubric_modification method is used to handle rubric changes by an instructor to an assignment. <code> 1.1. The rubric_modified_rounds method gets all rounds for which an instructor changed a rubric when updating an assignment. <code> 1.1. The get_responses_for_modified_rounds method retrieves all responses to reviews whose rubric was changed by an instructor when updating an assignment. <code> 1.1. The notify_reviewers_about_rubric_change method is used to notify(mail) reviewers that their review responses have been deleted. <code> Solution Screenshots Issue #1186 <image> ' Initial Page'- Assignments tab selected The Questionnaires tab gets selected and Review rubric is auto-loaded. <image> Review Rubric Page <image> Meta Rubric Page Issue #1186 <image> ' Initial Page'- Assignments tab selected - editing assignment <image> User alert <image> After Cancel in alert <image> After Ok in alert <image> Reviewer mailed <image> Review response deleted. When one tries to select ""Manage > Questionnaires > Review rubrics"" , it just takes back to the Questionnaires Main page rather than displaying the Review rubrics page. componentDidMount: function() . <code>. <code>. We also alert the instructor about the above happening and they may choose not to update the rubric. The following functions were updated: edit, update 1. The edit function was updated to- store the current(before edit) rubric values in session. store the current assignment in session. <code> 1. The update function was updated to- call the private handle_rubric_modification function. 1. The rubrics_before_edit function is used to store the values of rubrics on an assignment before the users tries to update them. <code> 1. The handle_rubric_modification method is used to handle rubric changes by an instructor to an assignment. <code> 1. The rubric_modified_rounds method gets all rounds for which an instructor changed a rubric when updating an assignment. <code> 1. The get_responses_for_modified_rounds method retrieves all responses to reviews whose rubric was changed by an instructor when updating an assignment. <code> 1. The notify_reviewers_about_rubric_change method is used to notify(mail) reviewers that their review responses have been deleted. <code>. <image> ' Initial Page'- Assignments tab selected The Questionnaires tab gets selected and Review rubric is auto-loaded. <image> Review Rubric Page <image> Meta Rubric Page. <image> ' Initial Page'- Assignments tab selected - editing assignment <image> User alert <image> After Cancel in alert <image> After Ok in alert <image> Reviewer mailed <image> Review response deleted.","The description of changes is rather hard to follow, because descriptions of changes do not point out where in the code the change was made.  One has to read the prose, then study the code.  One way of showing the correspondence better would be to link to particular Github commits using the diff view where it would be easy to see what code was changed.  It could also be done by referring to methods and/or line numbers in the displayed code. They have added all screenshots at the end of the document. It would have been better if they would have added the screenshots while describing the particular issue."
E2081,"The issue asks us to have a Cake type for the question taking in a participant’s contribution, whenever s/he is reviewing the other teammates. We add in a new Question type ‘Cake’, which will be extended from the Scored Question model [cake < scored question < choice question < question]. 1. Stars: Existing design for teammate reviews uses stars to symbolize the contribution provided by each student. We can implement the cake type using the same. <image>. The amount of credit assigned to self will be the remaining amount of percentage not given to the other teammates for the reviews. The self percentages for the cake questions will only be assigned to a student once they have completed the reviews for all other teammates. The questionnaire for reviewing teammates includes the question asking the cake (contribution) factor. Ideally, the cake should include the reviewer as well. Currently, whenever a participant is reviewing their teammates they are shown a view where the names of their teammates are displayed with a 'Review' link next to them. We plan on updating this view once the reviews are complete for all teammates with a 'View' link in the user's line item that will show all of the self cake contributions. 1. Log in to expertiza to view the home page 2. Login as an Instructor, and then impersonate a student or login as a Student 3. Go to Assignments -> Your team 4. You will see a list of your teammates with a link: ‘Review’ 5. You will see yourself with no present link, this will become visible once you complete all reviews as: 'View' 6. You can see the questions for asking the contribution as a cake type 7. There will be a text description next to it denoting what part of the cake is taken (what contribution factor of the work is used) 8. For yourself the view will automatically be filled out with the leftover percentages for each cake contribution. We found that it was efficient to calculate a self contribution as the remaining percentage not assigned to all other teammates. A new class Cake has been newly introduced as a subclass of ScoredQuestion. The Cake class is a type of question that can be offered as part of any questionnaire, which keeps an account of all the answer values recorded for one specific question. The maximum value that can be given to a question of type cake is 100, and any value entered above 100 is automatically void, setting the answer entered to zero by default. 1. app/controllers/questionnaires_controller.rb Added cake type in editing the questionnaire. And it is called in methods new and edit to calculate and update the total contribution for a cake question when a student wants to create or edit a review. <code> 3. *app/models/cake.rb A new class Cake was added as a subclass of the ScoredQuestion class. A cake type question has a textbox that takes the percentage contribution assign to the reviewee for this specific question. <code> <image> 4. app/views/questionnaires/_questionnaire.html.erb Added cake to the dropdown list. Now the instructor can choose to add a cake type teammate review question to the questionnaire. <code> <image> 5. app/views/response/response.html.erb Added response showing how much of the total contribution has been assigned for a cake-type question. <code> <image> 6. app/views/student_teams/view.html.erb Added a new table intended to display the remaining score in each question the reviewer currently has. <code> <image>. There are several things we plan on testing in this project as follows: 1. Test the Cake question type to see that it properly renders and is editable 2. Test the view for 'Your team' to verify the table containing Review Questions and Self Contributions is present when reviews are enabled 3. Test the string reminder text for the cake questions that indicate the amount of contribution left to assign 4. Test the cake contribution text boxes for valid responses (no negative numbers, over-allocation, or non-numeric characters) <image>. The implementation that is done in this project adds the Cake type question for questionnaires and verifies that a total of 100% is not exceeded by all contributions given to team members. For the future scope of this project, the next step would be to add to the table view in student_teams so that the cake questions included in the teammate review rubric display along with the self contribution percentages. This can be done by pulling the response map for the user id and team id they are assigned to and populating all cake questions in the list. By using the calculation functions that exist in cake.rb, it should be possible to find the total contribution at any given time that has been assigned to teammates and subtract that that value from 100 to receive a self contribution. This value can then be displayed next to each cake question and be assignable to a grade for that student when being evaluated by the instructor.","This is a very readable description of the changes made by this project.  Good descriptions are given of how the new methods work.  Would have liked to see you use subheadings, e.g., 3.1, 3.2, etc. to describe each of the files."
E1765,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.1.1. <link> 1.1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.3. <link>. <link> is an open source project based on <link> framework. Expertiza enables the instructor to create new and customize existing assignments. This class manages the questions attached to a questionnaire. It enables the creation of new questionnaires, and editing of existing questionnaires. The questions attached to the questionnaire can either be added/updated manually from the user interface or imported from an existing comma separated file. Once the questions are added/updated satisfactorily, they can be exported as a comma separated file. The controller currently has its own import and export methods to achieve this functionality. The following tasks were accomplished in this project: 1. Fixed Issue <link> : Instructors can make changes to each others' rubric, which should not happen 2. Updated action_allowed for access_control to prevent unauthorized access of methods.. 3. Implemented new feature <link> : Dumping and loading rubric criterion from CSV 4. Refactored Questionnaires Controller to use existing Import and Export controllers. 5. Added import method in Questions model to enable creation of questions from CSV. 1. Any user irrespective of his/ her privileges can edit the questionnaire. The questionnaire should be restricted to be editable only by an instructor, administrator, or a super administrator. Furthermore, an existing questionnaire should be restricted to be editable only by the instructor who created the questionnaire in the first place. 1. Import and Export functionality in the Questionnaires Controller The current implementation of the Questionnaires controller uses its own import and export methods. The Questionnaires controller should instead use the import and export implemented for the intended purpose. <code> 1. Solution : The implementation has been changed in such a way that the restriction on who is allowed to edit an existing rubric is as follows: 1.1. A super administrator can edit any existing rubric. 1.2. An administrator can edit any existing rubric. 1.3. An instructor can only edit an existing rubric if it was created by him or her. An instructor cannot edit a rubric created by another instructor. a new or existing rubric. 1. Problem 2 : Import / Export controller The feature to allow importing Questions from files and exporting the questions had been broken since the refactoring of Questionnaire controller in <link> . 1. Solution : Solution 1.1. The export file and import file views have to be enhanced to allow import/export of questions. 1.2. Questionnaire edit view will have to be enhanced to render the export_file/start and import_file/start views which would support importing questions from and importing questions to CSV files. method in Questionnaires controller has been modified to check for separate roles based on the action: 1.1. If the action is edit, it checks that the user is a super administrator, an administrator, or an instructor who created the questionnaire in the first place. (Assuming that even a student is allowed to add a questionnaire such as polls, surveys, etc) <code> 1. Integrating export_file and import_file section with the questionnaire view allows questions to be imported into system from file, example CSV file and also to export question entries from system into an external file. 2. The export_file and import_file views are now partial rendered as part of the edit questionnaire view. <code>. Following are a few testcases with respect to our code changes that can be tried from UI: 1. Log in as instructor 1 and create a new rubric. 2. Log in as another instructor. Go to [ Edit] page for the rubric and try to edit the questions. Go to [ Edit] page for the rubric and try to edit the questions. 3. Re log in as instructor 1. Go to [ Edit] page for the rubric and try to edit the questions. 4. Re log in as a super administrator / admininstrator. Go to [ Edit] page for the rubric and try to edit the questionnaire. 5. ""Export"" button can be used to export all the questions and its associated details from the current questionnaire into a csv file that would named with the name of the questionnaire. 6. Choose the file that contains the questions to be imported into the questionnaire and press ""Import"" button to import the details into questionnaire. 1. The columns expected in the csv file would be displayed in the same page in the expected order. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. Clean Code: A handbook of agile software craftsmanship.","In my opinion, this writeup is too short.  While it does describe the changes to the action_allowed? method in detail, there is very little description of how the dumping and loading of rubric criteria work.  Also, there is no indication of whether feature tests have been written."
E1730,"Expertiza is an open source peer review system. While grading students, a grader might want to organize reviews by sorting them by a particular metric. The only available metric was ‘Average Volume’ (number of words in the review). A new metric called ‘Overall Sentiment’ is added which is a gauge of the sentiment of the review, that is, whether the review was positive or negative. The task was to allow a grader to select a particular metric, and the view displays that metric for each review. In addition to that, the grader should be able to sort the reviews by that selected metric. 1) For each review, send a POST request to the Sentiment Analysis URL for sentiment analysis with the review as parameters. 2) Store the sentiment values in a list. 3) In the view, allow the grader to select the metric(average volume or overall sentiment) from the drop down menu. 4) The view is rendered accordingly to either show overall sentiment in the metric or the average volume 5) Using the tablesorter (jQuery) addParser method, the Metric column is sorted by the appropriate metric. Only a single metric for sorting reviews called ‘Average Volume’ was present. The table was sortable only by that metric. The ‘Overall Sentiment’ metric is added to the system. The grader can choose between two metrics (Average volume, Overall Sentiment) and sort reviews by that metric. to the web service using Ruby code. app/controllers/review_mapping_controller.rb app/helpers/review_mapping_helper.rb app/views/review_mapping/_review_report.html.erb app/views/review_mapping/_searchbox.html.erb spec/helpers/review_mapping_helper_spec.rb. Method description: This method constructs the query to be sent to the sentiment generation service. It takes the review id and the text in the review and constructs the query in the format required by the sentiment generation server. Code: <code> Method description: This method retrieves the response from the sentiment generation service. It makes a JSON request and expects a JSON response. It takes two parameters, the review for which the sentiment is to be obtained and a boolean to check whether it's the first try in obtaining the sentiment value. In the cases where the Sentiment generation server fails to calculate a proper sentiment value, we will retry our request with only a single sentence of the review. It was decided after a meeting with professor to simply use the first sentence of the review text as the single sentence that would be used during the retry, to try and generate a sentiment value. Code: <code> Method description: This method creates a sentiment hash with the id of the review and the results from the sentiment generation service. Code: <code> Method description: This method handles the case when a sentiment generation query has been retried. This is the last effort to retrieve a sentiment from the server. If it succeeds and a 200 response code is received, we parse the JSON response to extract the sentiment value. If unsuccessful, we assign the sentiment a -500 value to represent an error condition where even the retry had failed to get a proper response from the server. Code: <code> Method description: This method generates the sentiment list for all the reviews. It gets the sentiments created from parsing the responses from Sentiment generation server and inserts them into a list. Code: <code> Method description: This method creates the correct format i.e. Metric Name: Metric Value, so that the view can easily render it. Code: <code>. Scenario 1: Testing Tool: RSpec Description: Check whether the sentiment query is constructed. <code> <code> Scenario 2: Testing Tool: RSpec Description: Test whether the webservice returns a response <code> Scenario 3: Testing tool: RSpec Description: Check whether the web service does not respond with a 404 error or a 500 error <code> Scenario 4: Testing tool: RSpec Description: Check whether the web service returns a response in JSON format <code> Scenario 5: Testing tool: RSpec Description: Check whether the retry returns a valid response. <code> Scenario 6: Testing tool: RSpec Description: Check whether the sentiment list does not return a nil value <code>. 3) Click the Assignments tab on the page, in case the Courses are loaded(which happens by default sometimes) 4) For any assignment, click View Review Report icon 5) That will take you to the review report page 6) To choose a metric (Average Volume (default), Sentiment), choose from the Metric dropdown and click Select 7) The page will reload with the appropriate metric 8) You can sort using the arrows in the column header. If you have any issue with testing the feature, check out the Youtube video: <link>.","It would be helpful to have some kind of intro and perhaps also a summary giving the big picture.  The writeup as it is is just a series of changes, with no explanation of why the change was made, or how it fits into the overall goal of the project.  To understand what you have done, the reader will likely have to read the text over and over again, trying to figure out how everything fits together."
E2109,"Therefore, the application allows for the project's authors to provide feedback on the peer review, this is called ""author feedback."" The instructors have no easy way to access the author feedback while grading peer reviews, which would be a useful feature to have since this shows how helpful the peer review actually was to the group that received it. Thus, making the author feedback more accessible is the aim of this project. Our primary task is then to follow their implementation, refactor any code that may require it, make the suggested improvements that were left in their project feedback and make the feature compatible with the latest beta branch of Expertiza. Secondary tasks are to make the author feedback column toggleable and to refactor the function that averages author feedbacks so that it reuses existing code that exists somewhere in Expertiza already. 1. Our primary goal is to take the author feedback column functionality from the 2018 branch and update it so that it merges successfully with the current beta branch. 2. In the 2018 branch, there is an author feedback column to the review report, but the previous team's submission added new code to calculate the average. 3. Part of the 2018 group's feedback said that the review report UI began to look somewhat crowded in its appearance. However, there is often no author feedback, and so the column for that should be made toggleable. So we will make it so that the column is dynamic and will only be present if there is author feedback to display. The user could then toggle the column to show or hide that information depending on their own preference. Below is the current implementation of the page we are going to edit on the beta branch. It can be seen that the ""author feedback"" column is not present in this view at all. <image> Here is the 2018 group's version of the page we are editing. It has the ""author feedback"" column as well as the necessary functionality. However, the user interface has clearly changed since 2018, and therefore, there will likely be merge conflicts between their branch and the current beta branch. Part of our task would then be to resolve those merge conflicts and port the functionality back over to the most recent beta branch. (Sourced from this <link> ) <image> Currently, in the 2018 group's branch, the entries in the ""Score awarded/Avg. score"" and ""Author Feedback Score"" columns contain a lot of missing entries. code that removes the missing entries represented by the dashes) to the missing entries available in the beta branch to the 2018 group's branch code. In addition, the 2018 group's branch has the author feedback in its own column in-between ""AVG score"" and ""Metrics"". Instead, we will move it under the same header column ""Scores"" as seen in the current beta branch, just to the right of the ""AVG Score"" column. To accommodate for this additional column being introduced, the ""Team reviewed"" column width would be reduced a bit so that the ""Scores"" column renders approximately at the same location on the page. reviewer and team reviewed, have been reduced to accommodate the new author feedback column. <image>. This attribute gives the controller access to the model's author feedback scores that have been calculated. It is required to properly read and display the computed author feedback scores from the hash they are stored in. The _review_report.html.erb file had to be modified - the width of the other columns was reduced to make room for the author feedback column, the column header was added, and the necessary call to the author feedback column partial was also introduced. This file is the partial required to render the author feedback column, and is a reintroduction of the 2018 group's _team_feedback_score.html.erb file. The response argument is the review a team provides for the author's work. Lastly, in order to obtain the final average score for a particular review (response) that the authors (team) have gotten, they obtain a sum of the feedback scores from each of the authors and divide it by the total number of feedbacks that were obtained. These methods have already been implemented by the 2018 group and are included here again for the reader's convenience. Since we will need to modify the user interface to introduce the author feedback column, we expect to add a column within the .erb files in the views folder that were identified above. These files were selected as they were the files necessary for the previous group to implement their UI changes. The following method was written by the previous team to calculate the average scores for the feedback given by authors for the reviews of their work. It is likely better for this method to be moved to this controller's corresponding model, and we will do so during our project to make the code follow the principles of MVC. The 2018 group wrote a RSpec test when they wrote their function to calculate the author feedback scores. 6. This will navigate you to the report page as seen above and you will be able to view the Author's Feedback column and score obtained for every student.","The design document seems based on editing and debugging the 2018 project.  It has not been updated to incorporate many of the changes made in their project, though I do see that it was edited on April 30. The other issue I see is that the design doc treats the 2018 project almost as a black box ... code that should be modified to get it running, without describing the design of that code.  The changes that this team made are described better, but to know how the code works, it would still be necessary to understand the 2018 project."
E2086,"1. Expertiza Project - E2086 : Let course staff as well as students do reviews. Peer review is a great way for students to learn about how well they have developed their application. Hence this is what this project aims at, allowing instructor/TA to perform reviews. This project aims to allow instructors to submit reviews of student work, using the same review form that students use to do reviews. Our project aims at enabling the instructor/TA to review the submissions using the same form that a student uses while peer-reviewing. 2. The second part involves allowing the students to identify from their end, which review has been performed by an instructor/TA. 3. Third, we plan to enable the instructor/TA to do review instead of assign grade in the review round. After the review Round, the review review session will be closed and replaced with assigning grade interface. 1. In the assignment page of the Expertiza, If an instructor or a TA is a participant in an assignment, then the instructor should be able to review any team that has submitted the assignment. <image> 1. Then, to perform reviews, the instructor/TA would click on the clipboard-like “View submissions” icon, as shown below. <image> 1. A list of submissions would be pulled up: <image> 1. If the last due date for the assignment has not passed, then the “Assign grade” link should be changed to “Perform review”, and when clicked on, it should pull up a review page for the team, showing their submitted work at the top, as a review page normally does. 2. We will add the review link in views/assignments/list_submissions.html.erb and once instructor/TA click that link. The review link will be replaced by the grade link. 1. Also, it would be more clear if we could mark the instructor's review with something special on the reviews page, as shown below. 2. We will add an icon in views/grades/view_team.html.erb and app/views/response/view.html.erb if these review is made by instructor or TA. We create a link ""Begin review"" in list_submissions.html.erb in order to let staff(TA/Instructor) perform review before the review deadline. And if the current stage becomes ""Finished"", we show the ""Assign Grade"" link. We use function current_user_is_assignment_participant to check if the current user have access to perform review. If the current user does not have the access to this assignment. No link will be shown. <image> This is what it looks like. <image>. <image> <image> Second, we found it is better to use unless instead of using if ! <image> Third, we found that the student review and the staff review have a lot of common code. So we refactor the student_review/_responses and let student review and staff review share one common template. <image>. In this file, student review and staff review share one template. The page will show different review action base on the current stage and if the review did this review before (For example: if the current stage Finished and no previous review, the page will show ""Begin review""). <image>. Before modification, the normal review could only be done by students. When the student finished the review and clicked “Submit”, the page seemed to redirect from the students' review. Since we newly added staff to review, the location of redirect should also be modified accordingly. <image>. app/assets/images/staff.png is displayed to make an instructor performed review stand out from other reviews. <image> If the mouse hovers over the icon a tooltip appears saying ""Icon indicates this review was done by course staff"" <image> <image>. The basic idea of this project is to change the 'Assign Grade' link to 'Perform review' if the deadline of a assignment has not passed. 1. Click 'Manage' -> 'Assignments' to go to assignment page. 2. Add a new assignment for a course that the current account has registered. Make sure the due date of the assignment is after the the time to perform the review as an instructor. 3. Click 'Add participants' icon in the new created assignment row, and 'Copy participants from course' to add all students registered to this course. 1. Click 'Manage' -> 'Assignments' to go to assignment page as instructor. 2. Click 'View submission' icon in the new created assignment row. Now the 'Begin review' link show be under participants name if the due date has not passed. 3. Click one of the 'Begin review' link to do the review for a certain submission by using the same templet of student peer review. Check score for the assignment, and the review from the instructor should be recognizable from other student reviews. <image>.","The document is comprehensive and readable.  The list of team members is in the middle of the document, which is unusual.  The long partial _response_actions.html.erb should have been described in more detail (or divided into multiple partials).  Also, the rspec tests should have been described in more detail, by saying what is being tested.  However, these are minor points; overall, it is a very good job."
E2079,"This project works on improving the search functionality of Expertiza, by adding search bars if not present, introducing an advanced search feature where user can search on the basis of more than one parameters, and making the search functionality appear more elegant. 2. An instructor should be able to search for assignments by name, due date, or other characteristics. 5. An instructor or administrator should be able to search for all the assignments that a particular user has participated in. In the current system workflow, the user is unable to search in the Manage Users view. In the proposed workflow, we plan to enable the user to search by all the columns in the UI viz. The user will be able to apply multiple filters at a time and the output of the query will match all filters applied. However, the search is case sensitive. In the proposed system, the user will be able to search for an assignment using additional filters such as Creation Date and Updated Date along with Assignment Name. The user will also be able to apply multiple filters at a time and the output of the query will match all filters applied. To search for an assignment by Creation Date, the user will be prompted with a calendar where he can select a date and all the assignments created on or before the selected date will be displayed. To apply multiple filters, the user can tap on the Advanced Search button available, adjacent to the Search button; a hidden div will then be rendered below-containing text boxes for all the columns. All assignments that were created before the selected date for Creation Date or Updated Date columns and the ones that match other filters will be returned. An empty list will be returned if the search criteria don't match any records in the database. The existing system does not have search functionality under Questionnaires. The user will be able to apply multiple filters at a time and the output of the query will match all the filters applied. To search for an assignment by Creation Date, the user will be prompted with a calendar where he can select a date and all the assignments created on or before the selected date will be displayed. To apply multiple filters, the user can tap on the Advanced Search button available, adjacent to the Search button; a hidden div will then be rendered below-containing text boxes for all the columns. All assignments that were created before the selected date for Creation Date or Updated Date columns and the ones that match other filters will be returned. An empty list will be returned if the search criteria don't match any records in the database. The existing system does not have search functionality under Reviews. The user will be able to apply multiple filters at a time and the output of the query will match all the filters applied. The user will be able to apply multiple filters at a time and the output of the query will match all filters applied. QuestionnairesSearchBar is the main search bar containing the traditional search bar also with the advanced search bar which is QuestionnairesAdvancedSearchBar. For example, when the user types text in the advanced search box, it can be accessed from the model and added to the query conditions. Added the extra search fields to the query conditions. React code for advanced search. React code for advanced search. React code for advanced search. React code for advanced search. React objects were added to implement search filtering functionality for assignments. React code for UI components in Advanced search for assignments and courses. React code for UI components in Advanced search for assignments and courses. React code for UI components in Advanced search for assignments and courses. React code for UI components in Advanced search for assignments and courses. <image> The JS code for the advanced search box. The following screenshots show before and after an advanced search for courses, assignments, and users. 1.1. Log into expertiza to view the home page 1.2. Go to Manage > Users 1.3. Type the search string in the search box available on the UI and select the column to search for from the dropdown. 1.4. To perform a search based on multiple filters, the user can tap on the Advanced Search button adjacent to the Search button, the view renders a hidden div containing text boxes for all the columns, allowing the user to search based on multiple columns. 1.6. An empty list is returned if the search criteria don't match any valid records in the database. 1.4. To perform a search based on multiple filters, the user can tap on the Advanced Search button adjacent to the Search button, the view renders a hidden div containing text boxes for all the columns, allowing the user to search based on multiple columns. 1.6. An empty list is returned if the search criteria don't match any valid records in the database. 1.4. To perform a search based on multiple filters, the user can tap on the Advanced Search button adjacent to the Search button, the view renders a hidden div containing text boxes for all the columns, allowing the user to search based on multiple columns. 1.6. An empty list is returned if the search criteria don't match any valid records in the database.","This document was not the easiest to read.  The changes for advanced review search should have been included.  Referring to the previous team's document makes it harder for the reader, who must flip back and forth.  Since the project was not merged, it is not useful to have future developers read about it.  For advanced questionnaire, assignment, and course search, the logic should have been described in more detail.  What are the various elements or methods in the views?  How do they fit together?  Many screenshots are segued together with no comments.  The reader would have to figure out what they are for.  I'm not sure why you said your automated tests could not pass."
E1762,"In Expertiza, there are several types of response maps (model files in app/models). as per that model). These models do not have any unit tests. • Create a factory for each response map models in factories.rb file (review_response_map factory has already existed). • Then create test files in spec/models (you can refer to answer_spec.rb, due_date_spec.rb for how to write specs); write model specs for methods (if you find any method has no caller, remove the method instead of write tests for it). To write the unit tests for the models, we need to define the spec files for the models. For this we use the following files (in app\models ) – • Response_map.rb • Review_response_map.rb • Teammate_review_response_map.rb • Feedback_response_map.rb • Quiz_response_map.rb • Assignment_survey_response_map.rb • Bookmark_rating_response_map.rb • Metareview_response_map.rb • Self_review_response_map.rb • Course_survey_response_map.rb • Global_survey_response_map.rb While writing our tests we will need a way to set up database records in a way to test against them in different scenarios. Now, we use RSpec to create the test cases for these models. The convention of naming the files is MODELNAME_spec.rb , hence we get following files. • Response_map_spec.rb • Review_response_map_spec.rb • Teammate_review_response_map_spec.rb • Feedback_response_map_spec.rb • Quiz_response_map_spec.rb • Assignment_survey_response_map_spec.rb • Bookmark_rating_response_map_spec.rb • Metareview_response_map_spec.rb • Self_review_response_map_spec.rb • Course_survey_response_map_spec.rb • Global_survey_response_map_spec.rb After studying the given models to be tested, we realize that many of the models contained either a blank/unimplemented method or contained a standard ruby implemented method. The following models did not contain any relevant method, hence the tests were not necessary for them: • Assignment_survey_response_map.rb • Teammate_review_response_map.rb • Bookmark_rating_review_response_map.rb • Self_review_response_map.rb • Course_survey_response_map.rb • Global_survey_response_map.rb Also, the ReviewResponseMap model has a few private methods which according to unit testing rules need not be tested. Each response map model needs its own factory for testing to create relevant mock objects to test the specs written. Hence here is a sample of a factory we created for the response_map.rb model. <code> Here, we create a mock object for the model ResponseMap to test its methods. The test cases implemented in the project can be observed in the respective spec files of the models. <code> <code>. The test plan of this project involves running the newly made RSpec files for respective models and check if the expected output is attained or not. To check the test cases of a particular model, run the given command in terminal: <code>. Condsider the given RSpec for export method in ReviewResponseMap model: <code> The export method is as follows: <code> The export method takes an empty array and the aassignment id as input. It returns a list containing mapping between the reviewee name and reviewer name and the mapping list is sorted according to the reviewee name. In the unit test, we need to check two conditions: 1)It should return the mapping between reviewee name and reviewer name. 2)The mapping must be sorted according to reviewee name. In the RSpec we have tested the two conditions as shown in the code. When we run the export method, we get the expected mapping between the reviewee and the reviewer. Now when the export method is executed, we get the mapping in sorted order based on reviewee name which can be seen in the RSpec code. For another example, condsider the given RSpec for feedback_report_response method in FeedbackResponseMap model: <code> The feedback_report_response method is as follows: <code> The feedback_report_response method takes assignment ID as input and returns a list of response ID's for all rounds of reviews(1, 2 or 3). In the RSpec code, we need to test that the function returns list of authors and responses by rounds. In RSpec code, we create mock objects for reviewers, reviewees, team and responses. Please refer the github code to see other defined RSpec files.",Writeup is straightforward. Explained one of the tests.  Would have been helpful if all tests had been explained like this.
E1737,"We are converting the assignment creation form to ReactJS. It is used for dynamic reloading of the page. The Assignment Create and Edit Form are multi level forms. Also, edit page is reloaded whenever a topic is added. The assignment creation form consists of multiple inputs and requires interactions from the user. When a user wants to create a new assignment by clicking the new assignment button, a server request is generated and new view is rendered. <image> <image>. Similar to assignment creation page, edit page lacks the dynamic view rendering which makes the user experience cumbersome. Every time user wants to make changes to the assignment, a server request is generated and new view is rendered. The save button hit on completion will again generate another server request and render a new view. <image>. In current implementation whenever a topic is added to the assignment, a request is sent to the server and user is redirected to a form in another page. Upon creation of topic user is rendered back to edit assignment page. Now, the task is to avoid this redirection of pages and create a interactive ReactJS form for adding and editing topic. With this action new.html.erb page is rendered. Add topic: <image> Similar is the case for editing a topic. For editing a topic user is rendered to a form in edit page and again redirected to edit assignment page. Edit Topic: <image>. Currently after creating an assignment, we can add topics related to the assignment. The ""Topics"" tab in the edit assignment form shows the list of topics that are added to the assignment. The picture below shows the current page for displaying the list of topics of an assignment. The task is to make it sortable using ReactJS by topic id, topic name, Num. <image>. There are many such problem causing situations in the new assignment form, such as This is essential in both new assignment or editing assignment page. 1. User can add the number as new assignment name or he can give only special characters for it like ""$$$$"". <image>. The new implementation uses ReactJS to generate a drop-down window on clicking on the New Assignment button (private/public) , providing same features as before. Database entry is made on submitting the form and the form is closed. Below is the view of the new implementation: <image>. We created a new React class 'NewAssignmentForm' which dynamically creates and displays the form for New assignment. Similar to assignment creation, in the new implementation, using ReactJS, when the edit assignment button is clicked, instead of making a server request and rendering a new view, a drop down window appears and saving the details will make the database entry.Since all the processing is done on the client side there will be decrease in the number of server requests. However, the edit form is a multilevel form with different tabs. We managed to implement only the general view as React JS form, hence we added a new action item ""Quick Edit"" which renders the ReactJS form and the ""Edit"" action item works as before. Below is the view of the new implementation: <image>. In tree_display.jsx we created a new React class EditAssignmentForm which dynamically creates and displays the form for Editing assignment. This should show a form in that page to create topic. 2. Correcting the code in edit assignment page too. Here is the display of the implementation: <image> <image>. 3. Click on the 'New public assignment' or 'New private assignment' button 4. Verify if drop-down window is displayed. 6. Verify if new assignment is successfully created. 3. Click on the Edit button for any of the available assignment. 1. Login as an instructor (user-name:instructor6 password:password) 2. Create an assignment 3. Click 'New Topic' link or 'edit' action in topics table for a particular topic 4. A pop window or form should be displayed in the same page 5. Add topic details in that window/ form 6. Save it 7. Created or modified topic should be seen in topics table. 1. Login as an instructor (user-name:instructor6 password:password) 2. Create an assignment 3. Add 2 topics to the assignment 4. Click sort on Topic ID and check if they are sorted 5. Click sort on Topic title and check if they are sorted 6. Similarly test using other columns. 3. Click on the 'New public assignment' or 'New private assignment' button 4. Try adding the assignment using the weird names, with special symbols, ignoring check boxes 5. Verify if the assignment is shown in the table. Another way to check is from editing page too. 3. Click on the Edit icon page. 4. Try adding the assignment using the weird names, with special symbols, ignoring check boxes 5. Verify if the assignment which is updated with special characters is shown in the table. 1. Covert the multi-level edit assignment form to ReactJS 2. Convert add/edit topics to ReactJS.","Covers all the changes to be made.  There are a good number of diagrams, but the size should be reduced so they are viewable without scrolling.  Could have provided more details on how functionality would be achieved (e.g., saying more than ""make it sortable using ReactJS"").  Plan does not include automated tests."
E1640,"<link> is a web application developed using <link> for online assignment assessment. It is an open source project and its code base is maintained in the <link> . Expertiza authorizes the instructor to create new assignments as well as modify the existing ones. Students can team up with other students in Expertiza to work on various projects and assignments. Students can also review other students' work, thus enabling peer learning. After a particular response is recorded, the rubric gets displayed in graphical form under Your Scores tab. The submitted work can be seen in Your Work tab and the feedback given can be seen in Others' Work. The teammates for a particular project can be seen in Your team tab. Response.rb is a class that manages the response to all rubrics in Expertiza. The review form, quiz attempt, teammate review, review for others' work, filling a survey are all treated as responses. Method display_as_html handles the front-end for displaying a rubric. Response_helper.rb It contains two kinds of methods: 1) Methods related to the display of questionnaires. 2) Methods to open a rubric on selecting a particular section name. This contains a method that rearranges the questions based on the frequency of answers to the questions. In response.rb: 1) The class contains code that checks the rubric type (ReviewResponseMap, MetareviewResponseMap, FeedbackResponseMap, TeammateReviewResponseMap). These classes are sub-classes of ResponseMap. Rather than checking the map type, the code should send a message to the ResponseMap, and the code for specific types of ResponseMaps should be implemented in the subclasses of ResponseMap. 2) Code for calculating scores seems to be incorrect, as it should multiply per-question scores by the weight for each question. It seems to ignore weighting. 3) Most of the code for sending e-mails should be moved to app/mailers. 4) Remove the comment in lines 25–27 about TeamResponseMap; it is no longer relevant to the current version. In response_helper.rb: 1)The rearrange_questions method was written before we added sequence numbers to questions. At the very least, it needs to be modified so that questions above the threshold are kept in sequence. Ideally, it would be extended to allow the person who creates the rubric to specify whether each question could be moved or not, and then rearrange only the questions that are allowed to be moved, and add a column of check boxes to the Rubrics tab for assignment creation, saying whether questions on a particular rubric can be rearranged or not. In response.rb 1) The functionality for email notification was initially cluttered in a single class Response. In the current version, this functionality is been divided into sub-classes depending on the response type. This has facilitated improved modularity and segregation of functionality into different classes. 2) In the current version of the code, the total score is calculated by considering the weights for each question. 3) The code for email notification is in the mailer module in the current version and the syn_message function is used for sending synchronous email messages after a response is entered. 4) The irrelevant lines from TeamResponseMap are removed. In response_helper.rb 1) The response_helper.rb is removed in the current version since it is dead code and not referenced anywhere in the code. The email notification functionality was initially in Response.rb and was shifted to the sub-classes as below: Before Refactoring : Model: Response.rb <code> After Refactoring : Model changed: Response.rb, ReviewResponseMap.rb, MetareviewResponseMap.rb, FeedbackResponseMap.rb, TeammateReviewResponseMap.rb Function added: email In ReviewResponseMap <code> In MetareviewResponseMap <code> In FeedbackResponseMap <code> In TeammateReviewResponseMap <code>. NOTE :- Our project work is concerned on refactoring the code. So no new Rspec tests have been added. New refactoring has been tested and verified using existing Rspec tests. Manual testing has been done for the functionalities which does not have any existing Rspec tests. Steps to test from UI: 1). Login as the instructor. 2). Select Manage Content tab. 3). Create new course. 4). Add new assignment. 5). Select appropriate rubrics. 6). Add the participants to the course. 7). Login in as one the participant. 8). Select the assignment from the participant's assignment list. 9). Submit an assignment. 10). Login in as another participant. 11). Submit the feedback for the previous participant. 12). The participant will receive the feedback mail. 1. <link> 2. <link> 3. <link> 4. <link>.","This writeup is less detailed than some, but then there weren't as many changes to describe as in some projects.  It accomplishes what it needs to."
E1615,"The Expertiza is a software project to create reusable learning objects through peer review. Review mapping controller contains methods related to peer reviewing strategies. It contains methods to add a reviewer, delete a reviewer, selecting a reviewer. Depending on the number of students and number of submissions, the topics to be reviewed are assigned to the students automatically. Generation of review report, feedback report and teammate review is done. <code> <code> In the above case teams_hash should consist of a hash with both keys and values but the sorting is done based on values. <code> <code>. The method automatic_review_mapping_strategy handles the number of reviews assigned to a individual and also the number of reviews that can be done with in a team. The method is very long and has many nested if statements due to which the complexity of the method is very high. Instead of a single method handling all the parts of the strategy, it is divided into several parts due to which the code is more readable and also the complexity of code is shared by each method. The method first checks the number of participants that are in an assignment and the number of teams that are present. It then sets the values for the maximum number of reviews that are possible and also the minimum number that are required. Then it assigns the reviews to each of the teams randomly when a request for review is made by a participant. At last it checks if the participant has the minimum number of reviews required after allotting the reviews. If not, it assigns more reviews to valid teams so that the minimum requirement is met. The part of the code that is moved out of automatic_review_mapping_strategy as peer_review_strategy: <code> The method is made private so that it can only be called with in the controller and cannot directly be called through a view. The complexity of the original method reduced after breaking it and can be easily readable now. <code> 4. Moving code specific to models to models instead of controller The method response_report contains code which generates reports based on the input of one of the three of 'ReviewResponseMap', 'FeedbackResponseMap', 'TeammateReviewResponseMap' and 'Calibration'. But the other three are models that are subclasses of ResponseMap model. Moving the code to the models and calling the methods in the model through the controller makes more sense than writing the code in controller. The following is the code snippet from the original method which contains the calls to ResponseMap model: <code> The same code after moving the methods to their respective models looks as follows: <code>. Peer review information: 1. Instructor Login: <code> 1. Student login: <code> Steps for testing UI: 1. Login as an instructor (Using Instructor6 will help you import the participants from other assignments). 3. Click on ""New Public Assignment"" for creating a new assignment. 4. Create a new assignment by providing assignment name, selecting a course, submission directory (Give any name) and description URL. 5. Select ""has teams?"" Click on create to create a new assignment. 1.1. After that, click on review strategy and limit the number of reviews per submission. 1.2. Click on ""Due dates"" and update date for submission and review. Adjust the review date and time in order to test the reviews. 1.3. Click on ""save"". A new assignment is created and it can be viewed in ""Manage->Assignments"" section. 6. In order to add participants, there are two methods to add students to the assignment. 1.1. Click on ""add participants"" against the assignment. Enter the user login to add the student. Add atleast 6 participants so that the review mapping can be seen. 1.2. Click on any previous assignment ""add participants"" and export the students list (I used wiki assignment). 1.3. Click on your assignment ""add participants"" and import the students using the export file. 7. Go back to ""Assignments"" section and click against ""create teams"". 1.1. After clicking on ""create teams"", Click on ""create teams"" in the directed page. 8. Login as a student to submit the links for assignment (Valid hyperlink must be provided in the submission link). Add submission for atleast 5 students in order to check the automatic review mapping. (Password for student is password) 9. After submitting the links for some students, Log in as an instructor to change the assignment phase to review phase. 1.1. To change the review phase period, Go to assignments section and click on edit. Click on due dates and change the review due date. 10. Now, login as a student and go to others work. Click on ""Request a submission to review"" and check whether a review is assigned automatically. 11. For teammate review report, author feedback report and review report, click against ""review report"" and all the review reports can be seen by selecting it in the drop down menu.","Description of ReviewMappingController is incorrect.  Topics are not assigned automatically to reviewers.  Submissions may be assigned automatically, but only if ""Auto-selected"" reviewing is being used.  In the middle of the paragraph, you switch from talking about a UI user to talking about a programmer, without ever specifying the change.
The code snippets you show are hard to read because they scroll off the right side of the screen. 
It would be easier for the user to pick up the changes if ""before"" and ""after"" views were shown side by side."
E1854,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link> 1.1.9. <link>. <link> is an open source project based on <link> framework. Students can also peer review other students' submissions. Expertiza has the ability to require self-reviews on projects, self-review is basically asking each team member in the group to evaluate their project on the same criteria as peer review, these self-review scores do not have much functionality currently. The main points of this project are as follows: 1. Create a method to calculate a derived score (composite score) between self and peer-reviews. The closer the self-review is to the peer-review, the greater the score. Display this score on the ""View Scores"" page. 2. Make sure that the peer-reviews should not be visible before self-review completion. Display the correct review scores accordingly. 3. Display the self-review scores in the ""View Scores"" and heat map of peer-reviews, denoting that they are a different type of review. The self-review link is visible in the page. The student should give the self-review. After giving the self-review, the student should be able to see the peer review, self-review and the composite score.\. <image> Actors: <code> All the other use cases are implemented except “View Scores with self-review column and composite score” Use Case: View score with self-review column and composite score Preconditions: <code> Student Sequence: <code> Post Conditions: <code>. The composite score is calculated using both self-review score and peer-review score (both are graded over 5 points for each criteria). The composite score is calculated as follows: <code> By using this formula for calculating composite score we are discouraging students from either exaggerating or underrating their performance. The composite score model assigns more weight to the peer review score since the peer review score being used is the average of all peer review scores assigned and hence tends to be more appropriate than a single self-review. Also this composite score formula gives the score on a scale which is identical to the scale of the self and peer review score. Thus this formula is not dependent on the scale of the self-review and peer-review score as it will also return the composite score on the same scale. For example: If someone gets an average peer review score of 3.5/5 and he gives 3.5/5 (self-review score) while reviewing his project, then he will get a composite score of 3.5/5. And instead if the student reviews his project for 2/5 then the student will get a composite score of 2.975/5. As stated above the ability to do self-reviews has already been implemented. The instructor has this ability to enable self-reviews . <image> In our project, we were successful in displaying both the self-review score and composite review score on the view scores page. As we can see the self-review icon has a blue background to indicate that it is different from other peer reviews. <image> The alternate view was also modified to accommodate a pictorial representation of the self-review scores. The modified alternate view scores page is shown below. In the current implementation of expertiza when self-review was not assigned, the instructor would view the scores of the first student in each team (it wouldn't matter much because without self-review all students in a team would have the same scores). But this would be a problem when self-review was enabled so we decided to display all the self-review scores of all students in the team for instructor view. As it can be seen below self-reviews of all students in the team (distinguished by their usernames) are indicated by blue background to differentiate them from peer review scores. <image>. Test cases are as follows: 1. Peer-reviews cannot be viewed before a self-review is completed. This ensures that the student is not able to see his peer-review score before writing his self-review as the composite score takes into account the difference between the student peer-review and self-review score. 1. Self-review scores are displayed with peer-review scores. This enables the student and instructor to view all his scores in one place. 1. The composite score must be properly calculated. The composite score must be calculated so as to give students more points if their self-review score is closer to the peer review score. 1. Composite score must be visible in both view scores page and Alternate view. The scores must be displayed in both the views. 1. <link> 2. <link> 3. <link>.","The document describes the method and gives an example, but does not tell how the grading formula was derived.  Has it ever been used anywhere before?  Also, while the document mentions the files that were modified, it does not describe how the code was changed.  The screenshots are very useful in being able to see the functionality that was added.  The test plan is not well developed, as noted by several reviewers."
E1976,"This page is a description of Expertiza OSS project E.1976 Issues Related to Assignment Creation. Project Github pull request: <link> Github links about this project: <link> Video Presentations: Issue 1354: <link> Issue 1384: <link> Issue 1430: <link>. Firstly, a TA can unassign an assignment from the course which he don't belong to, and when TA does this, the other TA may lose access to the assignment, so they can't fix it. The second issue is, Sometimes, when an instructor creates an assignment and hits “Save” without completely filling out the form, (s)he ends up editing a different assignment. But right now an instructor is not able to choose whether to see these actions on the homepage or on a tab associated with each assignment. Proposed solution: We want to make sure that the TA can't access other assignments except the assignment which he assigned to this courses And we should then check if he is not in this course, he will not grant the right to unassign assignments. <image> Proposed solution: An instructor should be able to choose whether to see these actions on the homepage or on a tab associated with each assignment. Proposed solution: The problem can be because there are two assignments with the same name.so it would lead to the old assignment when it is created, the system will sort all the lists of assignment names, then find the past duplicate name assignment, resulting in ends up editing a different assignment. During changing the assignment, first we ask which course an assignment is a part of, and then list only those courses that the instructor or TA has access to. So the TA and the instructor can only deal with the courses they related to, but not the irrelevant courses. <image>. The instructor could edit the course settings, and in ""other stuff"" the instructor could change the action icons to show whether these actions on the homepage or on a tab associated with each assignment. <image>. While the instructor creates the assignments having the same name with a created assignment, It was dropped into another assignment. In this problem, we need to set a double check while creating the assignments, if the name of the assignment has been used. <image>. <image>. <image>. <image>. <image>. <image>. ... as issue required) <image>. <image>. Now instructor can view all actions. <image>. 1. Login as an instructor 2. Edit the course settings of other stuff 3. Recording a video to show how the homepage change. 1. Login as TA 2. Find out whether TA can view all assignment (this part our mentor need to discuss with the professor to clarify) 3. Try to remove assignment which is not included in TA course 4. Login as an instructor 5. Try to remove the assignment. 1. Create two assignments but choose a different course. 2. First one's course is fall 2017, the second one's we choose fall 2016. 3. Hit the ""save"" button of the second assignment, it will automatically show the page of the first assignment of course fall 2017. 4. Add tests in files list below, and pass all tests. <link> <image> <image>. <link> <link> <image> <image>. <link> <image> <image>. 3. Click on New Public Assignment 4. On the new assignment creation page, under the General tab, give details for Assignment name , Course (choose CSC 517, Spring 2016) and Submission directory . 5. Check the Staggered deadline assignment? 7. Click on Create at the bottom. 8. Now, click on the the Topics tab and further click on New Topic . 10. Click on the Due dates tab. 15. Now, click on the Other stuff tab and and further click on Add participant . 16. Click on Copy participants from course . 19. Click on Assignments and further click on the assignment that was created in the earlier steps. Manual Testing Task Description: Teaching Assistant creating an assignment Precondition: The instructor has set up the page for assignment creation Primary Flow: 1. Log in to Expertiza 2. Select New Assignment 3. Enter the Assignment Name and select Course . 5. Click Create Task Description: Instructor deleting an assignment Precondition: There exists at least one assignment created by TA. Primary Flow: 1. Log in to Expertiza 2. Select the Delete option in the action section for an assignment that is created by the TA . 3. If Logged in as Instructor , the assignment gets deleted for that action. Manual Testing 1. Login to Expertiza as an instructor 2. Create a new Assignment 3. Click on the add participant button for the assignment created 4. Modify the participant list by adding an instructor as a participant 5. Check the list to see the instructor added to the assignment as a participant Automated Testing No automated test cases, only manual testing since the modifications are made to the view files. 1. <link> 2. <link> 3. <link> 4. <link>.",Good description of the issues and the changes made.  It would have been useful to have shots of the complete screen for Issue 1384.
E1923,"Expertiza provides multiple export and import features for eg. Most imports and exports just import or export a single table. Existing import functionality is primarily routed through the ImportFileController and an import class method for various models. Questionnaire relies on a helper method that can import Question objects (objects that make up a Questionnaire) from a CSV and adjust the size of the associated QuestionAdvice (the words that pop up after you pick a certain number of stars). However, these functions might be deprecated, as it appears that Question importing is now routed through the ImportFileController unsuccessfully. 1.2. Import methods: 1.1.1. #import_from_hash - Primary import functionality. 1.1.2. #import - Larger controller of import, sets error messages and displays. 1. questionnaires_controller , the list of methods in the controller are the following: 1.1. ::import - Allows import from CSV using QuestionnaireHelper (Appears to be deprecated/unused). 1. questionnaire_helper (Appears to be deprecated/unused), the list of methods in the file are the following: 1.1. ::get_questions_from_csv - Allows Question and QuestionAdvice import/creation with CSV file. All these models have an ::import method called by the ImportFileController. The import functionality should be routed through the ImportFileController. Luckily, most import functionality is routed through the ImportFileController and import class methods on models that are being imported. It makes sense for each model to have its own import method because each model knows what to expect for itself. We intend to remove other helpers and files, such as the ImportFileHelper, the ImportTopicHelper, and the QuestionnaireHelper to keep import routing consistent. We will also remove the QuestionnaireController and route that import through the ImportFileController. Consider if a user's import contains objects that do not exist in the database. To summarize our changes: 1. Route all import traffic through ImportFileController and ::import calls on models. 2. Refactor ImportFileController. 4. Add ability for ImportFileController to import Question objects for Questionnaires. This method now checks to make sure that each column header is unique regardless of which model you are in. 1. In the ImportFileController we moved the #start method to the beginning of the file for consistency and readability. 1. The #import_from_hash and the #show method inside the ImportFileController is markedly shorter now then when we found it. <image> <image> 1. Questionnaire.rb has a #import method that is now routed through the ImportFileController and the actual act of importing works. We removed all functionality related to importing from the QuestionnaireController and QuestionnaireHelper. 1. We removed the ImportFileHelper and ImportTopicsHelper and moved that functionality into the corresponding models. 1. We removed import functionality from question.rb because there is no way to import a question out of context from a questionnaire. Importing a questionnaire, means importing questions to fill that questionnaire. 1. SignUpSheet no longer has an import method. After discussing with our mentor, we were instructed to removed the import link on the front-end, the import method, and all related tests. This is done by adding these three methods to each model that has an import method: <code> The above content is specific to the course_team.rb but the three method names are consistent to all the models and are called on the front end. 1. The models that have a ""self.import"" method that does not branch out into other controllers beside ImportFileController will be looked at to make sure they are as concise as possible. None of them can be all the same because they all need to have checks specific to what they need to import. We can, however, make sure that similar models, like assignment_team and course_team, have similar imports. Now, these are the final models/places where a user may import a file into Expertiza: - assignment_participant - assignment_team - course_participant - course_team - review_response_map - metareview_response_map - sign_up_topic - user - questionnaire. The import link did not match the capitalization format in the rest Expertiza. 1. Method get_questions_from_csv has 41 lines of code (exceeds 25 allowed). [172/160] 1. Method has too many lines. (3). The goal was to get all the export functionality routed through one place, the ExportFileController. The overall effect would have been similar to what we hope to achomplish when updating the import functionality. We ran out of time to work on this functionality. All these models have an ::import method that we amended and as a result we need to update the tests. We added or amended tests in their respective .spec files to make sure that the ::import method has 100% coverage.","For design doc:There are many good aspects of this design doc.  It explains what was done, and why, in narrative fashion.  It has a useful diagram showing the changes.  But there are also shortcomings.  The ""what we plan to do"" and ""what we did"" are two separate sections, requiring the reader to read both.  It would be easier to read if the ""what we plan to do"" section had been changed to explain what was done.  The code in the Github screenshots is illegible.  There are several really long lists, that would be hard for the reader to grasp.  It would be better if the lists had been refactored into general topics, with a smaller number of items under each header.  (Code in Github screenshots is now legible, and big lists have been broken up. )"
E1989,"Knowing how much time a student spends on a review is helpful when determining the quality of the review itself. That being said Expertiza needs to be able to track and display how much time a student spends on each review. The time spent on a review is the sum of multiple sources: 1. The time spent on the Expertiza assignment review page itself 2. The time spent looking at external pages linked from the review page 3. The time spent looking at downloadable files submitted by other students The purpose of this project three-fold: 1. Gather the timing data from the sources above. 2. Display the data on the ""Review Report"" page (views/review_mapping/_review_report.html.erb) to show the time the student spent per review. 1. <link> identified how to track the active time of windows opened from the submitted links. ( <link> ) 2. <link> provided detailed insights on how they planned to track time taken by a student in viewing a submission and possible edge cases. ( <link> ) 3. <link> tried to solve this by incorporating the statistics in the review reports page, but their UI made the page cluttered and not friendly. ( <link> ). The reason for choosing to build off of this particular project is because they have already put the work into tracking time spent viewing external pages as well as time spent viewing certain types of downloadable files. In order to achieve our goals outlined in the <link> section, the following changes need to be made: The time spent on the Expertiza assignment review page needs to be tracked. At that point, the time contributed towards the total by the Expertiza page will stop being tracked until the user interacts with the popup to indicate they are still working. This is already implemented in project <link> . The time spent viewing the external links and downloadable files will need to be made more accurate. 1. Currently, if a student has an external link open as well as the Expertiza page, time is being tracked for both. Changes will be made so that when the student is working on the Expertiza assignment review page time is not tracked for the external links or downloadable files. The overall time spent on the review needs to be displayed in a ""user friendly manner"" on the ""Review Report"" page. When clicked, they will display a popup that contains detailed information on where the time for the review was spent. For example, if a student spent a total of 22 minutes on the review, it will show that the student spent 5 minutes on the Expertiza review page, 10 minutes looking at external links, and 7 minutes looking at downloadable files. The purpose of choosing this design is two-fold: 1. It will not require the instructor to have to go to a different page every time they want more details on a particular review. Given that the review report page takes a substantial time to load, this is a necessity. 2. It will prevent the table on the review report page from being cluttered by figures and too much data. Strategy: In this project, for each review page, we need to deal with different type of links. For other files that need to be download and open locally, we can only make approximation for review time. Reviewer Every time a start time is logged for expertiza/link/file, a new entry will be created in the database.End time will be updated on the last entry present for the same link/file. <image> Instructor Time for individual links will summed and then displayed as bar graph. <table> 3. Added view that will display with pie chart when instructor wants to see time spent on individual links/files. <image>. <code> The record_end_time function records the end time for links that have been visited by the user. <code> The mark_end_time function records the end time for links that have no end times. Previous implementations attempted to record the time users spent viewing each link, but their solution has multiple problems. We hope to not need any manual UI testing, though if it is needed, it'll look something like this: Verifying Time is Tracked Correctly: 1. Sign in as as a student 2. Review an assignment 3. Go through the review as normal 1.1. Make sure you open links to github or pull requests 1.2. Make sure you download and/or view files that are attatched 4. Submit your review when you're done 5. Log out as a student 6. Log in as an instructor 7. Navigate to the review report tab 8. You should see a new column detailing the time the user spent on the review. <code>. Because of this the response entry is not updated with the end time and hence when we try to calculate the total response object time, it calculates that as zero and hence shows ""Review hasn't been submitted"". Solution to that would be to save all the entries locally in users system and update the database only with expertiza time and link time after performing the time calculation, once the user clicks Save/Submit.","Very good description of the problem and the approach.  I would have liked to see more description of the code than a single line describing each method.  Most of the files changed don't have any description of the changes.

The algorithm would be more readable if it didn't overflow the text box at the right.

The automated tests should have been described."
E1806,"<image> Users can either view a Bookmark or add a new Bookmark for a particular topic. Users can submit links via add Bookmark to provide helpful sources for the author to complete their work. Authors can rank the usefulness of these bookmarks as 1-5 with a drop down menu next to the bookmark. This can be based on the rating provided by the Author. This project intends to build on the bookmark functionality by allowing instructors to access the bookmark ratings rubric, and designing a way to assess if these bookmarks are being utilized by the author. <link>. When an instructor is logged in, they can manage rubrics under the Manage > Questionnaires tab. However, bookmark ratings are not available to be selected. <image>. After going through the migrations we observed that there have been migrations to add the Questionnaire nodes to the Menu Bar. In these migrations we did not find any code which specifies that the ""Bookmark Rating"" Questionnaire Node has been added to the Menu Bar. We believe that a migration has to be added which will add the Bookmark Rating Node to the Menu Bar thereby enabling the user to see ""Bookmark Rating"" as a type of rubric when they go to Manage > Questionnaires. When logged in as superadminstrator, we can access the menu editor. The menu editor shows the Bookmark Rating link (as shown below) which was added because of the new migration. Although this change is not visible in the actual Menu because the menu editor is not working properly. Admin view shows Bookmark Rating in the menu editor but the change is not reflected in the actual Menu. <image> <image>. When a user logs in as an instructor and selects Manage > Questionnaires, the links associated with the Bookmark Rating rubric are broken. When a user clicks on Bookmark Rating link, it should link to a page to create a new Bookmark rating Questionnaire. <image> <image>. <link> Previously, the Folder node was named ""Bookmarkrating"" because of which, after clicking on ""New Public Item"" or ""New Private Item"" we get an Error message. New migrations have been written in which the node has been renamed to ""Bookmark Rating"" because this is how it has been defined in the Questionnaire Model. Now the links for ""New Public Item"" and ""New Private Item"" works properly resulting in the screens shown below. Page that shows the links for ""New Public Item"" and ""New Private Item"" <image> Page that is redirected to after we click ""New Public Item"" or ""New Private Item"" <image>. The current functionality only allows for the author to review the bookmark, and the reviewer is not able to assess the usefulness of a bookmark. This would involve modification to the existing classes to add “karma points,” which are points a user acquires for submitting helpful bookmarks. Both the reviewer and the author can submit a 1-5 rating on a bookmark- the author does so based on how helpful they found the link, and the reviewer based on how impactful the bookmark appeared to be on the author’s work. These ratings translate directly into karma points, making a user who submits a bookmark eligible to earn up to 10 karma points for that bookmark. This would require a field for karma points in the user database, where points would be stored and accumulated. Only the instructor would be authorised to view a students karma points, and the instructor would be able to list, sort, and filter users by karma points. How the karma points are utilized is at the discretion of the instructor; two examples of usage could be for recognition of helpful students and awarding participation grades based on a baseline of karma points. <image>. 1. Creating a Bookmark Rating Questionnaire 1.1. Login to Expertiza as an instructor 1.2. Navigate to the Manage > Questionnaires menu and select ‘Bookmark Rating’ 1.3. Choose either new public item or new private item 1.4. Enter a name, min score, max score, and choose whether the bookmark questionnaire is private from the drop down menu 1.5. Select ""Create"" 1.6. You will now see a page that will allow you to add questions to your questionnaire. 1.7. Click ""Save"" to save your questionnaire. Our team was required to do the following task : 2. Allow Instructor to add bookmark rating as a type of rubric from the questionnaire menu. 3. Build on the current 0-5 rating system by adding criteria for a bookmark ratings. For example, rather than a simple ask for a 0-5 rating with no rubric, ask the user “How informative was the bookmark?” and “How much did the bookmark influence your submission?” 4. Our team proposed the following extension to the project : 5. In addition to building the feature designed above, karma points could be extended to other parts of Expertiza to reinforce positive user interactions.","The writeup explains the hurdles encountered and the solutions you've found, along with suggestions for future enhancement.  I agree with the reviewer who said it would have been helpful to include code … it would give the next person who works on this confidence about where to start."
E1458,"<link> is a peer review based course management system. It supports project submission,team creation, and review of the submitted material including URLs and wiki pages. Students can manage teammates and can conduct reviews on other's topics and projects. Expertiza is an open source project based on Ruby on Rails. As a part of the OSS project 1 we were expected to refactor the Response Controller of Expertiza. Response Controller is responsible for managing the review versions, finding the latest responses and fetching the review scores. This wiki provides a detailed walk through of our contributions to the Expertiza project with a focus on refactoring. The response controller allows the user to create and edit responses to questionnaires such as performing a review, rating a teammate or giving feedback to a reviewer. Our project requirement was to perform the following changes : 1. Perform authorization properly. 2. Remove the duplicated methods. 3. Reduce the complexity of the rereview method. 4. Move the functionality incorporated in the controller, to the model, as it is the model's responsibility to implement this functionality. The following changes have been made in the project, as described in the requirements document. 1. Authorization to perform actions was done incorrectly via the redirect_when_disallowed method. It is supposed to be done through the action_allowed? method at the beginning of the class definition. Different authorizations are required for different operations. 2. For example, someone should be allowed to view a response if they wrote the response, or they are the person or on the team whose work the response is applied to, or if they are an instructor or Teaching Assistant for the class. The person who wrote a response should be allowed to edit it, but not the person/team who was being reviewed, nor the instructor and neither the Teaching Assistant for the class. 3. Earlier, the authorization was handled by denying incorrect access using the redirect_when_disallowed method, which was a more error-prone way of controlling access. This method has now been removed, and now the class has an action_allowed? method which does the authorization check and allows the user to perform the action only if he/she has the correct permissions. Before Refactoring: redirect_when_disallowed Method was used for authorization purposes. <code> After Refactoring: We replaced the redirect_when_disallowed Method by action_allowed? Method. <code>. 1. There were two copies of the edit, new_feedback and view methods . The second being the newer one, and, according to the rules for method definition, is the one that is currently in use because the latest version overrides the previous versions. We refactored the code by removing the redundant methods for edit, new_feedback and view. Edit method: <code> New_feedback method: <code> View method: <code>. 1. The rereview method was 98 lines long. We refactored the code by turning several parts of it into methods. Now the code is 81 lines long. Before Refactoring: <code> After Refactoring: <code>. 1. The rereview method contained a special code to check whether an assignment is “Jace’s assignment”; this was the first assignment that was ever created with a multipart rubric. It was hard-coded into the system, rather than working on a rubric that was created in the normal way. It is impossible to remove this code without breaking that assignment. It is now implemented as a separate method named handle_jace_kludge. Before Refactoring: The following code was present in the rereview method. <code> After Refactoring: We added two methods named 'handle_jace_kludge' and 'check_user_name_jace?' <code> <code>. 1. Sorting review versions is not a controller responsibility; So we moved it to the Response model . <code> 1. Similarly, the logic for determining whether a review is current or not(i.e., the review was done during the current assignment phase) is not a controller's responsibility and thus was moved to the Response model . <code>. Although ResponseController is a complex class, we managed to improve its code significantly through refactoring. We made use of <link> in order to run analysis of our changes against the original Expertiza code. We have managed to reduce the overall complexity of this class from 719 to 581 and duplication from 685 to 410. Also one of the major refactoring was performed on ""rereview"" method. We have managed to reduce its complexity from 129 to 91 by extracting methods. Original ResponseController on Codeclimate: <ref> <link> </ref> <image> <image> ResponseController on Codeclimate after Refactoring: <image> <image>. 1. <link> 2. <link> 3. <link> 4. <link>. <references/>.","Good, readable, not as extensive as some."
E1971,"<link> is an open-source project based on <link> framework. Expertiza allows instructors to manager courses and assignments for students. Students can form up teams in Expertiza to work on different projects and assignments and do peer review about other students' submissions. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link>. 1. E1971 Project aims to fix the associations problems between the Institution and Instructor class. 1. The forked git repository for this project can be found <link>. The following tasks were accomplished in E1971 project: 1. Task1: The institution list should be sorted alphabetically. 1.1. Details: When creating a course, the drop-down list for selecting the institution does not show in alphabetical order. <code> 1. Task2: Adding a new institution during creation of an instructor profile. 1.1. Details: The admin can attempt to create a new institution when creating a new instructor. But, after one types in the name of the institution & clicks create, it crashes. <code> 1. Task3: Listing of instructors should show their institutions on the same line as their new feature. 1.1. Details: When listing users, there is currently no column to display the user’s associated institution. <code>. As the issue is the Institution drop-down list is not alphabetically sorted. We simply added a step of sort when the Institution list was retrieved from the Database. <code>. The issue occurs when the admin trying to create a new instructor with a new institution name. To fix this problem, we added a function to create a new institution and a confirmation prompt to alert the admin. <code> <code>. The issue is that the user page is not displaying the user's associated institution. To fix this issue, we added an 'institution' column in the HTML file retrieving the institution names of each user. <code> <code>. <code>. <code>. <code>. We created 4 institutions and check if they are alphabetically sorted in the selection box <code>. <code>. <code>. <code>. <link>. <link> <link> <link> <link> <link>.","This wiki page is very well structured and clearly guides the reader through the problem/fixes. 
The test plan, however, does not explain what is tested and how.  It just gives a code listing, and the listing does not even contain any comments
There are links to videos, which is nice, but since the videos do not contain audio, it is much harder to figure out what they are showing than it should be.."
E1924,"Currently, when an instructor updates a questionnaire rubric of an ongoing assignment, the reviews are not reset and moreover, no notifications are sent to reviewers to update them of the changes made. As of status quo, the instructor, post making changes, would have to individually inform each reviewer of the changes made and ask them to change the reviews accordingly. The project aims to resolve the two main issue arising from the problems mentioned above: 1. If a rubric is replaced, or the items/questions are changed, then all the reviews that have been done need to be redone 2. The system should then email the previously done reviews to the reviewer and delete the response object and all associated answer objects. <image>. <image> The main function of the code is to change the rubric questionnaire. There are three main functions to change the rubric of a questionnaire: add, remove or edit questions. Editing a question is considered a minor change as it does not change the general format(i.e. number of questions or their types) of the rubric. The two major changes are highlighted, they are adding or removing a question. In case of a minor change the question in the database is simply updated, no other action/notification is required. In case of a major change, the reviews given for that question need to be deleted in case the question has been removed and the consequent changes need to be relayed to the appropriate databases. Moreover, the reviewers, whose reviews have been removed, need to be informed about the changes made and be asked to update the reviews via email. The primary metric for identification of a major change is when the ids of questions associated to a questionnaire change. When a rubric is submitted after an edit, the update method is called. The current rubric is made such that the question type (Radio/Checkbox/True or False) is not editable, however, the wording of the question can be edited. As per the definition of a major change, it is obvious that there is no change in the question ids(records/objects) associated with the questionnaire. Hence this would be a minor change. The questions can be deleted and/or added. We term an edit as major edit if the change involves addition or deletion of a question because it entails a change in the objects associated with the questionnaire. The params passed to the controller also includes a tag/identifier if a new question was added. We are using this tag to identify there was a new question added and hence major change. <image> In the diagram shown above, the ""Save teammate review questionnaire"" would result in a minor change. Clicking on the highlighted add and remove would result in a change of the questions and is therefore a major change. Once this solution finds that the rubric has major edits and there exists some user who has started the response (corresponding records exist), email notification module is initiated. In this phase, these records are pulled from the ActiveRecord and sent to the user through email. Once the email is sent successfully, records are deleted from the DB. At this stage, the user has all the details already added by them and when they click on ""Review"", the questions now correspond to the new rubric. This lets the user respond to the new rubric without losing data for any question. Firstly, we need to check if there has been a change in the questionnaire, i.e if any question has been added or deleted. The view has been coded such that it adds a tag called "":add_new_questions"" whenever there is a post method to add a new question. We have used this tag to identify a major change and redirected to necessary helper methods. This is indicated in the image below: <image> Similarly, we have identified when a question is deleted and redirected again to helper methods. The next step, is to look iterate through answers database and group the answers for the edited questionnaire per user/reviewer. Using the question ids returned from view, we obtained the response id from the answer database. We tracked this response id through the response, response_map and user models to arrive at the user id. This has been achieved using the code shown below: <image> Once we have identified the answers, user mail id and other associated information, this has to be mailed to the user and then the records deleted. This has been achieved using the code shown below: <image>. As stated in the earlier sections, the update method of the questionnaire controller would be edited to identify major changes and trigger emails and deletions of records of responses. A context corresponding to this in the spec file for questionnaire controller under the describe block for update would be added. Currently, we have added two tests: 1. To verify whether a new question has been added or not and check whether the corresponding answers in the questionnaire have been appropriately deleted. 2. To verify whether a question has been deleted or not and check whether the corresponding answers in the questionnaire have been appropriately deleted.","For design doc:  This is a good description of the rationale and the changes to be made, along with showing how the code was updated.  Only two things jump out at me.  1. It would have clearer if when you showed the update method, you showed it as a diff; I'm sure it existed before, and I'd like to see what changes were made.  Also, it is not clearly stated which controller that change is made to.  2. You should have described what the new tests tested."
E1754,"Expertiza is a web application which provides a dashboard to the students where they can submit and peer-review assignments, projects, codes, and other such objects. It allows students to review each other’s work and improve their work upon this feedback. Rubric advice allows reviewers to see what characteristics of work merit a particular score. Rubric advice lets a user see what criterion or characteristics of work merit a particular score. An instructor can retrieve peer review assignments and leave some advice or give scores based on some criteria. Similarly, students can log in and retrieve the rubric advice left by the instructor. We mocked the behavior of the user (both as an instructor and student) to see how different scenarios work, like modifying, saving and retrieving advice and building feature tests for it. The testing frameworks used for the same were Selenium and Capybara. An instructor when creating a questionnaire, can associate marks with comments which can enable a student to understand what score is appropriate for a particular work. An instructor can subsequently edit or delete an advice. A student can view and use this rubric advice when peer reviewing other's work. Thus the test cases formed check if an instructor is able to: 1. Create a questionnaire 2. Edit or delete an advice Creating a rubric advice has not been added as a test case because both edit and delete advice make an instructor 'create' an advice. An additional test case to do the same would have slowed down the testing process and hence is not advisable. Student Side: A student, when filling a peer review should be able to see the rubric advice associated with a particular test score. We test this task through adding a test case in the peer_review_spec.rb since Peer Review is superset of the Rubric Advice feature as it is a task where a student uses the rubric advice and submit it. Files changed: peer_review_spec.rb The test case checks if student is able to select a rubric advice that the instructor has created and then submit it. <code> The existing code given creates the required environment for the test student. It sets up a team, assignment and other required elements for the test student to submit a review. <code> The rubric advice is prepared in factory.rb with the following code addition . This allows our test Student to get a ready rubric advice that he can choose. <code> Instructor side: Edit a certain review rubric, and add advice to it. Test that when advice is added for a particular criterion, the advice can be retrieved and that it is exactly the advice that was added. Files added: review_rubric_spec.rb <code> Apart from the major test case for Rubric advice, it is essential to test if the logged in instructor is an authorized instructor. To test this, we have added the following test in review_rubric_spec.rb. Also, the task of loading the questionnaire and the question types is implemented in separate methods to allow reuse. <code> Factories.rb <code> It associates a merit score with each type of advice. As an example, 5 denotes 'very good'. 1. <link> 2. Build passing with Coverage increase of +0.3% <image> <image>. 1. <link> 2. <link> 3. Run the test cases: <code> <code>. 1. <link> 2. <link> 3. <link>.","Fairly readable.  Prose could be written to describe the workings of the test, rather than just their result.  Not clear why testing advice requires verifying that the logged-in user is an instructor.  Shouldn't this be performed in the class that implements logins?"
E1701,"<code> One reason is that we use fixture to create records in test DB each time running tests. <code> One solution is building an complete database to support all RSpec test without creating new records. Formally, we need to: 1. Create the records in test DB according to the content in fixtures. 2. Check each test file and delete certain DB records creation code that insert default records (eg. create(:deadline_type)). 3. And keep all the test cases passing when using test DB and make sure the time running test cases is shorter than before. 4. You should submit the sql file of test DB to Expertiza. To finish these tasks, we need to modify all RSpec test files in Expertiza and using a new Database:Expertiza_test. test database Rspec tests. <image> In this design, we create a new database for testing, and we save some related information in this database. Every test just need to fetch data from this test database, and after the testing, we need to add some operation to rollback the data. For example, if the test is about creating a new quiz, in this situation, we need to delete this quiz after this test. Because of it, the state of database can be saved, and also it will not influence other test or test this test case again. We design a expertiza_test database to save the test date used for Rspec. The test database owns the same structure as the real expertiza database, including the relations between tables and some restriction of attribute like it cannot be null or some other requirements for different attributes. Besides, the data in test database is the same as the data in factories part in spec, which includes FeedbackResponseMap.rb, Respone.rb, factories.rb, quiz_factory.rb. In this situation we do not need to create some data before testing, and we can use the data in test DB directly. like the Rspec statements in creating some User objects. : <code> then transfer this into SQL query and then add the information the same as designed for Rspec test into expertiza_test database. We will try two method to achieve the goal: 1. Write a script to create all test data automatically then don't clean the database. 2. We transfer the data in girls_factory into the data base, and there are some steps: 1. we delete some related information in Rails_hepler.rb <code> Those statements is used for adding the technology to clean the database before everytime using Rspec test, and then also clean the database(using turncate to increase the time of cleaning database). 2. We generate a new create rb file, and in this file we just put the create statements in Rspec style function, like create(:deadline_type, name: ""submission"") to transfer the data into database when running rspec create.rb. To accelerate the feature test, we have to eliminate pseudo data creation. Now all the feature tests must create their own data before each test. For an example, now a test first create a user before it can do the login operation. After building a test database, all the pseudo data creation statement can be removed from the test files. Instead, the tests reference data stored in the test database. The way tests reference data from database is the same as it does in the development mode. To login, or do other operations, the test can invoke existing user data in test database. Using ""User.find()"" or ""User.where()"", test data can easily be invoked by tests. For existing tests, they can directly use the test database. For new tests added later, they can use the records in test database or create specialized data use FactoryGirl. So to keep the test database up to date ,it needs to be maintained regularly. With test data in the database, we modified the RSpec feature test files: 1. Disable the data clean statement in rails_helper.rb. <code> 2. Eliminate data creation statement in each test case. Delete” create(:assignment)” like code 3. Modify url visit statement. Modify “visit '/student_teams/view?student_id=1'” to @student=User.find_by(name:”student2064”) “visit '/student_teams/view?student_id=@student.id’” 4. Recover test database before or after each change data operation For tests involved with create or delete actions, the data modified should be rollback. We run a single rspec test ""airbrake_expection_errors_feature_tests_spec.rb"" to test the performance improvement when using test database. Without a test database, the feature test costs 1:37 minutes: <code> Using the test database, the same test costs 1:10 minutes: <code> The time is decreased by about 20%.","I do not think your UML is correct. (should not include github pull request and github repo, etc.) You pasted a lot of code. It will be better to explain what each piece of code does."
E1689,"For example, if the server on which the application is deployed is down, then the reviewer can send a message that the server is down to the authors and then the authors can get the server up and running and send a message to the reviewer informing the same rather than receiving low grade on that review. To implement the chat feature , we are creating 2 new models i.e Chat and Message. The associations for these models are Chat belongs to AssignmentTeam and has many messages while Message belongs to Chat. Now, the Chat model will contain the assignment_team_id element. Using AssignmentTeam, we can find whether the chat user is a reviewee or the reviewer. 1. Chat (belongs to AssignmentTeam) 1.1. id - primary key - int 1.2. assignment_team_id - id of the team - int 1. Message (belongs to Chat) 1.1. id - primary key - int 1.2. body - contains the message body - text 1.3. user_id - id of the sender. - int 1.4. chat_id - id of the chat to which this message belongs to. - int. <image>. 1)Scenario 1: When the reviewer has a doubt and wants to send a message to the reviewee group. A new link for chat will be provided along with the begin/edit options of a review. Clicking on this link will pop a chat up. <image> 2)Scenario 2: When the reviewee group wants to view their messages or send messages to his reviewers. A new link for messages will be provided along with ""Your work"". Clicking on this link will pop-up a chat box where the reviewee can see/send messages. For implementing a chat feature using the above technique requires the client to keep on poling so that it receives the latest messages from the server. We will have the messages of the chat displayed in a partial which is updated using Sync - Realtime Rails Partials. <code> The first tag fetches all the messages that are related to this chat that were previously sent and the second tag fetches new messages in the real time. Message.bychat function helps us in scoping so that only the messages related to this chat are fetched. Instead, we publish the messages to the corresponding chat box and using sync config , we make the users, i.e the authors and reviewers subscribe to this particular chat box. The dependency between them is a one-to-many relationship , i.e a Chat has many messages and Message belongs to Chat. The message model also has a many-to-one relation with User while Chat has a one-to-one relationship with AssignmentTeam. We added the relationship corresponding to chats and messages in existing models User and AssignmentTeam. We also added a oncreate method in Assignmentteam for creating a new chat whenever a AssignmentTeam is created. The major functionality this controller provides is that via sync gem, it syncs a new message to the corresponding chat as soon as the new message has been saved which facilitates the real time chat. It contains the method is_reviewer(message) which take the message object as input and return whether the message was sent by author or reviewer. It is the partial in which messages are rendered row wise in a chat box. The _responses.html.erb partial in student_review view has been modified to provide the Chat option for the reviewer. The reviewer has to click on the Chat link to send or view messages to or from the reviewee team. The view.html.erb in student_task view has been modified to provide a Your messages link for the reviewee team. 1. Chats.js file has been added for managing the pop up chat logic. 2. Chats.css file has been added for managing the styles related to the chat popup. 4. Click on the chat button next to the assignment topic. 5. Type the message. 6. Assert the presence of the message in the window. Post conditions: The message has been sent to the author. 3. Click on ""Messages"" 4. Assert the presence of the message in the window. 5. Type the message. 6. Assert the presence of the message in the window. Post conditions: Author has received the message and can send messages. Testing the newly added Models - Chat,Message. 1. Model validations for the chat model: validating the chat so that it has a unique assignment_team_id. 2. Model validations for the message model: validating each message has a user_id, chat_id and a body. Also, checking that it belongs to both user and chat classes. Currently, a member of the reviewee team can view messages from all of the reviewers in a single pop-up box . In future, a unread messages feature can be developed which shows if the user has any new messages since the last time they have opened the pop-up box.","This is a very good example of what we expect in a design doc.  It could include more details on the tests that were anticipated.  It would also be useful to update it to say what you actually did, as a group following on to your work would need to know this."
E1676,"In the current version of Expertiza, members among a team can evaluate each other’s contribution and give appropriate scores based on the same questionnaire. However, in the lifetime of software development, members in a team often take on different roles whose works content are vastly differentiated. Like in an agile development environment, such as Scrum, there are typically <link> can take: software engineer, architect, programmer, analyst, QA expert, tester and UI designers . Job description and evaluation entailed are vastly varied among these roles, thus a generic assessment rubric cannot hold reasonably. The rationale of our project is that we want to give project members the option to evaluate each other's work based on the specific role or duty they take in the development process. This can ensure a reasonable assessment for different duties and can also help to improve the utility of using members-reviewing in the whole reviewing process. Task Description: There are general three aspects we would do in order to achieve the Role-based reviewing function. 1) A new option (check box) would be added to the Review Strategy tab from the instructor view when he creates a new assignment. What’s more, the instructor can create different roles or duties available for the assignment by typing into a text filed. The instructor also has the power to allow multiple members to choose for the same duty. 2) In the Rubrics tab from the instructor view, New rubric would be generated by creating different questionnaires for different roles when adding new assignment. 3) A new option (drop box) would be added to the “Your team” page from the student view when an assignment was created to be role-based reviewing. Student can choose their roles or duties from the drop box which were generated by the instructor for this specific assignment. When the instructor enabled the multiple selection option, different members in the team can choose same duties for this assignment. Tasks can be viewed more clearly by the graph below: <image>. We have modified following three database tables to support role(duty) based reviewing: 1. assignment_questionnaires 2. assignments 3. teams_users <table> <table> <table>. Below are the key files modified: <code> <code>. See <link> section above. Below are the view files that we modified <code> 1] View showing newly added checkbox for setting duty based option and allowing duty share <image> 2] View showing different questionnaire for different teammates based on their duty <image> 3] Assign questionnaire to teammates based on their duty <image> 4] View showing ""select duty"" link for teammates. Every student can select their duty in the team. <image> <image> 5] After selecting, students can update their duty. Also, they will get the review questionnaire based on duty. <image> 6] Review questionnaire based on duty <image>. In our project, we are providing an option of adding duty for different team members in an assignment and giving review options based on their duty. We will add following functionalities: 1. How instructor create assignment with duties/roles 2. How students take duties from a given list of duties 3. How teammate evaluation rubric assign different review questionnaire based on duty. UI will be tested manually. First, we will test creating an assignment as an instructor with different duties and assign different review questionnaires to each duty. Then we will login in as a student and take a duty from given list of duties. We will try covering all edge case scenarios in test cases section. Following will be the test cases: 1. Login in as an Instructor: <code> 2. Login in as an Instructor: <code> 3. Login in as a Student <code> 4. Login in as a Reviewer <code>. For functional testing, we will use RSpec. It uses Behavior Driven Development (BDD) for testing functionality of the system. It provides way to describe specific functionality of the system being tested and helps in better visualization of test cases. We will use Capybara for automating the manual test cases. It is a web-based automation framework and coupled with RSpec. It allow developers to write the test cases which simulate the whole scenario of manual testing. 1. Verify if instructor can select duty option <code> 2. Verify if instructor can correctly set the duty <code> 3. Verify if duty share is allowed <code> 4. Verify if student can select duty <code> 5. Complete test cases are present in following files: <code>. Expertiza <link> RSpec <link> ScrumRoles <link> CapyBara <link>.","Good work with design document. Sufficient information about design
Information provided for both Manual and Automated testing
Explained problem statement with visualizations"
E1753,"Please note that the requirement for the project has been changed to feature tests (different from the previous review) after discussing with the project mentor and the professor. Updated in Problem statement. Expertiza is an open source project developed by North Carolina State University using Ruby on Rails. It is mainly a tool used to collaborate among students and faculty on a course and act as a common repository to track students’ progress on assignments. It is a simple tool where the instructor creates multiple assignments required and teams are assigned projects. Students submit their work and review other’s work and provide feedback. 1. <link>. 1. <link>. The bidding feature allows students to sort topics by preference. This is needed in order run the team assignment algorithm, to match students with others based off the similarity in their topic preferences. The feature matches students to teams by calling a team forming algorithm hosted on a web service. Teams are then matched to topics by choosing the most common priority chosen by each member in the team for each topic. Topics are then assigned to students with preference given to the largest team. • Students submit bids on the sign-up sheet view. The bidding process is done in the lottery controller. • One set of bids is possible for entire team. When one team member changes a bid, it will affect the whole team. Currently, each participant has a bid record. A Json request is sent to a webservice hosted on PeerLogic which responds with the new teams. (More information: <link> ) • During topic assignment the teams’ bids are determined by using whichever priority most students placed on a topic (Ex. If 3 students set topic 3 as their 1st priority and 1 set it as their second. Topic 3 would be set as the priority for the team.) • Matching algorithm: Teams are first sorted by size and a matching algorithm assigns each team to its highest available bid. This is an only Testing project to write feature tests for the process. The same is explained in screen shots and video attached. The previous requirement regarding the modifications in sign_up controller have been changed to feature tests and the following problem statements have been taken care of. Each team or an individual can go through the list of topics and set priorities for different projects. And once the priorities are set up for all projects, bidding algorithm is executed to assign projects to teams based on the priorities. The following need to be taken care of as part of this work package. (E1753) • Test for the entirety of the bidding process. • Users are able to place bids on interested topics. • Users are assigned topics. /spec/features/bidding_spec.rb. All bidding process like creation of assignment, adding topics and enabling bidding has to be performed before every test case. This code is placed in the before block of the rspec test code. This code is executed before all the test cases. <image> For the first test case, code is written to verify the web-service which runs the bidding algorithm is working properly if the bidding process is enabled. <image> For the second test case, code is written to verify that the bidding process fails if no participant has placed bids. <image> For the third test case, code is written to verify that each user is assigned a topic after running the bidding algorithm. <image> For the fourth test case, code is written to verify that when the user places multiple bids the bid with the highest priority is assigned to the user. <image>. Code coverage is extremely low and only limited to the function signature even after executing 6 test cases. Screenshot below shows code coverage before implementation of test cases. <image> Solution Code coverage has drastically increased after the integration test cases are executed. Screenshot below shows code coverage after the execution of the test cases. <image>. Manual testing of features on Local host is done with a running Expertiza environment. ( As seen on video). The following steps have been taken care of to setup ad run the bidding process manually. • Login as instructor and create assignment. Create topics under the assignment. • Enable bidding and associated properties for the created assignment. • Login as student, create teams and bid for projects. • Login as instructor and run the bidding algorithm. • Login as student and check if topics are assigned. The screen shots for the added feature test cases have been attached below. (Also attached as video file). Test cases written to check for the following scenarios. • Check for whole bidding process to run successfully. • Check for Error message for unsuccessful bidding run. • Check if user is assigned a topic successfully. • Highest priority bid assigned when multiple bids are placed. Screenshot of the executed integration tests is attached below. <image>.","The functionality of the tests is described.  It would be helpful if (i) the working of the test code was described and (ii) the fonts were larger so the code could be read without zooming in.  The section on code coverage refers to integration tests, but these are not mentioned by name in the writeup."
E1671,"Expertiza is an open source web based peer review system developed and maintained by students and faculty members at North Carolina State University. It enables students enrolled in a particular course to form online teams and complete assignments. The participant, course_participant and assignment_pariticipant models does not have any unit tests. 1. Create a Factory for assignment participant and course participant model. 1. Test the relationships and validations 1. Write model spec for major instances. 1. spec/factories/factories.rb 1. spec/models/participant_spec.rb 1. spec/models/assignment_participant_spec.rb 1. spec/models/course_participant_spec.rb. Unit tests are used to test the functionality of methods in the model. These tests can be based on either test-driven development (TDD) or behavior-driven development (BDD). BDD is preferred for testing because it easy to understand compared to the more specialized TDD.<ref> <link> </ref> In this project, BDD is used to test the functionality using RSpec. RSpec is a testing tool for ruby using the BDD approach.<ref> <link> </ref> Factories are used to populate the database before the tests are run. The factory for the Participant class is already present. The factories for the other two classes will be very similar. The only differentiating value will be type which can either equal AssignmentParticipant or CourseParticipant depending on the class. Below the factories for AssignmenmentParticipant and CourseParticipant are given. <code>. The Participant class is the base class for both the AssignmentParticipant class and the CourseParticipant class. We have used the rspec framework to test each of these three classes. The factory library used is Factory Girl and the factories themselves are located in factories.rb. Tests are usually centered around conditional statements, for example if there is a statement following a condition that evaluates to be true. Here it can be tested that the statement is always executed correctly when the condition evaluates to true. The participant class is used to describe the participants of a university class. Unit tests for this class is written in the participant_spec.rb file. The first few unit tests defined are used to test the value of data members. There are also three unit tests to test the functionality of the fullname, topicname and name methods. <code>. The AssignmentParticipant class inherits from the Participant class. This first test is to validate whenever an object of AssignmentParticipant is created. Then there are three tests for the methods type, average_scores and copy. Lastly there are four unit tests defined to test the functionality of the method import. These tests can be found in assignment_participant_spec.rb. <code>. The Course Participant class is to show the participation of the student into a particular course. The course participant class is inherited from the participant class associated with the course class through belongs_to relationship. We have tested the four different methods of the class course participant. These tests are found in the course_participant_spec.rb file. The first method to test is the copy method. The copy method checks if an assignment participant exists for the corresponding parent_id. If it exists then a null is returned otherwise a new object for assignment participant is returned. We check both the functionality of the methods using two different tests for the method class. The next important method is the import method. The import method consists of four different scenarios and thus we have written test for testing four different scenarios for the import method. The import method takes a record field and input and checks for various condition on the record field and creates the course participant object. Below is a short snipped of the various tests written for the copy and import method <code> <code>. The tests can be run on the terminal from inside the expertiza folder using following commands: For participant: <code> For assignment_participant: <code> For participant: <code>. <link>. <references />.","The CourseParticipant tests are described much more fully than the other tests.  I would have liked to see similar descriptions of the other tests, though as it stands, the code is already pretty readable."
E1624,"Suggested topic functionality is designed for students to suggest topics they interested in. An assignment can be set up to allow students to suggest topics at the discretion of the instructor. The proposer can state that (s)he wants to work on the suggested topic. When the instructor approves a suggested topic, if the proposer wanted to work on it, it is assigned to the proposer. The purpose of suggested topic is to make the writing assignment more personalized. Currently, there is no functional test for student's topic suggestion function. 1. Understand the flow of the suggested topic function. 1.1. One team is on the waitlist. They sent a suggestion for new topic and they want to choose their suggested topic. After their suggested topic is approved, they should leave the waitlist and hold their suggested topic; 1.2. One team is holding a topic. They sent a suggestion for new topic and they want to choose their suggested topic. After their suggested topic is approved and they choose to switch to suggested topic, they will hold suggested topic and their old topic will be released. And if another team is in waitlist of that old topic, that team should hold the old topic now; 1.3. One team is holding a topic. They sent a suggestion for new topic and they do not want to work on their suggested topic. After their suggested topic is approved and they choose to public suggested topic, they will still hold their old topic. Their suggested topic will be added in sign-up sheet. To test the functionality of student's suggest topic, we plan to use Capybara to write the test code for each step listed below, covering all three scenarios. In the project, we assume that an instructor account instructor6 and a student account student11 is already created. First step is to login with the instructor account ( instructor6 here), and then create a course with the new public assignment function. We will create the assignment and edit the topic feature to enable the topic suggestions function for student, where in the UI, it means select the ""Allow topic suggestions from students?"" Also, to test the second and third scenarios that the student already hold a topic, we will add a new topic with 1 slot for testing the later two scenarios. After all above are done, the course just created can be saved to the test database. In this step, we need to write two functional tests: one is to check whether the course can be added and does the added one have topic suggestion enabled, the other one is to check whether the topic is added by instructor with 1 slot. <image>. After the course is added, the student ( student11 for this test project) will be added as participants to the course. In this step, we need to test whether the student, named student11 , is added to the course correctly. <image>. For the first scenario, which the student does not holding any topic, we should test after login with student11 account and choose the assignment just created by instructor6 . Then, we will suggest a topic with the choice of ""Yes"" for the question Do you wish to work on this topic? and submit the new topic suggestion. In this step, we need to write the function test to check whether the new topic is added and the student is willing to work on this topic if it is approved. <image>. For the second scenario, we should first let the student login and Signup the only topic created by the instructor in the Signup sheet. Then do the same thing as depict in Step 3.1. In this step, we need to write two function tests: one is to check whether the student is already on the student list the topic, and the other one is to check whether the topic's available slots of the topic is 1 and the max number of slots is 2. <image>. After login the instructor account, use the assignment view suggestions function to view and then approve/reject the new suggested topic. In this step, we need to write two function tests: one is to check whether the Signup sheet does have/not have the suggested topic if it is approved/rejected, the other one is to check whether in the student suggest new topics , the topic suggested by student11 is indeed approved/rejected accordingly. Note that, this step is the final test step for the case of suggested topic is rejected. The following 3 possible step 5 is for the case the suggested topic is approved. <image>. In addition to step 4, since the choice is ""Yes"" for willing to work on this topic when the student suggested, we will also need to test whether the student is already on the list of the new suggested topic and the number of available slot of the new suggested topic is 0. An error occurred while attempting to extract the child content. For the student was holding a topic, coupled with the test written for Step 5.1, there is another test need to be written to check whether the slot of the previous held topic is increased by one. <image>.","Should use Factory Girl to create assignment.
Duplicated code on instructors' logging in and approving the topics
"
E1865,"This project aims to enhance the review mapping of the two conflicting reviews which causes an email to be sent to the instructor when there is a considerable disparity in the grading between two reviews. The goal is to help the instructors by making the process of grading reviews easier and more accurate. Currently, when a new review is submitted and the difference between the score of the new review and (average of the) scores of all previous reviews differ by more than a set threshold, an email is triggered to notify the instructor for such disparity. The email consists of an URL only for the new review. <image> <image>. <image>. Current scenario: The function 'significant_difference?' in the model response.rb takes on the average scores of all the existing reviews (by looping through each review to calculate the average) and compares it with the score of the recent response. If the difference is greater than the limit specified(notification_limit), it triggers an email to the instructor with the new response’s (conflicting response) URL. Implemented changes: Instead of taking on the average scores for existing reviews, we will loop through each review not for calculating the average but to compare the new review score with each review score (a new function will be called to compare with existing responses once a new review is in system). If for any response the notification_limit is exceeded, the review URL of that iteration will be stored and at the end of the function once all the reviews are looped an email will be triggered comprising of the URL of a new page ""conflict_view.html.erb"" which displays the new review and all the previous conflicting reviews.. Files created/changed: 1. response_controller.rb Added a function ""conflict_view"" which returns all the IDs of the conflicting reviews. <image> 2. response.rb Added a function ""scores_and_count_for_prev_reviews"" which checks the difference between the score of the new review and the score of each of the previous reviews and returns the response IDs of all the reviews whose difference is greater than a set threshold to an function named ""significant difference?"" which in turn triggers an email to notify the instructor. <image> 3. conflict_view.html.erb Created a new view to display the new review and all the previous conflicting reviews to the instructor. (File on the github repo: <link> ) 4. routes.rb Added a route for a newly created ""conflict_view"" page. <image> Snapshot for notification email triggered before implementing our changes. <image> Snapshot for notification email triggered after implementing our changes. <image> Snapshot for the view which the instructor receives (before implementing our changes) <image> Snapshot for the view which the instructor receives (after implementing our changes) <image> Please watch the video provided to have a look on our implementation. Link: <link>. 1. Rspec file ""conflicting_response_spec.rb"" is created to check if there is the function significant difference is working and an email is triggered or not. <image>. Expertiza 1. <link> Expertiza Github 1. <link> Github repo 1. <link> Expertiza Documentation 1. <link>.","The wiki page does a good job of describing the changes made.  However, the header, ""Review for Mail check"" is cryptic.  I don't know what it means, or how to get to it.  The text in some diagrams and code snippets is huge, which requires zooming way out to read it.  Also, the code snippets are not really described.  They do contain comments, but only one or two prose sentences describe what they do."
E1830,"GitHub hooks to Expertiza to encourage contributors. Expertiza project is supported by National Science Foundation. Description of the current project This project is intended to make Bookmarks more user-friendly, credible and valid. Bookmarks in expertiza are created by reviewers and can be used by authors for their work on any project. On each line of the signup sheet are two icons, one for adding a bookmark to the topic, and another for viewing bookmarks on the topic. If the instructor allows the participants to create bookmarks, then only a participant has access to create and view them. He should be able to create a new Bookmark only if he enters a valid one. Now a new rubric is added for reviewing the bookmarks added to a topic and this is accessible only to members belonging to the topic. Therefore ratings can be now done via a drop-down or rubric. Problem 1 When a user after logging into expertiza goes to 'Create New Bookmark page"" or ""View existing bookmarks page"", he's not able to go back to Sign-up sheet using ""back"" button. <image> Solution : <image> Problem 2 Bookmarks had only one option while reviewing and it was to use a drop down to give a score. Also the average rating metric had a bug and hence showed wrong values even when bookmark was not reviewed. The bug was fixed and the rubric feature was adding a new controller. Now choosing ""Scale"" Option instead of ""Dropdown"" allows one to use a rubric instead. <image> The rubric for rating the bookmark shows up as a link that looks as follows : <image> The rubric looks like : <image>. Scope of our changes The changes made in this project affect the Bookmark Controller so tests are written for its validity. Also we noticed that the Bookmark Model didn't have any testing done so we are planning to test that. While manually testing for correctness we came the issue of average rating present even when no rating of the bookmark was added, additionally the computation of average had a bug and was hence giving wrong average value. The picture below shows the the bug the previous code had : It shows an average rating value of 4.0 even when no review was done. <image>. 1. Fixing Average problem and adding Rubric feature : The following files were modified for fixing the average rating bug and adding rubric for the same. app/models/bookmark_rating_response_map.rb app/controllers/bookmark_rating_questionnaire_controller.rb app/controllers/bookmarks_controller.rb app/controllers/response_controller.rb app/views/assignments/edit/_rubrics.html.erb app/views/bookmarks/bookmark_rating.html.erb app/views/bookmarks/list.html.erb app/views/response/view.html.erb config/routes.rb 2. Tests for Model and Controller : spec/controllers/bookmarks_controller_spec.rb spec/models/bookmark_spec.rb spec/factories/factories.rb. Automated RSpec tests were added to ensure the bookmarks are valid. Separate tests were written for the Bookmark Model and BookmarkRating Controller files. Below shown is the coverage details <image> <image> a) Back button for the page ""View Bookmark"" and ""Create Bookmark"" was resolved. 1. Login with the credentials to expertiza. 2. Go to 'My assignments' and select OSS Project/writeup. 3. Select 'Signup sheet'. Select a title and choose either 'View Bookmark' or 'Add Bookmark' button 5. If you choose 'View Bookmark', after viewing, press the back button to go back to Signup sheet. 6. You will land up in Sign-up sheet page. 7. If you choose 'Add Bookmark', you can add by giving Bookmark details and save it. 8. Now press back button. 9. You will land in Sign-up sheet page. b) Adding Bookmark Rubric. 1. Login into the expertiza with the Instructor/TA credentials. 2. Go to 'Manage Content -> Questionnaires' 3. Select new public/private item under BookmarkRating 4. Fill in with required values and create it. 5. After this if you go to bookmark rubric option it should be visible c) Allowing Bookmark Rubric. 1. Login into the expertiza with the Instructor/TA credentials. 2. Go to 'Manage Content -> Assignments' 3. Select the appropriate project 4. Now edit the project. 5. Check the box ""Allow participants to create bookmarks?"" 6. Choose the appropriate rubric from the list or create one following steps from above. 1. A reviewer can be recognized or credited if he added useful bookmarks i.e if the author has made use of the bookmark.","This is a pretty good narrative of what the authors have done.  It gives screenshots for all bug fixes and describes the tests written.  The only weakness is that it does not say anything about what code has been changed to address the bookmark issues.  It wouldn't have to include code snippets, but it should at least describe the changes."
E1947,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.5. <link> 1.1.6. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.2. <link> 1.3. <link> 1.1.1. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. The following tasks were accomplished in this project: 1. Rename filename such that it follows the coding standards 2. Remove redundant information from method names 3. Add comments to methods and complex lines of code 4. Remove unsafe reflection method 5. Simplify RSpec 6. Try to fix issues from Code Climate. It is used to allow students to take quizzes. The idea is that the author(s) of submitted work can write a quiz that is given to each reviewer before the reviewer is allowed to review the work. If the reviewer does badly on the quiz, then we know not to trust the review. It is also possible to set up an Expertiza assignment so that some participants just take the quiz and don’t review the work. 1. A student can create a quiz questionnaire for the assignments that allow a quiz to be generated. This quiz will be taken by the reviewers, once they are done reviewing the development/project. Based on their answers the TA's can know whether to consider the reviewer's review or not based , because if the reviewer didn't perform well on the quiz, then it is likely that the review is not done properly. 1. The question cannot be blank and correct answer must be selected to create a quiz. 1. Problem 1 : Rename filename such that it follows the coding standards 1.1. Solution : Currently the file was named as quiz_questionnaire_controller.rb . Hence it was changed to quiz_questionnaires_controller.rb 2. Problem 2 : Remove redundant information from method names 1.1. Solution : Since this controller was separated from the questionnaires_controller.rb , the method names were kept the same from the previous controller which had redundant information. Method names were renamed by removing the succeeding '_quiz'. Also valid_quiz was renamed to validate_quiz to make more sense. Also the routes.rb was changed to accept these changes. 3. Problem 3 : Add comments to methods and complex lines of code 1.1. Solution : Many methods had more than 325 lines of code and performed multiple functionalities. These methods were changed by creating private methods that performed individual tasks, thus reducing the lines of code and the complexity. 4. Problem 4 : Remove unsafe reflection method 1.1. Solution : This part was already implemented, hence no changes were made. Method questionnaire_params was already defined and takes care of this issue. 5. Problem 5 : Fix issues from Code Climate 1.1. Solution : Refer to Solution for Problem 3. 1. The method save_choices had a congnitive complexity of 23 and had 37 lines of code. By refactoring, the number of lines was reduced to 20 and private methods create_checkbox , create_truefalse and create_radio were implemented to break up functionality and to reduce cognitive complexity. Before: <code> After: <code> 1. The method action_allowed? has been implemented in quiz_questionnaire_controller.rb to specifically allow Student to edit an existing quiz. 1. The quiz_questionnaire_controller_spec.rb has been updated to allow edit tests to work for Student role. <code> Before: <code> After: <code> Before: <code> After: <code> 1. The method update_quiz has been renamed to update and has been refactored to reduce the line count by breaking functionalities. (The function multiple_choice_checkbox was renamed to update_checkbox and multiple_choice_radio was renamed to update_radio so as to reduce function name length and bring consistency with methods performing create operations: create_radio , create_checkbox , create_truefalse ) The Cognitive Complexity of update method has now been reduced to 15 (from 29). Before: <code> After: <code> <code> 1. The method valid_quiz has been renamed to validate_quiz . The Cognitive Complexity of 12 has now been reduced to less than 5. Before: <code> After: <code> <code>. Link to <link> showing the RSpec testing. <image>. <image> <image>.","The structure of the document is good; it is easy to see what has been changed.
It is clearer to paste in code snippets from Github than to use the wiki textbox for it, because the font is more readable and long lines are wrapped.
In the first code improvement, it appears that you moved some code out of save_choices.  Where did it go?  BTW, comments are needed on/about the method.
In general, more comments are needed to explain what each method is doing.
The test plan does not say anything about automated tests."
E1912,"Expertiza is an Open Source Web Application Software managed by National Science Foundation. Expertiza is used by many courses including CSC 517 for assignment management. It has functionalities such as peer reviews, teammate reviews and tagging reviews in which students can provide feedback on other's work which helps peer in better developing the project. The Expertiza team currently had to manually fire queries in the database in order to get the tag submissions made by an individual user(student) on each review for a particular assignment. In this way, the team got the data from the entire class, which was then used to feed the Machine Learning algorithms. But many times it used to happen that students made random tags and the ML algorithm was not able to make good predictions out of it, hence in order to solve this issue a new idea was proposed as to select on the students which did not create outliers in the predictions and hence, therefore, it is a good proposal. In order to perform this task following files were identified where the code hasbeen added. 1. In _answer_tagging_report.html.erb view, a button is added for exporting the student's tagged values 2. A checkbox for each row has been added in order to select students whose tags are to be exported(By default all will be selected). 3. A method is written in export_file_controller.rb controller named export_tags that exports the CSV file. The workflow diagram of our implementation is shown here: <image> We have added a default select all checkbox under Report tags done by each user which enables student selection for exporting tags in the CSV file. We have added a column for the checkbox and a button named Export which on click generates the CSV file. <image> Below is the snippet of the same view _answer_tagging_report.html.erb <code>. 1. <link> is the link to a screen recording on how to access the functionality and export the CSV file. We have written a method inside the export_file_controller.rb . Once this method is called it queries on the name array passed from the view and exports the CSV file with the required data. The attributes named variable stores what all data is needed from their respective table and only that data is dumped into CSV. <code> The output file has user_id, tag_prompt_deployment_id, comments and value . We can see that some comments are repeated it is because every review that is received has at least 1 tag for it. Hence we see the repetition. The value column has -1, 0 and 1 as No, not answered and Yes meaning respectively. <image>. The code was written for adding functionality such that selected students data can be dumped into a CSV file. A valid test case for this would be if nothing is selected and still the export button was clicked it would not dump any data into CSV file. The data is well structured so there would not be any scenario that a NULL data will be dumped. Every column will have its value in every row. The functionality for our project was to implement exporting of tagged comments from the Expertiza system. For this, we will approach the project by using the delegation pattern to add exporting capabilities to the export file controller for exporting tags. 1. <link> 2. <link> 3. <link>.","I thought you could have described in more detail what the code does, e.g., what tables and fields are involved, and how you iterate through them.  Giving the final code doesn't provide a very easy way for the reader to understand your approach."
E1837,"At the heart of Expertiza is the ability to review the work of other teams and review your own teammates.The Review Mapping Controller is at the heart of coordinating all of the necessary steps to assign reviews in various ways to specific students or teams. As such, this controller has become rather large and unmaintainable over time as new types of reviews and review assignment strategies are created. The purpose of this work is to improve the maintainability of this controller based on the goals listed below. - separation of concerns - remove unused methods - properly group like methods - remove SQL statements from the controller into models/helpers where applicable. As part of refactoring, we have introduced several new Helper classes and methods. This helper now contains isolated methods for each report type that needs to be built from the controller. This helper is implemented as a module, so any/all instance variables are added to the class including it. This allows us to keep the controller logic very small but still populate all needed values for the report views. Each report type is represented by a separate method in the Helper and the Helper exposes a single public method to render the report. This allows us to hide implementation details to be changed later as needed from within the module and the controller can generally stay the same. The only caveat is that all of the correct instance variables will need to be defined and populated per report. We considered refactoring the reports section, but after discussion with our mentor, we decided it would be a large enough effort in of itself to change how reports are generated and rendered. The previous implementation for the Automatic Review mapping method ( automatic_review_mapping ) was lengthy and overrode specific arguments within the Automatic Review Mapping Strategy method ( automatic_review_mapping_strategy ) before actually assigning reviews. We decided to implement an actual Strategy pattern here. We created a simple ReviewStrategy class with the following subclasses: - StudentReviewStrategy - TeamReviewStrategy Each of these strategies determines the number of reviews per team, the number of reviews per student, and the total number of reviews needed. After implementing this pattern, we were able to simply use the methods provided on the ReviewStrategy class in the algorithm that assigns reviews with minimal refactoring. Below is a simple UML diagram of these new classes: <image>. We were able to remove the following methods that were either obsolete or had functionality that could be refactored into other methods. - execute_peer_review_strategy : This functionality simply performed a check that is now in automatic_review_mapping. Several methods had raw SQL, or at the very least SQL-like statements. Where possible, these calls were pushed down into their respective models. This method had the following SQL SELECT t.id as t_id FROM teams_users u, teams t WHERE u.team_id = t.id and t.parent_id = ? and user_id = ? It was migrated to be a scope inside of the Team model ( find_team_for_assignment_and_user ). The majority of our changes were refactors, and thusly required a few new tests, but we did need to adjust existing tests to expect proper mocked/seamed methods. <table>. The report generation should be refactored to allow each report to specify how it should be rendered. One idea was setting each report to supply a collection of ""report lines"" that are rendered one at a time in a table. This would allow for each report to specify its data and its rendering functions separatly.","This is exactly what I want in a design document, though I would like to see more of it.  You mentioned which methods you removed, but did not give any examples of changes that you made, beyond listing the methods that were deleted."
E1940,"1. E1940 Improving e-mail notification. 1. The forked git repository for this project can be found <link>. The following tasks were accomplished in this project: 1. Issue1: Send new account welcome email to user, when imported from CSV through assignment page. 2. Issue2: Don't send email to reviewers for a new submission after review deadline has passed. 3. Issue3: Adding relevant links to reminder emails. app/models/assignment_participant.rb 1. Call method to send mail after user imported successfully. <code>. 1. Before fixing this issue, we had to write the logic to send emails to reviewers on submissions. app/controllers/submitted_content_controller.rb 1. Added the logic to check for last review date to the function submit_hyperlink <code> 1. Function to identify the reviewers and send mails. <code> app/helpers/mailer_helper.rb 1. Helper function to mail reviewers <code> app/mailers/mailer.rb 1. Mailer function to send the mail. <code> app/views/mailer/notify_reviewer_for_new_submission.erb 1. Email template for the mail <code>. 1. Modified function email_remainder to add functionality. app/mailers/mail_worker.rb <code>. Step 1: Navigate to Manage --> Assignment page. Step 2: Click on add participants for any of the assignments. Step 3: Click ""Import course participants"" Step 4: Choose a csv file to be imported (follow the format given on the website). Step 5: The users mentioned in the csv file and don't exist on Expertiza should get a new user email. Step 6: To check e-mail is received or not, log in with following credentials: username [ 'expertiza.development@gmail.com' ] password [ 'qwer@1234' ]. Step 1: Create new assignment [Manage --> Assignment --> + Button (to create new assignment)] Step 2: Fill the details for the assignments. Step 3: Navigate to due dates. Step 4: Change the number of review rounds to 2. Step 5: Select ""Yes"" in the dropdown for review allowed during submission and select ""Yes"" for submission during the review. Step 6: Add two users to the assignment(author and reviewer). Step 7: Log in with some user credentials (author credential). Step 8: Make a new submission to this assignment. Step 9: Log in with another user (reviewer). Step 10: Submit a review of the assignment submission. Step 11: Login as an author again. Step 12: Edit the submission. Step 13: After this check the mailbox of the reviewer [development mail for development]. Step 14: Reviewer should get the mail to re-review the work. Step 15: Change the due date to some date and time which has passed. Step 16: Now making a new submission from the author account should not send a re-review mail to the reviewer. [Repeat steps 7-15]. This test requires an approaching deadline scenario. Since the reminder mail goes through as a sidekiq background, the part of this issue was to fix the email link. Create a new scenario with an approaching deadline. The email is sent already, we have added the link which was missing, directing users to visit the required page.","This document is mostly just a copy of the code that was written and a list tof steps for manual testing.  As several reviewers pointed out, it doesn't explain why the code was written the way it was.  The steps for manual testing do not explain why things are done in that way, or how they verify that the three issues have been resolved. "
E1915,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link> 1.1.9. <link>. <link> is an open source project based on <link> framework. method which determines which users are allowed to perform which actions 2. This logic is in most cases correct, but is often repeated between controllers (un-DRY) 3. This logic is in some cases slightly incorrect 4. The Roles model provides a helpful method hasAllPrivilegesOf, which could be used to simplify authorization logic. 1. Problem 1 : Much of the authorization logic is repeated (un-DRY). <code> 1. Solution 1 : Use one of the helper methods from the new authorization_helper.rb ( <link> ) to allow TAs *and above* (instructors, admins, super-admins) to perform this work. <code> 1. Problem 2 : Some logic is slightly incorrect. <code> 1. Solution 2 : Use one of the helper methods from the new authorization_helper.rb ( <link> ) to allow Students *and above* (TAs, instructors, admins, super-admins) to perform this work. <code> 1. However, in case there IS a need to know if the current user has one specific role, this is still supported by the helper method current_user_is_a? 1. Problem 3 : Too much authorization logic is present in the controllers. <code> 1. Solution 3 : Establish helper methods in the new authorization_helper.rb ( <link> ) to centralize as much authorization logic as possible. In this way, a developer with questions about authorization knows just where to look to find answers - authorization_helper.rb ( <link> ). <code> 1. Problem 4 : Some action_allowed? <code>. 1. We make use of the existing role.rb model ( <link> ) method hasAllPrivileges of. We use this existing method to support the DRY principle, and to keep this logic in the model, where it belongs. <code> 1. We establish several methods in authorization_helper.rb ( <link> ) to expose easy-to-read method names for use in controllers. <code> 1. We establish a method in authorization_helper.rb ( <link> ) to expose an easy-to-read method for determining if the current user ""is a"" [particular user role]. <code> 1. We establish several methods in authorization_helper.rb ( <link> ) to centralize more complex authorization logic so that it is not scattered among controllers, but rather is kept in the same helper file as other authorization logic. <code>. 1. Look through authorization_helper.rb ( <link> ) for the method(s) you need. 1. If you do not find a method you need: 1.1. Add a new method to authorization_helper.rb ( <link> ). 1.2. Comment the new method so that future developers can understand your work. 1.3. Add new tests covering your new method, to authorization_helper_spec.rb ( <link> ). 1.4. Ensure that authorization_helper_spec.rb ( <link> ) still passes with zero failures. 1. What the authorization helper needs in order to work correctly: 1.1. The authorization helper needs users to have IDs. 1.2. The authorization helper needs users to be associated with roles. 1.3. The authorization helper needs roles to exist. 1.1.1. this is handled in spec_helper.rb ( <link> ) 1.4. The authorization helper needs session[:user] to be populated with the current user. 1.1.1. this is handled in rails_helper.rb ( <link> ) in the stub_current_user method 1. Writing RSpec tests for new controllers (provide these needs): 1.1. Use the factories defined in factories.rb ( <link> ) to create objects to manipulate in your tests. <code> 1. Write new comprehensive RSpec tests, in authorization_helper_spec.rb ( <link> ), for every public method in our new helper, authorization_helper.rb ( <link> ). <code> 1. The test suite for a single helper method is below. There are many such suites in authorization_helper_spec.rb ( <link> ). <code>. 1. <link> 2. <link> 3. <link> 4. <link>. 1. <link> 2. <link> 3. <link> 4. <link>.","On the micro level, every change made was well described.  On the macro level, I would've liked to see an overview of the new methods you created and what they would be used for.  E.g., one use case is to make sure that someone with at least a certain level of privilege is executing method m.  Another use case is to make sure that only users involved with a review, meta-review, teammate review, etc. can see it."
E1664,"Instructor can create and manage a course, enroll students in the course, create, manage and personalize assignments, project submissions and reviews for the particular course. Assignment Creation can be done in Expertiza by an instructor for a particular course. Two types of assignments can be created, Private and Public. Further, there are various ways an assignment's attributes can be modified by personalizing reviews, deadlines, teams allocation, rubrics, calibration etc associated with the particular assignment. There are many functionalities within assignment creation, thus the main motive for testing of this feature is to ensure that an instructor can create an assignment without any hick-ups with all of its properties intact. And this is. Test cases have been written using RSpec and Capybara. In RSpec, test cases are written such that they describe the specific functionality in the system being tested and helps user in better visualization of what the test cases are supposed to do. To make the assignment creation testing complete, and to avoid covering the same scenarios again by adding new working test cases unnecessarily, these test case were fixed. 2. Running the test cases were giving an error in the code, when fetching a row from the deadline type table. 1. We noticed that the structure of the test file was wrong. The code to populate the the ""deadline types"" did not run, but were supposed to run for each test case. We made this code run for all test cases. 3. Rubrics test cases were searching for links that weren't present on the page. 1. Test Assignment Creation a. Test Creating public Assignment: This test will check if public assignments are getting created properly or not with proper attributes. <code> b. Test Creating private Assignment: This test will check if private assignments are getting created or not with proper attributes. <code> c. Create Assignment for Team: This test will check the creation of new private assignment for the team. The maximum size of the team is 3 and the test will check if all these features are there or not. <code> d. Create Assignment with Quiz: This test will check the creation of new private assignment with the quiz. The maximum number of questions in the quiz is 3 and the test will check if all these features are present or not. <code> e. Create Assignment with review visible to all reviewers: This test will check the creation of new private assignment with review visible to all the reviewers. <code> f. Create public micro-task assignment: This test will check creation of new public assignment with microtasks. <code> g. Create calibrated public assignment: This test will check creation of new calibrated public assignment. <code> 2. Test General Tab of Assignment Creation a. Edit assignment available to students: This test will edit the existing assignment and enable micro tasks and calibrated options. The test will verify if all these options are updated in the assignment. <code> b. Edit number of quizzes available to students: This test will check the feature of editing the number of quizzes in the existing assignment. <code> c. Edit number of members per team in an Assignment: This test will check the feature of editing the maximum number of members in a team for an assignment. <code> e. Edit review visible to all other reviewers: This test will verify the feature of adding/removing review visible to all the reviewers for an assignment. <code> f. Should create teammate review row in rubrics: This test will verify that adding teams and team members in an assignment will create one more row of teammate review in rubrics. <code> g. Check if checking calibration shows the tab: <code> 3. Test Topic Tab of Assignment Creation a. Edit topics properties - Check all options <code> b. Edit topics properties- uncheck all options <code> c. Add new topic : This test will check feature of adding new topic for an assignment. <code> d. Delete existing topic: This test will check feature of deleting new topic for an assignment. <code> 4. Test Rubrics Tab of Assignment Creation a. Update review questionnaire rubric: <code> b. Update scored question dropdown <code> c. Updates author feedback questionnaire <code> 5. Test Review Strategy of Assignment Creation a. Test all auto selects feature <code> 6. Test Due dates tab of assignment Creation a. Loads the due dates page <code> b. Set the deadline for an assignment review: This function will test if deadlines are getting assigned properly or not for the review. <code> 7. Test Adding participants by Instructor a. Add New Participants to assignment: This test will verify if an instructor is able to assign new participants to an assignment. <code> b. Verify assignments assigned to participants: This test will verify if assignments are properly assigned to participants. Participants should be able to see newly assigned assignment in their page. <code> 8. Check if assignment can be added to a course: It will check an assignment can be added to the course <code>. Whenever we push changes in our repository, travis will start building and run all test cases.","As mentioned by a couple of reviewers, this writeup does not explain the rationale behind the tests.  It simply gives their title, one sentence of description, and the test code."
E1850.3,"It is an open source software created by North Carolina State University's students. It works on ruby on rails framework. This platform allows instructor to post notification about tests and assignments and also allows students to view grades, submit assignments, find teammates etc. Review_response_map.rb file is a newly added feature in Expertiza. The ReviewResponseMap class in the file is the sub class of ResponseMap class.The file review_response_map.rb deals with mapping of review's review to the feedback that reviewee gives to that review. Since the file is new it is not tested. We have worked on the file review_response_map_spec.rb which use RSpec framework to perform unit testing on the given file. 1.Create a new file named review_response_map_spec.rb under spec/models folder 2.Write RSpec unit tests to make the path coverage above 90%. 3.Coverage as many edge cases as you can. 4.Achieve as high branch coverage as you can. We will use the mutant-rspec gem to measure test thoroughness and fault-finding capability of your tests. We created the following stubs to implement unit testing: <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code> <code>. <code>. <code> <code> <code> <code> <code>. <code> <code>. <code>. <code>. <code>. review_response_map.rb review_response_map_spec.rb spec_helper.rb. We used RSpec framework to test the given file.RSpec is a 'Domain Specific Language' (DSL) testing tool written in Ruby to test Ruby code.It is a behavior-driven development (BDD) framework which is extensively used in the production applications. The basic idea behind this concept is that of Test Driven Development (TDD) where the tests are written first and the development is based on writing just enough code that will fulfill those tests followed by refactoring. It contains its own mocking framework that is fully integrated into the framework based upon JMock.The simplicity in the RSpec syntax makes it one of the popular testing tools for Ruby applications. The RSpec tool can be used by installing the rspec gem which consists of 3 other gems namely rspec-core, rspec-expectation and rspec-mock. <link>.","In the Test Plan, you should explain why you created the various stubs, instead of just listing them.  The rest of the document just lists the tests, with the exception of why you used RSpec, which could apply to any of the testing projects."
E17A4.2,"In this separate assignment that the instructor creates, the student and the instructor will simultaneously do peer review for the project. After submission of the reviews, the student's and instructor's reviews are compared and a calibration report is generated for the student to view and improve their peer reviewing skills. Once the student submits the calibration reviews, the calibration results comparing the student and expert review are provided to the student. When the actual review period starts, the student will review other assignments, and submit peer reviews. First is the calibration review of sample assignment, then normal assignment submission followed by rounds of peer reviews for the submitted assignments. The due date for the calibration review is entered and the assignment is saved. <image> <image> 4. 2 students are assigned as participants (student1, student2) and 1 student (student3) as reviewer for the assignment ""Program 4"". 5. The review strategy was set to ""Instructor-selected"" for calibration review. Then, the instructor assigned student3 as a reviewer for this sample assignment submitted by the expert and also, submitted an expert review for this sample submission. <image> 8. In ""Other's work"", one calibration review for the sample assignment is displayed for which the reviewer can submit the calibration review. Show calibration results gets enabled when the expert and the student submits the review. Since only one peer review is present, the ""request new submission for review"" button is enabled. Peer reviewing is the concept of review your peer’s work. Use Case Diagram : <image> 1. Add/Edit Assignment: Enable Calibration Use Case Id: 1 Use Case Description: Instructor can select the option - ""Calibration for training?"" Actors: Instructor Pre Conditions: The assignment is present in the assignments list Post Conditions: Instructor can navigate to the edit assignment page where the enable calibration option is present 2. Edit Assignment: Set Due Dates for Calibration and Peer Reviews Use Case Id: 2 Use Case Description: Instructor can set due date for calibration under due dates tab Actors: Instructor Pre Conditions: Once calibration option is enabled, a separate row for calibration should be created Post Conditions: The instructor should be able to see the new date set for calibration. 3. View the current stage in assignments as ""Calibration"" during the calibration period Use Case Id: 3 Use Case Description: In assignments home page, the assignment should now be in the calibration period. Actors: Student 4. View the pre-assigned sample assignments in ""other's work"" tab which can be opened even before submitting the assignment Use Case Id: 4 Use Case Description: Student should be able to see the list of assignments in others' work tab for reviewing Actors: Student Pre Conditions: Sample assignments are provided by the instructor for the student to review and the tab ""other's work"" is enabled. 5. Submit 'n' pre-assigned Calibration Reviews Use Case Id: 5 Use Case Description: Student can now review those assignments and submit them Actors: Student Pre Conditions: Sample assignments are provided by the instructor for the student to review Post Conditions: Student can now see and edit the newly submitted review and also see the instructor's review for the assignment 6. View the 'Calibration Result' after submitting Use Case Id: 6 Use Case Description: Student can see the comparison between student's and instructor's reviews for the pre-assignment Actors: Student Pre Conditions: Student had already submitted a calibration review Post Conditions: Student can now view the comparison results 7. Submit the assignment before the due date Use Case Id: 7 Use Case Description: Student should submit the assignment before the submission deadline Actors: Student Pre Conditions: An assignment exists and the calibration review is submitted Post Conditions: Student can successfully submit the assignment before the deadline 8. Request for a Peer Review Use Case Id: 8 Use Case Description: After the student submits the assignment, the student can request to do peer review of other student's submission Actors: Student Pre Conditions: peer review period has started and other students' submissions are available for reviewing Post Conditions: Student should be assigned with a project for reviewing. 9. Submit the Peer Review and request for next one after minimum number of peer reviews are completed Use Case Id: 9 Use Case Description: After the student requests for a peer review, he can review the assignment and submit it, After minimum number of reviews are commpleted, he/she can request for more assignments to be reviewed Actors: Student Pre Conditions: Student received an assignment for peer reviewing Post Conditions: View and edit options are available for the submitted review until the peer review period deadline All the actions performed by the student can be done by the instructor by impersonating a student. 7. Go to the calibration tab and submit one expert review for the sample assignment. Begin the review and submit. Post submission due date, the peer review period will start. 13. When the peer review period begins, in others' work, the student will now see two sections: Calibrated review and Review.","Overall, this is a very good document.  It describes the functionality comprehensively and is pretty readable.  There are a few opportunities for improvement: It doesn't discuss code changes at all, just UI changes.  Some of the screenshots are so large that you need to zoom way out to see them.  The automated tests are not extensive and do not consider edge cases."
E1632,"<link> is an open source type of project that has been undertaken by the National Science Foundation. Various articles, codes in multiple languages and links can be submitted using the platform. It is popularly used by students studying at NC State to submit assignments, review works and get feedback. It allows users to switch between multiple environments if an user is not satisfied with a particular environment. The setup development can be done using OSX, Linux or Docker. While using the OSX method and Linux method (RHEL), shell access and root access is a prerequisite. Docker is another method to install Wikipedia. It is cross Operating System (OS) compatible. Docker pull is needed to pull the docker image. Docker run is then used on port number 3000. Expertiza allows user to contribute to their project. The expertiza project needs to be forked and cloned to create a local directory. Changes can be pushed and committed to a new branch. Finally the code is reviewed and changes are possibly made after a pull request. The project is related to the class scheduled_class. The associated MVC framework relate to sending out reminder emails around the deadline of a task. The project objective includes- 1. Removing duplicate code that is common in scheduled_task.rb and delayed_job.rb. 2. Subclass Deadline_Type in the perform method. 3. Refactoring mail_signed_up_users to multiple named methods and modifying it in a more elegant manner. 4. Checks to the new refactored code. One of them looks like: <code>. This includes the splitting of the method to multiple methods to make it more elegant Earlier Code: <code> Modified Code: <code>. The perform method has been modified to a large extent as it now uses Single Table Inheritance (STI) <link> instead of if-else cases statements. Earlier Code: <code> Modified Code: <code>. The scheduled_task_spec.rb is the test class for the above changes.All the test cases pass for scheduled_task_spec.rb following our changes. <link>. Installation for Reviewers Because asynchronous events require a daemon running in the background and the new Delayed::Job class for Rails 4 has additional fields, the following steps are recommended. 1. Install Expertiza and execute 'bundle install' 2. Create database and perform data migration using 'rake db:migrate' 3. Execute 'rails generate delayed_job:active_record' at the prompt. This will create a delalyed_job file in /bin directory. 4. Execute 'rails generate delayed:upgrade' if delayed_job has been created before. 5. Enter your smtp server account settings in config/environments/production.rb file. You may find an example in config/environments/developments.rb file. 6. Start the rails server by entering rails server 5. Start the delayed_job server by executing RAILS_ENV=production bin/delayed_job start Please watch the video : <link> to see how to test the use cases of the functionality that we have refactored.","The cycle detection may miss come cycles.
There should be UI which allow instructor to input the k.
There should be some visulization, or at least table of cycles in the report page."
E1746,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.4. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The following tasks were accomplished in this project: 1. Complete the pending tests in user_spec.rb There are many pending tests needed to be finished. And for the methods which are needed to be refactored or renamed, this is also can been seen as writing failing tests first. 1. Refactor get_user_list method. The get_user_list methods contain many conditions and each of them has a lot of code which makes the method very long. The factor is to transfer the statements to the corresponding subclasses ,and writing method calls instead. 1. Refactor self.search_users method The method has many repetitive codes which are used in the conditionals. We refactor it by writing a single method call and let the method call to choose the conditional. 1. Rename methods and change all other places it is used. 2. Use find_by instead of dynamic method. The find_by_name or find_by_email method which are used in the user.rb is like old style code. And this kind of code can be replaced with new dynamic ones like, find_by. There are many pending tests in the file 'user.rb'. What we have done is finishing these pending tests and makes them pass.The user_spec.rb file on github is below. <code>. The task is to write failing test first and ,move if conditions to corresponding subclasses (eg. ta.rb, instructor.rb) with same method name,then replace the conditional with the relevant method calls. First writing the failing test first according to the requirements of the refactor. <code> The next step is to move if conditionals to its relatively subclasses. In this case,the superadministrator.rb, instructor.rb and ta.rb. <code> <code> <code> Then replace the conditional with the relevant method calls. <code> So the refactor of get_user_list method has been done. This task is required to write the failing test first and extract duplicated code to a new method. First, write the failing test. <code> Then,extract duplicated code to a new method.Since this is kind of changing original method.So below is the changing on github. <code>. First, is to write failing test of the renamed method which has been finished in mission one.So just skip to the second part to rename them. is_recursively_parent_of → recursively_parent_of? <code> is_creator_of? → creator_of? <code> is_teaching_assistant_for? → teaching_assistant_for? <code> is_teaching_assistant? → teaching_assistant? <code> After writing the test, it is going to rename the method in the user.rb. Below is the changed part of the code. <code>. ：：There are three lines using find_by_name and find_by_email which are now be instead of find_by[params].The task is to replace the old one to refactor the method. First,writing the failing tests,here is the original test code including find_by method. <code> And below is the new failing test <code> And so as the other codes contain find_by method <code> And then change the find_by_name and find_by_name in the user.rb file in to dynamic one. <code>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. Clean Code: A handbook of agile software craftsmanship. Author: Robert C Martin.","There are descriptions of all the methods written.  It would be helpful to have more detail, but it is good that they made an attempt to document it."
E1713,"It has been developed using the <link> framework, and the code is available on <link> . In this project, the files <link> and <link> were to be refactored. After an instructor creates an assignment in Expertiza they will have the ability to edit the details of the assignment by clicking the Edit action icon beside the assignment. From the ""Editing Assignment"" screen instructors have the ability to set due dates for each round of an assignment on the ""Due dates"" tab. On this tab, the instructor can elect to apply a late policy to the assignment by checking the ""Apply penalty policy"" checkbox and selecting a late policy from the adjacent drop down menu. If no late policies exist, or if the instructor wishes to define a new late policy, then they can click the ""New late policy"" link to define a new late policy. An instructor can define a late policy with the following fields: 1. Late policy name - This name will show up in the drop down menu on the ""Due dates"" tab when editing the assignment. 2. Penalty Unit - With the options of 'Minute', 'Hour', and 'Day' this field will define the frequency with which penalty points are deducted if an assignment is submitted after a due date. 3. Penalty Point Per Unit - This is the amount of points which will be deducted from the student's score for the assignment round every time the Penalty Unit time has elapsed between the due date and the submission date. [Range: > 50] 4. Maximum Penalty - Points will continue to be deducted from the assignment round score for each Penalty Unit time that has elapsed, but the number of points deducted will not exceed the Maximum Penalty [Range: 1..50] Once an assignment has a late policy applied to an assignment, students' submissions will be checked against deadlines to determine if the late policy should be enforced. The penalty is applied to the grades under two circumstances. When a student is viewing an assignment task and they click on the ""Your scores"" link, the applicable penalties will be applied before displaying. Also, when an instructor is viewing the list of assignments on the ""Manage content"" page, if they click the icon for ""View scores"" the penalties will be applied to all submissions within the list which were submitted past the due date. The penalty_helper.rb and late_policies_controller.rb files are central to the creation and maintenance of late policies. Late policies are created by instructors and associated with assignments. The late_policies_controller.rb file is primarily used in the communication with view where late policies are displayed, created, or modified. The penalty_helper.rb file includes many useful methods related to late policies and the penalties which result from their use. For instance, if an assignment is designated as having penalties calculated then when it is graded the PenaltyHelper module will allow the penalties for each assignment to be calculated and applied to the final grade for the assignment. This was achieved by performing analysis on the files to identify methods which are not used within the Expertiza code base, methods which are too long, and redundant code which can be extracted from other methods and replaced with a call to a single method. This is controller class for late policies. It handles all the basic operations on late policies like create/edit/delete policy. The project goal was to refactor the code of create and update methods to make them smaller and more readable. Three helper methods were added in the PenaltyHelper module to make the code shorter. There was a common input check in both create and update methods which was separated to write two new methods ""check_penalty_points_validity"" and ""check_policy_with_same_name"", which helped to reuse the code. <code> <code> In case of update action call, there was a part of code which was updating already calculated penalty objects based on the updated late policy. <code> Some variable names were changed in order to make it easier for reader to understand the meaning of code. There was some unused commented code which was removed. The aim was to keep the methods below 25 lines of code if possible. calculate_penalty is the main method of the PenaltyHelper module. It is called from the <link> module. The other methods are called from within the calculate_penalty module. The method mainly contains a few assignment statements, and some method calls. A particular segment of code converted a time difference into respective unit. This code was inserted into a method with the parameter 'time_difference'. Inserting the conversion logic into a separate method allowed the simplification of both methods. <code> The method was called in two places. <code> <code> Apart from the method which was defined, some other methods which were not being called were removed, extraneous statements which were written and then commented were also removed. Navigate to <link> and click the ""Make a Reservation"" button. Click the ""Reservations"" button and then click ""New Reservation"". button. <code>.","Somewhat hard to follow because penalty object was not defined.  Should have been described like late_policy.  Writeup showed the ""after"" version of code, but not ""before"", so the two couldn't be compared."
E2008,"Students can view their project scores and instructors can view student's teammate review scores on the view scores page. This Summary helper aids in calculating these scores and rendering the results on the view scores section of an assignment. Summary helper is a helper module that consists of methods used to calculate scores for these reviews. This is for the use of instructors. This method is used to summarize reviews by a reviewer for each question. Changes Made: This method could be refactored into smaller methods namely summarize_reviews_by_reviewee and summarize_reviews_by_reviewee_assign where summarize_reviews_by_reviewee calls summarize_reviews_by_reviewee_assign to get average scores and summary for each question. Before: <code> After: <code> Impact: 1.1. Assignment Branch Condition size for summarize_reviews_by_reviewee is reduced from 44.61 to 20.64. This method is used to summarize the review for each questions Changes Made: 1.1. This method was refactored into 3 smaller methods namely summarize_reviews_by_criterion , summarize_reviews_by_criterion_questions and end_threads . 1.1. The method summarize_reviews_by_criterion calls summarize_reviews_by_criterion_questions to get answers of each question in the rubric. Before: <code> After: <code> Impact: 1.1. Assignment Branch Condition size for summarize_reviews_by_criterion is reduced from 42.34 to 17.2 1.2. Cognitive complexity is reduced from 16 to 7. This method is used to produce summaries for instructor and students. It sums up the feedback by criterion for each reviewer Changes Made: 1.1. This method was refactored into 4 smaller methods namely summarize_reviews_by_reviewees , summarize_reviews_by_teams , summarize_by_reviewee_round and end_threads . Before: <code> After: <code> Impact: 1.1. Assignment Branch Condition size for summarize_reviews_by_reviewees is reduced from 89.93 to 16.64 1.2. Cognitive Complexity is reduced from 17 to 7. This method calls web service to store each summary in a hashmap and use the question as the key. Changes Made: Removed variable summary <image>. Changes Made: The method is broken down into 2 smaller methods namely break_up_comments_to_sentences and get_sentences where get_sentences is called by break_up_comments_to_sentences to get sentences in desired format. <image> Impact : 1.1. The Cognitive complexity of break_up_comments_to_sentences reduced from 6 to <5. This method returns the rubric for given assignment Changes Made: 1.1. In IF CONDITION: Removed unnecessary use of variable which was being used only once (questionaire_id) and replaced the variable with its assignment (assignment.review_questionnaire_id(round + 1) 1.2. In ELSE CONDITION: Removed unnecessary ternary operation for variable questionaire_id and replaced the variable with its assignment (assignment.review_questionnaire_id) <image>. This method is used to calculate average round score for each question. Changes Made: Refactored the method into 2 smaller methods namely calculate_avg_score_by_round and calculate_round_score where calculate_avg_score_by_round calls calculate_round_score to calculate average round score and calculate_avg_score_by_round rounds the round_score upto 2 decimal places. Before: <code> After: <code> Impact: 1.1. Assignment Branch Condition size for calculate_avg_score_by_round is reduced from 18.57 to <15. Coverage increased (+17.1%) to 41.407%. Login Details: USERNAME: instructor6 PASSWORD: password Click Assignment >> Click the View Submissions of Madeup problem >> Click on any student >> Click on Madeup problem >> Click on Your Scores <image> <image> <image> <image> The 3 main functions of the Summary helper are summarize review by reviewees, summarize review by reviewee and summarize reviews by criterion. This function summarizes all the reviews and displays average score. <image> To check summarize reviews by reviewee is working, click on any review. <image> A new webpage pops up with all the reviews and scores given by an individual. <image> To check summarize reviews by criterion is working, click on any criterion. This should display summarized reviews and scores for a particular question in the questionnaire. <image>. 1. Modularize summarize_by_rounds to even smaller modules so that Assignment Branch Condition size is reduced from 36.73 to 15.00. 2. Create more test cases for the new modularized methods.","The documentation clearly explains most of the code changes they have made. Some descriptions should be more detailed, e.g., ""Removed variable summary""  Why is the refactored method clearer without it?
They also explained how their code changes address Code Climate issues. They have given a detailed explanation of their manual testing plan as well. However, there is no mention of automated tests.
They added huge chunks of code in the beginning and then shifted to github view. So that looks a bit inconsistent. Otherwise, i think wrt to the project the documentation is pretty good. 
"
E1663,"The current project deals with addition of AJAX whenever we add a new record or modify an existing record. In the current scenario, we submit the entire page to save a record and reload the entire page back again. Using Ajax, we should only submit the newly added record information to server instead of submitting the entire page. This project takes care of below scenarios: 1. Add Participants: Once an assignment has been created, an instructor can Add Participants to the assignment. 2. Add/Delete TA (Teaching Assistants): Once a course has been created, an instructor can Add/Delete TAs to the course. 3. Edit Questionnaire: Modify the Edit Questionnaire screen to use ajax while adding new questions to the questionnaires. 1. Controllers 1.1. participants_controller.rb 1.2. course_controller.rb 1.3. questionnaires_controller.rb 1. Views 1.1. course 1.1.1. _add_individual.html.erb 1.1.2. _ta_list.html.erb 1.1.3. add_ta.js.erb 1.1.4. remove_ta.js.erb 1.1.5. view_teaching_assistants.html.erb 1.2. participants 1.1.1. add.js.erb 1.1.2. list.html.erb 1.3. shared_scripts 1.1.1. add_individual.html.erb 1.1.2. _user_list.html.erb 1.4. questionnaires 1.1.1. _ajax_partial.html.erb 1.1.2. add_new_questions.js.erb 1.1.3. edit.js.erb. We have added respond_to method in add method of participants controller and add_ta/remove_ta methods of course controller, which will allow us to render both javascript and html requests from these methods. In course controller the function looked something like this: <code>. The same methods added in participants were added in questionnaire controller, the difference being in the action the controller takes after receiving a JS request. In the partial _questionnaire.html.erb, the attribute remote was set to true. This is rendered as the attribute ""data-remote"" being set to true in HTML, which allows the rails UJS (unobtrusive JS) to make AJAX calls without needing any jQuery statements. The JavaScript file then takes action on the webpage it is called on. In the case of adding new questions, the page is updated with the new questions by the JavaScript file that is called. This is achieved by rendering a partial in the JavaScript file and then using jQuery to update the page with the rendered HTML. Although new partials had to be created, the JavaScript functionality is easy to understand. Additional divs were added in the HTML to serve as hooks for the jQuery statements to update HTML on the page. Additionally, saving questions in the edit questionnaire section also works on AJAX, and flashes the standard rails success message without refreshing the page. We have put the :remote => true flag on the link or form tag in our .html.erb files (view) for the element where we wanted to trigger the AJAX call, like, <code> <code> With :remote => true, rails will not automatically switch views, which allows the JQuery to be run instead. RSpec Testing There were no existing test cases for the course controller. We have added some related to the functionality which we have worked on. The following test verifies mapping between TA and course: <code> Below test verifies whether error message is displayed or not when TA does not exist: <code> The test below verifies whether TA is removed from the course or not: <code> UI Testing Following steps needs to be performed to test this code from UI: 1. Login as an instructor. 2. You will land on Manage Content page with list of courses and related actions to it. 3. Under action column try to Add TA for any course. 4. It will take you to Teaching Assistants page. 5. Try to add a valid TA for eg. teaching_assistant5549. As soon as you press Add TA button, list will get updated with the newly added TA without refreshing the page. 6. If you try to delete any TA, a popup will open to confirm your action, press ok and you will see that particular TA is deleted in the background. 7. Similarly, for perform these actions for Add participant action for any course. Table will be updated with newly added participant without refreshing the page. 8. To test add questionnaire, switch to questionnaire tab from courses tab and click on add questionnaire. 9. As you add questions, page would not refresh and questions would be added as expected. 10. If you try to delete any question, delete action would also not refresh the page and perform the required action.","The documentation is well structured thus. it's short and easy to find information. Test cases could surely be extended. I'm questioning the approach "" the controller renders a JavaScript file in place of the usual .html.erb. The JavaScript file then takes action on the webpage it is called on"". why not just render html pages that have links to those javascripts? It would have been nice to see some reasoning there. "
E1812.1,"Per Dr. Gehringer's instructions we have posted <link> to prove the tests work. In the video, the unit tests are run from the terminal, and then we check the coverage. Contents 1.1. <link> 1.1.1. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.4. <link> 1.1.1. <link> 1.5. <link> 1.6. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.7. <link>. <link> is an open source web application developed with <link> framework. The OnTheFlyCalc model does not have any test cases corresponding to it. Thus, the task of this assignment is to write unit tests for on_the_fly_calc.rb using RSpec. > 90%. This module calculates the score for both students and instructors. E.g., when a student clicks “view my score”, Expertiza calculates the review scores for each review. It directly calculates the total review score for each review, using the score values in the answer table during run-time. What we need to do is to write tests for four public methods listed in the module OnTheFLyCalc. However, the on_the_fly_calc itself has some code issues in #scores, and IDE reports some errors when we run the test case for it. For this project we use <link> which is a testing tool for Ruby, created for <link> (BDD). In order to accomplish this task, that is to build tests for the OnTheFlyCalc model, we need to implement the following plan: 1. Set up the Expertiza environment; 2. Understand the functionality of the model; 3. Understand the relative methods and objects involved with each function of the model; 4. Create test objects; 5. Write ‘it block’ test scenarios with appropriate contexts for all public functions of the model, and check if all <link> pass. The following set-up lines create variables that are common across tests: <code>. The function compute total score totals the scores of each questionnaire in an assignment. <code> To test this function We mocked the calls made in the Questionnaire class. For example, to mock the call: <code> we used the rspec line which looks like this <code> similarly, other calls made to <code> was mocked using calls that look like :- <code> cases for consideration : 1. when avg score equals nil 2. when avg score is not equal to nil. Below is most of the code used in the test case. The first test case is for when assignments vary by rubrics. We check that the function returns {}. In the second test case we check that it returns {1=>{1=>50}, 2=>{1=>30}}. This is correct because we create 2 response maps and set their value to 50 and 30. <code> <code>. This function calculates the average score and score range for each reviewee (team). <code> We consider 2 scenarios to test for this function: 1. When current assignment varies rubrics by round: function computes avg score and score range for each team in each round and return scores <code> 2. When current assignment does not varies rubrics by round: function computes avg score and score range for each team and return scores <code>. <code> This method calls a lot of private methods to calculate a score hash. To test this method we had to mock calls made in these private methods. is true this method calls <code> <code> <code> we mocked the call to 1. so it is not covered in our coverage as it just initializes our hashes. to mock the call to 2. and 3. calls such as the ones given below can be seen in our test cases. <code> we are basically mocking calls to run through all lines of the methods and only calls that is returning something or are assigning value to a variable need to be mocked. for example the call <code> is to mock the call made to compute_score function in the Answer class we made it to return an empty hash. cases for consideration : 1. when current assignment varys rubrics by round and number of assessments is 0.in this case <code> <code> 2. when current assignment varys rubrics by round and number of assessments is non-zero. 3. when current assignment does not vary rubrics by round. 1. To run RSpec for a particular file (on_the_fly_calc_spec.rb): <code>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","This is pretty readable, explaining the need for on_the_fly_calc, and how the tests work. Would have liked to see more explanation of compute_avg_and_ranges_hash. 
Nit:""varys"" should be ""varies"""
E1714,"In order to sign up or drop teams from a topic, an instructor must first impersonate a student and then perform the necessary action. To add or drop multiple teams, the instructor must impersonate each student and navigate back and forth between the same set of pages. An instructor can view a list of all the topics for any given assignment. Each topic shows any signed up teams and whether students are signed up or waitlisted. The proposed change introduces a new button next to each team that allows an instructor to remove a team from a topic. In this manner, an instructor can drop a team from a topic with relative ease. An additional button was also implemented to give an instructor the option to sign a specific team up for a topic. An instructor can select a team by specifying one of the team members. If the student specified by the instructor is not part of a team, a team is created for the student as part of the signup process. The signup button is located in the topic name box and redirects to a new page. The new page contains a form where the instructor can enter a student's name. Once a team is added, the instructor is redirected back to the edit assignment page where the topic is updated with the specified student's team. From the instructor's edit assignments page with the tab topics selected, the instructor should see a list of topics for the given assignment. For each topic, the instructor should be able to: 1. Sign a student up if ""No choosers"" is displayed 1.1. If the student is part of a team, the whole team should be signed up 1.2. If the student is not part of a team, a team should be created with only the given student as a member 2. Sign a student up for the waitlist if a team is already signed up 1.1. If the student is part of a team, the whole team should be signed up 1.2. If the student is not part of a team, a team should be created with only the given student as a member 1.3. The team should be added to the end of the waitlist Each action is performed by choosing the green checkmark next to the desired topic name. From the instructor's edit assignments page with the tab topics selected, the instructor should see a list of topics for the given assignment. For each topic, the instructor should be able to: 1. Remove a team's signup for a specific topic 1.1. The team should no longer be signed up for the topic 1.2. Any waitlisted teams should now be signed up for the topic 2. Remove a team from the waitlist for a specific topic 1.1. The team should be removed from the waitlist Each action is done by choosing the X enclosed by a red circle next to the desired team. Login Information: <table> Review Steps: 1. Check with assignments a student is signed up for 1.1. Log in as a student 1.2. On the main page, there should be a list of assignments which the user can be removed from signup 1.1.1. Note removing the signup only works if the student hasn't turned in work or the drop deadline has not passed 2. Add a student to a course or assignment 1.1. Log in as an instructor 1.2. Go to ""Courses"" tab to add a student to a course, go to ""Assignments"" tab to add a student to an assignment 1.3. Choose ""Add Participants"" button under ""Actions"" column. It renders the table cell where the topic, team, and students are listed. The following links were added to the partial where appropriate: <code> Note that the instructor will see a different set of links depending on whether or not a team has already been assigned to a topic. If no team is present, only a single link that adds a student and their team will be visible. If a team is already present, then an additional link that drops that existing team will be visible. This additional view renders a form where the instructor can specify a student for the signup action. The instructor is redirected to this page after clicking the signup link in the topic names partial. <code>. Similarly for the delete action, the user must be extracted from the team ID. The flash messages were also modified to notify an instructor rather than a student. We can assume that signing up a student will sign up the whole team as indicated by the contract with the existing function. The same contract exists for removing a student's sign up. It is not to remove one student from the team. It is to remove the whole team from a topic. We create two students and an instructor. Two teams are created with a student assigned to one of the teams. The other team is used for tests where no work is submitted. One student is signed up to a topic and is used to test the delete functionality. The other student is signed up by the instructor and tests the signup functionality. <table>.","It would definitely help to see screenshots of the functionality.  Also, writeup does not specify what happens when there is more than one slot for a topic.  When showing modifications, it is good to show before & after snippets, e.g., cutting & pasting from the Github diff."
E1955,"Students can also peer review other students' submissions. 2. He can see details of each assignment like marks, his team, send invitation to student to join a team 3. Review other students' work <link> <link> The following functions were tested: 1. complete? This function returns true if the participant stage deadline is ""complete"" or else return false. This function returns true if the participant has submitted hyperlinks in the current stage and the stage is in ""submission"" 1. hyperlinks This function returns all the hyperlinks submitted by the participant team 1. in_work_stage? A assignment is said to be in work stage if its stage is any of ""submission"", ""review"" or ""metareview"" 1. incomplete? This function returns true if the participant stage deadline is not ""complete"" or else return false. A participant can review other people's work and add comments. Also a user can review a review, called ""metareview"" that is given to him. This method checks if the participant has given any metareview and return true otherwise. This function checks if the assignment is in ""metareview"" stage and metareviews. This function checks if the assignment is in any of ""submission"", ""review"" or ""metareview"" stage 1. relative_deadline 2. reviews_given_in_current_stage? 4. from_participant(participant) This function return the StudentTask from the participant with assignment, topic, current_stage 1. from_participant_id(id) This function return the StudentTask from the participant with assignment, topic, current_stage using the participant id 1. from_user(user) 2. get_author_feedback_data(participant_id, timeline_list) 3. get_due_date_data(assignment, timeline_list) 4. get_peer_review_data(participant_id, timeline_list) 5. get_submission_data(assignment_id, team_id, timeline_list) 6. get_timeline_data(assignment, participant, team) 7. teamed_students(user, ip_address = nil) This function return the list of all the students that the logged on user has teamed up until now. and return true and false 1. topic_name Return the name of the topic. <code> Below are some of the functions tested 1. Function: teamed_students - Write a test case to find teamed up students. This method is an instance method, having a user passed to it. It return the list of students that the current user has teamed up. It does not consider the teammates that are from calibration assignments The test cases described check for the following scenarios: 1. When not in any team returns empty 2. When assigned in a cource_team returns empty 3. When assigned in a assignment_team return the list of teammates <code> 1. Function: get_due_date_data - Write a test case to get the due dates of the assignment. This method is an instance method, having an assignment and timeline_list list passed to it. The test cases described check for the following scenarios: 1. When an assignment passed to the method has no assignment attributes. 2. When an assignment passed to the method has some attributes but not the attribute due_at 3. When an assignment passed to the method has some attributes along with due_at due_at attribute is checked, upon which the timeline_list is populated with the updated_at and label values. <code> 1. Function: get_peer_review_data - Write a test case to get the peer review data. This method is an instance method, having an review and timeline_list list passed to it. The test cases described check for the following scenarios: 1. When no review response is mapped. 2. When review response is mapped. <code> 1. Function: get_author_feedback_data - Write a test case to get the feedback response This method is an instance method, having feedback and timeline_list list passed to it. The test cases described check for the following scenarios: 1. when no feedback response is mapped. 2. when feedback response is mapped. <code> 1. Function: get_submission_data - Write a test case to import participants This method is an instance method, having a submission and timeline_list list passed to it. The test cases described check for the following scenarios: 1. When no submission data is mapped. 2. When submission data is mapped and hyperlink is not submitted or hyperlink is removed. 3. When submission data is mapped and operation is submit_hyperlink. 4. When submission data mapped and operation is Remove Hyperlink. <code>. <code>. 1. <link> 2. <link> Test Coverage: <link> <link>. <code>. 1. While creating the test for ""reviews_given?","There are lots of spelling/grammer/formatting errors. 
[About Expertiza/About Rspec] -> ok, 
[DbSchema] -> this section seems to have no importance. If it is necessary then more explanation of the schema design and relevance to the project is necessary. The image here is hard to navigate/read. 
[Project Description] -> layout of this section is hard to follow. Indentations indicate wrong subsections for function explanations and testing plan. Simply changing the font for the method name, and inlining the description after the method name, would have improved readability greatly.
Several functions are missing explanation (needs to be consistent). In the test plan, the mock objects are just listed.  It would have been very helpful to have a description of why they were created and how they would be used.  Ideally, that should be done in comments inside the code.  Additionally, why were only some functions elaborated upon? Were these functions more important? 
However, the description of what the tests do is very good, and among the best I have seen this year.  To some extent, this counterbalances the deficiencies in other areas of this report, especially since this is a testing project.
[Video] -> Editing is needed to draw focus to the results of the test rather than spending 3 minutes watching '...'. In general, the overall formatting of the wiki needs to be revised to enhance reader understanding and clarity. Images should be embedded rather than linked and reference as to why they are included. Otherwise, the reader has not motivation to redirect to the image and make connections."
E1877,"Expertiza allows instructors to view kinds of reports of assignments in their courses such as submissions, scores, and review reports. To improve the report views, some table columns such as team name, score, the average should be made sortable by using the same existing sort library. 1. #issue 1: We have to sort “Topic name”, “Team name”, “Team member(s)”, “Links” alphabetically in the “view submissions” table. <image> 1. #issue 2: We have to sort “Team” alphabetically, sort “Average” and “Range” (the first percentage) for “View scores” table, <image> 1. #issue 3: For “View review report” table, we can see that the columns “Reviewer” and “Metric” are already sortable. We have to sort “Review done” by the first number than the second number (e.g., 0/1, 0/2, 0/3, 1/1, 1/5, 2/2...), sort “Team reviewed” alphabetically and sort “Score awarded / Avg. <image> 1. #issue 4: For “Author feedback report” table, we have to do several changes. After that we are supposed to sort “Rejoinder” and “Review responded to” as string (alphabetically), sort “# author feedbacks done” by the first number than the second number, and sort “Last responded at” as a date. <image> 1. #issue 5: We have to sort the first 3 columns as a string and sort the last column as a date(MM/DD/YYYY) in the “View scores” table <image>. We will be using tablesorter jQuery to sort the table. For table columns which have constraints on them for sorting, we will be creating custom scripts which tablesorter library supports to sort those columns. After including the script, we are supposed to do some modifications in the table tag by including the class. Three types of scenario may arise: 1. Sorting by columns alphabetically - To sort the columns alphabetically, the table-head attribute must include sorter-true class with it to enable the sorting alphabetically. 2. Sorting by date - It includes adding of a date default format in the script to denote the sorter type that must be used to sort the column of the date. <image>. Then with the table head, we added suitable classes and added scripts at the top of the file to sort the table contents within the file. Added the following script to the file. <code> Then, we changed the table to this. <code> <image>. We made this change as tablesorter library was sorting the expanded view as well and spoiling the table structure on sorting the table by Team name. <code> <image>. We have modified the views/review_mapping/_review_report.html.erb file and also added a custom script to sort ""Reviews done"" and ""Score awarded / Avg. score"". To sort ""team reviewed"", we used tablesorter which is similar to the issue#1. Following script has been added for custom sort. <code> <image>. You can see the arrow marks beside the table header. <image>. <image>. 1. Login as a super_admininstrator2. 2. Click Assignments tab next to Courses 3. Select the ""View submissions"" icon for the assignment for which you want to see the report of 4. Sort the table by clicking on headers. 1. Login as a super_admininstrator2. 2. Click Assignments tab next to Courses 3. Select the ""View Scores"" icon for the assignment for which you want to see the report of 4. Sort the table by clicking on headers. 1. Login as a super_admininstrator2. 2. Click Assignments tab next to Courses 3. Select the ""View report"" icon for the assignment for which you want to see the report of 4. Sort the table by clicking on headers. 1. Login as a super_admininstrator2. 2. Click Assignments tab next to Courses 3. Select the ""View report"" icon for the assignment for which you want to see the report of 4. Select the ""Author Feedback report"" from the drop-down menu 5. Sort the table by clicking on headers. 1. Login as a super_admininstrator2. 2. Click Assignments tab next to Courses 3. Select the ""View submissions"" icon for the assignment for which you want to see the report of 4. Select the ""Teammate Review report"" from the drop-down menu 5. Sort the table by clicking on headers.","The wiki is detailed and well organized, they included many screenshots to explain the changes they’ve made and compare the UIs before and after their changes. However, the UML design document is not UML; it's just a flowchart. They also added more explanation about their solution of sorting one table as suggested in the demo. Most 2nd round reviews gave them the highest scores."
E1822,"The primary objectives for this project are as follows: 1. Allowing Instructor to create new badges - which involves adding name and badge image and letting the instructor add them to the assignment 2. Students must be able to suggest ""Good Teammate"" badges during the teammate review periods. 3. Students must be able to suggest ""Good Reviewer"" badges, for reviews received. 4. Create a pipeline to enable instructor to manually approve badges suggested by students. The use of badges will encourage students to have a visual motivation based on their achievements and thus perform better. Two such badges, Good Reviewer and Good Team mater were implemented, with students receiving them automatically based on a threshold score in those categories. This was a static system with fixed number of badges. Also, allowing students to suggest Good Teammate and Good Reviewer badges for their peers will give them an incentive to put in more effort towards carefully reviewing other's work, and encourage them to actively participate in team projects. Two major flows exist in this project , one being new badge creation and associating them with the assignment. Second one is modifying the flow for good teammate and reviewer badges to be present in appropriate question section. When an assignment is created/edited, there is a checkbox called ""Has Badges?"" . Checking this renders the ""Badges"" tab. This tab currently lists the two available badges namely ""Good Reviewer"" and ""Good Teammate"" as specified in expertiza/app/views/assignments/edit/_badges.html.erb . To add a new badge which is a new functionality, we display a button, at the end of the badges tab, which redirects the user to a page enabling him to create a New badge. The new form fields include Badge Name , Image and Description . <image>. We change this view to allow an instructor to add a new badge, and select all badges that will be applicable to this assignment. The view is changed to display all the available badges and a check box to select each of them. It was initially present as a badge vs threshold display. Similar to Good Teammate badge, in the existing workflow, good reviewer was also assigned based on score and threshold. This is modified in our implementation, in a similar way as that of teammate badge. We add a ""Good Reviewer check box"" as a question in the feedback of the reviews given page. An entry is made to the awarded badges table with the approval status as 0. Once this field is changed to 1, it would display badges in the assignment row . Once approved by the instructor, the badges assigned would be visible in the assignment tab of the website as shown in the image. Badges corresponding to each of the assignments will be seen on the row of that particular assignment. 1. expertiza/app/models/assignment_badge.rb - create badges without threshold method was added 2. expertiza/app/models/assignment_form.rb - update assigned badges method was added. this method modifies the db entries for assignment_badges table based on the checkbox entries 3. expertiza/app/models/awarded_badge.rb - suggest badge method was added, which is called when badge is suggested by student by checking the checkbox in questioner. 1. expertiza/app/controllers/assignments_controller.rb - Modifications were done to include the functionality of displaying all badges in the badges tab and check box based selection process 2. expertiza/app/controllers/badges_controller.rb - This was a new file added in this implementation . Code on handling new badge creation, in create method was added. 3. expertiza/app/controllers/response_controller.rb - Modification to process question responses from checkbox about badges were added to this file. 1. expertiza/app/views/assignments/edit/_badges.html.erb - Modification to display all available badges to badges tab as checkbox was done. Also a link to creating a new badge is provided 2. expertiza/app/views/badges/new.html.erb - New file to create a new badge was added to this file 3. expertiza/app/views/badges/_form.html.erb - New file to create a form for badge was added to this file 4. expetiza/app/views/response/response.html.erb - Modification to display checkbox questions in review questioner was added to this file. 1. Routes for badges was added. New rspec file was added in spec/models/badge_spec.rb. Test cases were written to validate the different conditions of creating a new badge. 2. There is currently no way for a newly created badge to be assigned to a student through the UI, even if it has been added to an assignment. 3. Instructors cannot directly assign “Good Reviewer” badge through the UI.","The explanation has been improved, and the design document covers most of the bases.  However, it is still weak at describing the working of the code; there is just a listing of files changed, without an explanation of how the added functionality required making these changes."
E1907,"The file response_controller.rb handles the operations on responses based on user permissions. The user is redirected to the appropriate place on Expertiza after the action is complete. The problem statement for E 1907 can be viewed here <link> The pull request of our project can be viewed here <link>. Problem: edit_allowed function The function name is misleading - it checks if the response can be viewed by a person or not. <code> Solution: The edit_allowed? function was renamed to view_allowed? in the response_controller.rb file. <code>. Problem: Move the pending_surveys function to survey_deployment_contoller.rb. Ensure that moving the function does not break the code functionalities. The original code for the pending_surveys method in the response_controller.rb is shown below. <code> Solution: Moved the pending_surveys function to survey_deployment_controller.rb Made changes in the following files and folders: 1. app/controllers/survey_deployment_controller.rb (the pending_surveys method was moved to this file) 1. app/controllers/response_controller.rb Original - <code> New - <code> 1. config/routes.rb Original - <code> New - <code> 1. spec/controllers/respose_controller_spec.rb Original - <code> New - <code> 1. Moved pending_surveys.html.erb from views/response to views/survey_deployment. Problem: The assign_instance_variables method violates several principles - The method is doing two things, and the method is not really needed at all. It is called only in two places and does entirely different things based on where it is called from. The original assign_instance_vars method is shown below: <code> Solution: The assign_instance_vars method was removed as it was not needed. The logic from this method was combined with the Edit and New sections as shown below. The edit method with modifications. <code> Moved assign_instance_vars for the New action inside the new method : - <code>. Problem: In the create() code in create method, especially the was_submitted and is_submitted part, is hard to understand. The original code of the create method is shown below. <code> Solution: The first instance of was_submitted was removed. This variable was renamed to previously_submitted in the other lines of the create method. The purpose of this variable is to determine if the response was previously submitted or the submitted response is a new response. These changes are shown in the code below. <code>. Problem: The private methods have few to no comments. Solution: Comments were added to the private methods as shown below. <code> <code> <code> <code> <code> <code> <code> <code>. Problem: Redirect method has a if-else ladder. Originally, the redirect method was :- <code> Solution: A local variable was created to hold the description of the action to be taken by the redirect method. The if-else ladder was transformed into a switch (case) statement to make the code more legible. The modifications to the redirect method are shown below. <code>. The test file used for the response_controller.rb was located in the */spec/controllers/response_controller_spec.rb. This test was previously created from a different project. However, the test file did have to be modified since the pending_surveys method was removed. The following snippets of code show the modifications to the test file. Original content: <code> Modified content: <code> There were no observed failures after performing the modified test. After completing the changes to the code, the code modifications were committed to GitHub. Then, a pull request was performed on the committed code. During this process, two automated bots were used to analyze the code. These bots were from Code Climate and from Travis CI. The Code Climate bot did not detect any major errors with the code. However, it did comment that the code complexity was too high for some methods. Since our team did not make any changes to these sections of code, no additional changes were made to the code to resolve the complexity concerns. The logic for the code appears to be working and it was uncertain how the logic could be further reduced to lower the code complexity score. The second bot, Travis Ci, performed four different analysis cycles on the committed code. It reported that the code passed its inspection with no issues. 1. The problem statement for E 1907 can be viewed here <link> 2. The pull request for this assignment can be viewed at: <link> 3. Team Branches: All the three team members have contributed towards the project and their branches can be viewed here <link> 4. Screencast: <link> 5. Expertiza Main Repo <link> 6. Expertiza Documentation <link>.","The descriptions of most of the changes are clear.  However, the project asked you to add comments where needed, and very few of these comments or descriptions appear in the design doc.  You did include method comments for private methods, but not the bodies of those methods, which makes it hard to see the value of the comments."
E1559,"Code refactoring is process of changing the code to make it more maintainable, without changing the functionality of the code. Some of the reasons for performing refactoring are: 1. To remove duplicate code. 2. To make the code more maintainable. 3. To divide functionality of the class. Expertiza is a web application where students can submit and review learning objects like code, writings, etc. It gives scope for creation of reusable learning objects. Students submit assignments, which can than graded through peer reviews. The Expertiza project is supported by the National Science Foundation. JoinTeamRequestsController and InvitationController. invitation_controller.rb is used by a user to invite other users to join his/her team. It performs validation before creating a request. Following chunk of code checks whether the user is allowed to get the invite or not. <code> Now, invited user can accept or reject the request. Once the user has accepted the request, he can be seen as a part of the team. join_team_requests_controller.rb is used when user decides to join a team. This is achieved by creating an advertisement for the team. Once the advertisement is created, it is shown in the Topic Selection section. The user who wants to join the team can send a ""Request"" to the members of the team. The members can then decide whether to send him/her an invite or decline the request. The invitation_controller.rb is doing the required task but it is difficult to understand the code, hence it becomes difficult to maintain the code. And the functions in the accept and create method can be broken down into separate methods. In join_team_request_controller.rb has duplicate code in various methods which can be removed by creating a separate method for this common code. invitation_controller.rb 1. Rename to Invitations_Controller.rb, as is not in accordance with current naming convention. 2. Add comments explaining what each method does, and comments on how important variables are used as currently there are no comments. 3. Refactor create and accept methods. Shorten and clarify them by adding private methods, as create and accept methods currently have a lot of code. 4. Change the find_by_sql call(s) to Rails (Active Record) statements. 5. Make sure that it can be used by a user with a TA or instructor account, if they are participating in this assignment. 6. Change grammatically wrong or awkward flash messages. join_team_requests_controller.rb 1. Add comments to the code. 2. Remove duplicate code, from create and accept methods. 3. Decline and destroy method should check for successful operation before returning. 4. Change grammatically wrong or awkward flash messages. The controller renaming had to be incorporated in different files of the project. The table contain the file names along with the lines before and after the changes. <table>. <table>. <table>. <table>. To test the functionality of join_team_request_controller and invitations_controller, please follow the steps provided in the video below. This video covers the functionality of how these controllers work. This will help in manually testing the functionality. <link>. <link> <link> <link> <link> <link>.","As to what's been done, there are only tables and no explanatory text."
E1870,"Expertiza supports multi-round peer reviews. Currently, in this situation, student who did not do the previous round peer reviews can still do the subsequent round peer reviews, but will lose about 50 points according to the deduction policy. Therefore, it will be fairer to provide instructor an option to decide whether a student can do the subsequent round peer reviews when s/he did not do the previous round peer reviews. In assignment#edit page “Review strategy” tab, add a checkbox (e.g., “Allow student to join reviews late”*) to allow instructor to decide whether students can do the second round peer reviews without the first round peer reviews; by default this box is unchecked and it only appears when there are multi-round peer reviews. 1. Before <image> 1. After <image>. Currently, when students didn't request enough reviews(e.g. Each student is required to do at least 2 reviews, but s/he only request one in the first round), they can still request more reviews in the second round, but will lose points due to lack of first round reviews. Now, we want to add a functionality to split the case. Below is the flow chart that explains the improvement. * Note that whether submit or not doesn't matter, as long as request, it counts. <image>. 1. First, check whether a certain assignment is multi-rounds Go to expertiza/app/models/assignment.rb, find the following function <code> <code> check current rounds, if >=2, then checkbox can be clicked. 2. Then, Edit the database Go to DB, add an attribute named 'is_second_round_allowed_checked' to assignment 3. Finally, add the function Go to expertiza/app/models/assignment.rb, add a function called 'allow_second_round_review'. When rounds <2, do nothing; else, allow second_round reviews if box checked. 4. Change the view of student_review as following: <code> where the second if-statement ensures that the student can only have request option during first peer review round or get the permission from instructor during second or more round. We plan to write a feature test for the project. Go to expertiza/spec/features folder, add a file named 'Allow_second_round_review'. Below is the details of our test. 1. Log in as instructor 2. Navigate to “Manage…”,then “Assignments” 3. Under “Actions”, choose “Edit” 4. Navigate to “Review Strategy” 5. See the checkbox “Allow student to join reviews late”. 1. Log in as student 2. Navigate to “Assignments” 3. Choose an assignment 4. Navigate to “Others’ work” 5. Student cannot do the second review without the first one. 1. Log in as student 2. Navigate to “Assignments” 3. Choose an assignment 4. Navigate to “Others’ work” 5. Student can do the second review without the first one. <link> <link> <link> <link> <link>.","This is a good description of the code changes that were made.  The changes were not extensive, but  they are cited directly in the design doc.  The test plan could have been elaborated similarly.  But no code is shown for it."
E1825,"Expertiza is a web application where students can submit and peer-review learning objects (articles, code, websites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. -- Expertiza project. The E1825 project is a course project for CSC 517 - Object Oriented Development and Design for Fall 2018. It involves adding some enhancements to the existing system. The primary goal of this project is to differentiate past due assignments from current assignments. The tasks to be completed are as follows:- 1. Add past due assignments to the student’s task list (on Student View). 2. Color code assignments by closeness to due date (on Student View). 3. Check for correction in due dates of assignments (when an assignment’s due date is edited, it should be appropriately moved from the “Past assignments” list to the “Current Assignments” list if needed) 4. On Student Task page, separate the list of 'teamed with' students from the current tasks box. 5. Write the required tests before implementing/refactoring the methods in the above-mentioned classes. student_task_controller.erb app/views/student_task/list.html.erb student_task_helper.rb Airbrake_exception_errors_feature_tests_spec.rb. will_paginate_array_fix.rb student_task_controller_spec.rb. The existing system contains the view where all the assignments of a student are displayed as a single list regardless of their due date. Now we have created a separate table for assignments that are overdue by the student. The displayed list is such that the most recent due assignment is shown at the top. To accomplish this task we have modified student_task_controller.rb and list.html.erb file (in student_task). A helper function was also added to format a string into multiple lines. In student_task_controller a new instance variable was created to capture all the student tasks that are overdue in ascending order of dueness. The existing instance variable was used to capture all the tasks that are currently due. In the view file i.e list.html.erb, a new table is created to contain a list of past assignments. The current task-table on the homepage contains all the assignments displayed in white background. So to alert the user of approaching deadlines, we color code the background of each assignment title as red, orange, yellow or green depending on the proximity to its deadline. To accomplish the above-mentioned task, we added a helper method for student_task_controller that receives a due_date and calculates the days remaining for that date and then using this value it returns a string which denotes what should be the background of the row. Separate the list of 'teamed with' students from the current tasks box Currently, the current task lists and the student you have teamed up with are being shown in the same box. We need to separate these two. To achieve this we create an additional box, by adding a new ""taskbox"" div tag in list.html.erb. So the task list and the teammates are shown in different boxes. You can find the snapshot of the changes here: <link> <link>. Our project involves mostly changing the view based on certain conditions. The testing of our project is based on simply checking whether the elements on the view change after a certain condition is satisfied, like changing of the background color for tasks as we approach the deadline. For example, if the due date is within a day, then the background color should be red or if it's more than 10 days it should be green.","The strategy to fix the issues is not clearly laid out. The authors have also not included any sample output / screenshots. The project revolves around changes in the UI so screenshots would have a gone a long way in helping a reviewer understand what the project was about.

Several reviewers also think the test plan is inadequate

Code snippets are included as png images, instead of text. Overall, the structure of the document does not look very organized."
E1614,"This page provide the details of the changes done as part of the refactoring response controller project(E1614). Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.6. <link>. <link> project is a platform to create reusable learning objects through peer review. It is an open source project which uses <link> framework. The main aim of this project was to refactor the response_controller. The following tasks were completed as part of refactoring in this project: 1. Moving variable declaration to right places. 2. Removing unused variables. 3. Fixing code duplication. 4. Replacing if else block with switch statements. 5. Remove the unreachable code. The Response controller is responsible for the CRUD (Create, Read, Update and Delete) operations on responses. The users can fill out a questionnaire such as review rubric or feedback on the partner's contribution. So the ResponseController handles the various operations on the responses, which are objects that Expertiza creates when you fill out a questionnaire. There were two variables ""msg"" and ""error_msg"" in the create method which were declared and initialized to blank strings and then again assigned some string value before it was used in the method. So we moved the variable declaration to the place were it was used and removed the unnecessary variable declaration. Below if the code snippet for the changes done: <code>. There were some unused variables in this controller. The edit method contained a variable ""array_not_empty"" variable which was not used anywhere. So we removed the unused variables. There was some duplicate code in the update method. So we removed the duplicate code and retained the code snippet inside the if block. Below is the modified code for the update method: <code>. The redirection method used the if-else statements. The if-else block was replaced with switch statements. Below if is the code snippet for the redirection method after the code changes: <code>. In the action_allowed? method of the controller there was a case for the ""edit"" case which was getting executed all the time making the second case block unreachable. Modified the code to use the proper case statements for ""edit"", ""delete"" and ""update"". Below is the code snippet for the action_allowed? method after the code changes: <code>. As the main motive of the project was refactoring the response controller, we list down below the steps to test the flows involved with response controller so as to make sure that nothing is broken due to changes done as part of refactoring and the functionality as expected. 1. Login as a student user. 2. Click on the Assignments tab and Select the assignment you want to submit review for others work. 3. In the assignments page click on others work and select one of the assignment for review. 4. Click on Begin and then answer different questions which are presented in the review rubric. 5. Once done with the review, click on Submit review to submit the review. 1. Login as a student user. 2. Click on the Assignments tab and select the assignment you want to submit the teammate review. 3. Click on the your team option. 4. In the teammates page, click on the Review option against the user you want to submit the feedback. 5. Fill out the questionnaire presented in the teammate review rubric. 6. Once done with the responses, click on Submit review to submit the review for the teammate. 1. <link> 2. <link> 3. <link>.","The code snippets are rather large, and they really don't show the changes done.  They seem to be the ""after"" view.
It would be better to show before & after side by side, as is shown in Github."
E1641,"It handles all different types of response maps (review response map, author feedback response map, teammate review response map, meta review response map and quiz response map). The controller has many methods and involve with many other controllers and views, the code is long and complicated. Some of the methods in this controller have unreasonable name associated with their functions, some methods are too long, some methods haven't been used by any other methods or views. 2. Method response_report has some SQL - like code. 3. Test whether method add_user_to_assignment is used. There is no way that this method should be in ReviewMappingController. Please remove this method and caller. Plus those two views are not called anywhere. Please verify this and if so, you should delete those two views, two method and also related records (e.g. 5. Method delete_all_reviewers actually only deletes the outstanding review response maps (the ones which has been initiated, but there is no response yet). You can try to test this method by clicking “Assign reviewers” icon on an assignment. In addition, delete it if you find this method is not called anywhere. 7. Method delete_mappings is problematic. It does not looks like a controller method. Please refactor it or delete it if you can validate that this method is not called anywhere. 8. Method automatic_review_mapping_strategy is too long. Please refactor and test it. ', params[:contributor_id], reviewer.id]) to more rails quey like ReviewResponseMap.where(reviewee_id: params[:contributor_id],reviewer_id: reviewer.id) 3. We search the function name( add_user_to_assignment ) in the whole files, and find that this method is invoked in ""participants_helper.rb"", and also being invoked in the function of add_reviewer and add_metareviewer in the controller of review_mapping_controller 4. By searching the whole project and routes, we verify that methods add_self_reviewer and get_team_from_submission in this controller are not called by any other methods except for views ""show_available_submissions_for_quizzes.html.erb"" and ""show_available_submissions.html.erb"". And those two views are not linked to any other views. 6. By searching the whole project and routes, we verify that methods release_reservation in this controller are not used in anywhere. 7. By searching the whole project and routes, we verify that methods delete_mappings in this controller are not used in anywhere. 8. Method automatic_review_mapping_strategy have many long lines. The rails query we change in this controller: 1. From <code> To <code> 2. From <code> To <code> 3. From <code> To <code> 4. From <code> To <code> 5. From <code> To <code> 6. From <code> To <code> 7. From <code> To <code>. <code> <code> <code>. <code> <code>. def delete_reviewer <code>. def delete_all_reviewers <code>. <link> . <link> 3. We use some data to test the result of old query and new query in rails console <code> <code> <code> 1. We write RSpec feature tests to prove that all changes are correct and the project performs well as before. Automatic_review_mapping method The function of method automatic_review_mapping is to automatically assign reviews on students in teams when instructor set either student review number or submissions review number. To test the correctness of our refactoring, we design a scenario and 4 cases of assigning reviews to students: Case 1. Instructor has not set both students review number and submissions review number (They are both 0). Case 2. Instructor set both numbers (They are both not 0). Case 3. Instructors set students review number. The controller will change database: create new relationship in ReviewResponseMap. For example, if assign student review number to 2, and there will be 20 peer reviews in total and need to allocate to 3 teams. Case 4. Instructors set submissions review number. The controller will change database: create new relationship in ReviewResponseMap. For example, if assign submission review number to 3, and there will be 21 peer reviews in total to allocate to 10 participants. 9 among 10 participants will review 2 teams’ artifacts and 1 participant will review 3 teams’ artifacts. require 'rails_helper' <code> <code> <code> <code> Refactoring add_reviewer, add_metareviewer, delete_reviewer, delete_metareviewer, delete_outstanding_reviewers and delete_all_metareviewers Since we merge methods have similar functions, we need to test their functionality. <code>.","There is a good description of the needs and of how the code has been changed.  This is exactly what we wanted.  However, it is not very effective to juxtapose ""before"" and ""after"" versions of the code without any annotations showing changes."
E1763,"A staggered-deadline assignment is an assignment in which different topics have different deadlines. Currently, the system requires the instructor to enter, manually, all submission and review deadlines for all topics. We were also asked to create a ""Duplicate Topic"" button for the instructor, to copy a particular topic within a assignment. Currently the assignment topics are displayed on the basis of ""first created"". Motivation Currently when the instructor wants to assign the same deadlines to certain topics, s/he has to manually enter all deadline dates. It will be more efficient to have a method where the instructor can assign this deadline to certain selected topics from the assignment. In an assignment that has staggered deadlines, say a topic has 3 slots. The solution to this problem is to let the instructor duplicate a topic with remaining slots and set the duplicate topic deadline to the latest deadline of all topics(default) or any date that s/he wants. The current display of topics is not intuitive in the sense that say, topic 1.1.1 was created after topic 2.1. Now the newly created topic (1.1.1) will be displayed after 2.1. Thus, we will display the topics sorted according topic identifier. If a topic is created without identifier it will be displayed before all the topics with identifiers, on the basis of ""first created"". We have also provided a text box at the end for the instructor to enter the due dates for the selected topics. This text box is auto-populated with the latest deadline of all topics in that assignment, thereby saving the instructor the hassle of having to enter all the fields from scratch. <image> The default deadline for the textbook is set to the latest deadline among all the topics under the assignment. Assign the new deadline from the text box to the topic that has a selected checkbox <image> 2) Along with the check-boxes, we have also implemented shift+click for topic selection. Without it the instructor would have to select each topic individually. Thus with this, if the instructor selects a single topic, then presses shift and selects another topic, then all the intermediate topics will also be selected. <image> 3) We have also sorted the topics that are displayed for the assignment based on the topic_identifier. Say the instructor first creates a topic with identifier ""4.1"". Second s/he creates another topic with identifier ""1.2"". Intuitively the newer topic must be displayed first. Get the available slots fo the topic. The number of max_choosers for this duplicate topic is equal to the available slots for the original topic. 2) Click on the edit assignment button for any assignment. We can also see the ""New deadlines for selected topics"" text box. This text box automatically fills the boxes with corresponding values of the topic with the latest deadlines of all topics. When we press the save button the dates entered in the text-box is applied to all the selected topics. <image> 6) The first case is when we try to duplicate a topic with zero slots available. In this case too it will not duplicate a topic and display an error message. <image> 7) The second case is when we try to duplicate a topic with all slots available. It will not duplicate the topic and display an error message. 1.3. Go to topics. You can see the ""duplicate topic"" button in the action column for all topics. 1.4. To duplicate a topic press the button for any topic. 1.7. Select check-boxes against topics whose deadlines you want to change. Press shift and select another topic. All topics in the middle will also be selected. 1.9. The text box at the bottom has the latest values of all the topics by default. 1.11. The entered deadlines are saved for all topics selected. 1) For the first issue where the instructor was forced to enter due dates manually for each topic, we have added a checkbox against each topic in the assignment. We have also provided a text box at the end for the instructor to enter the due dates for the selected topics. This text box is auto-populated with the latest deadline of all topics in that assignment, thereby saving the instructor the hassle of having to enter all the fields from scratch. 2) Click on the edit assignment button for any assignment. We can also see the ""New deadlines for selected topics"" text box. This text box automatically fills the boxes with corresponding values of the topic with the latest deadlines of all topics. 3. Go to topics. You can see the ""duplicate topic"" button in the action column for all topics. 4. To duplicate a topic press the button for any topic. 7. Select check-boxes against topics whose deadlines you want to change. Press shift and select another topic. All topics in the middle will also be selected. 9. The text box at the bottom has the latest values of all the topics by default. 11. The entered deadlines are saved for all topics selected.","This is a really good writeup.  It could be improved still further if standard Mediawiki topic headings were used throughout instead of ""1)"", ""2)""."
E1813.1,"BDD focuses on: 1. Where to start in the process 2. What to test and what not to test 3. How much to test in one go 4. What to call the tests 5. How to understand why a test fails Test-driven development is a software development methodology which essentially states that for each unit of software, a software developer must: Define a test set for the unit first; Make the tests fail; Then implement the unit; Finally, verify that the implementation of the unit makes the tests succeed. Substitutes such as method stubs, mock objects, fakes, and test harnesses can be used to assist testing a module in isolation. Some of the advantages of unit testing are: 1. Finds problems early: Unit testing finds problems early in the development cycle. In test-driven development (TDD), which is frequently used in both extreme programming and scrum, unit tests are created before the code itself is written. Unit tests detect changes which may break a design contract. 3. Simplifies Integration: Unit testing may reduce uncertainty in the units themselves and can be used in a bottom-up testing style approach. By testing the parts of a program first and then testing the sum of its parts, integration testing becomes much easier. 4. Documentation: Developers looking to learn what functionality is provided by a unit, and how to use it, can look at the unit tests to gain a basic understanding of the unit's interface's API. 5. Design: When software is developed using a test-driven approach, the combination of writing the unit test to specify the interface plus the refactoring activities performed after the test is passing, may take the place of formal design. Each unit test can be seen as a design element specifying classes, methods, and observable behavior. This project is to write unit tests using rspec for menu_items.rb model. The unit tests are to be written to make the path coverage of menu_item.rb more than 90% and achieve the highest possible branch coverage. The task in hand was to write test cases for testing the menu_items model file. 5. Writing testing conditions for different functions and cross checking with the expected outputs. 3. Parent id: It gives the id of the parent and establishes the hierarchy of the various objects of the menu item model. 4. Sequence id: It gives the sequence numbering for determining the way the attributes are ordered within a parent. Different instance methods and class methods exist in this models . 2. delete: Instance Method This methods deletes the entry and all the child entries (entries having the same parent id) lined to it 3. above: Instance Method It returns the entry that is above a present sequence number for a given parent id 4. below: Instance Method It returns the entry that is below a present sequence number for a given parent id 5. repack(repack_id): Class Method It modifies the sequence numbers, making them in order, removing the skip entries present in it. repack_id tells the parent id under which these changes are to be made 6. next_seq(parent id): Class Method It returns the next possible sequence id corresponding to a given parent id entries. 7. items_for_permission: Class Method It returns the set of items that are possible to be displayed for a given permission id and also based on controller action id and page id being present for it. Stub objects are needed to be created for any unit testing criteria.These objects are loaded freshly and deleted after every testing condition. Several methods exist for creating such a objects, whose parameters need to be designed to satisfy the conditions under test. For testing menu_items, we created required entries into the database using ""Let"" and ""MenuItem.create"" method, giving different values for each of the test inputs to cover the required testing conditions. <code> The above is an example entry used for menu item. 5 more similar objects were created with entries giving combinations of parent_id, sequence numbers and controller_action_id. We also created objects for controller_action and content_page which were used to define conditions for coverage of items_for_permission. A total of 13 unit tests were performed for testing all the functions in menu items model file and achieving complete code coverage. The conditions that needed to be tested are as below: 1. .find_or_create_by_name: <code> 2. #delete: <code> 3. #above: Test cases were written to check the below conditions: <code> 4. #below: Test cases were written to check the below conditions: <code> 5. .repack: Test cases were written to check the below conditions: <code> 6. .next_seq: Test cases were written to check the below conditions: <code> 7. .items_for_permissions: Test cases were written to check the below conditions: <code>. After writing the test cases we used SimpleCov to measure the C0 coverage of our rails application.","Too much of the document introduces BDD and unit testing, which the readers can be expected to know..  Also, it shouldn't be necessary to discuss setting up Expertiza on your machine. 

What follows this is a list of items, parameters and methods.  Lists are hard to read and remember.  A list could appear as a table, but should be accompanied by narration to help the reader comprehend what's in the list. The case descriptions don't fit in the boxes, which makes them hard to read."
E2078,"<image>. In the current implementation of Expertiza, students can view a compilation of all peer review scores for each review question and an average of those peer-reviews. Furthermore, the average composite score is displayed on the page under the average peer review score, labeled ""Final Average Peer Review Score"". The formula we use to determine a final grade from, 1) the peer reviews and 2) how closely self reviews match the peer reviews, uses a type of additive scoring rule, which computes a weighted average between team score (peer reviews) and student rating (self review). More specifically, it uses a type of mixed additive-multiplicative scoring rule, which multiplies student score (self review) by a function of the team score (peer reviews), and adds its weighted version to the weighted peer review score. and where: w - weight - (0 <= w <= 1) is the inverse proportion of how much of the final grade is determined by the closeness of the self review to the average of the peer reviews (w is the proportion of the grade to be determined by the original grade determination: the peer review scores). An example: 1. The average peer review score is 4/5, the self review score is 5/5. 2. The instructor chooses w to equal 0.95, so that 5% of the grade is determined from the deviation of the self review from the peer reviews. If the instructor chose w to equal 0.85 (instead of 0.95), the grade is 77% (instead of 79%) because deviation from peer reviews is a larger weighted value of the final grade. It is basic in that it only allows deviations of the self review scores from the peer review scores to result in a decrease in the final grade and a deviation will always result in a decrease of the final grade. The parameter l - leniency - can determine a threshold by which the final grade will account/adjust for self reviews' deviations from peer reviews only when the deviation reaches this threshold (measured in percentage deviation from the average peer review). If the difference does not meet the threshold, no penalty will be subtracted from the peer review. In addition, if the difference does not meet the threshold (the self review score is sufficiently close to the peer review scores), the instructor can choose to add points to final grade based on the magnitude of the difference. To recap: w should be chosen based on the instructor's desired percentage (w) of the final grade to be determined from peer reviews and, conversely, the instructor's desired percentage (1-w) of the final grade to be determined by the extent to which self reviews deviate from peer reviews. In addition, l - leniency, should be chosen based on the instructor's desired percentage of the deviation of self review from peer review that could result in no grade deduction from the deviation if the deviation is sufficiently small (or even a grade increase if the instructor wants to increase the score of individuals with a small deviation). Notice that the leniency condition, the instructor's desired percentage of the deviation of self review from peer review , is naturally part of the grading formula in SELF: <code> In addition. The formula for determining the final grade would thus add the small extent of deviation to the final grade rather than subtracting it (in SELF, 1 - ..., is changed to 1 + ...): <code> where: <code> In this case, the pseudo-code is: <code> Using the previous example (average peer review score is 4/5, self review score is 5/5, w = 0.95), the self review score (5/5) differs by 25% of the peer review score (4/5). <image>. In the current implementation of self review, the user is able to see the peer reviews before they have made their own self review. Below is a control flow diagram for how a student will be able to view their peer and self review score. <image>. This also includes displaying the final score that aggregates the self-review score utilizing a chosen formula. In this implementation, we added a display for the Final Average Peer Review Score, which is the score that takes the average self-review score into consideration based on a set formula. <image> <image> <image> The following screenshot shows the final result of the code implementation. The following implementation shows the addition of the new columns for self-review score and the final composite score (along with a doughnut chart for the final score). <image> <image> The following screenshot shows the final result of the code implementation. <image> <image> <image> <image>. <image>. <image> <image> <image> <image>. 6.1. Assure that there is a column for self-review scores 6.2. Confirm there is a composite score calculation underneath the average peer review score. This tested to see if the Vossen formula that we implemented would output the correct score when given a average peer, average self review score, weight, and leniency. <image>.","The general approach is described quite well.  The description of the self/peer-review grade calculation is very clear.  The document contains all of the required parts.  However, there is not enough description of the code changes; in most cases, code diffs are just pasted in without further discussion."
E2087,"Expertiza includes the functionality of notifying instructors when a conflict occurs in review scores for a submission. Currently, when two reviews for the same submission differ significantly, an email is sent to the instructor of the course, but there is no link to the review that caused the conflict. This improvement will allow the professor to have links to the reviews that caused the conflict and will be formatted better to help the instructor understand the conflict. 1. The functionality is good but the UI of conflict report needs work. 2. The UI needs to be cleaned up a little. When charts have only one or two bars, the chart can be compressed. The reviewer whose scores deviate from the threshold can be displayed in a different colored bar. 3. Tests need to be refactored. 4. They included their debug code in their pull request. 5. They have included a lot of logic in the views. 6. Shallow tests: one or more of their test expectations only focus on the return value not being `nil`, `empty` or not equal to `0` without testing the `real` value. The previous team implemented new logic to determine if a review is in conflict with another and created a new page to link the instructors to in the email. Because their functionality was good, we will mainly be focused on improving the UI of the conflict reports. Furthermore, there is a lot of logic that lives in the views that can be refactored and moved to controllers. Additionally, there is debug code that can be removed and tests that can be fleshed out. File: app/views/reports/_review_conflict_metric.html.erb The UI can be improved for the conflict metric to give more information on the conflicted reviews. File: app/views/reports/_review_conflict_metric.html.erb The logic to determine if answers are within or outside of the tolerance limits can be moved to functions outside of the .erb file. <image> <image>. To verify the conflict notification is working correctly, a mock assignment will be created and two reviews will be entered that should trigger a conflict. Successful retrieval of the email and verification of the links included in the email will provide sufficient verification that the changes were successful. File: spec/models/answer_spec.rb Currently, tests only check if the values are not empty. More tests can be written to make sure the actual value is being returned correctly. File: spec/controllers/reports_controller_spec.rb More tests can be written to ensure correct names and values are written. Adding base_url from the controller as this method is not accessible from model <code> <code> This method generates statistics (average, standard deviation, tolerance limits) for each round. This method was created to move logic that was previously contained in a view to a helper class. <code> This logic highlights all reviews' score in red which is out of limit range, and all other background color will be green. <code> Passing the colors to bar background. <code> comprising the chart height for how much it need to clearly display all data. <code>. Based on the previous changes from last group, the notification email triggered will send to the instructor whenever a new review is significantly different from other people's review, who has the same submission team (the threshold is specified in the ""Notification limit"" on the Rubric tab of assignment creation). The graph showing below is the previous team email UI. <image> On the email notification, the formatting can be improved to make it more readable and clear as to which links relate to what actions and what caused the conflict to trigger. The previous group of snapshot for the view which the instructor receives <image> On the 'review for mail check' page, more information can be added to indicate if a review has a conflict. We will add indicators beside each review that have conflicts. We added a link for review_conflict_report_url, which will let instructor to access the review conflict report page by the email he received. <image> Chart before improvements. <image> Chart after improvements. <image> The improved chart has the student name on the y-axis, scaled chart sizes, and more intuitive highlighting with red bars indicating an out of limits score. This is a great improvement to the previous implementation where only the student name was highlighted to indicate an out of limit score. Added additional tests to cover the average and standard deviation calculations. File: spec/helpers/review_mapping_helper_spec.rb <code> File: spec/controllers/reports_controller_spec.rb Improved tests for conflict report controller. Tests now check for correct values rather than just null or empty. <code>. GitHub - <link> Pull Request - <link> Demo Video - <link> Website - <link>. 1. Previous Wikipedia page - <link> 1. Previous Final Video - <link> 1. Previous Pull Request - <link> 1. Previous Github Repo - <link>.","The document is readable, and does a good job of explaining changes, especially to the UI.  I would have liked to see it cover more of the changes (less than 1/3 of the code changes, other than tests, were described), and also focus less on the previous implementation of the project, since readers are going to be interested in the functionality, not a previous project that was never merged."
E1613,"It provides a platform to view assignments, manage teams, select topics and work improvement through anonymous peer reviews. For the instructor it provides complete control to create assignments, view reviews submitted and provide feedback. The current implementation of the project works only for assignments that have topics assigned to them. This needs to be enhanced to include assignments that do not have associated topics as well. 6. WI-6: Expertiza provides a functionality to import topics from a file (.csv or .txt). The following files were modified for this project. For this work item the following files were modified: app/controllers/sign_up_sheet_controller.rb: In this file the method ad_info is defined. Original Code: <code> Modified Code: <code> Additionally changes were also required in the models signed_up_team.rb and team.rb. The following changes were made to the files: app/models/signed_up_team.rb: <code> app/models/team.rb <code>. For this work item the file app/controllers/sign_up_sheet_controller.rb was modified. The first part of this task is it enable the view_publishing_rights view to all the assignments. When logged in as an instructor, (s)he can go to the list of assignments by navigating through Manage > Assignments . Here, only the assignments which have topics associated with them have the icon to go to the view_publishing_rights page. This icon should be available to all the assignments. The part of the code that made sure that only the assignments with topics have this icon is in app/assets/javascripts/tree_display.jsx . <code> Here we see that the code that adds the icon to the content if two conditions are met. To get the icon for all the assignments, the change to made is pretty simple. But in reality, the view just made use of the @sign_up_topics and @assignment . Only those assignments that have topics can be shown in the view. So, by using @sign_up_topics"", the scope is limited to just the assignments with topics in them. Original code (what was in place and moved, but did not work as expected) <code> Modified code <code> The final part of this task was to move the corresponding view to the views/participants views/sign_up_sheet/view_publishing_rights.html.erb <code> The above view had a lot of controller related logic in it. Since it is not the best of practices to have such logic in the view code, the changes shown above in the participants_controller.rb had to be made, so that the view code is just responsible for displaying the information rather than computing it as well. For this work item the file app/controllers/sign_up_sheet_controller.rb was modified. Original Code: <code> Modified Code: <code> Another file that was modified for this work-item is app/models/sign_up_topic.rb . This was changed to columns . Additionally the original check which verifies whether the number of columns in each row is 4 was modified so that it also works if the imported file has only 3 columns. Original Code: <code> Modified Code: <code>. We have added Rspec test cases to check functionality of import feature and view_publishing_rights view. View Publishing Rights : This test case checks whether view_publishing_rights page has column headers ""Topic name(s)"" and ""Topic #"". Since an assignment created without a topic does not have topic name and topic id. The test case will fail if the page contains topic name and topic id. <code> Import tests for assignment topics : There are 4 tests written under this category.They check the topics import feature. The tests perform the following tasks: Check the import pass when the import file has 3 columns. <code> Check the import pass when the import file has 3 or 4 columns. <code> Check the import fail when the import file has 2 columns. <code> Check the import fail when the import file doesn't have valid data. <code>. Follow the instructions below to check the: 1. view_publishing_rights 1. Login as a instructor (better to log in as an instructor that has assignments in the tree_desiplay view. instructor6) 2. Navigate 'Manage > Assignments' 3. Against each assignment in the table, an icon for 'view_publishing_rights' can be seen 4. Click on the 'view_publishing_rights' icon against any assignment 5. If the assignment has topics (eg. 6. If the assignment does not have topics, the table will not have the above two columns 1. Topics import feature for an assignment 1. In the tree_display view of assignments, click on the edit icon. Note that the topic identifier should be more than 10 characters long, else import will fail.","Good narrative describing changes made.
Topic headers ""WI-1"", etc. are not very informative, esp. in the Table of Contents.  You should explain what ""WI"" stands for and write out a short name of the change you made."
E2108,"This project focuses on a specific feature of expertiza which allows administrators, instructors or teaching assistants to impersonate another user (like a student) and access their account. <image> figure 1 <image> figure 2 <image> figure 3. Expertiza allows administrators, instructors and Teaching Assistants to impersonate other users like a student. The rules to impersonating a user is, the impersonator has to be an ancestor of the impersonate. For Example, a Super Administrator can impersonate any user apart from other Super Administrators, an Administrator can impersonate Instructors, TA, Students and not other Admins and so on. The aim of the project is to refactor the impersonate controller. The pre-existing code had the following major issues. 1. All functions related to impersonate controller were present in a single method which is 79 lines long. 1. Presence of repetitive code (Around 40 repetitive lines) <code> 1. Block nesting <code> 1. Too many return statements <code> 1. The impersonation can be done by using an impersonate bar which currently does not allow initial impersonation. <image> This project is focused on resolving the issues mentioned above. It impersonates that user provided that user can be impersonated. The above-mentioned issues have been tackled by refactoring the impersonate controller by splitting into many smaller methods which are later called by the main impersonate controller. This method plays the main role in tackling issue3 - 3 levels of block nesting apart from issue1. Intial Code <code> After recfactoring - Moved to separate method <code>. This method is used to tackle issues1, 2 and 4. All the error message related code is moved to this method. <code>. This method reduces the number of return statements used in impersonate controller, apart from reducing the size of the controller. Initial Code <code> After Refactoring - Moved to a separate method and accessed through the adapter method do_main_operation <code>. This code is used to reduce one functionality performed under the impersonate controller. <code> In the current code, the following code is added to accomodate the navigation bar funcionality of impersonate. <code>. This like an adapter method that is used to interface the impersonate method with display_error_msg and check_if_user_impersonatable. One main purpose to do this is to make the methods flexible for change apart from reducing the number of lines from the impersonate controller. <code>. Initially, while using the anonymized view to impersonate the account: student8597, we received the following error. <code>. As mentioned earlier, in order to impersonate we have two methods: Using the Manage --> Impersonate User Using the Navigation Bar. In order to make the impersonate from the Manage --> Impersonate User work, the form that was rendered was the expertiza/app/views/impersonate/start.html.erb. However, the Navigation Bar makes use of the :impersonate symbol to pass the impersonated user’s name and other details to the controller, for which no check was included earlier. Thus, there was no way to procure a user from the navigation bar. <code> As you can see, in the above code snippet, there is a check for the :impersonate’s params, which earlier was missing(Refer <link> ). The UI testing of this project can be performed on three fronts: 1. The normal impersonate functionality from the Manage tab and Revert functionality. 2. The impersonate functionality using the navigation bar. 3. The anonymized view's impersonate functionality(both from the Manage bar as well as the navigation bar). <table> To test out the three fronts, follow the steps mentioned below under each sub-heading: Checking if impersonating a user is working <code> <image> figure 7 <image> figure 8 <image> figure 9 <code> <image> figure 10 <image> figure 11 <code> <image> figure 12 <image> figure 13 <code> <image> figure 14 <image> figure 15. In order to perform the following testing: <code> <image> note: The above screenshot was captured after instructor6 impersonated student8597, you can also try to impersonate student8597 <image>. <code> <image> <code> <image> <image> <code> <image> <image>. Instructor should be able to impersonate a user while already impersonating a user but from navigation bar. This test is to ascertain the functionality of the user being able to impersonate another user(obeying hierarchy) through the navigation bar on the top right hand corner. Now, from the navigation bar, we try to impersonate another student, student2. This test finally checks if the session is true and the parameters are correct. <code>. <code>. 4. <link> - Spring 2020's wiki for the refactoring of impersonate controller. 5. <link> - Spring 2020's pull request for the refactored impersonate controller.","The first thing I noticed was that the title omits the word ""Refactor"", which could cause trouble finding or understanding the page.  The description of the issues is pretty terse (e.g., ""Block nesting""), doesn't really explain what needs to be changed.  The code snippets are pretty long relative to the explanation of changes made.  You could help the reader a lot to understand if you wrote a paragraph describing the changes and highlighted somehow (e.g., Github diff view) where the changes were made in the code."
E1731,"Today, Expertiza stores the scores based on each response to each criterion, but no holistic scores are stored. The ""answers"" table only contains the scores that user A has given user B on each criterion. This design slows down Expertiza as every time an instructor clicks on ""View Scores"", all the calculations are done to display the score. The situation is even worse if we want to weight the scores by the reputation of each reviewer, which is a measure of how closely that reviewer's scores match other reviewers. But this method will compute the total score by querying and summing the scores saved in local_db_scores table instead of summing the scores given on all questionnaires 1.2. It will also contain a method ""store_total_scores"" which will be called when an instructor clicks on ""Save Scores to db"" icon for an assignment 1.1.1. This method will compute and save the total scores for all the response maps (reviewer -> reviewee) in the assignment for each round in local_db_scores table. When an instructor clicks on ""Save Scores to DB"" icon for an assignment, ""store_total_scores"" method is called in LocalDBCalc class which calculates the holistic scores for each response map from the individual scores and saves it in local_db_scores table. Now, the next time someone tries to view these scores, they are computed using the scores saved in local_db_scores. When an instructor tries to view scores for an assignment, 1st it will be checked if the local_scores_calculated attribute is true or false for the assignment. If it is false, compute_total_scores from OnTheFlyCalc class is called which will add the scores from the questionnaires. However, if it is true, compute_total_scores from LocalDbCalc class is called which will add the corresponding scores from local_db_scores table. Clicking this icon stores the total scores for each response map of the assignment for each round in local_db_scores table. <image> The addition of the new icon on Manage Assignments page to save the scores to database. The project can be broken down into below use cases: 1. Instructor wants to store the total scores for each response map, round for an assignment in the database. Instructor clicks on ""save scores to db"" icon and the scores are stored 2. Instructor/User wants to view the scores for an assignment before storing the local scores. Total scores are calculated ""on the fly"" by adding score given for each question by each reviewer 3. Instructor/user wants to view the scores for an assignment after storing the local scores. Scores are calculated by using the values stored in local_db_calc database. <table>. 1. Currently OnTheFlyCalc and LocalDbCalc are used to compute the total score for an assignment. More functionalities as below can be added to calculate/display the total scores for a team in an assignment or the total score given by each reviewer. 1.1. LocalDbCalc stores the total score for each response map for each round 1.1.1. These stored values in local_db_scores table can be used directly every time a student wants to view the total score they received from a particular reviewer in a particular round or when an instructor wants to see the total scores by each reviewer given to each team. 1.1.2. These stored values in local_db_scores table can also be used to calculate the total score received by each team, every time a team wants to view their total score or an instructor wants to view the total scores received by each team. 2. Adding conditions to show the ""save scores to db"" icon only when an assignment has finished, and stop showing it again once the scores are stored. While viewing the scores, only the latest scores saved in database are considered. 1.2. So, as a future work, this can be modified such that the icon is seen only when an assignment has finished and the scores are not yet stored. This will prevent the scores being stored multiple times or before an assignment has finished. 3. Adding the functionality to remove the scores stored in the database. This will especially be useful after implementing the above mentioned future work because after the above future work functionality, the icon to store the scores will not be shown and if scores are updated somehow, they can't be stored again. 1.1. In our current functionality, if the scores are updated, the latest scores can be stored again because the icon is always present. 4. Add functionality to call OnTheFlyCalc to compute the scores of an assignment whose scores are already stored (if required). 1.1. Currently, once the scores are stored in database for an assignment, every time LocalDbCalc will be used to view the scores of that assignment.",Good work … explains functionality well.  Could use a screenshot or two.
E1764,"Expertiza is an educational web application for students to submit the articles, code, websites and peer-review learning objects. It is an open source project based on Ruby on Rails and developed by students for many years and keep refactoring and fixing bugs upon peer review. This project is to refactor grades controller which calculates the grades of assignment participants' from peer review and views of listing the scores. After refactor the previous work, it is the part of TLD that use RSpec to examine the correctness of functions and do the integration test. 1. grades_controller.rb 2. grades_controller_spec.rb. The main purpose of grades controller is to allow students and instructors to see grades and reviews through Expertiza, providing functions such as update scores, view teams, make chart and calculate penalties. Some functions were written in long and redundant way which makes it hard to understand and behaves inefficient. We extract some part of functions to become a helper function to make each function more clear and easier to understand. Besides, we slightly change some variable names by using more specific words to promote the readability. Grades_controller_spec includes 10 Rspec tests for each function inside the grades_controller.rb. Some of the tests are integration tests and the rest are unit tests. 1. Refactor make_chart method 2. Refactor calculate_penatly_attributes method 3. Refactor assign_all_penaties method 4. L136-138, L146-150: Refactor instructor_review method 5. L109: Use find_by instead of dynamic method 6. L178: Adjust the format of sprintf 7. Finish pending test in grades_controller_spec.rb. 1. Refactor make_chart method This is a function to make a bar chart based on the grades of participant. The original implementation contains lots of duplicated codes, so we extract the duplicated part out as a helper function called drop_decrement_from_scores. We make the type of participant scores as parameters such as metareview, feedback and teammate. <image> A helper function for make_chart method. <image> 1. Refactor calculate_penatly_attributes method We refactor this method by using zip function to prevent from running the loop three times when passing the different parameters and promote the readability. <image> 1. Refactor assign_all_penaties method We refactor this method by restructuring the code to make it clear and easier to understand. <image> 1. Refactor instructor_review method We refactor this method by replacing 'where.first' to 'find_or_create_' and then create. <image> 1. Use find_by instead of dynamic method When assign questionnaires, we extract the 'find type' statement out from the for each loop, in this case, we can reduce the execution iteration. Instead of using 'find_by', we use 'where' because 'find_by' will return the first element that match the condition; however, 'where' will return all the elements match the condition. <image> 1. Refactor format over sprintf Instead of using sprintf function, we use the format printing here which is more flexible and concise. <image>. For the integration tests, we tested four actions in grades_controller and five scenarios in total: 1. view 1. when the current assignment varies rubric by round, it retrieves questions, calculates scores and renders grades#view page 1. when the current assignment doesn’t vary rubric by round, it calculates scores and renders grades#view page 2. view_my_scores 1. when view_my_scores page is not allow to access, it shows a flash error message and redirects to root path (/) 3. view_team 1. it renders grades#view_team page 4. edit 1. it renders grades#edit page The output coverage is 55.61% now, and the stats are here ( <link> ). There are still some pending tests to be finished: 1. view_my_scores 1. when view_my_scores page is allowed to access 2. instructor_review 1. when review does not exist 1. when review exists 3. update 1. when total is not equal to participant's grade, it updates grades and redirects to grades#edit page 1. when total is equal to participant's grade it redirects to grades#edit page 4. save_grade_and_comment_for_submission 1. it saves grade and comment for submission and redirects to assignments#list_submissions page. 1. Pass all tests created in grades_controller_spec.rb 2. Although some tests are passed, there still a room for improving the test coverage.","The descriptions of the refactorings are adequate, and the tests are motivated well.  The Solutions Implemented and Delivered section should have contained some subheadings, instead of just bullet points."
E2080,"Various metrics will be tracked including 1. The time spent on the primary review page 2. The time spent on secondary/external links and downloadables. 1. <link> were able to implement the tracking mechanism for recording the time spent on looking at submissions that were of the type of links and downloadable files. The time spent on links were tracked using window popups when they are opened and closed. The downloadable files of the type text and images were displayed on a new HTML page to track the time spent on viewing that. Each time a submission link or downloadable file is clicked by the reviewer, a new record is created in the database. Other than these issues, the team provided a good <link> of the feature. 3. <link> is the most recent implementation, built from earlier designs, features a solid UI and ample tracking of review time across the board. The issue of extensive database operations still remains as future work in their <link> . 1. From the suggestions of the previous team, <link> , we plan to improve their implementation by reducing the frequency of database queries and insertions. In <link> current implementation every time a start time is logged for expertiza/link/file, a new entry is created in the database. The solution is to save all entries locally on the users system and once the user presses Submit, save the entry in the database. 3. The previous team also mentioned other issues involving the ""Save review after 60 seconds"" checkbox feature, that may be looked into in the case of extra time. PStore is a file based persistent storage method that is based on a hash. To create a PStore file you need the following declaration: <code> If the file ""filename.pstore"" does not exist it will be created with the given name, otherwise the existing data will be read. See <link> for more information on PStore. To preserve the logic implemented by team E1989, our Local Storage class is designed to have the same methods you would use to access an entry in a database, but instead interfaces with a PStore file. For instance, in team E1989's method ""record_start_time"" the line: <code> is intended to check if a link is already opened and timed by looking up the link via the ""where"" method. This line was refactored to: <code> The ""where"" method is instead an instance method of the LocalStorage class that looks up the link in the same way, but in the PStore file rather than the database. To solve the issue of too many viewing event entries in the database, two separate kinds of ""save"" methods were written. ""save"" saves a viewing event entry into the PStore file, while ""hard_save"" saves entries stored in the PStore file, in the database. This allows us to save entries into the PStore file and only officially save those entries in the database once the review is complete. Our method ""remove"" in the LocalStorage class removes entries from the PStore file. This method is called in the ""submission_viewing_events"" controller after saving an entry into the database. The following is the flowchart presented by E1989 that does a good job outlining the logic for tracking the time students spend reviewing: <image> The following flowchart outlines how PStore and its methods work together to emulate methods used to access a database <image>. This class serves as a sort of ""instance"" or a standard for representing the tracking of the time for a single link which was visited. <code>. This class serves as the medium for transaction of data between the local @registry instance variable, pstore and the database It manages the pstore ""hash"" by restricting access and saving instances of LocalSubmittedContent when required. It has a lookup feature with .where() where the user can search for LocalSubmittedContent given specified parameters Lastly it provides the functionality to save the entries from pstore into the database <code>. There are already tests written to test the total time tracking feature. Our major focus for this project is to change the current implementation to use significantly less number of database operations by storing the intermediate timings in the local storage of the browser and write only the final time spent on viewing the submissions. 2. Click on a particular assignment and review the submission by click on links and spending some time viewing them. 5. To look at the time spent on the reviews, log in as the instructor. 8. You should be able to see the total time spent on the submissions by the student. RSpec tests were written to test the following LocalSubmittedContent methods: 1. initialize 2. to_h 3. ==. RSpec tests were written to test the following LocalStorage methods: 1. initialize 2. save <code> 1. sync <code> 1. where <code> 1. read <code> 1. hard_save <code> 1. hard_save_all 2. remove <code> 1. remove_all. 1. <link> 2. <link> 3. <link>.","The description is quite readable, and the diagrams are good.  The document considers only changes made by this team, not the code that was written for the previous project and is still present in their commit.  This would require the reader to consult the previous document in order to understand the changes made by this project.  Description of the classes changed is good, but it would have been better if prose had been written about the individual methods."
E1925,"Expertiza provides teammate reviews to gauge how much each team member contributed, this information could be generated from data from external tools like Github (for example, number of commits, number of lines of code modified, number of lines added, number of lines deleted.) Currently, Expertiza provides Teammate Reviews under View Scores functionality for each assignment. 1. Teammate Reviews functionality in the View Scores page gauges teammate views on how much other team members contributed to the project. We need to augment this data with data from external tools like GitHub in order to validate that feedback. New metrics will be appended under each student data under the same functionality. 2. Github Metrics under View Submissions page should include a bar chart that shows the number of commits by the team throughout the assignment timeline. Overall data for the team, like the number of committers and number of commits may also help instructors to predict which projects are likely to be merged. The link for our project PR is <link>. Extract Github metadata of the submitted repos and pull requests. For each participant, record should include at least: 1.1. Committer id 1.2. Total number of commits 1.3. Number of files changed 1.4. Lines of code changed 1.5. Lines of code added 1.6. Lines of code removed 1.7. Lines of code added that survived until final submission [if available from Github] 2. The code should sync the data with Github whenever someone (student or instructor) looks at a view that shows Github data. 3. The data for teams should be shown in the instructor’s View Scores window, in a new tab, probably between Reviews and Author Feedback. Please discuss this with the project mentor(s). 4. Create a bar chart for the # of lines changed for each assignment team on “view_submissions” page. This task has been partially implemented by another group for project E1858. Github Metrics Integration in 2018 Fall semester. Detailed document about project E1858 on framework design and implementation can be found in <link> and the PR for Project E1858 is shown in <link> . However, their work has been rejected with the feedback ""They have integrated the github metrics into expertiza to show the number of commits, pull requests status, etc against every project. They have also integrated it into the metrics. The goal of our current project is to resolve issues existing in their previous work, refactor codes they created and modify their code following ""DRY"" principles. The ultimate goal is to have the Github Metric Integration work in Expertiza. Actors: 1. Instructor: This actor is responsible for viewing GitHub metrics of teams and team members of an assignment. Pre-Conditions: 1. The Team should have submitted the assignment with a PR link or GitHub repository. 1. The instructor should browse teams for an assignment. Github Metrics Features can be accessed from manage content UI <image> Then click the 'view submissions' <image> Then we can see 'Github Metrics button' in each project submission <image> Below is the bar chart of commit numbers. <image>. After understanding the project E1851, We found some issues in this project and give our solutions below. Solution: We will refactor their code and fix code smells with the help of code climate platform. For example, some code like the format below can be rewritten in the shorter line. <code> Some code like the format below can be rewritten and shorten by putting } in one line. <code> Also, there are many useless spaces make the code look less elegant. To make sure the refactor code can work correctly, we need to run the original rspec test code and add some new test. Besides, we are plaining to test from UI to make sure all the features work. The test results are shown below. 1. Run and pass existing RSpec Tests after refactoring 2. Develop New RSpec Tests for the new features 3. UI testing on the deployed project. You can run the following code rspec spec/controllers/github_metrics_controller_spec.rb to test the result. Our rspec test coverage is 100. The test video is <link>. For this project, we add an API from the GitHub, all we need to do is to test whether the API can work appropriately after changing codes to another controller and moving javascript codes. Management -> Assignment -> Github Metrics You can see the test result in <link>. We added and changed the new controller github_metrics controller and some ralated files. 1. <link> 2. <link> 3. <link> 4. <link> The GitHub metrics part is separated into the new files. Previous work includes JavaScript code. After carefully testing and examination, we found these JavaScript code were another version of the implementation of our task. So we remove those redundant codes to make our code clean. 1. <link>. 1. <link>. <link> <link> <link> <link> <link> <link>.","For design doc: You do a good job of explaining the problems with the previous implementation.  And you show code that has been changed.  I think there should be more comments.  A Github diff view would be clearer than the monochrome wiki listing.  The main issue that I see, though, is that when you show code that has been changed, you don't say what file it is in.  True, the reader could search in Github.  But (s)he shouldn't have to."
E1970,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.1.1. <link> 1.1.1.1.2. <link> 1.1.1.2. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.1.1. <link> 1.1.1.1.2. <link> 1.1.1.2. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.1.1.1. <link> 1.1.1.1.2. <link> 1.1.1.2. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. Students can also peer review other students' submissions. The following tasks were accomplished in this project: 1. Fix <link> 1.1. The ‘view submissions’ page of an assignment does not have an appropriate header. 1.2. The header should be added to reflect text such as “Submissions for <assignment name> 2. Fix <link> 1.1. The New review page contains a spurious ""p"" before each criterion is shown 1.2. The status p (paragraph) should be removed 3. Fix <link> 1.1. When an assignment is being created with a rubric that uses the “Use dropdown instead” option, it falsely indicates the save was successful. 1.2. The save is not persisted when we review the assignment rubric. The option “Use dropdown” is not selected. 1.3. The option should be saved in database and reflected on the review page. The ‘view submissions’ page of an assignment does not have an appropriate header. The header should be added to reflect text such as “Submissions for <assignment name>. <image>. 1. The view submission page currently has no title representing which homework submission the viewer is viewing, a title needs to be added into where the red circle is. <image> 1. View change Since this page already uses `@assignment` in a lot of places, and we found it in the corresponding controller, so directly using it wouldn't pose additional problems as the query of the assignment is already done in the back-end. <code>. <image>. (This should be 1352, there must be a typo in the project google doc) When an assignment is being created with a rubric that uses the “Use dropdown instead” option, it is indicated the save was successful. However, the save is not persisted when we review the assignment rubric. The option “Use dropdown” is not selected. <image>. <image> 1. DB change There's a new attribute `use_dropdown_instead` in `assignment_questionnaires` table now, it's default value is false <code> 1. Controller change The attribute `use_dropdown_instead` is being passed by all functions relating to rubric editing now <code> 1. View change The view reflects values stored in use_dropdown_instead now <code>. Following are a few testcases with respectto our code changes that can be tried from UI: <link> 1. To see homework title related to submission, go to ""Manage > Assignment > View submissions"" after logging in with a instructor account 2. To review text box for reviews: 1. 1.1. Login as a instructor 1.2. Create an assignment set submission time to be an hour later 1.3. Log in as student A 1.4. Do assignment, then submit 1.5. Log in as student B 1.6. Do assignment, then submit 1.7. Login as a instructor 1.8. Set submission deadline to be an hour earlier 1.9. Log in as student A 1.10. Go to view other's work, and ask for a new review 1.11. Begin review, user should find the textbox without the P 3. To see the checkboxes reviewing what's saved: 1. 1.1. Login as a instructor 1.2. Create an assignment, set checkboxes in rubric items 1.3. The landing page (edit assignment) should review the checkboxes checked in previous step. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. Clean Code: A handbook of agile software craftsmanship.","Problem statements are clear.
In the Solutions, when you present a view, it would be very helpful to identify what in the view has changed (using Github diff view).  It would be a lot clearer than pasting in ""before"" and ""after"" code sequences.
In Issue #1352, I don't understand why the dropdown menu would need to be refactored in the future.  I can't understand the two different ways that dropdown is being used.
When you present a test, you should explain in prose what it tests and how it works.  It's also not clear why the first test tries to add a member to an assignment team.
In the ""Testing from UI"", it's not clear what you intend for a user to do when it says ""Do assignment, then submit.""  This should be explained in more detail."
E1459,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link> 1.1.1.1. <link> 1.1.9. <link>. <link> is a web based application used by students and professors to create, select, submit and review assignments. Selection of assignments may be individual assignments or group assignments. Additionally the professor can review the assignments submitted by the students. Assignments are what Expertiza calls learning objects. The Expertiza project is open source with many programmers contributing to the code base. The source code is available at <link> . The role of the signup_controller is to process requests from the user to sign up for an assignment. The purpose of the controller is to process actions from the user; however, in many cases the controller is doing functions that should be provided by the model. Any calculations should appear in the model rather than the controller. The code should use RESTful names such as new, create, edit, and delete. In many cases it does not. The sign_up_sheet_controller handles actions pertaining to creating assignments. On the first round of refinement the code was simply cleaned up by untabifying the code and using the Rails and Expertiza coding standard of using two spaces for indentation. This makes the code more readable to those who view the source code so that blocks don’t look like run together. In the following examples, the original programmers did not employ the <link> (DRY) principle to their code. In the app/controllers/sign_up_sheet_controller.rb the index and add_signup_topics actions were changed to index_signup and index actions respectively. These two actions did similar functions and were made clearer by merging them. <image> The design of the SignUpSheetController class controls two different behaviors of the SignUpTopics model: creation of topics for an assignment by the instructor, and allowing students to sign up for a topic. To clearly distinguish between these two different behaviors, all actions performed by the instructor to manage a topic (index/create/update/destroy) were renamed to follow the standard Rails naming convention. All actions performed by the student (index/create/destroy) to sign up for a topic have the suffix _signup. The add_signup_topics method displayed a list of topics for the teacher to modify the topics. The index method although following Rails convention in naming the function name did describe its purpose with respect to the scope of the controller in which it lives. The index method originally listed the topics for the student to sign up from. This however is the sign up sheet controller and therefore the index method would have been expected to list topics and perform actions on them at a higher level. Therefore the add_signup_topics method was renamed to index and the original index method was renamed to index_signup. The latter was renamed using the index convention but with the _signup suffix. The original index method displayed the list of topics that the user could sign up for. In this case the student is interested in acting only one one topic therefore the signup suffix reflects intent. In the Model View Controller (MVC) paradigm code pertaining to the business logic of an application belongs in the model layer of the program. For instance, the confirm_topic method is used in the sign_up_sheet_controller.rb file to assign a topic to a user after performing several model layer checks to make sure that the user can, in fact, be assigned a topic. This code is better moved to the model layer as its performing business logic and not simple validation or control statements. The decision was made to move this method into the SignUpTopic model. <image>. A <link> file has been written explaining how to access features updated in this project. Administrator account: 1. admin - Password: admin Student accounts: 1. student1 2. student2 3. student3 4. student4 5. student5 6. student6 7. student7 8. student8 9. student9 To log in as a student first log in as an admin and then use the Manage=>Impersonate User functionality to switch the student account of your choice. There are two assignments pre-creted: 1. due_date_assignment1 : Due date is same for all topics. These two assignments are provided for testing convenience - you are free to add topics and have students sign up/ drop topics. However, PLEASE DO NOT DELETE THESE TWO ASSIGNMENTS . Deadlines for these two assignments were manually populated in the database. You are free to create a new assignment for this purpose. <link> <link> May be invalid after a few weeks <link>.",Insufficient explanation of changes.
E1807,"Expertiza is an open source project based on Ruby on Rails framework. Expertiza allows the instructor to create new courses, assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can use the expertiza platform to form teams to work on various assignments/projects. Students can sign up for various OSS topics to work on, peer review other students submission. Students can submit their assignment in the form of URLs, upload files. 1. For Instructor, username: instructor6, password: password 2. For Student, username: student7490, password: password 3. For Student, username: student7495, password: password. Sometimes when a reviewer fills out a review rubric, one or more fields can be left empty by the reviewer. While calculating the peer-reviewed score, the program is counting the empty fields as zero. However, this is not correct. The empty fields should not be counted at all, as this may affect some other metrics (like average score) of the reviewee. <image>. While calculating the peer-reviewed score, the program checks whether the score is empty or not. If a score is empty, it should not be counted while calculating average score. Only not null review scores are to be counted while dividing by the total number of reviews, for the average score calculation. <image>. GitHub link 1. <link> Pull Request link 1. <link>. /app/models/vm_question_response_row.rb. The method ‘average_score_for_row’ is used to calculate the average peer-reviewed score. We added a variable ‘no_of_columns’ to count the number of review scores that are not null. We changed the way the average score is calculated. Previously, ‘row_average_score’ was calculated by dividing by ‘@score_row.length’, where the length will include both null and not null values. Now we divide ‘row_average_score’ by ‘no_of_columns’, which does not include null scores. <image>. /spec/models/vm_question_response_row_spec.rb. We added a RSpec file for the class ‘VmQuestionResponseRow’ to test the method ‘average_score_for_row’. We tested the following scenarios for calculating average score: 1. All scores are not nil 1.1. This is the scenario where no fields are left empty. Average score was calculated correctly in this scenario before the issue fix. We test that the score is calculated correctly after the issue fix too. 1.2. All not nil scores that are all zero are also tested to ensure that the output is zero. 2. All scores are nil 1.1. This test ensures that when all fields are empty or are nil, average score is also nil instead of being zero. 3. Mixture of nil and not nil scores 1.1. This test ensures that when some fields are left empty, they are not taken into consideration while calculating average score. To compute average score, the total score will be divided only by the total number of fields that are not nil. 1.2. We tested this scenario by including or excluding zeroes in the scores and varying number of nil scores to verify correctness in average score. <image> <image> <image>. 1. <link>. Expertiza 1. <link> Expertiza Github 1. <link> Expertiza Documentation 1. <link> RSpec Documentation 1. <link>.","Good writeup, and good motivation for the changes that you made.  Would have been helpful to explain the magic hex constants in the tests."
E1988,"When reviews are marked 'public', instructors will have the option of adding them as a 'sample review' to any assignment. When reviews are marked 'private' they will not be shown to other students as a sample. 2. Add a feature for the Instructor to select a subset of 'public' reviews and make those reviews visible as sample reviews of any of their assignments in the course. 3. Add a feature for instructors to select a subset of 'sample' reviews and set those reviews as sample reviews for a particular assignment. 4. Create a view where the student can see a list of sample reviews of the assignment and have a detailed view of each. Thus the students will be able to see good reviews that one student has submitted for another student's work. 1) Creating a checkbox : When a student submits a review, they should be able to choose if they want to make their review public or private. Thus we added a checkbox to the review page. Checking this checkbox will make the review public. Unchecking it will make the review private. 2) Allow students to make a review private : Students should be able to change the visibility of their review even after they have submitted it. If a review has been made private after an instructor has selected it as a sample review, it is still not displayed to students as an example review. 3) Allow instructors to select (remove) sample reviews : If a review has been made public by the reviewer, the instructor is able to select that review to be made a sample review. If the review is already a sample review, the instructor is able to remove from the set of example reviews. If the review was private, the instructor is shown a notice that 'This review is private.' and they are not allowed to select it as a sample review. This selection can be done when the instructor is viewing the review. 4) Set some of selected reviews as sample for an assignment : Sample reviews can be identified by the assignment, reviewer (a participant) and the reviewee (a team). When editing an assignment, the instructor is able to select past assignments, select a reviewer and select the reviewee. The way in which the instructor selects the assignment is to select the from a dropdown. When the assignment is selected, the reviewer dropdown will then be populated with the names of the reviewers whose reviews have been made public and have been selected by the instructor. This will identify the selected review. The instructor will be able to set it as sample review for the current assignment. This means that the instructor can even set a review from any of their earlier assignments as a sample. 5) Allow students to see sample reviews : When a student wants to review other team's work, they will be shown a list of sample reviews that the instructor has selected for them. In the list each review is a link to the full review. To allow students to mark their reviews as public. 1. The instructors will select sample reviews from a set of public reviews. 1. Students will be able to view sample reviews. 1. The instructor will be able to view the reviews which have been marked public by student. 1) They added a facility for instructors to select individual reviews and set them as a sample. The assignment_id is the id of the assignment for which the sample is to be shown. The response_map_id is the id of the sample review. 5. Displays a list of reviews submitted by students. 6. Click on any review in ""team reviewed"" column for a particular student. 7. Displays the summary of reviews submitted by that student, with a ""Make as sample"" button on the right of every review. 8. Click on ""Make as sample"" for the intended reviews, which opens a popup that displays a list of all assignments that are a part of the instructor's courses. 9. From this list select all assignments for which the review has to be shown as a sample. 11. Navigate to view reviews of that particular assignment and click on ""Sample Reviews"". 12. A new page is opened that lists out all the sample reviews of the assignment. 5. Click on the review tab. 6. Select an assignment from the dropdown 7. Select a reviewer from the second dropdown. 9. Click 'Add' button to add the selected review to be shown as a sample for this assignment. 10. Add as many sample reviews as you want in the same way. 2. Click on Assignments 3. List of assignments is displayed. 4. Click on any assignment for which the review has to be submitted. 7. Below the heading ""Reviews for ..."", click on the ""Show sample reviews"" link. 8. This opens a page where the student can view all sample reviews for that assignment. 2. Click on Assignments 3. List of assignments is displayed. 4. Click on any assignment for which the review has to be submitted. 5. Assignment task page is displayed. 8. Select a team for review and fill in the review.","The description of the problem is quite readable.  The implementation is well described in prose, but it would help to see some of the code snippets that were introduced.  This is the reverse of many design docs, which show the code, but don't adequately explain what was done. "
E1529,"<link> is a web application developed by Ruby on Rails framework. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.3. <link> 1.4. <link> 1.1.1. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.2. <link> 1.5. <link> 1.1.1. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.6. <link> 1.1.1. <link> 1.1.2. <link> 1.7. <link>. E1451. ​Create Mailers for All Email Messages <link> <link> <link> (Merged in <link> ) Extending this project, the new system should be capable of 1. If one task is added to the delayed job queue, the asychronous Email should be updated or deleted automatically. 3. Keep log of the scheduled tasks when they are scheduled and done, record events in the same log as project <link> . Using this gem, we can keep log of the scheduled tasks. All our code follows the <link> on Ruby style. Firstly, when we set a due time to test the mail features, we found the display of time is incorrect. In the “Assignment Edit”->“Due dates”, when we modify the “Date & time” of the deadline, the displayed time will be 4 hours ahead of the time we saved. <image> Set due time <image> After we click the save button, we can see that all the time are 4 hours ahead of the set time <image> The deadline time is stored correct in the database After several tries, we found that every time when we click ""save"", the saved time is 4 hours earlier then the last saved time. However, the time in the database is alway correct as the time we save. So the displayed time(local time, which is EDT) and time in database is different. In the previous version, when current time is compared with the time stored in database, they may apply to different time zones so that the result of comparison may be wrong. <image> Delay a time After click ""save"", the run time showed database is about 8:00 am. Since 20-16=4, the correct run time is 4:00 am. due_at is the system time for Rails (UTC), while curr_time is the local time which is EDT. The two time zones have four-hour time difference. 2. In the previous version, when the instructor postpone the review deadline and then postpone the submit deadline, the submit deadline’s modification will replace the the review deadline’s modification in database. 4. After our analysis, we found the due time object is identified with assignment_id, instead of deadline type id. We convert current time to the same time zone as the deadline stored in database. In each Assignment, each deadline type (E.g review, submit, metareview) should has its own Email reminder time in the database. New postponed deadline of one type can only replace the same deadline type in the same assignment id category. All the scheduled tasks are in the delayed_jobs table in database, so the system will read from that table to show all the tasks' information. <code> After adding to the delayed_jobs, the database will store each task's assignment's id, deadline type, due date, task run time etc. <image> add a button to display all scheduled tasks <image> The UI to show all the scheduled tasks. <image> four scheduled tasks are added in log. In our system, we would have four scheduled time: submission, review, metareview and team_formation. When due time comes, the system takes corresponding actions. These scheduled actions are called scheduled tasks. <image> Support more scheduled tasks. When we set the review’s due date, add an item into “delayed job” queue at the same time( refer to ""Add UI to visualize for scheduled tasks""). <code> The following screenshots show the function realization: <image> Before outstanding review is dropped <image> After outstanding review is dropped We set a review deadline in ""Assignment""->Edit->due date"". Then no matter which due time it is set, the action runs 1 minute later. You can refer to this <link> to test all the features manually. <code>.",Very good documentation of what's wrong in the way that time is being handled (though this is not the major point of the project). One of the main points of this project is to set up tests so the instructor knows e-mail is being sent.  This is not covered in the doc.
E1922,"<link> is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. ( <link> ). <link> is a 'Domain Specific Language' (DSL) testing tool written in Ruby to test Ruby code. It is a behavior-driven development (BDD) framework which is extensively used in the production applications. The basic idea behind this concept is that of Test Driven Development (TDD) where the tests are written first and the development is based on writing just enough code that will fulfill those tests followed by refactoring. It contains its own mocking framework that is fully integrated into the framework based upon JMock. The simplicity in the RSpec syntax makes it one of the popular testing tools for Ruby applications. The RSpec tool can be used by installing the rspec gem which consists of 3 other gems namely rspec-core, rspec-expectation and rspec-mock. ( <link> ). There are few tests for assessment360_controller.rb. We had to test the following functions: 1. action_allowed 2. all_students_all_reviews 3. course_student_grade_summary 4. populate_hash_for_all_students_all_reviews(assignment,course_participant,reviews,hash_per_stu,overall_review_grade_hash,overall_review_count_hash, review_info_per_stu) 5. find_peer_review_score(user_id, assignment_id) 6. format_topic(topic) 7. format_score(score). 1. Write RSpec integration tests to make the statement coverage above 90%. 2. Cover as many edge cases as you can. 3. Achieve as high branch coverage as you can. The code we created can be found below. We have also linked the video of our tests running with coverage to showcase the work we have done. 1. <link> 2. <link> 3. <link> With the goal of getting at least 90% coverage, our tests got about 97.94%. The way we split up the work by having Jasmine take care of the function: all_students_all reviews while Louis took care of course_student_grade_summary. This helped with potential merge conflicts since both these functions are the biggest of the file and working on them would allow both to make progress at the same time. The following files were the ones either edited or used as aid. 1. <link> <code> 1. <link> <code> 1. <link> <code>. In order to run the integration test, run the following command via terminal: <code>. Below shows the outline of what our test look like: assessment360controller <code> <code>.","The wiki page is very short and does not describe why you wrote the tests you wrote, or how those tests operate.  It just gives pointers to the code."
E1800,"Primarily, the goal of this project was to add past-due assignments to the student task list. The full list of tasks (the original task list with modifications from instructor feedback) is: 1. Issue #80: Add past-due assignments to task list (on Student Task page). 2. Highlight with specific colors current and next due dates (on Student Task page). 3. Check for correction in due dates of assignments 4. On the Student Task page, separate the list of 'teamed with' students from the current tasks box. 5. Show required action on: every student has to review others work and give feedback. Some Additional tasks accomplished by our team are: 1. Added pagination to past-due assignments on task list 2. Made various UI enhancements to the student_tasks page, specifically regarding the layout of elements. Currently, the student task list consists of one list of all assignments that are and have been assigned to the student regardless of their due date. Now a separate table exists for assignments that are past due. This table is sorted to show the most recent past due assignments at the top of the table. The table that used to be all student tasks is now assignments that are currently due. This table is sorted by due date to show assignments that are due the soonest at the top of the table. In the student_task_controller.rb, a separate instance variable was created to contain only student tasks that are past due and sorted by date. The existing instance variable was recycled to contain all of the student tasks that are still currently due. In the list.html.erb file a new table was created to hold all of the past assignments. Both the current assignments and past assignments tables are also individually paginated if there are more than 10 of either. <image>. Currently, all of the tasks in the table have a white background regardless of when the task is due. To make it more apparent when due dates are approaching, each row will now highlight green, yellow, orange, or red depending on how many days out the assignment is due. Based on the result the function will return a string containing a color that will be the background of an individual row in the current assignments table. <image>. Presently, the required actions list does not show entries for review tasks. That is, the list only displays tasks that have yet to be started. This code retrieved all active student tasks, and adds tasks which both are in the review phase and for which the student has yet to submit a review to the required task list. The current assignments will show all assignments that are not completed, and if the assignment is in the review phase, it will display a small warning icon indicating action needs to be taken. <image>. As mentioned in the “Adding past-due assignments to task page” task, the primary assignment list on the student_task page has been updated. In our new version, the list separates tasks that have been completed from ongoing tasks. This both improves the page aesthetically as well as draws attention to ongoing tasks. Previously, these were often buried underneath many past tasks which were already completed. Another task completed which enhances the usability of the student_task page is adding pagination to current and past assignments. Specifically, If there are more than 10 past or current assignments due, each table will individually paginate. Meaning you could be on page 2 of current assignments but also page 4 of past assignments. This makes the lists easier to read and parse for users with many tasks. <code>. For example, we could not conduct testing from an instructor's view and manage assignments and due dates, which was an important part of our test plan. Likewise, if a stage is due in a day, the row should be red. . 5. Assign to a student/class <image> Make sure that the student you are adding is a student of the instructor you are logged in as. i.e student563 is a student of instructor6. <image> Also make sure to change the due dates <image> 6. Check to see if the coloration works as expected (change the due date to test each case). Rspec tests were written for the list method in the student_task_controller.rb file. The testing consists of creating assignments with different attributes (due date in the future, due date in the past, and available or not) in order to test the functionality of the list method. Depending on what assignment gets tied to the student task, different instance variables will be populated with student tasks or be empty. The four tests that were added are very similar in nature: describe '#list' do <code> <code> <code> <code> These tests verify that the appropriate instance variables a being assigned to the correct values.These test were created to test the refactor that we performed on the list method of the student_task_controller. These lines were added to verify that the ""Current Assignments"" table and the ""Past Assignments"" table have content.","A very readable description of what has been done.  I'm not sure I agree with some of the design decisions, e.g., hardwiring the pagination scheme, making the backgrounds as intense as they are.  But the design decisions are clear from the documentation, and that is the goal of the writeup.  I thought the four RSpec tests should have been described individually.  All in all, an excellent job."
E1855,"The way Expertiza is set up right now is that only peers can review your work. However, there are cases when the course staff (Instructor/ TAs) would want to submit reviews as well. This project aims to implement this feature by allowing course staff to review the project on the same metrics as other students who review the project. The current system does not allow instructors to submit reviews of student work. We will work upon the feature which will let them review using the same review form that students use to do reviews. This is how some of the pages we are concerned with, currently look. <image>. <image>. Following changes will be made to let staff perform reviews as well: Step 1: Add a way for the instructors to perform a review. We have implemented links to Begin review , Edit review , View review and Submit review in the assignment submissions view. When the instructor/TA reviews a work for the first time, he/she is added as a participant and a review response mapping is created. Files edited: 1. View: app/views/assignments/list_submissions.html.erb - To add links in the instructor view 2. Controller: app/controllers/review_mapping_controller.rb - Method: add_instructor_as_reviewer In the second case, we can see a 'Begin review' link. This is the initial state when instructor review has not been added to the submission. Once the instructor adds a review and submits it, we can see the 'Update review' link. If the deadline has passed, Update Review will change to View Review. In case he just saves the review, an 'Edit review' link will appear. If the review deadline of one round is passed, the 'Edit review' link becomes 'Update review' link. This follows in line with what the student sees while performing a review. Similarly, just like students instructor would not able to edit the review once submitted. Instructor can update it till the final submission deadline passes. <image> <image> Step 2: Add the instructor review in Your Scores table in case he has reviewed your work. Provide an icon to highlight the special nature of an instructors review. Files edited: 1. Assets: app/assets/stylesheets/grades.scss - Icon to make an instructor's review distinct from other reviews 2. View: app/views/grades/view_team.html.erb - To modify the ""Your scores"" page to include an icon next to the peer review score indicating that the instructor's score is not included in the final peer review score. 3. Models: 1.1. app/models/answer.rb - Method: compute_scores | Modification in logic to ensure instructor review scores are not counted in the overall score of the student. 1.2. app/models/vm_question_response_score_cell.rb - Included a new variable called 'is_instructor_review' to identify an instructor review 1.3. app/models/vm_question_response_row.rb - Change in average_score_for_row method to not include an instructor review score 1.4. app/models/vm_question_response.rb - Modified the add_answer method to include the is_instructor_review to each row_score object A student should be able to make out if an instructor has reviewed his/his team's work. In case the instructor performs a review on the team's work, there will be an icon next to the instructor's review along with explicitly stating that it is an 'Instructor review'. The average peer review score for the team has been modified to exclude the instructor's scores. Same has been taken into account for the average score calculated for each row. <image> Like shown in the above picture we can see a info button on which if we hover the text is shown. Possible icons : <code>. We added a test for a method add_instructor_as_review . 1.Created a stub and mock to find the assignment team. <code> 2.Created a stub and mock to map the review with their response in ReviewResponseMap. <code> 3.Created a stub and mock to add current user as a participant in the assignment. <code> We use the above-mentioned stubs and mocks to test the following scenarios: <code> Using a similar approach we tested select_reviewer and select_metareviewer functions. After running the above test, we found out that all the test cases passed resulting in 71% coverage of review_mapping_controller.rb. Expertiza 1. <link> Pull Request 1. <link> Expertiza Github 1. <link> Expertiza Documentation 1. <link>.","Generally a good job of documenting the work.  Readable description.  I question whether describing the modifications in terms of files modified is the best organization.  The test plan is well defined, but could be more readable in a variable-width font."
E1771,"Expertiza is an open source webapp built on Ruby on Rails stack. It provides a platform to students with various features like peer-reviewing projects, submitting work, form teams, viewing grades etc. The project is being built and maintained by students and faculty at NCSU. team.rb is a fairly complex file. It contains a lot of methods that are long and hard to understand. These methods need to be broken down into simpler and more specific methods that are easier to read/understand. Also, the few instances of code duplication that exist should be removed. <code> Elaborating the edits made: Previous code: <code> This method has been edited and divided into following methods: Renamed the methods has_user to user? , get_node_type → node_type and get_author_names → author_names and also updated the function calls so that they call the correct (newly renamed) methods. <code> was refactored to <code>. <code> <code> <code> were changed to <code> <code> <code>. <code> <code> <code> were updated to <code> <code> <code>. We have completed all the pending tests in the file team_spec.rb and all the test cases are passing. This can be checked in the pull request which is linked below. Github Link to Pull Request: <link>.","The writeup says what was done, but not how or why it was done that way.  One would not learn much more from reading the documentation than from perusing the code."
E1606,"In addition, it lets an instructor create new assignments, questionnaire for reviews and so on. Questionnaire is one of the most important components of peer review. It lets the instructor create a set of questions(rubric) that needs to answered by students in order to complete their review. It also lets the instructor create a question advice that aids the reviewing process. We have been given the task of creating functional tests for the questionnaire creation function as currently, there are none. In order to complete the task we will be using Capybara to write functional tests to 1. Create new questionnaire. 2. Create/Edit/Delete different types of questions. 3. Create/Edit question advice for criterion and scale questions 4. Create multiple tests to check valid and invalid cases. Functional tests do not test a function or a method within a class but rather the functionality of the entire system. Understanding the different workflows helped us write comprehensive test cases for various functionalities within the questionnaire system. 3. Create ‘New Public review’ 4. Click on ‘Create‘ 5. Change the min, max or public values and ‘update’. 6. Click on ‘Add’ after choosing type of question. 7. Type in values for the question. 8. Click ‘Save review questionnaire’ There are 10 types of questions. 1. Click ‘View/Edit Advice’ 2. Edit the advice. (Only criterion and scale types have advice) 3. Click ‘Save and redisplay advice’ 4. Click ‘Back to questionnaire’ link. The test is to check whether a questionnaire can be created and the functionalities of the function are working. <code> The above code is written in Capybara and it creates a public questionnaire of type review. There are three text fields and one dropdown box which have to be filled to create the questionnaire. The values are populated using the fill_in function for the text fields and the select function for the dropdown. Finally, the ‘create’ button is clicked. For the test to pass successfully, there has to be a new questionnaire named ‘Review 1’ which exists in the test database. Hence, we use the expect function to check for the presence of the questionnaire. If there is no such questionnaire, then the test has failed and the functionality of the function has not been implemented correctly. The question type can be chosen while creating the question from a dropdown menu. Three different actions can be performed on each question - create, edit and delete. <code> The above code snippet shows a creation workflow for the criterion type question. Once the add button is clicked, a new question is created and the link to remove the question appears along with it. Using this we can test whether, a new question has been created. Also, once the questionnaire is saved, a message appears on the Expertiza system confirming that the questions have been saved. By checking whether the message appears or not we can test whether the functionality has been implemented properly. <code> The above code snippet tests whether the question has been edited successfully or not. When a question has been edited with some content, the same content remains in the text field for the question. This can be used to test the successful editing of the question. <code> The created question can be deleted by using the link ‘Remove’ which has been specified along with it. Also, after successful deletion a message appears implying that the question can be deleted. Thus the presence or absence of this message can be used to test for the delete functionality. Only two types of questions in Expertiza have an advice associated with them - the Scale and Criterion type questions. The number of text areas in the advice page depend upon the number of Scale and Criterion type questions and each question has a number of advice text areas, one for each possible score which can be assigned for a particular question. Two types of actions are possible for the advice - create and edit. <code> The above code snippet shows the way in which the advice is created. The button ‘Edit/View Advice’ is present for each questionnaire and the resulting page has all the text areas for the scale and criterion type questions in the questionnaire. This message can be used to test for the button’s functionality. Once the advice is created with some content, the presence of a message implying that the advice is saved and the presence of the saved content can test for the create functionality. <code> The workflow for the edit functionality is similar to that of the create advice functionality. The tests can be run on the terminal using the command: <code> A seed value is used to randomize the order in which the tests are run. This is because all the tests are independent and so every test must be able to run at any time so that all the functionalities can be tested successfully. All the tests are run and depending on whether a test passes or fails, we can find out which of the functionalities are successfully implemented in the system.","Looks like a very good writeup, at the appropriate level of detail.
Code snippets would've been more readable if they'd been single-spaced."
E1653,"method of questionnaires controller to restrict unauthorized access to edit review rubrics. 1. An instructor can no longer change others' review rubrics but can only view them. 2. Only those review rubrics can be modified by an instructor which are owned by him. 3. A Teaching Assistant can modify only those review rubrics which are owned by the instructor under whom he works. 4. A CSV file containing the questions with the correct column names can now be imported into the rubric. method of the Questionnaires controller. <code> The action_allow? However, any user can view the contents of the review rubric. <code> 2. a. The code initially was not using the read method to read the file data and was unable to import a file. <code> The modified code now reads data from the file and calls the method get_questions_from_csv and passes the data to it. <code> b. Removing unwanted code and modifying the get_questions_from_csv method declared in the questionnaire controller. The method get_questions_from_csv defined in the questionnaire helper was unable to read data from the file. <code> The unwanted code from the get_questions_from_csv method is now removed and the modified code successfully reads data from the csv file and saves questions present in the from of rows in the rubric. <code>. 1. The file to be uploaded should not be an empty file. The following test case checks if the imported file is empty. <code> 2.The following test case validates an imported CSV file. The test case passes if all the questions get successfully imported. <code> 3. The following test case validates the names of all columns in the imported CSV file. The following example shows that this test case passes when there's an error in the column name of the imported file. <code> 4. The following test case validates that no error message appears on the page while exporting. <code> 5.The following test case validates if a user is able to edit an advice. <code> 6. The following test case validates that the changes made in the advice page are re-displayed. <code> 7.The following test case validates if a user is redirected to the edit advice page after clicking on the 'Edit/View advice' button <code> 8.The following test case validates if the changes made in the edit_advice page are saved to the database after the 'Save and redisplay advice' button is clicked. <code>. 1. Login to expertiza as 'instructor6' (Username: instructor6 Password:password) 2. Select 'Questionnaire' Tab under Manage Content 3. Click on any one of the Review tab (For eg: Review, Metareview, Author Feedback) 4. Click on edit button of a questionnaire which is owned by instructor6 (This can be found out from the expertiza_development database using query: select name from questionnaires where instructor_id=6;) 5. User should be redirected to a page where he can edit the questionnaire 6. Impersonate 'teaching_assistant520' (is a TA under instructor6) and repeat steps 2-5 7. User should be redirected to a page where he can edit the questionnaire 8. Repeat the above steps for a questionnaire which is not owned by the instructor 9. An error message is displayed above the 'Manage Content' title. 1. Login to expertiza as 'instructor6' (Username: instructor6 Password:password) 2. Select 'Questionnaire' Tab under Manage Content 3. Click on any one of the Review tab (For eg: Review, Metareview, Author Feedback) 4. Click on edit button of a questionnaire which is owned by instructor6 5. Click on 'Browse' button under 'Import/Export (from/to CSV format)' and select a file of CSV format which contains the questions 6. Click on 'Import from CSV' button. The questions should be saved to the local system in a file of CSV format. 1. Login to expertiza as 'instructor6' (Username: instructor6 Password:password) 2. Select 'Questionnaire' Tab under Manage Content. 3. Click on any one of the Review tab (For eg: Review, Metareview, Author Feedback) 4. Click on edit button of a questionnaire which is owned by instructor6 5. Click on edit advice button. This should redirect to a page containing the advice for that questionnaire. 1. Login to expertiza as 'instructor6' (Username: instructor6 Password:password) 2. Select 'Questionnaire' Tab under Manage Content 3. Click on any one of the Review tab (For eg: Review, Metareview, Author Feedback) 4. Click on edit button of a questionnaire which is owned by instructor6 5. Click on 'save and redisplay' button.","Good job of explaining the changes made, the automated and manual tests.  My only reservation is that some of the longer code snippets should have had more explanation of the changes that were made."
E1776,"8. A list of topics for an existing assignment. During the import process, we create an array of hashes, in which each row of the array corresponds to a row of the original import file. We will work through the User import process as an example. The general flow of the original import process is as follows: 1. The user navigates to the ""Import Users"" link. 3. The user selects a file and clicks ""Import"". Improvements: 1. Added descriptive title 2. Fixed form alignment 3. Added ""Header"" radio button 4. Changed ""Expected Columns"" to be more legible <image> Old User Import View <image> New User Import View. NOTE: Course Participant changes are identical. Improvements: 1. Added descriptive title 2. Fixed form alignment 3. Added ""Header"" radio button 4. Changed ""Expected Columns"" to be more legible <image> Old Assignment Participant Import View <image> New Assignment Participant Import View. Improvements: 1. Added descriptive title 2. Fixed form alignment 3. Added ""Header"" radio button 4. Added ""Contributor"" radio button 5. Changed ""Expected Columns"" to be more legible <image> Old Reviewer Import View <image> New Reviewer Import View. Improvements: 1. Added descriptive title 2. Fixed form alignment 3. Added ""Header"" radio button 4. Added ""Contributor and Reviewer"" radio button 5. Changed ""Expected Columns"" to be more legible <image> Old Metareviewer Import View <image> New Metareviewer Import View. Improvements: 1. Added descriptive title 2. Fixed form alignment 3. Added ""Header"" radio button 4. Added ""Optional Columns"" checkbox list 5. Fixed bug where ""Expected Columns"" would not display if an assignment had no prior topics set up 6. Changed ""Expected Columns"" to be more legible <image> Old Topic Import View <image> New Topic Import View. <image> An example of the new User Import view when the given file contains a header. <image> An example of the new User Import view when the given file does not contain a header. NOTE: The new view for Course Participant is identical. <image> An example of the new Assignment Participant Import view when the given file contains a header. <image> An example of the new Assignment Participant Import view when the given file does not contain a header. <image> An example of the new Reviewer Import view. <image> An example of the new Metareviewer Import view. <image> An example of the new Topic Import view when the given file contains a header. <image> An example of the new Topic Import view when the given file does not contain a header. 1. config/routes.rb Routes were added to accommodate the new controller action and view written for the enhanced import process. The old import method was changed to use our new import_from_hash method. 1. NEW: app/views/import_file/show.html.erb The above file was created to accommodate the new controller action made for the improved import process. To begin the User import process, first select the ""User"" link from the ""Manage"" drop-down menu. <image> Manage Users Next, scroll to the bottom of the page and click the ""Import Users"" link. <image> Import Users You will then be redirected to the User import page. To begin the Assignment Participant import process, first select the ""Assignments"" link from the ""Manage"" drop-down menu. <image> Add Assignment Participant Finally, scroll to the bottom of the page and click the ""Import assignment participants"" link. <image> You will then be redirected to the Assignment Participant import page. To begin the Course Participant import process, first select the ""Courses"" link from the ""Manage"" drop-down menu. <image> Add Course Participant Finally, scroll to the bottom of the page and click the ""Import course participants"" link. <image> Import Course Participant You will then be redirected to the Course Participant import page. To begin the Reviewer and Metareviewer import process, first select the ""Assignments"" link from the ""Manage"" drop-down menu. <image> Finally, scroll to the bottom of the page, and click either the ""Import reviewer mappings"" link or the ""Import meta reviewer mappings"" link. <image> <image> You will then be redirected to either the Reviewer import page or the Metareviewer import page. To begin the Topic import process, first select the ""Assignments"" link from the ""Manage"" drop-down menu. <image> Edit Assignment Next, select the ""Topics"" tab, scroll to the bottom of the page and click the ""Import topics"" link. <image> Import Topics If topics have not been set up yet on the given assignment, you will receive an alert that will need to be accepted before continuing. <image> Topic Alert You will then be redirected to the Topic import page.","The writeup is very detailed and clear what changes were done. The formating is also done carefully. well done!  It would be helpful to add some prose description between the screenshots showing old & new views of various features ... say, describing what had changed in the views. Also, the filenames are in a giant font size."
E1789,"In expertiza, review report page and summary page give the information for instructors to view the overall review result. Review report page can be accessed via Manager -> Assignment, then click the “View review report” button (the one which has a spyglass and two people). The summary can be accessed through Review Page by clicking “summary” button of a particular student. The appearances of the two pages are shown below: <image> <image> For now, there are several defects need to be fixed to optimize the grade procedure: 1. Metrics column is not intuitive enough. 2. The layout of “Review Report Form” in “Summary Page” is unreasonable. 3. Reviewers don’t need to re-review the submissions which are not updated, so there should be a checking mechanism. Therefore, our tasks are: 1. Visualize Metrics column. 2. Reasonably reorganize the “Review Report Form” in “Summary Page”. 3. Check updates of submissions for reviewers to help them decide if they need to review aga. Metrics column, which is in “Review Report Form”, displays statistic data of words used in particular student’s reviews. This helps graders to value how the student compares with the average student. <image>. <image> <image> We compare the 1st round and the 2nd round review with their average separately, then compare the overall (Total) with the average. <image> 1. There is no header saying what course, assignment, or student this relates to. 2. The team name and student names are listed on separate rows. 2. Checkbox questions could be displayed more compactly, better in a visually appealing manner like the review is shown to the author. It will be more reasonable if there is a header in the page. The information of the header will include course name, project name and student number as below: <image> For example, the header will show as “CSC 517 OSS PROJECT : Student 666”. The form looks as below： <image> Firstly, we lay the reviewees on the top with its student details, then we just repeat reviewees’ team name in each question. Meantime, we fix the top row when we scroll down the page, so that we could always refer the student details whenever we like. This is consistent with the way that review is shown to the author. <image> In the review report, each team that has been reviewed is color-code. Text in red indicates that the review is not yet completed; text in blue indicates that the review grade is not assigned or updated. So if an instructor sees a name in red , the student should not be given credit for the review. If text is in blue , the instructor should grade it now. But another common case is after the reviewer has reviewed the work, the author didn’t update it. So the reviewer doesn't need to re-review the work. Therefore, it should be checked whether the author has submitted new files or links since the previous review, even the content pointed to by pre-existing links. To learn whether submission has been updated since the previous review, we need to get the latest updated time then compare it with the latest review time. In expertiza, one submission contains two types of content -- link and file. Both two types should be considered. For file, we just need to look at the last modification time. For link, you need to consider more: the link string itself, and the content that the link points to. Thus, for the file and the link string, we could simply get the update time from the records. The types of the links are various, and how to get update times from them is what we need to focus on. Sometimes we could use this time as our latest update time. Even you have logged in, the Last-Modified time is not equal to the latest commit time which is what we want. After we got the status of submission(updated or not), we could simply mark the not updated reviews green to indicate that it doesn't need to be re-reviewed. Test case 1: Manually open Review Report Page, see if the chart is displayed properly in the Metrics column, including the numerical data and the appearance, ensuring that they are corresponding to the data which should be shown. Test case 2: Manually open Summary Page, see if the chart is displayed as it is designed, including the numerical data and the appearance, check if the checkbox and those save button can respond correctly. Test case 3: Write unit tests to ensure the last update time gotten from SubmissionRecord is right and can be correctly shown. Test case 4： Write unit tests to ensure the last update time gotten from link-to website is correct. Test case 5: Manually open Review Report Page, see if the color of ‘submissions’ words are green if they are not updated.","Basically good; you did what we asked you to.  There is room for improvement.  Test plan is a bit sparse; you say ""correct"" in several places, but don't say exactly what you would check to determine if it's correct.  A number of reviewers said you didn't provide many design details and, indeed, you didn't identify what parts of the code you would change.  Also, the screenshots are often so large that you would need to zoom out to see them."
E1793.1,"A collaboration could be for an assignment where students teams up for an assignment and instructors grades them on the basis of their submission. Students could review other's works and give feedback as well. 1. <link>. 1. <link>. 1. <link>. 1. We already have bidding, which could help you to join a team with other team members hold similar bidding preferences. However, a student may not be satisfied with automated team formation and want to switch to another team. 1. In this project, we will build a new feature to help students find teams to join. Currently, there are 2 ways to find other students to join your team: 1. If your team is not full, you could invite people by inputting his/her UnityID. It will send an invitation to a certain user. If s/he accepts your invitation,s/he will leave the original team and join your team. 1. You could create an advisement by clicking “Your team” link and then clicking “Create” link under “Advertisement for teammates” section. In this way, all classmates could see your advisement. Someone could send a request to join your team. If you accept their request, s/he will leave original team and join in your team. Student: Advertisement icon doesn't appear in Chrome browser. <image> Instructor: Advertisement icon doesn't appear in Chrome browser. <image> Change Request requirements: 1. Students whose team is not full yet to be able to see a list of students who don’t already have teams. 2. Students should have an option of inviting other students to join their teams. 3. Instructors should be able to view a list of students who don't have teams. Fix the second way to find other students to join your team. We used Join queries to join tables participants, team_users, and teams to extract participants associated with the assignment with or without teams and then filtered out participants with team size > 1. def extract_assignment_participants(assignment_id, excluded_id = nil) Above method was defined in app/helpers/assignment_helper.rb. The second parameter was required to exclude current student's id to be excluded to be returned for student whereas, for an Instructor, all students without teams or with single-member team had to be returned. <link> <link> For student, we checked if student can actually send invites or not, and based on that we fetched the participant list. We considered cases enlisted below for verifying if a student can send invite or not: 1. Student can't send invite if student doesn\’t have a team 2. Student can't send invite if current team size is 1 and assignment\’s allowed team size is also 1 3. Student can send invite if assignment\’s allowed team size is >1 and current team size is less than allowed team size 4. Student can't send invite if current team size is equal to allowed team size 5. Student can't send invite if assignment is in finished stage 6. Student can send invite if assignment is not in finished state The table containing the list of students to send an invite to was created/not created based on above criteria only. For that, we considered the following scenarios Testing invitation criteria:- 1. Scenario 1 - Student can't see list of students to invite if student doesn't have a team 2. Scenario 2 - Student can't see list of students to invite if current team size is 1 and assignment’s allowed team size is also 1 3. Scenario 3 - Student can see list of students to invite if assignment’s allowed team size is >1 and current team size is less than allowed team size 4. Scenario 4 - Student can't see list of students to invite if current team size is equal to allowed team size 5. Scenario 5 - Student can't see list of students to invite if assignment is in finished stage 6. Scenario 6 - Student can see list of students to invite if assignment is not in finished state 7. Scenario 7 - The list of students contains only those students who don't have a team yet or whose team is not yet complete and who have not created an advertisement link. 8. Scenario 8 - A student can create an invitation link only if his team is not yet full. 9. Scenario 9 - The same student who accepted the invitation link actually gets added to the team. 10. Scenario 10 - A student won't be able to send the invitation to himself as he is already a member of that team. 11. Scenario 11 - An instructor sees only the list of the students who do not have teams with invitation link. All tests could be found here: <link> <link>. <image> All students whose teams are not complete would see list of other students without teams on their ""your team"" view so that they could invite them by an easy ""Invite"" link as displayed below: <image>.","I had a little trouble following the sequence of actions to be followed in adding students to teams.  The design doc describes it, but it's easy to miss.  And there are seemingly no instructions given to a user on what that ""Invite team mates"" (should be ""teammates"") invitation is about.  It should be said, perhaps in a tooltip, that these students in the class have no team yet."
E1601,"These students belong to the same team and work on an assignment created by the below instructor: 1. Instructor login: username -> instructor6, password -> password 2. Student login: username -> student5884, password -> password 3. Student login: username -> student6420, password -> password Please note : Please do not delete the above users or their team. Before : When a student submitted files and hyperlinks for an assignment, that content was submitted on behalf of his team, and not individually (even if there is only one person in the team i.e a student working on an assignment cannot be without a team even if he is working alone). All the hyperlinks were now recorded in one submitted_hyperlinks field in the team model instead of being present in all the participants of the team. What refactoring we have done to improve the code : Task1:: Removed “hyperlinks_array” method and “hyperlinks” method from assignment_participant.rb. Created “hyperlinks” method in assignment_team.rb. Task4:: All the calls to the above methods were refactored to call the appropriate method's functions. Task5:: Refactored some of the logic of controller methods. Task6:: Tests for submitting and removing submitted hyperlinks and files. Four methods hyperlinks , has_submissions? Task1:: The below methods hyperlinks_array and hyperlinks were removed from the assignment_participant.rb. Also the hyperlinks_array method retrieved the hyperlinks from the submitted_hyperlinks field of the team model so in moving to AssignmentTeam model we just had to remove the .team quantifier. <code> <code> They are both merged into a new single hyperlinks method in assignment_team.rb. All callers of both methods were refactored to use hyperlinks method of AssignmentTeam. <code> Task2:: Earlier, the following method submit_hyperlink was in assignment_participant.rb: <code> It has been now moved to assignment_team.rb as below. Again, as the method was moved to AssignmentTeam model, it obviated the need to invoke the team method. <code> A similar refactoring was done for remove_hyperlinks method in assignment_participant.rb. Task3:: The methods has_submissions? earlier existed both in AssignmentTeam model and AssignmentParticipant model. In assignment_team.rb <code> In assignment_participant.rb <code> What was happening earlier was that has_submissions? (AssignmentTeam method) used to call has_submissions? for each of the AssignmentParticipants in the team. Sample example : <code> This was refactored as <code> In refactoring the call points, we used the existing team method of AssignmentParticipant to get the AssignmentTeam object associated with the particular participant and then invoked the equivalent methods on the team object. In submitted_content_controller, remove_hyperlink method used to cycle through all the participants belonging to the team of current participant, and for each participant call the remove_hyperlink method of the AssignmentParticipant Model to delete the instance of input hyperlink. So we refactored it to directly call the AssignmentTeam remove_hyperlink method. Earlier in submitted_content_controller.rb <code> Refactored: <code>. There were no existing tests for the hyperlinks related methods. We have used Factory Girl for creating Assignment and Team objects to be used for testing. Below is the code to create object of team class. <code>. <code>. Before the test:: Have two students in an assignment team (say student1 and student2, you can also use the student logins listed in this wiki) for an active assignment. You can use an instructor login (example username: instructor6 password: password) to create a new assignment or update the due dates of some previous assignment and assign the team to it. Test1: Login as student1. Submit a hyperlink (say : linkA) as student1. Expected: Submit should go through. The hyperlink should be visible when you login as student2. Test2: Now as student2, submit another hyperlink (say linkB). Expected: Submit should go through. Now both hyperlinks should be visible from both student1 and student2. Test3: As student1, try submitting linkB. Expected: As linkB already exists in team's hyperlinks the submit should not go through. Test4: Remove a hyperlink (say linkA). Now only linkB should be visible from both student accounts. Test5: Remove all hyperlinks. Expected: Hyperlinks list is empty for team and this can be seen from both student accounts. Test6: Submit some hyperlink. Test7: Submit some hyperlink. Do a review of the team after logging in as a student in another team. Expected: Peer review should show the links submitted by the other team.","""It starts out with a synopsis of Expertiza (unnecessary) and a fairly unreadable explanation of what is wrong.
But after that, it describes the changes very well."""
E1654,"<link> is a <link> application made by the joint contribution of Professors and Students of <link> . The <link> allows the instructor to set deadlines for the assignments and peer reviews. 1) The current date-picker doesn't let you change dates easily. In order to do this, we need to change several due dates from the User Interface. This process needs to be simplified. 1) Fix the date time picker bug in _due_dates.html.erb. 2) Find a more user-friendly <link> <link> that supports time zones and allow users to define deadline by date and time (hour), if the bug is not fixed in the existing implementation. 4) Allow users to set all due dates ahead by x days, and the algorithm calculates the exact date and time. Problem 1: In the previous implementation for Expertiza, the professors observed that when they wanted to change the date for submission or review deadline for any project or assignment, Expertiza was not able to handle it properly. As in, when the professor tries to change the date - a calendar pops out but then the calendar should point at the date already in the text box.But this was not implemented as it was picking the date of the system and the professor had to go through a cumbersome process to change the date. And even when any date was not selected the field used to get updated by current date and time. Reason: In the back end , the date picker used was not able to read the date properly from the text box because of date format mismatch. We observed that if we resolve the mismatch in the date formats , this problem could be solved. <image> <image> Problem 2: When there is a requirement which asks for the professor to change the due dates of assignments or projects, (s)he had to change several dates from the front end one by one which was a very time-consuming and ineffective method. Reason: In the previous implementation , there was no functionality which allowed the professor to change dates for multiple projects,assignments without manually entering a new date in each text box or selecting each date using the date picker. We observed that we need to add a functionality where the professor can simply select the assignments/projects for which (s)he wants to update the deadline and input the number of days he wants to extend the deadline and by a click of a single button (s)he can change multiple deadlines. <image> <image>. We made two major changes. Change 1 - We have changed the date picker implementation. As stated, the date picker was not functioning properly. If, while changing the date in the text box , no changes were made, the picker defaulted to the system date instead of the previous date in the text box. The reason for this was a mismatch in the date formats. We made corrections to the code and resolved this mismatch. Now, the date picker is working as per the requirement. It is able to read the date in the text box and there is no mismatch in the date formats. The code below formats the date in a format which datepicker expects. Which removes the Bug in the system which was causing wierd behavior of the Datepicker <code> Change 2 - We simplified the process of changing the due dates of submissions for multiple projects/assignments. It was accomplished by adding check box in front of each assignment. And the professor wants to adjust the due dates of assignments 1,3 and 5 by 4 days. <image> <image> The Code below contains jQuery Functions which are called on click of ""Show/Hide Date Updater"", ""+"", and ""-"" button. <code> <image> <image> The Function Below is a generic Function which can be used to Increment/Decrement Days and Months written in jQuery <code> <image>. The changes made by us in the code can be tested using the below tests : 1. Navigate to Manage Tab, Assignments, Edit (Pencil Icon) page after logging in with the following URL: <link> ( Project successfully deployed ) <code> 2. After logging in as an instructor, Perform the following: change the due dates for an assignment. Go to the text field to change the dates, and without changing the date click on any whitespace. In the current production version of expertiza, the second action resulted in the current date and time being filled in the date and time section. <code> 3. For incrementing/decrementing the number of days allotted for an assignment, click on the show/hide date updater button to reveal the updater widget. check mark all those assignments that need to be updated and enter the number of days in the text field. <code> 4. The complete functionality of our project is well described in the <link> . Here is our <link> . In the link you can see all the changes made in the back end made to fix the date picker bug and implement additional functionalities to update deadlines. 1 <link> 2 <link> 3 <link>.","problems and implementations are clearly shown with screenshots. the description of the mismatch in the date formats, and what was the correct format should be written using a human language, not a copy paste of code!"
E1815,"This project aims to enhance the review report and summary page, and display more information necessary for grading. There are some issues with the current review report page with regards to the Metrics column. 1.1. Metrics are displayed as plain text. 1.2. No comparison on how this student compares with other students. 1.3. If more metrics are added, showing multiple lines of text for each metric can make the column cluttered and difficult to read. Showing a bar chart for the metric rather than just text would improve the user experience. The bar chart can also depict the average for all students for this metric, so the grader can see how this student compares with other students. Also, if several metrics are shown in the column, the bar chart can be made resizable to accommodate multiple bars. <image>. To view this page you click the summary in the row for any student. This page summarizes the peer Reviews given to the Author. 1. The first issue in this view is that there is no header saying what course, assignment, or student this relates to. <image>. Currently, in review report, each team reviewed is color coded as, red indicating that the review is not yet completed and blue indicating that the review grade is not assigned or updated. So if an instructor sees a name in red, the student should not be given credit for the review. If text is in blue, then the student has not been graded for the review, so the instructor should grade it now. But there is caveat here. If the reviewer has reviewed the work but the author did not resubmit, the reviewer has nothing new to review in the latest round and should not be downgraded for not re-reviewing the work. <image> This is what the current color scheme looks like. The text in blue indicates that the student has not been graded, while the text in red indicates the student should not be given credits. We replaced the text given in the Metrics column with a bar chart, as shown below. The bar chart depicts the overall average of all students for this metric, the average of this student for this metric (based on each round) and the metric values for each round for this student. 1. File: app/helpers/review_mapping_helper.rb The following methods were added to calculate average for this metric for all students and for calculating maximum value for this metric. The maximum is needed for constructing bar chart. The second method was added to construct the x-axis labels in the format ""0|50|100|...|max"" for the bar chart. <image> 1. File: app/helpers/review_mapping_helper.rb The following method constructs the bar chart. <image> 1. File: app/views/review_mapping/_review_report.html.erb The following code is added to get the average metric, maximum value of metric and x-axis value from controller. <image> 1. File: app/views/review_mapping/_review_report.html.erb The following code includes the bar chart in the review report page. <image>. <image>. A green tick is added if the reviewer selected the checkbox and a red cross mark is added if the reviewer did not select the checkbox. <image> The page looks as follows <image>. To address the caveat mentioned above, we have used green color to distinguish reviewers who have nothing new to review as the authors have not made any changes. This is what the end result looks like, <image> For doing this, we are getting the last modified date/time of the wiki links and comparing it with the last review submission deadline. If the last modified date/time of the wiki links is before the last review submission deadline, there is nothing new to review and hence green should be used instead of blue to display the author's name. 1) Log in as an instructor 2) Navigate to review grader by doing this (Manage > Assignments) 3) Click on the “View review report” icon (the one with the spyglass and two people) 4) Check if the visualizations are appearing in the review report. 1) Log in as an instructor 2) Navigate to review grader by doing this (Manage > Assignments) 3) Click on the “View review report” icon (the one with the spyglass and two people) 4) In the review report click on the “summary” in the row for any student. 5) Check if the changes are appearing in the page as mentioned in the proposed solution. 1) Log in as an instructor 2) Navigate to review grader by doing this (Manage > Assignments) 3) Click on the “View review report” icon (the one with the spyglass and two people). 1. <link>. Expertiza 1. <link> Expertiza Github 1. <link> Expertiza Documentation 1. <link>.","Clear organization, and good explanation of the changes that have been made.  The screenshots in Issue 1 show how the changes have been implemented.  The code in Issue 2 is less clear, and there is no description of how it works.  The test plan is OK except for saying what is supposed to happen when the code is tested; that is very vague."
E1569,"<link> is an <link> software tool developed at NC State University. It is used to facilitate assignment and course management. It is written as a <link> application, thus functioning natively in a web environment. It can be cloned from <link> . <link> is a process designed to change code without modifying the functionality. Refactoring can improve the readability and the logical design of the software, making sure everything is in the right place and has the right name. This allows code to be understood more quickly by a developer, which shortens the time it takes to develop new features. If you are using an Ubuntu system, the following commands can be used to install MySQL: <code>. <code> Visit <link> for getting more information on setting up git. Go to the local expertiza directory: <code>. From the expertiza directory, run the following command: <code>. The ReviewMappingController file in this application (review_mapping_controller.rb) is responsible for setting up mappings between reviewers and reviewees. It essentially connects a reviewer to an assignment. However, it is a fairly bloated file since it has to handle functionality for five different kinds of maps (review response, author feedback, teammate review, meta-review, and quiz response). It is a prime choice for refactoring because the refactoring can clarify the intent of the different methods in the file. According to the problem statement<ref> <link> </ref>, there were 11 tasks involved in refactoring the ReviewMappingController : 1. Method delete_rofreviewer should do the same thing as delete_metareviewer 2. Method delete_participant is not used 3. Method list_sortable is not used 4. Method automatic_review_mapping_strategy is too long 5. Method review_report has SQL-like code 6. Method add_user_to_assignment should not be in this controller 7. Method get_team_from_submission should not be in this controller 8. Method delete_all_reviewers doesn’t actually delete all the reviewers, but just the outstanding review response maps. We want to keep this functionality 9. Method delete_participant should not be in this controller 10. Method name release_reservation doesn’t describe the functionality well 11. Method delete_review is not used. In the process of refactoring, we have actively followed the Ruby coding guidelines <ref> <link> </ref>. We have also followed some design pattern rules like Single Responsibility Principle <ref> <link> </ref>, which state that every class should have responsibility over a single part of functionality provided by software and that responsibility should be entirely encapsulated by the class. All the services and operations within the class should be aligned with that responsibility. This function has duplicate functionality to another function, delete_metareviewer, and the other function is named much better. The method delete_rofreviewer was removed. This function was confirmed to not being used, since there is no other function in the application that calls it. Therefore, it was removed. This function was confirmed to not being used, since there is no other function in the application that calls it. Therefore, it was removed. This function was originally too long. Hence, we modularised it by moving the part of the code that loops over all teams and creates the ReviewResponseMap into a new function. To make this code easier to read for a pure Ruby developer, the SQL-like code was rewritten with ActiveRecord. This method does not belong in this controller, and it is only ever called by participants_helper. Therefore, the method should go into participants_controller, which is where it was moved. Since the only problem with this method is that the name does not describe the actual or intended functionality, we replaced all instances of “delete_all_reviewers” with “delete_outstanding_reviewers”. This function was confirmed to not be used, since there is no other function in the application that calls it. Therefore, it was removed. Since the method name does not accurately describe the functionality within, all instances of “release_reservation” were replaced with “release_mapping”. This function was confirmed to not be used, since there is no other function in the application that calls it. Therefore, it was removed. <link> is a Behavior-driven development for Ruby programming language widely used for Test Driven Development. <ref> <link> </ref>. <code>. <code>. <code>. <code>. <code>. View Response Report <image> View Response Report by name Search for Reviewer's name ""523, student"" <image> View Feedback Response Map <image>. By refactoring ReviewMappingController , extraneous and unused code was removed, readability was increased, and tests confirm that its functionality remained intact. 1. <link> 2. <link> 3. <link>.",Good job on writeup!
E1937,"Currently we have a few classifiers that can detect useful features of review comments, such as how many suggestions they contain. In order to make the API call, the response_controller.rb will be responsible for sending a JSON input to the web service. The input will contain the review comment submitted by the user in the following format: Below is a sample input <code> Once the request is send, we expect the output to be in the following format: <code> The output (which is a JSON) will be parsed and the suggestion metrics such as the tone and presence of suggestion will be extracted so the user will be able to view a summarized result of how well their review comments were. <link> 1. They had a functional suggestion detection API call that successfully communicated with the PeerLogic Server and retrieved the output. 2. They included their API call in response.html.erb using JavaScript. 3. They were able to display the output for each review beside the review. More information about the suggestion detection service can be found at <link> <image>. <image>. 1. Move API calls of suggestion-detection algorithm from view to response_controller.rb 2. Change default review view from displaying analysis for each comment to summarized analysis for all comments 1.1. Do not include comment text in analysis view 1.2. Focus on sentiment_score, suggestions, suggestions_chances returned from API 3. Include displaying analysis for each review as a ""debug"" option 4. Ensure that CORS does not need to be enabled for API call to work 5. Write unit tests for our method(s) in response_controller.rb 6. Fix grammar issues in response.html.erb 7. Evaluate how much time this API is taking and, if possible, work a way out to improve it. 1. app/views/response/response.html.erb - Refactored and reworked JS methods for the autosave and form submits, added a new hidden button to the response form 2. app/controllers/response_controller.rb - Refactored and reworked methods for the autosave and form submits, added an API method to pass to view 3. app/helpers/review_mapping_helper.rb - Adjusted the bar thickness according to desired specifications 4. config/routes.rb - Added another route to support the new review confirmation page listed below. 1. app/models/metric.rb - New ActiveRecord model added to act as a template for future API usage 2. db/migrate/20190425194052_create_metrics.rb - New table added for permanent storage of the Metric class 3. app/views/response/show_confirmation_page.erb - The new page added for review confirmation 4. test/fixtures/metrics.yml - In support of the new ActiveRecord model called Metric 5. test/models/metric_test.rb - In support of the new ActiveRecord model called Metric 6. app/assets/images/lightbulb.png - Lightbulb picture for the new review confirmation page 7. app/assets/images/music_note.png - A music note picture for the new review confirmation page. Lines 359 and 360 are where we will retrieve the input from each review comment found in the form. 1. The Answer model represents the review provided by the reviewer. 2. On line 360, answer: v[:score] is the review comment from a given textarea HTML element 3. params[:responses] stores the aggregate review data provided by the user <image>. The program flow is as follows: 1. After the reviewer has filled out their review, they have 2 choices: See an analysis of their review or Save the review. 2. The reviewer selects to view their analysis by clicking on ""Confirm Submission"" button 3. The program directs the reviewer to the new confirmation page which displays an analysis of their review. 4. The reviewer has 2 options in the confirmation page: Submit the review or go back and modify their review. 5. If the reviewer decides to Submit their review, the program directs them back to where they started (Create or edit review). <image>. Below we showcase the available information from the API if a reviewer is curious to find more details <image> <image> <image>. For tone, there are three options in the API: positive, neutral, and negative. We created conditional formatting in our view file so positive is green text, neutral is yellow text, and negative is red text. 1. For TESTFOLDER=features, in the response.hmtl.erb view, we changed the submit button text from ""Submit"" to ""Confirm Submission"" in order to accurately reflect the new redirect page. 1. We tested the new model added i.e. Metric model in metric.rb. 1. <link> 2. <link> 3. <link>.","I think this design doc would have been more effective if you described more of the code.  You did say what was done in Lines 359 and 360 of the response_controller, but you didn't explain any of the other changes.  This is important for giving programmers who follow you an idea of why the code is structured as it is."
E1962,"In Expertiza, students and instructors are notified of various events by e-mail, e.g., creation of a new account, submission of a review on their work, or updating of work that they have reviewed. Students receives email whenever their account is created in system. New users on Expertiza can be created by instructors directly from Users page or new user can also get created when added as an assignment participant but does not already exist in the system. After creating an assignment, the instructor can add participants to it by two ways 1. Picking participants by their usernames OR By importing a csv file which lists the participants If a user does not already exist in the system, then a new Expertiza account is created for the user and then added as a participant on the assignment. An email notification of account creation along with the user-ID and password must be sent to the user. The following issue was identified in the current system 1. When students' accounts are created by importing a CSV file on the Users page, they receive e-mails with their user-ID and password. However, if an account is created by adding them as participants to an assignment when they don't already have an account, e-mail notification is not being sent. File: app/models/assignment_participant.rb The code in the below snippet previously had the flow as follows: If user does not already exist in the system, then create new user account(if there is sufficient information about the user to create a new Expertiza account) Add this user to the assignment as a participant. If user already exists in the system, do nothing. If the user is already a participant on the assignment, do nothing. The issue here was that an already existing user in the system will not get added as a participant on the assignment. The code has been modified to facilitate the following flow: If the user does not exist in the system, create new user account (if there is sufficient information about the user to create a new Expertiza account) If the user already exists as a participant on the assignment, do nothing Add the user to the assignment as a participant; otherwise. This way, the user(whether newly created or already an Expertiza user) gets added on the assignment as a participant. <image> File: app/models/assignment_participant.rb Now that we have enabled the email functionality irrespective of where a new user is created from, we don't need to explicitly call the mailer from each location where new user is created. <image> File: app/models/user.rb Here, we enabled the email functionality by adding the .deliver_now method This method invokes the mailer to deliver an email immediately. <image>. Unit testing is not mentioned here because proposed implementation uses already existing mailer functionality for which test cases are already written. Below given file shows test cases for integration testing of this improvement. File: spec/models/assignment_participant_spec.rb While uploading participant list via a csv, for each new user created on expertiza, an email notification should be sent out. This is a test case which checks the count of email after a new user has been created. The email count should be 1 in the case that a new valid user is created. <image> <image> File: spec/models/participant_spec.rb Initially, on being added to an assignment, the user would receive an email. However, no email notification was sent on new account creation. Now that the email functionality has been added on account creation too, a total of two emails will be sent to new users added as participants - one for account creation and one for addition to assignment. We modified the expected email count to accommodate this change. <image>. Follow these steps:- (You can also watch the demonstration of the implementation <link> ) 1. First, make a CSV file on your local system using the following format. <image> 2. Follow <link> to the deployed application 3. Login with username 'instructor6' and password 'password' <image> 4. Navigate to Manage -> Assignments <image> 5. Click on 'Assignments' <image> 6. For an assignment, select the action 'Add participants' <image> 7. Click on import assignment participants <image> 8. Upload the csv file created above <image> 9. Confirm the participant list <image> TIP: To test fully, ensure that you have access to at least one of the email-ids mentioned in users listed in the csv. This way you can affirm the changes work when you receive an email notification as shown below. Issue: If a user already exists in the system and appears in the csv file while importing participants, then the code only checks that the user exists and moves ahead. However, the user is not added as a participant on that assignment. Participants are being added to the assignment only when user does not exist in the system already and user is newly getting created.","Although I disagree with some of the design decisions, the changes are very well documented.

Using the Github diff view is an excellent way to show your changes.

Unfortunately, many of the changes are to comment out code.  Code that is no longer needed should be deleted.

Explanation of the assignment_participant changes was very terse.  More complete explanation would save the next person considerable time.

It is not a good idea to email students whenever they are added to an assignment.  I don't know of any other class where students are emailed every time work is assigned.  Students may want to opt out of this, and there is no way to do so at present.

Team found another bug, which I will report to Github."
E1930,"This project works on improving the search facility by adding search criteria in existing search bars, making it look elegant and adding search bars if not present. 1. An instructor or administrator can search for a user by name, user-ID, or other characteristics. 2. An instructor should be able to search for assignments by name, due date, or other characteristics. 3. An instructor should be able to search for rubrics (or other questionnaires) by name, or by the courses or assignments they have been used in. It should be possible to search or click somewhere to bring up a list of questionnaires used in the course, expanding only the applicable questionnaires in the list of questionnaires. 1.2. One should also be able to search for questionnaires by words used in questions that belong to the questionnaires. 5. An instructor or administrator should be able to search for all the assignments that a particular user has participated in. 6. If more than one criteria needs to be specified, there should be an 'Advanced Search' button. In the current system workflow the user is able to search for a particular user by entering a partial or a complete text that matches with the user name. In the proposed workflow searching by name, searching by User ID will also be supported. The user will be able to apply multiple filters at a time and the output of the query will match all filter applied. Steps to reproduce the proposed workflow: 1.1. Log in to expertiza to view the home page 1.2. Go to Manage > Users 1.3. Type the name of the user in the search box available below the ‘Users’ tab 1.4. In the dropdown list that opens up, click on the ‘Advanced Search’ button if you wish to apply more filters. In the current system implementation, searching via the name of the assignment is supported. In the proposed system, the user will be able to search for an assignment using additional filters such as date created, date updated. The user will be able to apply multiple filters at a time and the output of the query will match all filter applied. To search for an assignment by creation date, the user can enter a time duration within which the assignment was created. All assignments that were created within this date range and which match other filters will be returned. Steps to reproduce the proposed workflow: 1.1. Log in to expertiza to view the home page 1.2. Go to Manage > Assignments 1.3. Type the name of the assignment in the search box available below the ‘Assignments’ tab 1.4. In the dropdown list that opens up, click on the ‘Advanced Search’ button if you wish to apply more filters ( date of creation, date updated). The existing system does not have a search functionality under Questionnaires. The proposed system will implement a search functionality for searching via the name of the questionnaire, the text in the question within a questionnaire, date of creation, date updated. The user will be able to apply multiple filters at a time and the output of the query will match all filter applied. To search for a course by creation date, the user can enter a time duration within which the course was created. All courses that were created within this date range and which match other filters will be returned. The procedure is same for searching by date of update. The existing system does not have a search functionality under Reviews. The proposed system will implement a search functionality for searching using the attributes like team name, score, reviewer, comment etc. <image>. We though about 2 ways of adding the search functionality in the system 1.1. Adding a search controller to the system 1.2. Adding search functionality to individual models. 1. Also, placeholders are removed from the search text bars in advanced search because it looked ugly. Also, labels for each search text box has been added directly above it so that the user can easily identify what parameter that text field contains. 1.2. User#get_user_list : Model returns list of users to the view, changes in this function uses regex to filter out the entries that do not match search params. 1. Search fields 1.1. Name. <image> 1. As seen in the image, the advanced search is closed at the start. 2. There is also an option of hiding the advanced search bar. <image> 1. Important changes made in the pop-up of advanced search bar context was that, before when we tested the functionality it was found that if you had searched something prior in the advanced search bar, then if you hide the advanced search bar, the data remains persistent until it is removed manually. 2. Hence, if you search again now, it will take the prior advanced search criteria into consideration as well. So unwanted parameters are not included in the search. <image> <image>. 1.2. Also, there were extensive tests written for the search functionality which was dependent on the user that was logged in.","Very good coverage of the design. Your screenshots are very effective in showing the changes, and they are motivated well. You did a good job of showing changes made to the db. But the doc was not updated to say which code was changed. That is one of the most important needs for teams that follow after you."
E1965,"Expertiza<ref> <link> </ref> is an open-source web application to create re-usable learning objects through peer-reviews to facilitate incremental learning. Students can submit learning objects such as articles, wiki pages, repository links and with the help of peer reviews, improve them. The project has been developed using the Ruby on Rails<ref> <link> </ref> framework and is supported by the <link> . Expertiza assignments are based on a peer review system where the instructor creates rubrics for an assignment through questionnaires which students use to review other students' submissions. The author of the submission is given an opportunity to provide feedback about these reviews. Expertiza displays reviews (i) to the team who was reviewed, and (ii) to the reviewer. A student user can see all the reviews of his/her team’s project. The instructor can see all the reviews of everyone’s project. The instructor also has access to a Review report, which shows, for each reviewer, all the reviews that (s)he wrote. The score report and review report use different code so UI is non-orthogonal, it would be great if we can follow same UI structure for score and review report which also reduce the DRY problems. 1. Currently Review report uses its own code to display reviews. This a pretty basic view, and it does not interpret HTML codes. It should be changed so that it calls the usual code that is used for displaying reviews, that gives the circle with the score inside. Currently, if you pull up a review report, and then click on one of the teams reviewed, e.g., the first one, you get a report that looks like this: <image> We need to change the views to existing templates in view_my_scores pages. For student view the UI is consistent in displaying reviews they have done and reviews they have received but for instructor's view the review report follows different UI and have different code. To make the UI consistent we have decided to choose the UI design of student view as the base and modify the UI design for review report in instructor's view. This will allow us to use the same code in both views, thereby following DRY principle. Updated View: <image> Our changes can shown more apparently in the following video.<ref> <link> </ref>. 1. app/view/pop_up/team_users_popup.html.haml 2. app/view/pop_up/team_users_popup.html.erb 3. app/assets/stylesheets/grades.scss. The specific changes can be seemed in the comments of code. Review report view is rendered in app/views/popup/team_users_popup.html.haml. First, we changed it to regular erb file. And fix some bugs between auto-change. <code> We replace the above code by code below. Just simply convert haml to erb. <code> Then we change the row and col layout and css style of this view. The previous tables can be listed as below. <code> After we change the lay out, it can be listed as below. <code> We also fixed some small bug about the checkbox questions and index of the questions. We fixed the if-else logic question, in order that checkbox questions can be showed properly. <code> We also changed the outlook of score and make it to be a circle. <code> And the css is in grades.scss <code> We added the ""index"" in this view, in order to show the proper sequence of review's question. <code> At last, we add the css style ""warning"" and ""info"" for the table and review score. So that it looks more beautiful. <code>. Our test plan are mostly manual. There are two reasons why we choose UI testing: 1. As we only change the layout of several views. We can only test them from UI testing. 2. The existing templates view_my_score are also tested with UI, without any Rspec testing. There are two test cases for UI testing. 1. To Test UI for student View 1.1. Log-in as Student. 1.2. Go to Assignment 1.3. Click Your scores 1.4. Click show reviews 1. To Test UI for instructor View 1.1. Log-in as Instructor. 1.2. Go to Manage Assignments 1.3. Click on review report of a particular assignment Expected result: <image>. <references/>. 1. <link> 2. <link> 3. <link>.",The code changes are hard to follow when you paste in successive versions of the code.  Github diff view would have more clearly shown the changes.  It would be very useful if your narrative described how the code worked.
E17A2.2,"This project is concerned with two preliminary badges — ""Good Reviewer"" and ""Good Teammate"" — but the design will be such that the badging system can be easily extended to include more badges in the future. The ""Good Reviewer"" badge will be awarded to students who receive very high review grades. The ""Good Teammate"" badge will be awarded to team members who receive very high teammate review scores. A new ""Badges"" tab will be added for instructors on the ""Edit Assignment"" page where instructors can add badges and configure the badge criteria for a given assignment. Badges a student has earned can be seen when they view their ""Task List"" page, and an instructor will be able to view all badges earned by students when they view the ""Participants List"" page. The following Credly badge will be awarded to students who meet the ""Good Reviewer"" criterion for a given assignment: <image> Good Reviewer Badge The following Credly badge will be awarded to team members who meet the ""Good Teammate"" criterion for a given assignment: <image> Good Teammate Badge. The following is an example of mock data in the badges table: <table> The following is an example of mock data in the assignment_badges mapping table: <table> The first row represents that the badge with badge_id 1 (""Good Reviewer"") has been activated for assignment with assignment_id 1 with the default threshold of 95 . The second row represents that the badge with badge_id 2 (""Good Teammate"") has been activated for assignment with assignment_id 1 with the default threshold of 95 . The third row represents that the badge with badge_id 1 (""Good Reviewer"") has been activated for assignment with assignment_id 2 with a customized threshold of 90 . The fourth row represents that the badge with badge_id 2 (""Good Teammate"") has been activated for assignment with assignment_id 2 with a customized threshold of 85 . The fifth row represents that the badge with badge_id 1 (""Good Reviewer"") has been activated for assignment with assignment_id 3 with a customized threshold of 80 . The following is an example of mock data in the awarded_badges mapping table: <table> The first row represents that the assignment participant with participant_id 1 has earned the badge with badge_id 1 (""Good Reviewer"") for the given assignment. The second row represents that the assignment participant with participant_id 1 has earned the badge with badge_id 2 (""Good Teammate"") for the given assignment. The third row represents that the assignment participant with participant_id 2 has earned the badge with badge_id 1 (""Good Reviewer"") for the given assignment. The fourth row represents that the assignment participant with participant_id 3 has earned the badge with badge_id 2 (""Good Teammate"") for the given assignment. The following screenshots show a comparison of the existing ""Assignments Edit"" page, alongside a mockup incorporating the new badging system where instructors can add and configure badges for a given assignment. The following screenshots show a comparison of the existing ""Participants List"" page, alongside a mockup incorporating the new badging system where instructors can view all awarded badges for a given assignment. <image> The original ""Participants List"" page. <image> The modified ""Participants List"" page. The following screenshots show a comparison of the existing ""Student Task List"" page, alongside a mockup incorporating the new badging system where students can view all of the badges they have earned. <image> The original ""Student Task List"" page. <image> The modified ""Student Task List"" page. Please click the image below to watch the video demonstration for this project, which demonstrates that: 1.1. Newly-created assignments are automatically added to the assignment_badges table (one entry for each badge) with default threshold values of 95 1.2. Updating a student's reviewer score appropriately awards or revokes the Good Reviewer badge 1.3. Updating the Good Reviewer badge threshold appropriately awards or revokes the Good Reviewer badge 1.4. Updating a student's teammate review score appropriately awards or revokes the Good Teammate badge 1.5. Updating the Good Teammate badge threshold appropriately awards or revokes the Good Teammate badge <image>. • app/assets/images/badges/Badge-Good-Reviewer.png The image used for the new ""Good Reviewer"" badge. • app/assets/images/badges/Badge-Good-Teammate.png The image used for the new ""Good Teammate"" badge. • app/models/badge.rb The model associated with the new badges table. • app/models/teammate_review_response_map.rb The file in which the code for the ""Good Teammate"" badge will be inserted. • app/views/assignments/edit.html.erb The UI changes allowing instructors to add and calibrate badges for a given assignment.","There's little prose in this document.  It is mostly a collection of lists, which might make it easy to look up information, but not to learn about the project by reading end to end.  The test plan merely consists of the test code.  The purpose of the document is to describe the functionality, not to present the code by itself."
E1740,"These badges will be “1st Submission”, “Dream Team”, and “Good Reviewer”. Students can also peer review other students' submissions. We are tasked with designing three badges - namely, Top Scores, Dream Team, and Good Reviewer. The end goal of this project is to have the earned badges appear on the student’s task view as well as the instructor’s participants view. The student’s task view appears as shown in the below screenshot, as per the current implementation. Hovering over the badges would give you a brief description of the badge earned. <image> The participants view after the proposed implementation would be changed as shown below. Use Case 1: First Submission Badge for Student The student here will be able to view the first submission badge in their view (student_task/list) page, if the badge computer component in the system can determine the submission made by the team of the student is the first submission of the assignment. Use Case 2: Dream Team Badge for Student The student here will be able to view the dream team badge in their view (student_task/list) page, if the badge computer component in the system computes the aggregate scores of all the teammate reviews to be greater than 95. Use Case 3: Good Reviewer Badge for Student The student here will be able to view the good reviewer badge in their view (student_task/list) page, if the badge computer component in the system determines the review grade for the student to be greater than 95. Here, the system needs to wait for the grade score from the teaching staff to display this badge. Use Case 4: First Submission Badge for Participants The instructor here will be able to view the first submission badge for participants in their view (participants/list) page, if the badge computer component in the system can determine the submissions made by teams of each participants (in the list) are the first submissions of different assignments. Use Case 5: Dream Team Badge for Participants The instructor here will be able to view the dream team badge for participants in their view (student_task/list) page, if the badge computer component in the system computes the aggregate scores of all the teammate reviews for each participant to be greater than 95. Use Case 6: Good Reviewer Badge for Participants The instructor here will be able to view the good reviewer badge for participants in their view (student_task/list) page, if the badge computer component in the system determines the review grade for the each participant to be greater than 95. Here, the system needs to wait for the grade score from the teaching staff for each participant to display this badge. TASK 3 - Implement the Dream Team badge 1. This badge will be given to a team when all of their members receive an aggregate teammate review score of 95 or above 2. To check for this, we will average the teammate review scores for each individual member and then check to see if each member had an average of 95 or above 3. If the team accomplishes this, each member will be awarded the Dream Team badge 4. If any member of the team does not have an average of 95 or above then none of the team members will be awarded the badge 5. The logic for this badge will be written in the teammate_review_response_map.rb file TASK 4 - Implement the Good Reviewer badge 1. This badge will be given to a student if they receive a review grade average of 95 or above from the teaching staff 2. In order to calculate this score we will have to get each individual grade the student received on their reviews and average it out 3. If that average is at 95 or above they will receive the badge, if not they will not be given this award 4. The logic for this badge will be written in review_response_map.rb On completing the tasks the badge system will be functional. 1. Log in as an instructor and identify the top scorer for a particular assignment and later later impersonate the students of that team and make sure that all the team members have received the 'top score' badge. 2. Log in as an instructor and identify the team which received an average score greater than or equal to 95% and later later impersonate the students of that team and make sure that all the team members have received the 'dream team' badge. 3. Log in as an instructor and give review scores for two students (one more that 95% and one less than 95% for the other) and later later impersonate the students to make sure that the student who received more than 95% review grade received the 'good reviewer' badge and the other student does not. 4. Log in as an instructor and check if the students tested above has the badges reflected in the participant_list/list view page. The page shows all the assignment specific badges (Top score, Dream team and Good reviewer badge). NOTE: The details about the badge should appear when we hover the mouse pointer above the badge.","Generally good flow, explains most of the items well.  Except for three mentions of files to be modified, there is no indication of how the code will be changed to allow for badges.  This should be described in more detail."
E1637,"It focuses on calculating a penalty which would be deducted from the total score obtained by the student if the student submits the assignment or review past the specified deadline. The files modified for the penalty functionality to work are as follows,. This controller contains the functions to create, update and delete a late policy. The instructor can create a late policy for any assignment, where in the instructor can specify the points per unit and the maximum penalty that can be applied for a particular assignment. In grades controller, the total penalty was not getting deducted from the total score due to the mismatch of conditions. The conditions were modified in this controller for the penalty to be deducted from the total score obtained. This helper file has functions to calculate submission, review and metareview penalties. This function was not returning the values of the calculated penalty as required and modifications were made so that the correct penalty values are returned. In the current implementation, the penalty deducted is not displayed when a student views scores. The views were modified so that the deducted penalties and total score are displayed appropriately. In addition, the tests also ensure that none of the fields are empty and ensures the maximum penalty and penalty per unit is a positive number which lies in a specified range. 1. T1: Refactor the create function in LatePoliciesController to make the code more modular 2. T2: Refactor the update function in LatePoliciesController to make the code more modular 3. T3: Modify the PenaltyHelper to calculate and return the correct penalty value 4. T4: Modify the GradesController to deduct the total penalty from the total score 5. T5: Modify the ViewScores page to display the penalties deducted 6. T6: Test the working of the LatePolicy model by writing necessary RSpec tests. The same checks were performed by the update function. This function checks that the penalty per unit is less than the maximum penalty. This function checks that another policy with the same name created by a different instructor does not exist. Duplicate policy names are permissable if created by the same instructor. The update function performs the same checks as the create function. In addition, when the late policy is updated, the corresponding penalty calculations have to be updated for students enrolled in assignments using the corresponding late policy. The helper function penalty_helper.rb aides in calculating associated penalties with a late submission. Minor modifications were made in the penalty_helper.rb file to return the value of calculated penalty. In the original implementation, the calculated penalties were not subtracted from the total score when a late submission was made. This controller is now modified such that based on the time of submission (if late) penalty points would be deducted from the total obtained score. When a student clicks on view scores link for an assignment he/she can view the scores obtained for that assignment. In the original implementation, the students could not view the penalty deductions obtained for the assignment. Now when the student clicks on the view scores link, he/she can see all the penalty deductions in addition to the total score obtained. While creating a late policy many constraints have to be kept in mind like the policy name should not be blank or empty, every late policy should have an instructor associated with it, the maximum penalty and penalty per unit should be a positive number and the penalty unit should always be set (seconds/minutes/hours). 1. Login as instructor 2. Create an assignment in course 3. In the due dates tab in create assignment check the ""Apply Late Policy"" box 4. Select ""New Late Policy"" link 5. Fill in the form with necessary details and submit 6. The newly created late policy will be displayed in the list of all late policies 7. Select the ""Edit"" option for the created late policy 8. Change the required fields and save the changes 9. The updated late policy is displayed in the list of late policies 10. Edit the assignment/create a new assignment 11. In the due dates tab, the newly created late policy will be displayed in the dropdown. Changes were made in the Penalty Helper file and Grades Controller to calculate the correct penalty value and deduct it from the total scores obtained. Changes were made in so that the View Scores option would display the penalties in addition to the total score. The following steps can be followed to ensure that the penalties get deducted appropriately from the total score and are visible to the student. 1. Login as instructor 2. Create an assignment in course along with a late policy 3. Create a team of 2-3 students for the created assignment 4. Login as a student 5. Make a submission for the assignment past the mentioned deadline 6. Go to view scores and the deducted penalty will be displayed. While the late penalty has been implemented, there are few aspects of this project that can be improved. 1. Currently the review penalty is not being calculated because submission of review is not allowed after the mentioned deadline. If the review for an assignment is submitted after the mentioned deadline no points get deducted even after enabling late review.","The writeup is generally pretty good.  There is no point in including the whole late_policy_spec.rb, but other than that, the changes are explained and shown with code snippets of reasonable length.  There is a good explanation of  how to test."
E1662,"Expertiza is an open source web application developed by students and faculty members of North Carolina State University. This portal is being used by both faculty members and students in order to carry out assignments. Typically following is the workflow of the system: 1. Faculty member adds students to a particular course. He also adds an assignment for the class. 2. Assignment has a specific deadline, review period and final submission. 3. Faculty members upload list of topics for the assignment. 4. Students have to bid for the topic or they can suggest their own topic. 5. At the end of the bidding process, students get a specific topic for the assignment. 6. Students can form the teams by sending out invitations to other students. 7. Students start working on the assignment and submit the assignment work before the initial submission date. 8. Every student then gets to review work submitted by at least one team. Student submit their feedback in the review. 9. Students then make the necessary changes as suggested by reviewer and submit the assignment before the final submission date. 10. Students are graded on the basis of their work and reviews. The main objective this project is to fix the issues in the current system. The current system has following issues: 1. Historically courses were created without providing Institution ID. Since data warehouse is now storing Institution ID for a particular course, this application should do support this function. 2. If an assignment is completed, no one can sign up for topics or drop topics. It would be better if the column did not appear. 3. Currently when admin/instructor tries to delete an assignment, there is no alert/confirmation shown. We need to add a confirmation step to avoid losing data. Capturing Institution ID Institution and Course has One-to-Many relationship where in one institution may have many courses associated with it. In current system while creating new course user does not have to choose which institution the course belongs to. Following basic changes are required in order to fix this issue. 1. Ensure that relationship exists between Course and Institution model classes. <code> 1. In app/views/course/_course.html.erb , add a drop-down list so that user can select institution from the available options. <code> 1. Ensure that the id for the selected institution is sent as a parameter along with other parameters back to controller. 2. Once we receive all the data in controller Institution ID should be saved in course table. Thus in app/controllers/course_controller.rb , add arguments to the Create method. <code>. 1. User should login to expertiza using Instructor's credentials. 2. Go to Manage Courses and click on New Course button so as to open form for it. 3. Fill up the form. you can see new field added as Institution Name. This is a drop down list which has list of Institutions. 4. User has to select one of these institutions. If user tries to go ahead without selecting this then he will get an alert flash saying this is a required field. 5. Once an institution is selected user can click on Create button to submit the form (with other fields completed). 6. Institution ID would be saved in database record against this particular entry of course in Course table. User can verify this by accessing Course table in the database. When student open sign up sheet for the Finished projects, he should not be able to take any actions for that assignment and hence Actions column should be hidden to him. For fixing this bug, we had to make following changes into app/views/sign_up_sheet/_table_header.html.erb . <code>. 1. Login to expertiza using student credentials 2. Go to assignment tab and look for the assignments which have current stage as ""Finished"" 3. Go to that assignment and open sign-up sheet. 4. You should not be able to see column Activities, which means the work is successful. When instructor clicks on delete button to delete assignment, It gets deleted without confirming it. System should ask for confirmation whether to go ahead with deletion or not. To post a confirmation to users, we used the flash method to put the message on the screen. When user is going to delete an assignment, he will firstly use the delete action in assignment model with parameter force=nil . Thus in app/models/assignment.rb , we added an condition in the beginning of the method to check whether it is the first attempt to delete the assignment. <code> The exception will be caught in the assignment controller. Then corresponding messages are passed by flash method to be shown on the page. <code>. 1. Login to Expertiza as an Instructor. 2. Go to manage assignment page. 3. Try deleting an assignment by clicking on an image from the activities column. 4. When delete button is clicked, system should ask for confirmation message whether you really want to delete or not. 5. If you select yes then that assignment should be deleted. Otherwise if selected no then that assignment should not be deleted.","The documentation does not mention that they skipped Issue #256. However, it is nicely structured thus it's easy to find information. however the solution presented are mostly just copy paste of the code. It should be described in a narrative, rather than a list of bullet points."
E1814.1,1. Test Two-Node Cycle 1.1. When the reviewers of the current reviewer (ap) do not include the current assignment participant it should skip this reviewer (ap) and return the corresponding collusion cycle 1.2. When the reviewers of the current reviewer (ap) include the current assignment participant and the assignment participant is not reviewed by the current reviewer it should skip the reviewer (ap) and return the corresponding collusion cycle. 1.3. When the reviewers of the current reviewer (ap) include the current assignment participant and when the current assignment participant was reviewed by the current reviewer (ap) it should insert the related information and return the corresponding collusion cycle. 1.4. When the reviewers of the current reviewer (ap) include the current assignment participant and the assignment participant did not submit a review of the current reviewer (ap) it should skip the current reviewer (ap) and return the corresponding collusion cycle. 1.5. When the reviewers of the current reviewer (ap) include the current assignment participant and the assignment participant did submit a review of the current reviewer (ap) it should skip the current reviewer (ap) and return the corresponding collusion cycle. 1.2. When the reviewers of the current reviewer (ap2) include the current assignment participant and the current assignment participant did not receive a review from the current reviewee (ap1) it should skip the current reviewer (ap2) and return the corresponding collusion cycle. 1.3. When the reviewers of the current reviewer (ap2) include the current assignment participant and the current assignment participant received a review from the current reviewee (ap1) it should insert the related information and return the corresponding collusion cycle. 1.4. When the reviewers of the current reviewer (ap2) include the current assignment participant and the current reviewee (ap1) received a review from the current reviewer (ap2) it should insert the related information and return the corresponding collusion cycle. 1.5. When the reviewers of the current reviewer (ap2) include the current assignment participant and the current reviewer (ap2) received a review from the current assignment participant it should insert the related information and return the corresponding collusion cycle. 1.6. When the reviewers of the current reviewer (ap2) include the current assignment participant and the current reviewer (ap2) did not receive a review from the current assignment participant it should skip the current reviewer (ap2) and return the corresponding collusion cycle. 1.7. When the reviewers of the current reviewer (ap2) include the current assignment participant and the current reviewee (ap1) did not receive a review from the current reviewer (ap2) it should skip the current reviewer (ap2) and return the corresponding collusion cycle. 1.2. When the reviewers of the current reviewer (ap3) include the current assignment participant and the current assignment participant received a review from the reviewee of the current reviewee (ap1) it should insert the related information into the collusion cycle and return results. 1.3. When the reviewers of the current reviewer (ap3) include the current assignment participant and the reviewee of the current reviewee (ap1) received a review from the current reviewee (ap2) it should insert the related information into the collusion cycle and return results. 1.4. When the reviewers of the current reviewer (ap3) include the current assignment participant and the current reviewee (ap2) received a review from the current reviewer (ap3) it should insert the related information into the collusion cycle and return the results. 1.5. When the reviewers of the current reviewer (ap3) include the current assignment participant and the current reviewer (ap3) received a review from the current assignment participant it should insert the related information into the collusion cycle and return the results. 1.6. When the reviewers of the current reviewer (ap3) include the current assignment participant and the current assignment participant did not receive a review from the reviewee of the current reviewee (ap1) it should skip the current reviewer (ap3) and return the corresponding collusion cycle. 1.7. When the reviewers of the current reviewer (ap3) include the current assignment participant and the reviewee of the current reviewee (ap1) did not receive a review from the current reviewee (ap2) it should skip the current reviewer (ap3) and return the corresponding collusion cycle. 1.8. When the reviewers of the current reviewer (ap3) include the current assignment participant and the current reviewee (ap2) did not receive a review from the current reviewer (ap3) it should skip the current reviewer (ap3) and return the corresponding collusion cycle. 1.9. When the reviewers of the current reviewer (ap3) include the current assignment participant and the current reviewer (ap3) did not receive a review from the current assignment participant it should skip the current reviewer (ap3) and return the corresponding collusion cycle.,"Good prose descriptions of what is going on.  Diagrams would probably be a more concise way to show the information flow, but I can't fault the way you described it in words."
E2009,"The assignment.rb model file consists of some basic CRUD operations along with some methods which help calculate scores and export details etc. Some of the coding issues with the assignment.rb file are 1) Methods performing more than one tasks, resulting in long methods 2) Methods with multiple conditions and loops resulting in increased cyclomatic and cognitive complexity 3) Large number of methods in one file. 69 issues were found on code climate and through this project, 30-35 issues have been resolved. Code climate gives different metrics that indicates the code quality. Some of the metrics the code climate gives are 1) Assignment Branch Condition (ABC) size - It is computed by counting the number of assignments, branches and conditions in a section of code. Specifically ABC size = sqrt(A*A + B*B + C*C), where A - number of assignments, B - number of branches, C - number of conditions. 2) Cyclomatic complexity - It is a quantitative measure of the number of linearly independent paths through a program's source code (or a method). It gives a measure of how difficult a code is to test. Higher the number of branches in a method, higher the number of independent paths and hence higher the cyclomatic complexity. :) increases the complexity by one. 3) Cognitive complexity - It is a measure of how difficult a unit of code is to intuitively understand. Generally methods with higher cyclomatic complexity will have higher cognitive complexity also. 4) Perceived complexity - It is a complexity score that's a measure of the complexity the reader experiences when looking at a method. In contrast to the Cyclomatic Complexity, this metric considers `else` nodes as adding complexity. All the metrics are quite interlinked, so aiming to reduce one complexity will also reduce other metrics. The longer methods are refactored mostly by extracting a method out which performs an independent task. Longer methods generally has higher Assignment Branch Size and higher complexity metrics. The methods refactored using Extract method are scores, review_questionnaire_id and response_map_to_metareview. The scores method is one of the biggest methods in assignment.rb file. The code climate gives the Assignment Branch Condition size as 131.2/15, number of lines of code as 48 and cyclomatic complexity of 8/6. The scores method computes and returns the scores of participants and teams as a hash. The participant scores are directly got by calling a method in Participant class. Two methods are extracted out of this method. Below is the screenshot for diff after refactoring (left is refactored code) <image> Hence after refactoring the number of lines of code in the method reduced to 17 . This method as the name implies returns the review questionnaire ID. This part is extracted as a separate method. Following is the diff after refactoring <image>. This method returns the best review to meta-review map if meta-review exists for a review. We found the same lines repeated in two places, so we extracted that part as one method. In one place the method includes a logic to get the reviewers in a map. Hence that part is also extracted out as a method. Following is the diff after refactoring <image>. Each if statement increases the cyclomatic complexity by 1. It is refactored by adding constant EXPORT_DETAILS_FIELDS with all the fields to export. <image> 2) Refactoring delete method The delete method has the following lines of code. Each line has a call to each method. <image>. 1) Three methods in assignment.rb file has the following check <code> Each predicate in if condition count towards one decision point and hence increase in cyclomatic complexity. Also the same condition check is done in 3 to 4 places. Hence we can write a separate method like below and call in all places the conditions self.staggered_deadline and topic_id.nil? <code> 2) Similarly the method valid_num_review has if condition with 3 predicates as can be seen below Before Refactoring <code> Here the 2 if conditions are quite similar. Also both are checking 3 conditions. Hence the condition check part can written as a separate function as below After Refactoring <code> <code> By this way, it is both reducing cyclomatic complexity and improving code reuse. <image>. The rspec tests for the assignment.rb file is pretty much complete with tests written for all the methods called from outside the file. Two rspec tests were failing before we started the refactoring. The methods added as part of refactoring are given a private scope and are added in assignment.rb since it is not called from outside. Testing the public methods implicitly tests these private methods. These errors existed in the base code before we started the refactoring. The assignment.rb file has too many methods in one file. It maybe a better idea to move some of the methods which are only used with the views to assignment_helper.rb file.","The wiki page includes screenshots from the IDE.  Although they are a bit blurry, they show very well the code changes that have been made.  The prose descriptions are also quite readable. Their test plan mentions that they have done exhastive testing on the UI but does not mention the scenarios. Their automated testing section mentions that they have fixed two previously failing tests but does not mention which ones either. "
E1712,"This project is part of an educational web application called Expertiza. <link> is an open source project managed by the faculty and students of NCSU. In the existing code the InvitationController and the JoinTeamRequestsController do the expected task but the there is a lot of redundancy and duplicity in the code, and the comments in the code are few and sparse. The aim of our project was to reduce the complexity of the controller by removing redundant code adding comments so that the code is easy to understand and all the variables used in the code are clearly explained. Invitations controller handles the functions required to send invitations out to potential teammates for a project. Once a student decides to invite someone into his assignment team the controller performs some checks before sending out the invitations. These checks are performed in the create function. The current implementation has a lot of redundant code and many nested if statements. The ABC size of the method is also very high. The controller also has functions which take care of cases where an invitee accepts/declines an invitation. There is also an option to retract a sent invitation which is handled by the cancel function in the controller. 1. Rename to invitations_controller.rb, in accordance with current naming convention. 2. The ABC size for create method is too high and needs to be refactored along by removing other nested if's in create and update_join_team_request methods. 4. Add comments explaining what each method does, and comments on how important variables are used. 5. Pending invitations needs to be displayed in the same format as other tables. 6. Feature tests need to be written for the controller. 1. A new private function check_users was added which performs some basic checks before the create function is called. In the original implementation, there were a lot of nested if conditions which checked if a user is valid, is a participant in the project, and if the team has slots available. All these checks were the cause of the nested if statements because they needed to be checked before an invitation is sent out to a student. The nested if's were removed by moving all these checks into the private function thereby reducing the ABC size of the create method. 2. Nested if statements in the update_join_team_request were removed by breaking the nested statements into separate conditions and using return when the condition fails. For example, when checking if the user is valid, instead of using a nested condition to check validity, if the user is not valid then we throw an error message and return from the function. The code snippet showing the change made is shown below. Before refactoring <code> After refactoring <code> 1. Styling was added to the pending invitations table in accordance with the existing tables so that the view is uniform across the entire page. 2. The name of the controller was changed in accordance with the current naming convention and comments were added explaining why some important variables were used and also giving more clarity to whoever wants to modify the code in the future. There were very few comments earlier and they did not explain much about what was going on in the functions. The below test cases written can be found at spec/features/invitation_check_spec.rb. A student is initialised and an assignment is assigned to the student. <code>. <code>. <code>. <code>. Some of the possible test cases which can be used for the controllers are given below. 1. Test for create method in invitations controller: Before sending out an invitation to another student there a lot of checks that need to be performed such as checking if the invitee is a valid user, if the student is a participant in the project etc. All these scenarios are tested and finally, we make sure that a new invitation has been created in the database. The image below gives a visual representation of all the checks performed before sending out an invitation. <image> 1. Test for create method in join teams request controller: Similar to the create method in the invitations controller we need to do a lot of checks before sending out a new join team request. The below flow chart explains all the checks that need to be asserted before sending out a new request. <image> 1. Test for cancel method: The cancel method is called when the student who sends out an invitation wishes to retract the sent invitation. In this scenario the invitation is destroyed from the database and we assert that change by checking the change in the count of the database. <image> 1. Test for decline method: In this test, we assert the change of reply_status to 'D' in the database. Further improvements to this project would be to write feature tests for the scenarios discussed above. VCL is used to host the project remotely. The login credentials as an instructor are ""instructor6"" with password ""password"". To log in as a student, you can use 'student5425' with password 'password' <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.",check_users is a bad method name (what are they being checked for?).  Should be something like eligible_to_join.  Ditto for check_team.  Why isn't cancel called retract?  Good documentation of testing scenarios.
E1747,"Expertiza is a web application where students can form their teams, submit their projects, peer-review other's work, view their grades and so on. Expertiza is open-source, maintained by students and faculty in NC State university. Code Refactoring is the process of restructuring existing computer code—changing the factoring—without changing its external behavior. Refactoring improves nonfunctional attributes of the software. Advantages include improved code readability and reduced complexity; these can improve source-code maintainability and create a more expressive internal architecture or object model to improve extensibility. Typically, refactoring applies a series of standardised basic micro-refactorings, each of which is (usually) a tiny change in a computer program's source code that either preserves the behaviour of the software, or at least does not modify its conformance to functional requirements. Many development environments provide automated support for performing the mechanical aspects of these basic refactorings. If done extremely well, code refactoring may also resolve hidden, dormant, or undiscovered bugs or vulnerabilities in the system by simplifying the underlying logic and eliminating unnecessary levels of complexity. If done poorly it may fail the requirement that external functionality not be changed, introduce new bugs, or both. Test last development is a traditional and most common approach of testing where testing is done only after implementation code has been written. But test driven development, test first coding or TDD is a relatively new concept where test cases are written before writing the implementation code. RSpec is a 'Domain Specific Language' (DSL) testing tool written in Ruby to test Ruby code. It is a behavior-driven development (BDD) framework which is extensively used in the production applications. The basic idea behind this concept is that of Test Driven Development(TDD) where the tests are written first and the development is based on writing just enough code that will fulfill those tests followed by refactoring. It contains its own mocking framework that is fully integrated into the framework based upon JMock. The simplicity in the RSpec syntax makes it one of the popular testing tools for Ruby applications. The RSpec tool can be used by installing the rspec gem which consists of 3 other gems namely rspec-core , rspec-expectation and rspec-mock. sign_up_sheet_controller.rb is the controller to handle topic assignment. sign_up_sheet_controller.rb is a fairly complex file. It contains a lot of methods that are long and hard to understand. These method need to be broken down into simpler and more specific methods that are easier to read or understand. Also, the few instances of code duplication that exist should be removed. 1. Refactor ""list"", ""save_topic_deadlines"" method 1.1. 1.Split into several simpler methods and assign reasonable names 1.2. 2.Extract duplicated code into separate methods 2. Use find_by instead of dynamic method 3. Complete the pending tests in sign_up_sheet_controller_spec.rb, and write integration tests for newly-created methods. Refactor corresponding methods, and only then finish pending tests. Refactor ""list"" method The 'list' method is a long method which is fairly complex and hard to read. It is not following ""good Ruby and Rails coding practices"". In ""list"" method we found that ""signed_up_topics"" occurred too many times, here we split it into three different methods, named as ""find_signed_up_topics"" ,""find_selected_topics"" and ""list"". The changes are showed below. Previous Code: <code> Modified Code: <code> <code> <code> Refactor ""save_topic_deadlines"" method We found the ""save_topic_deadlines"" method is not hard to read, but it's a little bit long and some of the codes can be reused. Here The ""save_topic_deadlines"" method is modified and two new methods were created, named as ""get_instance_variable_assignment"" and ""get_instance_variable_topic"". Previous Code: <code> Modified Code: <code> <code> <code>. 1.Complete pending test in sign_up_sheet_controller_spec.rb. 2.Write integration test for newly created methods. 3.Write test for refactor methods. The most important two tests are about ""list"" method and ""save_topic_deadlines"" method. Here we wrote 27 examples of test and all of them are passed. <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code>. <link> video about Refactor <link> video about test.","Most of the narrative is in providing background (e.g., about Expertiza and RSpec) that most readers would already know.  There are paragraph-long descriptions of two refactorings, but for the rest, the code is just pasted in.  That is not helpful; it's easier to read the code on Github, where you can see what was added, deleted, and sometimes, moved."
E1850.2,"Expertiza is an open source web based on peer review system developed and maintained by students and faculty members at North Carolina State University. It enables students who enrolled in a particular course to form online teams, complete assignments, review other's work and receive feedbacks of their works. Review_response_map.rb is used to prepare data for peer review. But there are no unit tests for it. 1. Create a new file named review_response_map_spec.rb under spec/models folder 2. Write RSpec unit tests to make the path coverage above 90%. 3. Coverage edge cases. 4. Achieve high branch coverage. Use the mutant-rspec gem to measure test thoroughness and fault-finding capability of tests. 1. spec/models/review_response_map_spec.rb. Follow the instruction on <link>. To better test the methods, we read the whole review response map model and understand the functionalities of what we want to test. 1.1. Questionnaire: find the specific questionnaire. 1.1. Get title: set the title. 1.1. Delete: delete the feedback response map and metareview response map. 1.1. Export fields: set the fields of export. 1.1. Export: export the review response map. 1.1. Import: import the review response map from local. 1.1. Show feedback: show the feedback via html. 1.1. Metareview response maps: fetch all the metareview response map and return. 1.1. Get responses for team round: get the responses for given round. 1.1. Final versions from reviewer: return the final review version from reviewers. 1.1. Review response report: find the reviewers for a given assignment. 1.1. Email: send an email to the members in a team. 1.1. Prepare final review versions: prepare the final review versions for an assignment. 1.1. Prepare review response: return the review responses id for an assignment. We mock the necessary instances for the test in the beginning of test file. <code>. Write test for the methods in review_response_map.rb. Questionnaire method returns a questionnaire associated with an assignment. <code>. Get_title method returns the title. <code>. Delete method deletes the feedback_response_map and metareview_response_map and return review_response_map. <code>. Export_fields method which shows the title of export csv file, ""contributor"" and ""reviewed by"". <code>. Export method exports the name of reviewer and reviewee and return the map. <code>. Import method allows user to import the csv file and check it. After that, it returns the name of reviewers. <code> When reviewee user = nil <code> When reviewee user exists but reviewee user is not a participant in this assignment. <code> When reviewee user exists and reviewee user is a participant in this assignment. <code> When reviewer user doesn't exist. <code> When reviewer user exists. <code> When reviewer user is not a participant in this assignment. <code> When reviewer user is a participant in this assignment. <code> When reviewee_team = nil <code>. Show_feedback method returns the html associated with response. <code>. Metareview_response_maps method returns metareview_list associated with responses. <code>. Final_versions_from_reviewer method returns the questionnaire and response ids associated with reviewer. <code>. Review_response_report method returns the participants associated with assignment. <code> When review user exists. <code> When review user doesn't exists. <code>. Email method can successfully send an email. <code>. Prepare_final_review_versions method returns the final review versions. <code> When round exists. <code> When round = nil. <code>. Prepare_review_response method returns the response id associated with assignment. <code>. The tests can be run on the terminal from inside the expertiza folder using following commands: <code>. app/models/review_response_map.rb 100.0 % covered 102 relevant lines. 102 lines covered and 0 lines missed. Full video for this test can be found at <link>. <link>.","The ""necessary instances"" built at the beginning should be described.  For the other tests, their outcomes should be described (why they pass or fail).  It would also be good to motivate why the tests are listed in the order that they are."
E1665,"<link> is a web application which enables students to choose a topic in an assignment, submit assignments and peer review others' work. Staggered deadline means having different deadlines for different topics under the same assignment. Deadline of different topics under the same assignment may need to be different for reasons like dependency of one topic on another. According to the instruction, we design 3 test cases: Initial state: Two students with different topics submit their work before the assignment's submission deadline in round 1. Scenario 1: Change deadline of topic 1 to bring it into review stage in round 1, check if the student assigned with topic 1 can review others' work, check if the rubrics are right for round 1. Scenario 2: Change the deadlines of both the topics to bring them into review stage in round 2, check if the students assigned with these topics can review each other's work, check if the rubrics are right for round 2. Scenario 3: Change the deadline of both the topic to bring them into finish stage in round 2, check that the students assigned with these topics are unable to review each other. Our test plan is divided into the following steps: 1. Create an assignment: Create an assignment with topic with varying rubric by round feature. 2. Add participants to newly created assignment. 3. Submit a Topic: Impersonate each participant, choose a topic and submit something. 4. Change topic Deadline: Change deadline of each topic and let each topic be in different stages (like submission round 1, review round 1, submission round 2 and review round 2) 5. View topic stage: Impersonate each participant and check their topic’s current stage on student_task#list view. 6. Submit reviews: Participant with topic in review stage can review other participant’s work, ensuring that right rubrics are used for different topics.The reviewers can fill in the rubrics, save and submit their reviews successfully. 3. Fill in the textboxes with assignment name, and assignment directory and other necessary details. 4. Click the 'Create' button. 5. Click on the link 'Rubrics'. 6. Check the box 'Review rubric varies by round?'. 7. Click on 'Save'. 8. Click the link 'Topics'. 9. Click on 'New topic' 10. Fill in the Topic id, Topic name,Topic category and Number of slots. 11. Click 'Create'. After returning, the assignment created is listed under 'Assignments' tab. 1. Create a new assignment 'Assignment1665' using factories, with two review rounds and Staggered Deadline enabled. 2. Added three participants to the newly created assignment using factories. 1. Create a stub to Impersonate the student 'student2064'. 2. Click on 'Assignment1665' from the task list. 3. Click on ‘Your Work’. 4. Fill in the textbox with the submission link. 5. Click on ‘upload link’ On clicking the 'upload' button, the submitted link is displayed on the page. 1. Create an assignment 'Assignment1665' using factories, with two rounds of reviews, and the staggered deadline functionality enabled. 3. Create two topics 'Topic_1' and 'Topic_2' under 'Assignment1665' using factories. 4. Create assignment due dates for 'submission' and 'review' for two rounds using factories. 5. Set the topic due dates to corresponding assignment due dates using factories. 6. Change the different deadlines of one topic to different dates. On returning, click on 'Assignments' tab, and click on 'Edit' under 'Actions'. Click on the 'Topics' tab and then click the link 'Show start/due dates'. 1. Change the deadline date of topic assigned to 'student2064' to a past date and change deadline date of topic assigned to 'student2065' to a future date. 2. Impersonate a participant 'student2064' using a stub. 3. Click on 'Assignments' tab on top of the page. 4. The page should display the current stage of 'Assignment1665' as 'Review' 5. Impersonate 'student2065' using a stub. 6. Click on 'Assignments' tab on top of the page. 7. The page should display the current stage of 'Assignment1665' as 'Submission'. 1. Impersonate 'student2064' using a stub. 2. Click on the link 'Assignment1665'. 3. Click on the link 'Others' work'. 4. Select a topic to be reviewed. 5. Click on the link 'Begin'. 6. The student can see 'Questionnare1' for the review round 1. 7. Fill in the response checkboxes. 8. Click the button 'Save Review'. 1. <link> 2. <link> 3. <link> 4. <link>.","I question whether the tests are really exhaustive because only a couple of different combos of deadlines and rights are checked;; suppose someone tries to review a topic too early, for example?  But as far as the writeup is concerned, the tests are well described, but the code should also be shown, so that the reader could easily verify what is being tested."
E1824,"The way Expertiza is set up right now is that only peers can review your work. This project aims to implement this feature by allowing course staff to review the project on the same metrics as other students who review the project. Peer review is a great way for students to learn about how well they have developed their application. 2. The reviewer might not know how well they are reviewing the peers work. <image>. <image>. We performed the following changes to let staff perform reviews as well: Step 1: Add a way for the instructors to perform a review. To do this, we added links for performing/viewing/editing/updating a review in the assignment submissions view. When the instructor/TA reviews a work for the first time, he is added as a participant and a review response mapping is created. Files edited: 1. View: app/views/assignments/list_submissions.html.erb - To add links in the instructor view 2. Controller: app/controllers/review_mapping_controller.rb - Method: add_instructor_as_reviewer Code snippet from the controller: <code> <image> In the second case, we can see a 'Perform review' link. This is the initial state when instructor review has not been added to the submission. Once the instructor adds a review and submits it, we can see the 'View review'. In case he just saves the review, an 'Edit review' link will appear. If the review deadline of one round is passed, the 'Edit review' link becomes 'Update review' link. This follows in line with what the student sees while performing a review. However, the course staff will be allowed to perform a review even if the deadline for reviewing has passed. Step 2: Add the instructor review in Your Scores table in case he has reviewed your work. Files edited: 1. Assets: app/assets/stylesheets/grades.scss - To make an instructor performed review distinct from other reviews 2. View: app/views/grades/view_team.html.erb - Modified the ""Others work"" page to include the instructor review as well as ensure the score is not used. 3. Models: 1.1. app/models/answer.rb - Method: compute_scores | Modification in logic to ensure instructor review scores are not counted in the overall score of the student. 1.2. app/models/vm_question_response_score_cell.rb - Included a new variable called 'is_instructor_review' to identify an instructor review 1.3. app/models/vm_question_response_row.rb - Change in average_score_for_row method to not include an instructor review score 1.4. app/models/vm_question_response.rb - Modified the add_answer method to include the is_instructor_review to each row_score object Code snippet from the add_answer method: <code> <image> A student should be able to make out if an instructor has reviewed his/his team's work. In case the instructor performs a review on the team's work, it will highlight the instructor's review with a golden border as seen in the round two score table along with explicitly stating that it is an 'Instructor review'. The average peer review score for the team has been modified to exclude the instructor's scores. Additional Files modified: 1. Controllers: 1.1. app/controllers/response_controller.rb - Change in re-directions in case of an instructor taking him back to the submissions page. | To identify whether the user is a TA or an instructor of the current course Code snippet from the model: <code>. 1. it ""should let instructor/TAs perform a review for the submission of latest finished round if instructor/TAs has not started a review for the submission yet"" 2. it ""should let instructor/TAs save a review"" 3. it ""should let instructor/TAs review a previously saved review"" 4. it ""should let instructor/TAs edit a previously saved review"" 5. it ""should allow instructor/TAs perform a review after the deadline for reviewing has passed"" <code> Controllers testing: review_mapping_controller#add_instructor_as_reviewer <code> More testing: 1. it ""should let instructor/TAs update a review for the submission of latest finished round if instructor/TAs performed and saved a review for the previous round"" 2. it ""should show ""Instructor review"" when a student views feedback on his/her submission if an instructor/TA has reviewed his/his team's work"" 3. it ""should exclude the instructor's/TA's review score when calculating the average peer review score for the team"" 4. it ""should exclude the instructor's/TA's review score when calculating the average score for each question in the review"".","The description is generally clear, but the organization is not.  The Problem Statement evidently consists only of a Current Scenario, which is subdivided into two parts.  The Proposed Solutions and Implementation are much longer, but are not divided at all.  The Test Plan is mostly pasted code, with minimal descriptions; it would be better just to refer the reader to the Github repo."
E1871,"Contents 1.1. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.3. <link> 1.4. <link> 1.5. <link> 1.1.1. <link> 1.1.2. <link> 1.6. <link> 1.1.1. <link> 1.1.2. <link> 1.7. <link> 1.1.1. <link> 1.1.2. <link>. For this project, our task was to create a view which consolidates information related to each assignment for each student in a course in a single page. <link>. <link>. This feature was requested by Dr. Gehringer in order to ease the process of collecting student grades for a course for reporting at the end of the semester. Looking through the commit history, we determined that 360 Assessment had been removed intentionally in commit <link> for unknown reasons, then added back when Zhewei needed to count the total reviews done by each student in a semester in commit <link> . It was then removed again when <link> the committer determined that the functionality the page was providing could be gained by accessing View Aggregated Teammate and Meta-Reviews from the Manage Courses page. This is the procedure for accessing the Grade Summary by Student view. <image>. 1.2. Once we have a course, it is straightforward to gets the assignments and course_participants. 1.3. For each course participant and for each assignment, we then conduct the rest of the procedure. 1.4. We get the user id from the course participant. 1.5. We use the user id to get an assignment_participant object from the assignment. 1.6. We use the assignment and user ids to get a topic id from the SignedUpTeam model. 1.7. Once we have the topic id we can add the name to the list for the UI. 1.8. Use the assignment id and user id to get a team id from the TeamsUser class. 1.9. Use the team id to get a team object. 1.10. Get a grade_for_submission from the team object. 1.11. Get questionnaires from the assignment. 1.12. For each questionnaire in an assignment, use AssignmentQuestionnare model to get rounds. The view for Grade Summary by Student must contain the following information, according to the requirements document and consultation with Dr. Gehringer. 1. 1.1. Each student's name and id in a course. 1.2. Each assignment given to each student. 1.3. The topic name for each assignment. 1.4. The topic id for each assignment. 1.5. The grade for each assignment. 1.6. The peer review score for each assignment. 1.7. The total score of each student over all of their assignments. From the Manage Courses page in Expertiza, we intend to place our view behind the 360 Assessment icon for each course. Being able to view every student's complete grades for each assignment constitutes a 360 degree view of every student's performance in a course, and no functionality exists behind the icon currently, so this seems to be a logical choice for placement. It shows our intention to list each student in a row, and to have each column be their assignments. We wanted to contain all the information about their assignment within the column, but did not decided on columns-within-columns until reviewing with Dr. Gehringer. <image> We took Dr. Gehringer's feedback and have created the following rough prototype for the view. <image>. All of the information required in this view is present in the system: the controller for this view will simply need to make the appropriate queries to the models and database. We intend to create a hash of students given the particular course id, and then use the course id and the student id to retrieve the specific information about the assignments. <link> <link>. Controller tests are tricky to write, as they can't be sensitive to the model's implementation or how the information will be displayed. This is identified as a best practice for controller tests in <link> . Here is an image of part of our Controller tests, showing how we handle the case where a course doesn't have any students. <image> Here is an image of some of the tests which verify that the controller instantiates the view's instance variables. <image>. To verify that our view is correct, we'll implement some simple feature tests. Given some dummy students with dummy assignments with dummy fields, we expect that our view's page should display certain information. In this way, we will verify that our view is performing its job. <image> Here is an image of some of the content-check tests for this feature. <image>.","This design doc has uneven depth.  The testing code is described in great detail, but the implementation code is only described in outline form (though the outline is quite readable).  There is a mockup of a screen, but not a screenshot from the final version, which would have been more useful."
E1558,"Primarily these changes involved the refactoring of overly complex methods, renaming methods for better readability, and the addition of missing unit tests. Project Requirements: 1. Code Climate<ref name=""Code Climate""> <link> </ref> shows import method is complex, because of lots of checks. This method can be fixed by adding private methods for raising import error. 2. Get_assessments_round_for method can be renamed to get_team_responses_for_round. 4. write missing unit tests for existing methods. The Single Responsibility Principle states that each class and method should have sole responsibility over one single part of the functionality of the system<ref> <link> </ref>. A prime example of a method that initially violated these principles was the import method, which in addition to performing the core import processes also performed a number of checks that would be more properly extracted into private methods. CodeClimate reports showed the import method to be overly complex, with a number of checks being included within the import method itself. The resolution for this problem was to refactor the import method, creating private methods to perform the null checks and throw import errors. Prior to refactoring, all null checks were performed within the import method. After refactoring, the import method adheres to the single responsibility principle, performing only key import tasks while making calls to private methods for any necessary validation. The size of the import method was reduced by doing this and counts for better readability of the code. Also, this method is a very important one and care was taken so that any existing functionality did not break. Before refactoring: <code> After refactoring: <code> Private methods added: <code> <code> <code> <code>. The get_assessments_round_for method’s name failed to provide a clear idea of the method’s purpose and functionality. We also removed the return statement at the end of the method. Before refactoring: <code> After refactoring: <code> The change in method name also required changes to the following files that referenced it: /app/models/assignment.rb:436: <code> ./app/models/assignment_participant.rb:268: <code>. The metareview_response_maps method was unnecessarily complex. We also renamed the metareview_response_maps method to get_metareview_response_maps method to be more descriptive about the intent of the method. Before refactoring: <code> After refactoring: <code> The change from this renaming also requires changes in the following files: app/models/assignment.rb:361: <code> app/models/assignment.rb:362: <code> app/ models/assignment.rb:363: <code> app/models/assignment.rb:377: <code> app/models/assignment.rb:378: <code> app/models/assignment.rb:379: <code> app/models/assignment_participant.rb:73: <code> app/models/response.rb:4: <code>. The export method contained mappings.sort! was not a method for an ActiveRecord_Relation"". So we changed that line of code to mappings = mappings.sort { |a, b| a.reviewee.name <=> b.reviewee.name } Before refactoring: <code> After refactoring: <code>. The final_versions_from_reviewer method was too long and repetitive. We removed common functionality from within the if and else statement and put it in a private method final_versions_from_reviewer. These private methods make the class more readable for other programmers. Before refactoring: <code> After refactoring: <code> Private methods added: <code> <code>. One issue flagged by CodeClimate that we did not change was to use the find_by method instead of where().first method. The where().first method occurs in the import, get_assignment_participant, and create_response_map methods. We also made some of the methods shorter by removing redundant functionality and adding private methods to methods with a lot internal functionality. We also added private methods in places where we saw repeated patterns to make the code DRYer . The test naming convention used is ""method_<name of method that is being tested>"". For example, the unit test for the export method is ""method_export"". If there are multiple test for one method the name of the test will include the test case after the normal naming convention. For example, one of the unit tests for the import method checks for an invalid assignment. The name of this method is ""method_import_invalid_assignment"". NOTE: Since this was a refactoring of the code and methods, the existing functionality was supposed to remain the same and not break for the changes we've made.","Good job of explaining changes; however, there are clearer ways to show code changes (side by side, or with github's red & green bkgrds. for code removed & added)."
E1906,"<image>. <link> <link> <link>. E1906 is an Expertiza based OSS project which deals basically with refactoring stage deadlines in assignment.rb file.Class assignment.rb has several methods for checking what kind of stage an assignment is in at the current time.These are: 1. current_stage_name(topic_id = nil) 2. find_current_stage(topic_id = nil) 3. get_current_stage(topic_id = nil) 4. link_for_current_stage(topic_id = nil) 5. stage_deadline(topic_id = nil) The goal of the project focuses on refactoring some of the above more complex methods, modifying some of the language to make it more Ruby friendly, removing some redundant code. A new private function next_due_date was added. <code> 1. One example of refactoring <image>. The above five methods were being used at various places to check if the assignment is 'Finished' which made the code very redundant. Assignment is said to be finished if the next_due_date is nil. We have created a new method ""finished?"" that checks if the next_due_date is nil (which means that the assignment is ""finished""). <code> We have called this method at all the places where previously different methods were being used to check the same thing. 1. Signup sheet table uses assignment finished? method instead of current_stage_name <image> 1. Use assignment finished? method where only a comparison to ""Finished"" was being done using get_current_stage and find_current_stage <image> <image>. The check for a topic_id to be nil when it is a staggered assignment and return 'Unknown' when it is true was being done at many places.This was not following Ruby and Rails rules. To make the code DRY and more easy to understand,we have created a new private method ""topic_missing?"" to check if the topic_id is nil in case of staggered assignment. <code> 1. Refactoring with new method topic_missing? <image> 1. stage_deadline( topic_id = nil) changed according to the modifications done <code>. find_current_stage(topic_id=nil) method is being used only locally in the assignment.rb and once in the student_teams controller to check to check whether to display or not the reviews option for team members.This method was calling another function to get the next_due_date for an assignment that was like nesting of calls and not very Ruby standard. We have removed this function and replaced it with finished? <code>. get_current_stage method is returning the stage name which the assignment is in at current time.This is not very clear from the name of the method. We have changed the method name to current_stage_name(topic_id=nil) to make it more clear to understand. <code> 1. Refactored get_current_stage with current_stage_name <image>. current_stage_name(topic_id=nil)[This is the initial one] method was implementing things which was already being done by other methods and thus this method was redundant. The initial code given was: <code> First thing we noticed was that due_date.deadline_name was always nil because there was no field to enter the deadline name on the form, and therefore, the statement <code> was never getting executed. This method was checking for the due_date.deadline_name which was always nil. After removing the dead code, we get: <code> Looking at the current_stage_name(topic_id=nil)[New one] method shown below and comparing it to what we have above, this code was surely redundant.That is why we removed this code and made appropriate changes wherever required within assignment.rb. 1. Below is the current_stage_name method for reference <code> The associated rspec tests that tested the old current_stage_name method were also no longer needed. Removed function. <image> Removed test related to the function. Removed the one call to this function. <image>. We have created and modified the tests as per the changes done in our project.We have added the tests to the file <link> and they are passing 100%. The current version of expertiza did not have any tests for get_current_stage(topic_id=nil) method.Now as we have changed it to current_stage_name(topic_id=nil),we have added its tests as well. <code>. We have added tests for the new method that we have added finished?. <code> As topic_missing? method is made private,there was no need to test this. We also have corrected the tests for stage_deadline according to the modifications done(It is using finished? and topic_missing? methods). <code>.",Great job!  Good documentation of changes made for each issue. There are no deficiencies that I can find.
E1953,"Students can also peer review other students' submissions. The following tasks were accomplished in this project: 1. If tagging is enabled, number of total tags per round is shown on student's score page 2. Implemented feature which shows number of tags student have entered 3. Implemented feature to show number of tags entered and total number of tags in Assignment page. 4. Implemented feature to show tagging counts dynamically when student change tagging type in score page 5. Added RSPEC testcases for testing changes done for tagging. Expertiza has a feature of peer review where other teams can provide feedback on student's work. There is also another feature of ""Tags"", where a student can answer if the feedback provided were helpful or not. Tags can vary from assignment to assignment but the main motive of it is to provide information on whether the feedback provides helpful information for student's assignment. The picture below shows an example of tags. For a particular assignment, there may be a lot of questions and hence multiple feedback. Students might miss a few tags and they might go unanswered. This feature will provide students to keep track of answered tags and show them how many tags have they answered out of total tags on the page. For counting, we are primarily concerned with two numbers: the number of possible tags for an assignment and the number of completed tags for an assignment. The former is more difficult: possible tags are stored as TagPromptDeployments which do not have a 1:1 correspondence to the number of prompts the user sees on their page. <image> The green classes are used to count the number of tags done, the red classes are used to count the number of tags possible, and the yellow classes are used to calculate both counts. All classes help to narrow the scope to a specific user and assignment. On clicking of particular Assignment, student can see his/her teams, work, scores, etc. There is no feature which allows student to show how many of the review tags has he/she answered on this page. This task implements this feature where student can see answered tags with respect to total tags in Assignment page. app/controllers/student_task_controller.rb - The following code counts the number of Tags present in an assignment and total number of answered tags in that particular assignment. <code>. On clicking of particular Assignment>Your Scores> student can see his/her score. Student can also see all the reviews per rounds in particular assignment. This new feature will allow student to see number of answered tags per round with respect to number of total tags present in particular round. app/controllers/grades_controller.rb - The following code counts the number of Tags present in a round and total number of answered tags in that particular round. <code>. If a user changes their tags, the page formerly needed to be refreshed in order to display the correct counts. app/assets/javascripts/answer_tags.js - The following code correctly increments/decrements the tag count on the page based on the user's action. <code>. Please find below RSpec Test cases for this feature. Follow the below steps to Verify the fix for this issue: Test Case 1 <code> Test Case 2 <code>. Follow the below steps to Verify the fix for this issue: Test Case 1 <code> Test Case 2 <code>. To test this we followed following steps:- 1. Login as a student 2. Select Assignment for Assignment Home Page Test Case 1 This page should show number of tags completed and total tags present including all the rounds in that particular assignment. ✓ Test Case 2 On selecting Your Scores on Student Task page, Each round should show Review Tagged Column. ✓ Test Case 3 Review Tagged Column should consist of tags completed and total tags count for that particular round. ✓ Test Case 4 Review Tagged Column should not consist of tags completed in all rounds and total tags count. ✓ Test Case 5 Review Tagged Column should dynamically increase or decrease tag count when user change their tagging. Below are instructions for navigating through expertiza to see the review tags in action. 1. Go to <link> and log in as {username: student7552 password: password}. It reads (You have tagged the available tags completed / total available reviews). <image> 5 . Further, click on ""Your scores"". On the next page that shows up, click on a row in the table to see the tags. Notice in the last column of the header of the table is a cell containing the available tags completed / total available tags. <image> 6. After clicking on a row to reveal tags drag the blue square towards 'No,' 'Yes,' or the middle. Observe that the tags left / total tags has updated. 7. To observe the new per round tagging capabilities log out and then log in as {username: student8115 password: password}. In the next page click on ""Your scores"" as in step 4 above. Scroll down and behold tagging statistics for each round in the last column of the table headers.","The ""Problem Statement"" section is not really a problem statement; it is a list of what was accomplished.  It should be later on in the report.
Tagging is about more than helpfulness; it can be used to identify whether or not a review comment has any characteristic.  If someone was unfamiliar with tagging, this explanation would not be of much help in understanding it.
The design diagram is quite useful.  So is the process diagram.
The code for all the tasks should include comments!  There are comments only for Task 3.
The test cases not explained at all, beyond a listing of the code. There should be an explanation of what the test does, and why it verifies that the new functionality works.
When it says, You have tagged x of y reviews, shouldn't it say, You have tagged x of y review comments?  In the example, there are only 17 reviews, but it says that there were 25 reviews to tag.
So, the visuals on this wiki are very good, but the prose needs improvement."
E1823,"1. index This method is used to list users in the database. A permissions check is done first to verify that the current user has permission to view the list of users. If the user is a student, he is redirected away from the page. All other user roles have access to the page. 4. list This method calls the get_user_list method in the user model which returns a list of users according to the role of the user that calls the method. 6. show_selection This method is used to show the users. It first detects if this user is valid or not. if this user is nil, it will redirect to the ""list"" page. If this user is valid, it will call the get_role method to get the role information of this user. and then use the role information to determine if this user is available for editing. For users available for editing, this method will render show ""page"", otherwise, this method will redirect to ""list"" page. In summary, this method will direct to ""show"" page, when the user is able to be edited, otherwise, it will go to ""list"" page. 7. show This method is used to show the details of a user. It first detect is the user is valid. There two condition for an invalid user: 1) the id of user is nil; 2) current user role is not student and the session id doesn't equal to the user id. Otherwise this user is valid. 8. new This method is called when method create is used to create a new user. 10. create This method is called when the user wants to create accounts. Thus, this edit method is called when accessing user's edit page and will pull the relevant user out of the database via user's id that stored in params[:id]. 14. update ""resources :users"" in routing rule makes update action get called when the form in user's edit page is submitted. This method will first find the relevant user by user's id that stored in params[:id] and then updates the user's information in the database based on the submitted params hash. If the update is successful it shows a success flash and redirects to user's show page otherwise it renders user's edit page. When this method is called, if no current user or current user is a student but is not the user stored in session, it will redirect to home page of the user stored in session. Otherwise generate_keys (a method of user model) will be called on the current user and the return value will be assigned to an instance variable @private_key defined in UsersController. 1. Download and set the Expertiza environment 2. Determine which methods should be tested 3. Define all the conditions needed to be tested for each method The methods have already been introduced on above, here are the test plan for each method: 1. index 1.1 ""If the user is student, we check if proper redirection is taking place"" 1.2 ""Else, the appropriate list of users should be rendered according to the role of the current user"" 2. auto_complete_for_user_name 2.1 ""The page should render suggestions only of those user names that are similar to the one being typed and not all user names"" 3. set_anonymized_view 3.1 ""The method should add the session ip to the list of anonymized ip's and redirect to the previous page "" 4. list 4.1 ""The @users instance variable should contain all the users that are permitted to be viewed by the current user. This is tested by the same test for index"" 5. list_pending_requested 5.1 ""check if it will render users/list_pending_requested page"" 6. show_selection 6.1 ""check if the user is nil, will the page redirect to users/list page"" 6.2 ""check if the user is not available for editing, will it redirect to users/list page"" 6.3 ""check if the user is available for editing, will it render users/show page"" 7. show 7.1 ""check if the user id is nil or if the role is student and session id equals to id, will it redirect to home"" 7.2 ""if the user is valid, check the return value"" 8. new 8.1 ""check if this will render users/new page"" 9. request_new 9.1 ""Here isn't any conditional sentence. Otherwise, register the user by email address."" 10.2 ""Is the user's information valid? 11.2 ""is the user already existed and valid? If the user already exist, send notification. 14. update 14.1 ""When user is updated successfully, it shows correct flash and redirects to users/show page. 14.2 ""When user is not updated successfully, it redirects to users/edit page."" (This also covers the condition that user is deleted successfully.)","This document reads too much like a reference model and not enough like a narrative.  It appears that the test descriptions have been changed in some ways, but it's still hard to determine what some of them do, e.g., """"does the user belong to any institution? If yes, good. Otherwise, set a new institution.""""  Shouldn't it really prompt the user for a new institution, instead of just setting it?"
E1876,"A key component of Expertiza is peer reviews, which provide feedback to authors so that they can improve their work. Expertiza also supports grading of these reviews to ensure students write quality reviews, helping them learn more about the assignment by looking at their peers' work. In addition, Expertiza allows for metareviews, which are reviews the authors of the original work write for the reviews of their original work. This author feedback is useful for grading the reviews because it indicates how helpful this review was to the authors of the original work. The objective of this project is to add metareview or author feedback information to the review report page, which shows a summary of all the reviews written by the students for an assignment. We need an additional column in the 'Review Report' page for reviews which shows the calculation of the author feedback. The aim of this project is to integrate the author feedback column in the summary page. In the page ""Review report for Design exercise"" (Log in as an instructor then go to Manage -> Assignments -> View review report. ), we are planning to add one more column to show the average ratings for the author feedback for a student's review of a particular assignment. The logic for calculating the average score for the metareviews would be similar to already implemented logic for the ""Score Awarded/Average Score"" column. The following method shows the code logic we are planning to write for calculating the average scores for the feedback given by authors for the reviews of their work. <code>. The following are the table structures we will need for this feature. First, the questions table has all the questions based on the questionnaire. We will be only concerned with the questions in the feedback questionnaire. The answers for each question in the feedback questionnaire are saved in the Answers table below based on the Question ID. Now, in order to know if the answer is a feedback by team members or a review by reviewer, the mapping for the Answers table is done by the response_id which is a foreign key to the Response table. This Response table gives us the map_id which maps to a response map table. Now, the response map table gives us information on the reviewer_id, reviewee_id, reviewed_object_id (which is the ID for the assignment being reviewed) and the type (whether it's a teammate review, author feedback, a regular review, etc.). We will have to fetch the answers from the Answer table based on response_id because in our case, the response is from a previous reviewee and not a reviewer. So, we will fetch those answers whose response type is FeedbackResponseMap and calculate scores for those questions for the corresponding ReviewScores table. <table>. <table>. <table>. <table>. 1. To calculate the average author feedback score: <link> 2. To populate the average author feedback score for the view: <link> 3. To add a field in the view: <link> 4. To add a field in the partial : <link> 5. To add a field in the partial: <link>. The methods in consideration are: 1. compute_author_feedback_scores 2. calc_avg_feedback_score(response) 3. calc_feedback_scores_sum The first method fetches the Feedback Response from ResponseMaps table based on the responses given earlier. Responses means the reviews given. Each feedback is saved to ResponseMap table with type = 'FeedbackResponseMap'. The feedback is fetched according to the assignment id, the reviewer who gave the review for that assignment and the reviews in each round. For each feedback response, we get the weight of the answer(feedback) submitted by author from Answer table and the weight of each answer from Questions table for the FeedbackQuestionnaire in consideration which we fetched from Questionnaire table. We calculate by taking an average of all feedbacks given by all team members to the reviews that they got. Following is the code snippet: <code> <code> <code>. We added another column to show the average author feedback score for each student who reviewed and for each team the student reviewed. <code>. We plan to test the response report page (/review_mapping/response_report?id={:assignmentID}) to make sure the new field (average author feedback) exists. <code> We also plan to manually test the response report page to make sure the new field is aligning well in the UI in the expected place. We will test the cases of one and multiple reviews by a reviewer and verify the number and average scores of the metareviews for those reviews are rendered correctly. Below is the screenshot of review report page which now shows a new column for Author Feedback Score. We added a rspec test in on_the_fly_calc_spec.rb which tests our method: 'compute_author_feedback_scores' that calculates the average feedback score. <link>. 1. <link> 2. <link> 3. <link>.","This is a concise summary of what the project does.  I would prefer that steps in the Relevant Database Tables and Implementation section be itemized; I think that would make it more readable, but overall, the authors have done a good job explaining how their project works."
E1954,"Expertiza is an educational web application created and maintained by the joint efforts of the students and the faculty at NCSU. It’s an open-source project developed on Ruby on Rails platform and its code is available on Github. It allows students to review each other’s work and improve their work upon this feedback. The following states the needs/issues with the current Expertiza project. Whenever an instructor/TA adds a new Assignment with the name of already existing assignment in the same course, then the newly created assignment is stored in the same directory as that of the previously created assignment which creates a conflict. Thus, need of a check that should be added to prevent two assignments in the same course from having the same name. Two assignments can currently be stored in the same directory. Thus, need of a check to stop two assignments from sharing the same directory. The directory name is not auto-generated from the assignment name. Hence, auto generation is required. The following is an Expertiza based OSS project which deals primarily with the AssignmentsController and AssignmentsView - _general.html.erb. Here is the details description of the project: The directory name is auto-generated from the assignment name. The instructor is allowed to edit It is done by changing spaces in the names to underscores. E.g., the directory for Program 1 is by default ""Program_1"". The special characters like '/','\','$' etc are to be removed from the auto-generated submission directory name. A check is added to prevent two assignments in the same course from having the same name. A check is made to stop two assignments from sharing the same directory. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>. A controllera, helper file and spec were modified for this project namely: 1. AssignmentsController 2. AssignmentsView - _general.html.erb 3. AssignemntsController - assignments_controller_spec.rb </br>. This is a controller that helps instructors create, modify, copy new assignments. Each assignment can be associated with specific Rubrics, Review Strategy and Due dates. This the View for creating the new assignments and editing the existing assignments. This view also handles specifications of Rubrics, Review Strategy and Dates. We worked on the following work items(WIs) WI1: Created exist_assignment and exist_directory to check if the assignment name and directory name already exists in the current course. If any of those are already present then flash the respective error, else save the assignment. Here is the create method of controller -> assignments_controller.rb: <code> WI2: Auto-generate the Submission directory name based on the assignment name. Allow, the Submission Directory name field to be explicitly editable by the instructor. Here is the javascript function introduced in views -> assignments -> edit -> _general.html.erb <code> <code> WI3: Earlier the assignment was getting generated even if the instructor was not giving it any name or submission directory path, now both of these fields have been made mandatory. Testing plan is divided into two - Rspec testing and UI testing. As the controller code has been changed now, which does not allows two assignment files to be stored with same name. Thus, in the spec file for assignments controller, a test case has been added for the same. <code>. Following Steps needs to be performed to test the project from UI:- Step 1: Login as Instructor (Username - instructor6, Password - password). Create an assignment under any of the existing courses with name as ""test assignment"". <image> Step 2: Check if the Submission directory field is automatically getting populated based on the assignment name (replacing spaces with underscores and removing special characters). <image> Step 3: Fill in the details for Rubrics and Review Strategy. <image> Step 4: Click on create. You should be able to see the assignment you created in the list. <image> <br Step 5: Now, try to create another assignment with the same name in the same course. Also, try to change the submission directory name to any of the existing assignment or same the assignment created in Step 2, Check if the system flashes an error in the creation of this assignment. <image>.","Wiki lists the code changes, but there are not many comments, and the approach is not described in prose.  Probably would not help a reader learn what was done.
They have added screenshots for changes and the test case they added.
Similarly, there is little prose to explain what the tests are doing.  There are screenshots, but they are huge, relatively speaking, and the reader would need to zoom out to read them.
"
E1625,"<link> is a web application developed using the <link> framework as a combined effort of students and faculty. The main advantage of using Expertiza, in an educational environment, is for the instructor to introduce peer reviewing among the students. The instructors can create and customize assignments, create a list of topics the students can sign up for, have students work on teams and then review each other's assignments at the end. 0536558. Additional funding from the <link> <link> (LITRE) program, the NCSU <link> , the NCSU <link> Initiative, and the Center for Advanced Computing and Communication. Confidence ratings are meant to provide objective value to student assigned peer review scores. During the peer review period it is important to determine which reviews are more accurate and show higher quality. Reputation is one way to achieve this goal; it is a quantization measurement to judge which peer reviewers are more reliable. Peer reviewers can use expertiza to score an author. If Expertiza shows a confidence ratings for grades based upon the reviewers reputation then authors can more easily determine the legitimacy of the peer assigned score. In addition, the teaching staff can examine the quality of each peer review based on reputation values and, potentially, crowd-source a significant portion of the grading function. <image> <link> There are two algorithms intended for use in calculation of the reputation values for participants. There is a <link> (the link accessible only to the instructors) available which serves a JSON response containing the reputation value based on the seed provided in the form of the last known reputation value which we store in the participants table. An instructor can specify which algorithm to use for a particular assignment to calculate the confidence rating. As the <link> on reputation system by observes, “the Hamer-peer algorithm has the lowest maximum absolute bias and the Lauw-peer algorithm has the lowest overall bias.This indicates, from the instructor’s perspective, if there are further assignments of this kind, expert grading may not be necessary.” Reputation range of Hamer’s algorithm is red value < 0.5 yellow value is >= 0.5 and <= 1 orange value is > 1 and <= 1.5 light green value is > 1.5 and <= 2 green value is > 2 The main difference between the Hamer-peer and the Lauw-peer algorithm is that the Lauw-peer algorithm keeps track of the reviewer's leniency (“bias”), which can be either positive or negative. This project determines reputation by subtracting the absolute value of the leniency from 1. Additionally, the range for Hamer’s algorithm is (0,∞) while for Lauw’s algorithm it is [0,1]. Reputation range of Lauw’s algorithm is red value is < 0.2 yellow value is >= 0.2 and <= 0.4 orange value is > 0.4 and <= 0.6 light green value is > 0.6 and <= 0.8 green value is > 0.8 The instructor can choose to show results from Hamer’s algorithm or Lauw’s algorithm. The default algorithm should be Lauw’s algorithm. A Sample of the webpage displaying reputations with Lauw's algorithm is given below. <image>. In an <link> , a software application is divided into three major components : Model, View and Controller. All the documentation for the Expertiza system can be found in the following links: <link> , <link>. participant. All our code follows the <link> on Ruby style. 1. Write a migration to add reputation field in participant table. (The default value of this field is 1, set any nil to 1) 2. Change the send_post_request method in <link> to obtain initial reputation values from DB instead of hard-coded. 3. Write a new method in <link> to extract reputation values from JSON response and insert into DB. 4. On view_my_score (student-end) and view_scores (instructor-end) pages: use different font color on students’ names to distinguish different level of reputation values. We will be using the existing test suite used by gem to test any new code modification. We will be writing new test cases for any new public method exposed by existing classes.Our priority is to add functional tests associated with reputation for instructor, assignment and student controller. For example, One test workflow would be Testcase 1 1) Instructor selects type of reputation algorithm 2) Chooses the assignment and the round for which the reputation needs to calculated 3) Receives the json response 4) Check if the response is in the right format and the that the reputation for each student is stored in the database. Testcase 2 1) Student logs in to Expertiza. 2) Selects a particular assignment. 4) Student should be able to see his/her reputation value along with the scores. 1. <link> 2. <link>.","Lauw is a boolean in db in assignments table, which is not correct. We may have more repu. algorithms
limited testing done."
E1670,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link> 1.1.9. <link>. Listed below are the functionalities and the Rspec unit tests corresponding to the function names along with a list of scenarios tested. It has two input parameters: List of assessments and questions. The function iterates over each assessment to get the total score of that assessment. After iterating over all assessments, Max score, and Min scores are calculated along with the average score based on the number of valid assessments. Their scores are returned by the function. Rspec Unit Test : Compute_scores Following scenarios are tested: 1. To return scores as nil if the input list of assessments is nil. This is to make sure no Null Pointer exceptions are thrown by the code 2. To return a particular score when a single valid assessment is given as an input. 3. To return a particular score when multiple valid assessments are given as an input. This is to test the looping functionality of the method. 4. To return a particular score when invalid assessments are given as an input. 5. To return a particular score when invalid flag is nil. This unit test uses a stub and returns a mock value. Failure in get_total_scores wouldn't break the compute_scores test cases. Function Name : Get_total_scores This function is called by the Compute_scores method of the answer.rb model to compute the total score of an assessment. The input consists of assessment for which the total score is being calculated and the list of questions being evaluated in the assessment. Before calculating the score, the function performs two crucial tasks. The total score is calculated using the below formula <code> Any edge cases would return -1 indicating no score Rspec Unit Test : Get_total_scores Following scenarios are tested: 1. To return an anticipated total score of a single response without any edge cases. Since this function will be called only on one response at a time, there is no need to test for multiple responses at the same time. 2. To return an anticipated total score of a response where nil answer is for a scored question. Return value of -1 is checked at the calling function to ensure if a score is returned or not. Function. This unit test uses two stubs and returns mock results <code> <code> This is to reduce the outcome of the test to depend on DB calls. Function Name : submission_valid? This function obtains a list of AssignmentDueDate objects in descending order which is then compared against the current time to determine which deadlines are valid and which ones are not. A list of ResubmissionTime objects is also retrieved from the controller. Observations: The current implementation of the function is bugged. It retrieves a list of sorted AssignmentDueDate objects and proceeds to check if this list is empty. Throws an exception if no AssignmentDueDate objects are passed, returns nil if any objects are passed. Rspec Unit Test : submission_valid? Following scenarios are tested: 1. Passing valid AssignmentDueDate objects 2. Not passing any AssignmentDueDate objects When valid AssignmentDueDate objects are passed, stubs are used to create fake AssignmentDueDate Objects and ResubmissionTime objects. Function rather than actually calling the function. Once this bug is fixed, this test case may be re-written to test a more legitimate test case. In case an empty list of AssignmentDueDate objects is passed back to the submission_valid? () method. This would cause the function to return nil. When this function is fixed, the following test case may be re-written to test for a more legitimate test-case. This unit test uses two stubs and returns mock results <code> The above stub returns two AssignmentDueDate objects whenever the where() and order() method are chained on AssignmentDueDate. <code> The above stub returns two ResubmissionTime objects whenever the where() and order() method are chained on ResubmissionTime. <code> This stub is used in the second test case to return nil objects. Any change in the table schema would be detected in these test cases. These records are cleared after every test case. Answer belongs_to question and this was tested using a simple dependency rspec test. <code>. 1. To run the test suite for a particular file only( answer_spec.rb): <code> 1. To run the entire suite of test cases: <code>. <code>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. <link>.","The intros to Expertiza and Rspec are really not needed, as anyone reading this writeup would already be familiar with them.  It might be appropriate to link to descriptions of them, but no more.  The descriptions of the test cases is very good.  I wonder why more of the descriptions are not backed up by showing the code."
E1707,"So, to enable students find different people for the assignments rather than just team up with same people for every assignment in the current course, students can ask for a team to be randomly allocated by not choosing the team members before hand. After the bidding for the project topics is over, the student is allocated a team. Here, in this case it may be possible that the student is allocated a team member they have previously worked with before. The main objective is to give students an option to choose whether or not they want to team up with their previous team members for a particular assignment in the current course. If they choose the option, then when a student is added to the team, a check is performed if he/she has worked with the student before. Another point to note is that if the student chooses some person to be on the team who he/she has worked with before, choosing this option would still allow the person to remain in the team. The web service is expected to respond back with new team after swapping the team members that have teamed up before. • The first step is to include a checkbox to provide student with an option to select if he/she want to be assigned new people who were not previously team up with the student. The following flow chart diagram describes this scenario at the front end: <image> • After instructor initiates the team creation process, first check is to know whether the team members have already been chosen by the student. If yes, then the team is created as it is with the chosen members. • If, the student doesn't have all/some team members already selected, a team is created for the student by calling the create teams method in the top trading cycle service. • After a team is created, the flag is checked if the student wanted new team members for the assignment who were not team up before. • Then for each team member selected to be on the team, it is checked if the he/she has been teamed up with before. • If the team member has been teamed up with before, we call the swap method in the top trading cycle service and pass the student's team history. • Using that information, he/she is swapped with some other team member who hasn't been on the team. • This process repeats for each member, until we cover all the team members. At the end, we have our team ready. 1. ""To check if team creation will create teams with students having put up with the teammates previously teamed up with"" 1.1. Set max number of students per team to 3. 1.2. Manually make change in DB to make 3 students previously team up with 3 other students. 1.4. Call the team creation method 1.5. Check if any student is paired with a student they had already teamed up with. 2. ""To check if the new team creation algorithm does not allocate more than the max number of people per team"" 1.1. Set max number of students per team to 2. 1.2. Have 6 students bid for a topic. 1.3. Call the team creation method. 1.4. Check if any team has more than 2 students. 3. ""To check if students who have chosen their own team members are not swapped even though they might have worked together before"" 1.1. Make 2 students teammates. 1.2. Set max number of students per team to 3. 1.3. Have a total of 6 students choose topics. 1.4. Check that in the team containing the 'A', 'B' is also present. 4. ""To check if the new_members flag is not set, then the team members should be the same for that particular assignment"" 1.1. Make four students, A,B,C and D. 1.2. Two teams where created, team A containing A and B, and team B containing C and D for an assignment with maximum team size 2. 1.3. Each team had unset the new_members option. 5. ""To verify if the student team history is returned correct: The teamed_students method is invoked there are no previous teammates"" 1.1. Verify that the returned hash is empty 6. ""To verify if the student team history is returned correct: The teamed_students method is invoked when the student has team mates."" 7. ""To verify if the student team history is returned correct: The teamed_students method is invoked when the student has team mates."" 8. ""To verify if the student team history is returned correct: The teamed_students method is invoked when the student has team mates."" 1.2. Verify that the user ids of team mates in the current assignment ids are not returned. 9. ""To verify if the student team history is returned correct: The teamed_students method is invoked when the student has team mates."" 1.2. Verify that the user ids of team mates in the current assignment ids are only returned.","The document says what is to be done, but provides very little detail on how it is to be accomplished.  For example, how are you going to refactor the code?  The purpose of the workflow diagram is unclear.  The top part looks like a plan for refactoring, the bottom half is a plan for an integration test."
E1752,"Expertiza is an open source webapp built on Ruby on Rails stack. It provides a platform to students with various features like peer-reviewing projects, submitting work, form teams, viewing grades etc. The project is being built and maintained by students and faculty at NCSU. The file assignments_controller.rb handles the logic behind Expertiza assignments and enables the creation and managements of assignments by instructional staff. Besides regular CRUD operations, it also integrates multiple parts of the expertiza components, such as users of different authorizations and priorities, corresponding courses associated with the assignment, due date and so on. Therefore, further unit and integration tests are required to guarantee that these operations work as expected. And also refactoring on the code in this controller is needed to make it more readable and reduce the complexity at the same time. Our tasks are based on the motivations above. Software testing is a process of examining a program or application with the intent of finding the software bugs. In software developemnt, it is usually defined as the process of validating and verifying that a software program or application or product meets the specified business and technical requirements. Additionaly, software is tested to: 1. Detect and rectify and errors made during the development phase, 2. Ensure customer satisfaction in the application, 3. Ensure the quality of the software product and 4. Optimize the performance of the system. Our project is guided by the Test-First Development principle. We write passing and failing tests for use cases of the assignment controller, and then turn to refactor the code. During the project, we implement the tests and refactor in Agile methodology with our mentor Zhewei through weekly delivery. RSpec is a 'Domain Specific Language' (DSL) testing tool written in Ruby to test Ruby code. It is a behavior-driven development (BDD) framework which is extensively used in the production applications. The basic idea behind this concept is that of Test Driven Development(TDD) where the tests are written first and the development is based on writing just enough code that will fulfill those tests followed by refactoring. The Expertiza project makes extensive use of RSpec to test the various components of the application. Tests of our tasks are in the code file: spec/controllers/assignments_controller_spec.rb. 1. Creating new tests for each method, 2. Testing the each method and making sure the tests pass. All 22 tests were passed with zero failure on the final version of project code. Please refer to our detail project demo to see the testing in action. Refactoring of computer software or code is the process of restructuring existing software code without changing its external behavior or performance of the software application. Refactoring improves nonfunctional attributes of the software. Refactoring aids in code readability and keeps the code well maintained and easy to understand. 1. Replace magic numbers in deadline_type_id by constants with reasonable names; 2. Formatting the code for readability and convention; 3. Split large chunks of code in to smaller manageable chunks; 4. Extract simpler and specific methods out of blocks of codes to remove code duplications using DRY principle; 5. Rename existing methods with meaningful names for better readability without change on external functionality. Actions: code block split, method extraction and add meaningful constants Original <code> After refactoring <code> Here we first grouped the blocks of code according to their similarity of functions. Then we extracted simpler methods from each code block to make it more readable and reduce the complexity and coupling. It is obvious that after refactoring, this part is simpler and easier to maintain. In addition, we also replaced the magic numbers by constants according to the deadline type. Actions: split long code block and extract specific methods Original <code> After refactoring <code> The update method was refactored in the similar way to reduce the size of codes and improve readability. The definitions of those helper methods were placed at the bottom of the assignments_controller.rb. Actions: rename for consistent Ruby code style <code> After each refactoring procedure, we perform the testing to ensure the expected functionality in Rspec. For more cases, please check our GitHub project repo. The files we make change on are: app/controllers/assignments_controller.rb and app/helpers/deadline_helper.rb. <link> <link> <link>. <link> <link> <link> <link>.","First, it shouldn't be necessary to give background on software testing, refactoring, etc.  It would be good to have considerably more discussion of how methods had been refactored.  The revised version of the edit method is much shorter than the original version because much code has been factored out, but the factored-out code is not shown.  Ditto for update.  The tests are not included or described in the writeup. Moreover, it's not too useful having a copy of the code in the Wiki. it should be simplified with pseudocode so it's much faster to read."
E1677,"This project will facilitate few text metrics to evaluate student's peer reviews. The text metrics will provide a result about the textual content, the nature of the review, whether it contains any sort of offensive or improper language, and quantify the sincerity of the review in general. The tasks that have to be completed as part of this project can be identified as follows: 1. Create DB table [review_metrics] to record all the metrics of volume, presence of suggestions, errors/problems pointed out by the reviewer and offensive words used in the review text if any. 4. Make sure the code updates the review text metrics table when the peer reviews are updated. 5. Sort the reviews based on the text metrics on the “Your scores” pages of students’ view 6. Create tests to make sure the test coverage increases. Currently, after completion of reviews, the reviewers can view their responses as shown in the screenshot below: Instructors can see the response of the reviewers. However, in order to analyze the quality of review given by the students, the instructors have to manually go through all the reviews given by every student one at a time. In order to ease the process of evaluating the reviewers, metrics that can analyze the text written by the reviewers can be added. This will give more information about the reviews given by the reviewers to the instructors evaluating them. The reviews do not show the metrics of the review, which could provide a quick summary of how the review is written/perceived. The reviews are not sorted <image>. The controller will update the attribute values in the review metrics table when a review is created or updated. <image>. This model will include all the metrics as follows: 1. response_id → int(11) → foreign key 2. volume → int(11) → # of [different] words 3. suggestion → tinyint(1) → if suggestion is given in the peer-review 4. problem → tinyint(1) → if problems or errors in the artifact are pointed out in the peer-review 5. offensive_term → tinyint(1) → if the peer-review contains any offensive terms There will be a consequent review_metric_controller which will include all the necessary CRUD operations for review metrics such as add, remove and update review metrics. The icons from left to right, will be indicative of the following metrics. TASK 4 - We will be defining an RSpec file in review_metrics_controller which will check that the metrics table is updated when a review is updated. Updating a review will effect a change in the review metrics table, therefore this will dynamically change the order if the metric has changed. We need to create new view and new rspec test cases for the same. Iterator pattern is used as the design pattern. In our case, the collection is the different responses given by a reviewer in one single feedback. Since we will be iterating over the different responses in a given feedback by a reviewer (where the different responses in a given feedback are the elements of the collection) in order to collect the text metrics, the design pattern used will be an iterator pattern. Added label or pop up which will indicate the metrics as icons, as shown below. These icons will directly summarize the review in terms of predefined metrics. The reviews will be sorted according to the text metrics and will be displayed to the student on the 'Your Scores' page. 1. When an instructor views all Assignments and clicks on the Review Report, this is the view that pops up <image> 2. When an instructor clicks on View Review Metrics, the popup containing the Metrics for all the responses done by the particular reviewer are displayed in a tabular format. <image>. 1. When a student clicks on Other's Work after clicking on a specific Assignment, this is the view that pops up, containing a View Text Metrics for each review that the student has done. <image> 2. When the student clicks on View Review Metrics, the popup opens which displays the metrics for the specific review. <image>. For user/reviewer, the steps will be as follows 1. Login to Expertiza with your credentials 2. Open the Assignments , click on Other Work 3. For every review entered, hover the mouse on the icons beside the review 4. The review will be summarised by caption texts on the icon like ""Good Content"" or ""Obscene Word usage"" or ""200 words reveiw"" 5. View the metrics for each review. Few of the Test cases added to the test file for Review Metric. <image> For the instructor, the steps will be as follows 1. Login to Expertiza with instructor credentials 2. Open Manage Assignments 3. Select the Assignment. Click on the icon 'View Reviews' 4. Depending on the stage of the assignment , the reviews will be listed in the order they were filled. 5. Metrics will be displayed on hovering the mouse over each icon.","No relevent information in document. Document only consist of images and code samples, no information about design of project
Josh: Documentation is a concatenation of diagrams and code snippets, with almost no prose.
"
E1688,"A new UI support needs to be given to enable them to directly send the issues they face to expertiza support through email. This new feature allows a user to send a complaint or feedback to expertiza support via email. 2. Create a feedback support form page which should be available to all the users including unauthenticated users. 3. The form page should have fields for email Id for fetching email id of the user facing issue, a description input box where user can describe the steps for reproducing the issue. 4. This form should have field email auto filled with email on user profile if the user has logged in. 6. Submitting this feedback form page should trigger email to “ <link> ”. 7. The project should provide User with an acknowledgment saying email has been seen and Expertiza Support will try to fix the issue as soon as possible. To eliminate the extra space on Manage Assignments page because of less data and more “actions” icons, we will replace all the “actions” icons with a single “actions” icon embedded with a pop up panel. So when a user clicks on this new “actions” icon, it will throw a pop up containing all these previous “actions” icons and the user can select one of them to invoke one of these actions (edit, delete, add participant, create teams, etc...). 1. Input: User clicks on Expertiza Support and issue description and captcha as input. The email id is auto-filled from the user profile. 2. Type of Input: Feedback Form 3. Source of Input: User interface 4. Processing: Validate input fields and form submit 5. Outputs: Email sent to Expertiza support and acknowledgement displayed to user. Provide a new icon in “actions” on tree display, then when you click on this new icon a new popup appears. This popup has all the previous “actions” 1. Input: User clicks on new icon 2. Description: new popup appears with all actions in it 3. Type of Input: Click on the new icon 4. Source of Input: User interface 5. Processing: Create popup 6. Outputs: Pop up Panel displaying all the previous “actions” icons for the user to choose from. Model : send_sync_message method with expertiza_support_helper(new helper class defining the body of email) will be responsible for sending email to expertiza support. Controller : Feedback form submission should call MailerHelper’s send_sync_message method with the appropriate parameters specifying that an expertiza user is facing some issue. View : A new expertiza contact support form to be created with fields email id, description of issue, captcha and submit button. A UI change replacing displaying tree with an icon. On click event will create a pop up panel. View : Instead of displaying all the ""actions"" icons, we will replace this code to display a single ""actions"" icon with an embedded pop up panel. 1. T.1: Contact Support’ button should be seen to all the users (even unauthenticated). 2. T.2: For unauthenticated users, clicking on ‘Contact Support’ should redirect to feedback support form page with blank email id field, description and captcha 3. T.3: For authenticated users, clicking on ‘Contact Support’ should redirect to feedback support form page with email id auto-filled with email on their profile, description and captcha. 4. T.4: Before form submission, none of the fields should be blank. 5. T.5: Captcha should be random on every page load. 6. T.6: Email should be received to Expertiza support “expertiza-support@lists.ncsu.edu” on the form submission and the user should get an acknowledgement of email received. 1. T.1: Ensure that when a user click on the new “actions” icon, it throws a pop up panel with all the old “actions” icons. 2. T.2: Ensure that Edit icon redirects the user to edit assignment view. 3. T.3: Ensure that Delete icon deletes the assignment. 4. T.4: Ensure that Add TA icon redirects the user to Add TA view. 5. T.5: Ensure that Add Participant icon redirects the user to Add Participant view. 6. T.6: Ensure that Create Teams icon redirects the user to Create Teams view. 7. T.7: Ensure that Create Assignment icon redirects the user to Create Assignment view. 8. T.8: Ensure that 360 assessment dashboard icon redirect user to One_course_all_assignments page of assessment360 view. 9. T.9: Ensure that Copy icon redirects user to Edit course page. 10. T.10: Ensure that Make public icon redirects user to the tree display page.","The document shows UI mockups, but it doesn't explain anything about how the implementation will be done.  It lists ""files to be considered,"" but doesn't say how they are going to be modified.  It is thus too ""early innings"" to be a good synopsis of the design."
E1700,"We are planning to achieve this by enabling alert messages to the authors and the reviewers who will use the newly created Google document links embedded into Expertiza. Depending on the criteria set, the Authors will be provided with notifications on two things: the permission setting of the Google Doc(Allow users with link to comment only) and to make reviewer comments anonymous. The Author of every Assignment will then need to create a Google doc based on these notifications. If the anonymous setting is enabled, the reviewers will need to log out from all their Google accounts before opening the Google doc. Once on the Google doc, the reviewer's comments will be posted anonymously, the reviewer's comment will be anonymous to both, other fellow reviewers as well as the author. The reviewers will just need the Google doc link to post comments and it wouldn't be required to login into Expertiza or any google account for using this feature. 1. The alert message should only pop up when the Faculty has indicated to do so (alert messages only whe Google Doc hyperlinks are uploaded, and when Anonymous commenting is Enabled ) 2. The Google Doc link needs to be added on the Assignment submissions page by the Author of the project 3. The settings for the Google Doc should be set to ""Anyone with the link can comment"" by the Author 4. A Peer Reviewer needs be directed not to login to any Google account to comment on the doc, and all Peer Reviewer comments shall be anonymous 5. Multiple commenting at a specific instance is taken care of by the Google Document settings and it will be placed one below the other. The first phase of our project aimed at embedding a Google document which enables the project Author to automatically generate a Google document with specified permissions for the reviews such that when a reviewer makes a comment it appears without his identity. On the other side whenever the reviewers click on the google document link attached to the project for reviewing or commenting on a project they will get a notification alert to log out of all google accounts in order to assure the anonymity of the reviewer. In this the assumption is that the google doc is created in the same manner as the other hyperlinks are added. 1. When an instructor will create a new assignment, he should be able to select a checkbox if he wants to enable anonymous commenting for google docs. 2. If the instructor selects this then the authors will not be able to identify the individuals commenting on the doc. 1. The authors need to create a Google doc, input their assignment content for Review and submit the hyperlink as shown below. <image> 1. We will try to create an alert message whenever the author submits a google doc link. 2. The alert message will ask the author to change the sharing settings of the doc to 'Anyone with the link can comment'. 3. This message should be thrown only when the author submits a google doc link and not any other link. 4. The below image shows the desirable alert message when author tries to submit a google doc link. <image>. 1. If the instructor has enabled anonymous commenting on google docs then the reviewer should see an alert message which will ask the reviewer to log out from all google accounts before opening the google doc link. 2. The reviewer will need to logout because google allows anonymous commenting on a doc only if the user is currently not logged into any google account. 3. The below image shows the desirable alert message when a reviewer tries to review a project which has google docs in its submission and anonymous commenting is enabled. 1. As explained above, once every author creates a Google document for their assignment, they can input their content for reviewal. (For example, their wikipedia article) 2. On following the above permission settings and security points, authors can upload the shareable link for commenting 3. One reviewers anonymously comment on the doc, this doc would look like the below image: <image>. 2. Possible security violations like an user with access to the link deletes all the content on that doc. Proposed solution to mitigate the risk: 1. When a reviewer goes on the page of submitted contents, he'll be shown an alert message to logout from google accounts if there exists a google docs link in the submitted content and instructor has enabled anonymous commenting. 2. The authors of the project will be shown an alert to modify the settings of their google doc to 'Anyone with the link can comment' when they submit a google doc link. <image> <link> ScreenShot of google document settings 1. As it can be seen, Google doc has 3 access levels and the 'can comment' option will allow the users only to add more comments on the Google doc. Any user having the doc link should only be able to comment on the Google doc ii. Alert should be shown to the authors only while submitting a google doc link iii. Users need not login to comment in the Google doc iv. Alert should be shown to the reviewers only if the submissions contain a google doc link and anonymous commenting is enabled v. Multiple comments made at the same time should not lead to any conflicts.","Problem 1-4 should be requirement 1-4 (use standard term in software development). A workflow / interactioan diagram would've been nice to get an overview of how you solve the problem (list of files changed is not useful, it can be obtained from github). "
E1914,"Problem : The users_controller.rb file included the standard CRUD methods for a User model along with methods for other workflows. The users_controller.rb file also handled the creation and management of a RequestedUser object in addition to handling the user object. Solution : Earlier, there was no controllers for a RequestedUser object and these were handled by the Users controller itself. We separated the RequestedUser workflow from the Users and we renamed the RequestedUser model to AccountRequest. As a part of this refactoring activity, we created a new controller called the account_requests_controller to handle the workflow of an AccountRequest. Solution: 1) What the method does: This method is used to find the list of roles the current user can embody. 2) Where the method is used: Used to display a drop-down selection of roles for the current user in the views. 1) What the method does: show(): If the current user is a student, they should only be able to see information about themselves. All other people should be able to see information about themselves or other students. If the request to show() passes these checks, then they are shown the view 'show'. Otherwise, they are redirected to the home page. show_selection(): If the role of a user's parent is less than the current user or if the current user is requesting to see itself or if user's parent_id does not exist then the show() method is called. All these conditions boil down to whether the current user of the system is authorized to see/edit the information about the user specified in the params. If the requested user does not exist or if the current user is not authorized to see the requested user, then the current user is redirected back to the list page. 2) Scenarios in which show_selection is called: in users/list.html.erb, a list of users is shown. On top of the list there is a functionality to search the list. When a person searches for a particular student, and selects that student, the show_selection method is called. If the person is allowed to see that student, the user is directed to the show() method. Otherwise the person stays on the list view. 3) Scenarios in which show() is called: From the edit.html.erb, if the person wants to see the information instead of editing it. Solution: The get_role method was named more like it would be in Java. We chose to keep the method in the controller instead of moving it to the model because it does not alter the data structure and it also has selection logic. Solution : Only instructor accounts can be created, so the drop-down was removed. <image>. <image>. Problem : When a list of all users are shown, the list is not paginated. So the instructors see a list of all users that have enrolled for a course over all the years that they have offered the course. Solution : The existing project does not have the feature of pagination for the user list. So, currently, all the users are shown to the instructor. The paginate_list method is supposed to paginate the list of users. The method was not called anywhere and also the method logic was incorrect. The method ""paginate_list"" is corrected and called at right place. Problem : Since we created a new controller, tests for this controller did not exist. Solution: We moved the tests from the users_controller_spec.rb file to the newly created accounts_request_controller.rb file. <image>. <image>. 1) To view pending account requests: Login as the administrator. Username = administrator5 Password = password Navigate to Manage(in the horizontal tab at the top of the page) -> Pending Requests. You will be able to see all the pending requests. The method that serves this view is in the newly created controller. username: instructor6 password : password Navigate to Manage(in the horizontal tab at the top of the page) -> users. You will be able to see a list of users and page numbers where the list ends. You will also be able to select the number of users to show on each page using a dropdown at the top of the list. You should also be ble to see the build status and all checks at the end of the pull request. 1) Partial Views : There are some partial views which are related to displaying forms to create/edit a user in the Users view. The same partials were earlier being used for displaying forms for requesting a new account. Option 1: Keep accessing the partials in the users view from the newly created Accounts_request view. This option gives some flexibility to the accounts_controller to modify the form without affecting the User's form. The partials that are now duplicated are: _email, _name, _institution, _password, and _prefs which can be found in user and account_request views.","On the micro level, every change made was well described.  On the macro level, it's not clear why you listed the changes in the order that you did.  More structure would've been helpful."
E1941,"1. There is no deadline that specifies when a team can drop their topics. Due to this, few problems occur: The team might drop a topic later on which is close to the submission date and this results in topic not being assigned to any other team on time such that they can submit their assignment. Also, if one team was wait listed for the same topic which the other team dropped closer to the submission deadline, then the first wait-listed team will be assigned to the dropped topic which is not desirable as they might be working on their assigned topic for long time. 1. There are different topics on which students can work during different times. This type of assignment is known as Staggered- deadline assignment in which different topics have different submission and review deadlines. For these assignments too, there is a need for ""Drop Topics Deadline"". In the current implementation, the drop topic deadline is same for all the topics in a Staggered Deadline assignment which is not desirable. 1. The following points were identified in the problem statement, regarding when a team should be dropped automatically: - They get a topic they were on the waitlist for - The last member leaves the team - A drop-topic deadline passes, or a submission passes Out the three requirements, first two features are already implemented. 1. The instructor cannot add a Drop Topic Deadline for topics The instructor has the functionality to specify Review and Submission deadlines, while editing a topic. This page however, doesn’t have any provision on the form to let the instructor add Drop Topic Deadlines. According to the current implementation, s/he can add in a date for Drop Topic Deadline as well. 1. The wait-list for a topic doesn’t get cleared on reaching the Drop Topic Deadline Whenever the Drop Topic Deadline is crossed, we expect: - The waitlist queue for the topic is cleared - The teams are not permitted to drop the assigned topics anymore. 1. Calculation of Drop Topic Deadline Issues could occur if user accidently sets a drop topic deadline which is after the submission date of the topic. This case can be handled by checking the submission deadline of the topic against the date user sets. The flow works as follows: - Case: 'no deadline date is set on topic' - the topic submission deadline is used to clear the teams waitlisted for the topic (but the drop topic deadline is not set) - Case: 'date prior to the topic submission deadline is set as drop topic deadline' - the date set by user is set and used for clearing waitlisted teams - Case: 'date after the topic submission deadline is set as drop topic deadline' - the date set as submission date is logically correct date in this case and gets set as the drop topic deadline as well and is used to clear the teams wailisted. 1. Problem 1 : No provision for taking user input for Drop Topic Deadline and persisting it in the database. Although the current schema supports a Topic/Assignment having drop Topic Deadlines, there is not form input field for the same. Below is the code snippet from app/models/topic_due_date.rb , dealing with the above change: <code> <image> 1. Problem 2 : Waitlisted topics not getting dropped after the Drop Topic Deadline. For executing the timed jobs, Expertiza uses Sidekiq, and creates jobs for every Topic. 1. Solution : We need a job to be executed on the day of the specified Drop Deadline, which would drop the waitlist. To resolve this, we added another job which gets created on every new Topic creation, to be executed at the Drop Topic Deadline. In case there is an update on a previously defined deadline by the instructor, we fetch the existing job, using the delayed_job_id, and modify the same as per the new Deadline. Edge cases addressed: 1. In case the Topic Drop Deadline is not defined, we set the default based on the following dates, whichever is earlier/populated: a. Topic Submission Deadline b. Assignment Drop Topic Deadline c. Assignment Submission Deadline 2. In case of an updation on Drop Deadline, we check if the new entry is different from the existing date, and reschedule the job only if it is, thereby avoiding any redundant updates. 3. Whenever the user-entered Topic Drop Deadline is earlier than the Submission Deadline, we set the date as per (1). Check 'Staggered deadline assignment?' for the assignment. 3. Create topics under the assignment. 4. Go to Assignment -> Topics. 5. Enter 'Drop Topic Deadline' and hit 'Save start/due date'. 6. Reopen the assignment topic to cross verify if the deadline has been saved. In case unable to do so, use 'MadeUp Problem' with Creation Date of 'Aug 30, 2017 - 9:03 AM' [Problem 2] When a deadline is assigned for a topic, we create a job (identified with delayed_job_id) to be executed on the deadline date.","Generally good descriptions of how and why code changes were made.  However, the UI for drop-topic deadlines is shown only for staggered-deadline assignments.  Does the blank appear on the Due Dates tab for regular (not staggered-deadline) assignments?
It's not clear from the description whether there are multiple jobs for dropping different topics, or if a single job completes the process.  A single job is better, of course.
It would be much clearer to cut and paste code snippets from Github rather than to use the formatting available in the wiki.
Testing does not seem extensive enough."
E1836,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can also peer review other students' submissions. The following tasks were accomplished in this project: 1. Created quiz_questionnaire_controller.rb 2. Moved view_quiz, new_quiz, create_quiz_questionnaire, edit_quiz and update_quiz from questionnaires_controller.rb, to quiz_questionnaires_controller.rb, and renamed it as view, new, create, edit and update respectively. 3. Refactored the the long methods in questionnaires_controller.rb, such as create and create_questionnaire, update quiz, valid quiz, etc. 4. Replaced switch statements in questionnaires_controller.rb with subclass methods. 5. Created models for the subclasses. 6. Removed hardcoded parameters, such as save_choice method. 7. Appropriate tests were written to test the code. Problem 1 : Create quiz_questionnaire_controller.rb and move some of the methods in the questionnaires_controller.rb to the new file created. 1. Solution : The methods view_quiz, new_quiz, create_quiz, edit_quiz and update_quiz in the questionnaires_controller.rb were the methods identified and moved into the quiz_questionnaire_controller.rb. They were respectively renamed as view, new, create, edit and update. The implementation of the newly created quiz_questionnaire_controller.rb can be seen below. <code> Problem 2 : Refactor the long methods in questionnaires_controller.rb, such as create and create_questionnaire, update quiz, valid quiz, etc. 1. Solution : a. Deleted the create_questionnaire method and replaced the call to it in create_quiz_questionnaire with the code of create_questionnaire and is later moved to quiz_questionnaires_controller.rb and the code snippet below is used. <code> b. Moved the large block of for and if statements into method called change_question_types in the quiz_questionnaire model. <code> c. Replaced large block of for and if statements in update with a call to the new change_question_types method. <code> d. Moved export, import, copy_questionnaire_details, and assign_instructor_id to questionaire model. <code> 3 : Replace switch statements with subclasses methods and create models for the subclasses. 1. Solution : Moved the switch-case statement from create in questionaire_controller.rb into a method called set_display_type in questionaire model. The following is the code snippet that shows the same. <code> Problem 4 : Remove hardcoded parameters, such as save_choice method 1. Solution : Hardcoded parameters are removed and necessary constants are defined. Because the purpose of our project was to better arrange our code, it follows that we also needed to rearrange the tests for that code. We first divided the tests for questionnaires_controller into two test files, questionnaires_controller_spec and quiz_questionnaires_controller_spec and separated the tests for CRUD operations of quiz_questionnaires_controller into the quiz_questionnaires_controller_spec, renaming them from view_quiz, create_quiz and the like to view and create. After this separation of CRUD operation testing, we tested the functionality that we moved out of the controllers into the model including the validation method for the quiz questionnaire. We did not include tests to cover the existing model functions, nor did we test the new set_display_type or change_question_types functions as they are setter methods, which, according to our testing instruction are not worth testing. The setup for testing was particularly troublesome for the deployment of this project. The tests did not run properly in RubyMine, so it was difficult to ensure they were set up properly, and none of the members of our group have any expertise in rspec testing. 1. The testing of the export feature is shown below: <image> <image> 1. The successful creation of quiz is shown below: <image> 1. The saving of question in a questionnaire is shown below: <image> 1. The successful updating of questionnaire is shown below: <image>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. Clean Code: A handbook of agile software craftsmanship.","This doc consists of large code sequences with very short (1 or 2-line) descriptions.  The reader is left to figure out the functionality by himself.  The code sequences would be better broken up into methods, or excerpts from methods.  It would be good to describe how the refactoring was carried out (e.g., which principles or patterns were involved, and how). It seems that the description of the tests is reasonable, given that this team only rearranged the automated tests, and they provided screenshots for manual tests."
E1863,"Assignment creation can be done in Expertiza by an instructor or a TA for a particular course. There were some issues related to the assignment creation. Overall assignment due dates are taking precedence, on the Due Dates tab. Due dates for the assignment needs to be changed manually to the due dates for the new topics just added. The overall assignment due dates should be irrelevant. In other words, topic should obey just the topic deadlines and not the assignment deadlines. <code> Fix to be implemented: Change the above piece of code to allow signing up staggered assignment topics bases on the topic deadline and not on the assignment sign up deadline. <code>. 3. Click on New Public Assignment 4. On the new assignment creation page, under the General tab, give details for Assignment name , Course (choose CSC 517, Spring 2016) and Submission directory . 5. Check the Staggered deadline assignment? 8. Now, click on the the Topics tab and further click on New Topic . 10. Click on the Due dates tab. 15. Now, click on the Other stuff tab and and further click on Add participant . It will open in a new tab. 19. Click on Assignments and further click on the assignment that was created in the earlier steps. At present, when the TA creates a new assignment, only he has the ability to delete it. The task at hand is to allow the instructor to delete the assignment that is created by a TA. When an assignment is created by the instructor or by the TA , the delete option is assigned to self, that is, to the one who created the assignment. This needs to be overridden in that the instructor must be able to delete any assignment that shows up in the list without the need for matching the assignment Id with it's own and giving Instructor the ability to delete any assignment created by a TA. <code> To allow instructor to delete an assignment created by TA, the if-else block is fixed as given: <code> Modifications made to the code check for the form id and allow permission to delete when the id belongs to assignment creator or when the role of the current user is 'Instructor'. Manual Testing Task Description: Teaching Assistant creating an assignment Precondition: The instructor has set up the page for assignment creation Primary Flow: 1. Log in to Expertiza 2. Select New Assignment 3. Enter the Assignment Name and select Course . 5. Click Create Task Description: Instructor deleting an assignment Precondition: There exists at least one assignment created by TA. Primary Flow: 1. Log in to Expertiza 2. Select the Delete option in the action section for an assignment that is created by the TA . 3. If Logged in as Instructor , the assignment gets deleted for that action. each round of the assignment review will have a different set of rubrics. When such an assignment is copied, there exists a problem where the rubrics from the original assignment are not copied over properly to the new assignment. This new assignment does not have rubrics that vary by round, as in the original assignment, but have the rubric from Round 1 in the original assignment copied over for all rounds. When an assignment is copied, all the rubric data is to be copied over. <code>. Manual Testing 1. Log into Expertiza as instructor 2. Access the Assignments listing 3. Access an assignment and go to the 'Rubrics' tab to see if there are multiple rubrics defined 4. Copy the assignment, if there are multiple rubrics, from the assignments listing screen 5. Access the newly copied assignment 6. Check if the rubrics tab lists down rubrics for all rounds in the original assignment Automated Testing This would reuse the existing automation tests. The Issue is that the Instructor is not able to participate in a given assignment. This issues require a fix so that the instructor can also add himself as a participant in the assignment created .This fix will allow the instructor to perform the same functionality as the other student participants as reviewing peer assignments , submitting assignment, etc. When the instructor is logged in he can create a new assignment or use an existing assignment . All the assignments that are created would require participants which happens to be the responsibility of the instructor . Thus the Instructor adds the participants to the assignment and with this fix the instructor will be added as a participant by default every time a new assignment is created.The new functionality in the assignment controller will be modified to resolve the issue. Manual Testing 1. Log into Expertiza as instructor 2. Create a new Assignment 3. Click on the add participant button for the assignment created 4. Modify the participant list by adding instructor as a participant 5. Check the list to see the instructor added to the assignment as participant Automated Testing No automated test cases, only manual testing since the modifications are made to the view files. While creating/editing an assignment, one of the configurations is setting up of the rubrics. This is done in the 'Rubrics' tab of the assignment page. If the check succeeds, we continue with the assignment saving process.","Very good, methodical, description of changes made.  Two weaknesses: The meaning of yellow & green highlighting was not defined.  Green is evidently for code added, but what does yellow mean (evidently not deleted).  Second, as the reviewers suggested, there was room for more automated testing, at the very least, describing how existing tests validated your work."
E1913,"This page gives a description of the changes made for the review_mapping_helper.rb of Expertiza based OSS project. Expertiza is a web application where students can submit and peer-review learning objects (articles, codes, websites, etc). Instructors add and grade the assignments submitted by students to Expertiza. Students can be assigned in teams based on their selection of the topics. It has functionalities such as peer reviews in which students can provide feedback on other's work which helps peer in better developing the project. It is supported by the National Science Foundation. The review_mapping_helper.rb has multiple functions with a wrong naming convention, they are classic examples of bad function names. These functions are to be refactored accordingly. Few of the variables names used in the method must also be refactored to make it more relevant and understandable. In addition, some function's code is to be optimized to ensure that it follows DRY principle. Tests must be written for the functions which are modified. Also, comments must be added to all functions of the file. The create_report_table_header function contains HTML code which should be ideally placed in the view as partials, which will allow to easily reuse the code in Rails application. The following process is carried out to complete the project- <code>. All the method names that are refactored are mentioned below- Before: <code> After: <code> Before: <code> After: <code> Before: <code> After: <code> Before: <code> After: <code> Before: <code> After: <code>. The following method was not used or called in any of the files in the project. Due to that reason, the entire function was commented out. <code> The method get_css_style_for_calibration_report had a switch case. It was refactored using a dictionary where the case numbers were keys and the outputs of each case were the corresponding values. Before: <code> After: <code>. There were several methods which didn't have any comments or the comments weren't meaningful. In all those cases, comments have been added or changed which are mentioned as follows: <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code>. The following method has been removed from the review_mapping_helper.rb and added to the views as partials: <code> The following is the code available in views in the file _report_table_header.html.erb : <code>. There were changes made in the function name as well as one of the function was added to partials. Testing was carried out to check the behavior of these functions. In one of the case, a drop-down menu was tested i.e, all the links that were accessed were tested. It was checked that clicking on every link produced the desired output in all the options of the drop-down menu. For these cases, Manual testing, as well as RSpec testing, was carried out. For the methods which were called in views, manual testing was carried out to check that the code was not affected after refactoring methods. <code> <code>. RSpec testing was carried out for the methods that had been refactored. The partial that was added had impacts on the drop-down menus. Given below is one of the snippets of the entire code written in the file review_mapping_helper_spec.rb . The file path is spec/features/review_mapping_helper_spec.rb . <code>. A design pattern is a general repeatable solution to a commonly occurring problem in software design. It is a description or template for how to solve a problem that can be used in many different situations. During the process of refactoring methods as well as method names, Strategy Pattern was used in the implementation. The Strategy pattern is most useful when you want to provide multiple ways of processing a request, without hard-coding knowledge about those different methods into the object that handles the request. For our project Strategy Pattern was very helpful in adding functions to views as partials. To access the screencast for our project, please click <link>. 1) <link> 2) <link> 3) <link>.","The before/after sequences involving only one method name could have been put in a table rather than in separate boxes, which hampers readability. The rest of the changes are better documented, but the rspec test should've been described in more detail."
E1946,"All of these are subclasses of Questionnaire. Different type of questionnaire can be created in Expertiza like Review, Metareview, Teammate review, Quiz Questionnaire, Global Survey, Course Survey and many more. Below is screenshot of questionnaire on expertiza. <image> Below is screenshot of all the review questionnaire we have created till now. We can edit, delete and do many other operations on questionnaire. <image> Below is screenshot which shows how we can edit any questionnaire. <image>. 5. Separating the business logic from controller and putting it in method. Creating of questionnaire was one method which was extremely complicated and not well commented about what is going on. Multiple things were done in just one method which we broke in modules doing that specific task. This is the questionnaire.rb model file and we have added self method in it, which will create questionnaire object for us and we will get that object in controller and process it in controller. This is the questionnaire_controller_spec.rb file and we have changed this file in order to test the changes we have made in Questionnaire controller. This file is quiz_questionnaires_controller.rb and was calling multiple methods of quiz questionnaire by passing questionnaire id as parameter which we have removed. This is quiz_questionnaire_spec.rb was changed as we have removed questionnaire ID from methods in Quiz Questionnaire controller. Below were the user stories that we have created: 1. US1 - As a developer i want to analyse create questionnaire so that i can refactor and break it into modules. 5. US5 - As a developer i want to analyse why Questionnaire is being checked as QuizQuestionnaire multiple times and functionality is being changed, so that we can make quiz questionnaire same as rest. 7. US7 - As a developer i want to run rspecs in Questionnaire spec to so that i can make sure the changes made are working correct. 8. US8 - As a developer i want to run rspecs in Quiz Questionnaire spec to so that i can make sure the changes made are working correct. This method was in questionnaires_controller.rb Create method was very long in Questionnaire controller and was not self explanatory, number of characters in one line is more than 80 and cant be seen in one window. Before Refactoring <code> After Refactoring In this user story we created self method in questionnaire model which will create questionnaire object and pass it in controller. Self method was divided in to two different modules which we then called into self. Method create_questionnaire_node(questionnaire) - This method will create a Tree node for new questionnaire in Expertiza <code> Method display_type_for_questionnaire(params) - This method will tell us about display type for new questionnaire in Expertiza <code> This method below will be the main method for creating the questionnaire object and will call the two method we have written above. Self - Assigning all variable values from UI into questionnaire object + create_questionnaire_node(questionnaire) + display_type_for_questionnaire(params) <code>. This method was in questionnaires_controller.rb and in this user story after deep analysis of create_questionnaire method, we found that this method has not been called anywhere so we have removed this method from the questionnaire controller. As a part of this user story we have removed unnecessary variables in questionnaires_controller.rb file. So, this variable was unnecessary. Below is the one of the methods named save_all_questions which was using questionnaire_id as method parameter and we refactored. Before Refactoring <code> After Refactoring <code>. As a part of this user story we have made changes in questionnaires_controller.rb file. Refactoring was done in method like add_new_questions. Before Refactoring <code> After Refactoring Constants created were: <code> We refactored the above method by making the constants and using them instead of just passing literals. <code>. Questionnaire_id is the variable which has value of params[:id], this variable was passed as method parameter in many calls when calling methods of quiz questionnaire controller, but as Quiz Questionnaire is subclass of Questionnaire and the ID can be read from instance variable, we do not need to send as separate value. As mentioned in US2, we have removed create_questionnaire method and we have also removed corresponding test of that method in spec file. Rest no changes were done in spec file. As mentioned in US3 we have removed unnecessary variables, one of the variable was questionnaire_id which was just params[:id]. This variable was passed as parameter in many of quiz questionnaire methods. we have removed this variable and method calls are changed. We have changed test cases also of all the corresponding method. We have made changes in 2 spec file and have run the test cases. 2. On editing any questionnaire, they are not getting updated.","Good try at describing rationale for changes.  Some of the descriptions could be more helpful, e.g., the one on refactoring the create method, which just said that it had been broken into two parts, not explaining how.  Actually it seems to have been divided into three methods.  The descriptions of removing unnecessary variables and unnecessary parameters are better.
The document would have been more readable if the section numbers (e.g., 6.1 Refactor Create Method) had appeared in the headers to the sections, rather than just in the ToC.
The test plan does not explain why expectations were removed from tests."
E1831,"<link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can also peer review other students' submissions. This project is focused on adding new email functionalities. 1. Issue <link> : Send out an email to the invitee when a participant sends out an invitation to another participant to join a team. And also, when a student responds to a teammate advertisement, the person who created the advertisement must be notified by email. 2. Notify an instructor by e-mail when a student suggests a topic. 3. Issue <link> : Create an option (in the instructor’s profile) to get a copy of emails being sent to students. 1. <link> 2. <link> 3. <link> 4. <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. <link> 9. <link> 10. <link>. 1. <link> 2. <link> 3. <link>. 1. <link> 2. <link>. 1. <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link>. On creation of a new suggestion, a mail should be sent to the instructor. To establish this, we test whether the create suggestion method calls a mail_instructor method. <image>. 1. Create a new account as an instructor on the deployment. 2. Log in as instructor. 6. Trigger any action that may result in mail being sent to the student. 7. Log in to instructor's email to check if copy of the same email has been received. As part of the email that is to be sent to the instructor, an important piece of information is the proposer. When a suggestion is made by a student, they can choose to make the suggestion in anonymous mode. The function set_proposer within suggestions controller determines whether the user has checked anonymous suggestion and then assigns the user_id to the proposer. In case, the student has chosen to make an anonymous suggestion, the proposer variable is set as the string “Anonymous”. <image> To send the email, a mail_instructor function was created. This function requires the suggestion title, proposer, and the email of the receiver. 2. The suggestion title is passed through @suggestion. 3. The assignment to which this suggestion is being made references to the instructor who created the assignment through instructor_id. This function then calls new_suggested_topic function in the mailer.rb file to send the mail with the information. <image> The mailer.rb file also gets a new function new_suggested_topic referenced above. <image> The last change made to suggestions controller is calling the mail_instructor method in the create suggestion method. If the assignment references an instructor, the mail method is called on any suggestion being saved. The ‘if’ condition here is put in for a test condition where an assignment is created through the factories and this assignment does not reference an instructor. <image> The final change is the addition of a new file which contains the content and formatting of the mail being sent to the instructor. <image>. The precondition here is that there is no participant and the instructor can add a non-existent participant. Further, a flash message is added when instructor adds a new participant. Instructor is forwarded to the user creation page by the corresponding link. <image> User should have the provision to review projects. For that, the user needs to access the review page. The link would take the user to the respective review page. <image> Link for submission deadline reminder User should get a deadline reminder in e-mail once a deadline to review is nearing. Once a user gets a deadline reminder e-mail, the user could review a team then. Email should have the link to review a team. <image>. More functionalities added to the e-mail that the instructor receives for contradicting reviews. <image> <image> response.rb <image> notify_grade_conflict_message.html.erb. When a student responds to a teammate advertisement, the person who created the advertisement must be notified by email. Any activity done on the assignment by a student can be viewed by the instructor. The instructor can make suggestions to the students. An e-mail could be sent by the instructor to the students regarding the activities done on the assignment. Now, the instructor has the option to choose to get all the e-mails that have been sent to the participants (students). <image> profile_controller.rb <image> users_controller.rb <image> delayed_mailer.rb <image> mailer.rb <image> user.rb <image> _prefs.html.erb.rb.",Most reviewers think the write up is good. Some feel that the test plan could have been in more detail and the ordering of the sections could have been changed.
E1864,"<image> Figure 1 - Application Flow Diagram -----------------------------------------------. set min and max number of reviews allowed as shown in 1.5. Set the rubrics and number of review rounds (min one round is needed) (Figure 6) 1.6. Review assignment should be automatic not instructor controlled(scope of the stated issue is here) as shown in Figure 7 1.7. Set the deadlines for submission and review (shown in Figure 8) 1.8. Login as a student and submit work(this needs to be done for each team), request for review 1.9. If the issue persist system assign the same topic to review multiple times(as shown in Figure2).difficulty with this problem is that its reproducibility factor which is very low. 1.2. Example : When the reviewer submits a review for a project, the reviewer cannot edit/ update his review again. So the review done for the first round actually becomes review for round 2. Hence the reviewer would not be able to update this review. Steps to reproduce the issue: 1. Initial steps to reproduce this problem is same as the issue #1093 2. Change the deadlines for the review to a few days after the present date and check if you are able to update the review. <image> <image>. When a reviewer tries to review the work, sometimes it happens that the system shows the reviewer that the work has not been submitted yet. The reviewer should have been shown the work of the author to review. Steps to reproduce the Issue #1029: 1.1. steps to reproduce this issue is similar to issue #1093, only the difference is once reviewer requests the assignment to review system throws a message saying there is no work has been submitted even though there is actually submitted work. This issue is not always reproducible. 1.1. When updating the number of review rounds for an existing project, and error is generated and this action fails. 1.2. Example : An instructor attempts to edit an existing assignment and change the number of review rounds. Steps to reproduce the Issue #972 : 1.1. The <link> states that ""You can change the # of rounds from 1 to 2. You can then change the # of rounds back to 1, and the assignment will appear to be saved with one round of review. Several attempts to reproduce this issue were made. - Test Case 1 : Increment beyond current number of rounds then decrements back to the original assigned number of rounds for an existing assignment. - Test Case 2 : Decrement below current number of rounds an existing assignment with submissions. 1.2. Unstated Issue : there is an issue that arises from the reduction of rounds for assignments that currently contain submissions. A bug should be created for this issue for another round of project issues. 1.1. Several attempts have been made to reproduce this problem. 1.2. We also tried with creating a new assignment, adding participants to the assignment, assign reviews to the student then logging in as student and request for a topic to review even with this issue did not reproduce 1.3. After discussing with mentor and Dr.Gehringer we are marking this issue as not reproducible. 1.1. As all attempts to reproduce this issue were not successful, and after discussing with Dr.Gehringer, we realized that this issue is not reproducible. Hence marking this issue as not reproducible. 1.1. As no attempts to reproduce the stated issue were successful, no solution to this problem can be proposed. 1.1. As no attempts to reproduce the stated issue were successful, no solution to this problem can be proposed. To ensure correctness of bug fixes following test plan was implemented: 1.1. Problem 1 : Issue #1093 - No Testing Required - Bug not Reproducible 1.1. Problem 2 : Issue #1097 - Verify that upon submission of the review, the reviewer maintains an option to ""update"" the review until review deadline ends 1.1. Problem 3 : Issue #1029 - No Testing Required - Bug not Reproducible 1.1. Problem 4 : Issue #927 - Verify assignment holds the number of review rounds value - Verify that the increasing number of review rounds after creating the assignment saves successfully and the new value is retained - Verify that the decreasing number of review rounds after creating the assignment saves successfully and the new value is retained 1.1. Problem 5 : Issue #1142 - Verify that when user views score review comments rendered as processed HTML only(there should not be any rendered HTML tags) 1.1. The setup for testing both problems 2 & 5 is complex as there are many necessary associations and procedures that are required to achieve the appropriate testing state. Assuming that a sufficient setup is achieved, a feature test for Issue 2 would simulate logging in as a student, visiting the Others Work page and submitting a review submission which would allow for the verification that an option to update his or her review is available, upon returning to the student assignment page.","The issues are nicely described, but unfortunately, the solutions are separated from the problems, forcing the reader who has not completely internalized all of the issues to flip back and forth to understand the changes.  And then the reader needs to go to a third section to read about the testing plan.  Also, merely showing code in monochrome is not very helpful; it could've been shown instead via links to Github diffs, where it would be obvious what changes had been made."
E1975,"Review process occurs in stages. This process might be repeated again and the average score from the last review stage is considered as the final score for that work-product. The system currently is designed to give a reviewer a new form for each round of review (rather than requiring the reviewer to edit an existing file) and automatically remove scores of reviews that are not redone. The scores are calculated on the fly based on the rubrics. Testing of the score calculation, display for the weighted and non-weighted scores based on the combination of the rubrics are part of this project. The system currently is designed to give a reviewer a new form for each round of review (rather than requiring the reviewer to edit an existing file) and automatically remove scores of reviews that are not redone. The scores are calculated based on the rubrics defined in the system. The system currently is designed to give a reviewer a new form for each round of review (rather than requiring the reviewer to edit an existing file) and automatically remove scores of reviews that are not redone. <image> Scores for students in Expertiza can be based on a combination of rubrics: review rubrics for each round of review, author feedback, and teammate review. In CSC/ECE 517, we don’t really use the student-assigned scores to grade projects, but the peer-review score shown to the student is based entirely on the second round of review Here is how scores are calculated: 1. If only zero-weighted scores are available (here, in the first round of review), the average of all zero-weighted scores should be shown in grey font. An information button should explain why the scores are shown in grey (“The reviews submitted so far do not count toward the author’s final grade.”): 2. If any non-zero weighted scores are available, then the score shown for the assignment should be the weighted average of the scores. For example, if Round 2 reviews are weighted 90% and author feedback is weighted 10%, and two Round 2 reviews each gave the work a score of 80%, and the only author-feedback score was 100%, then the overall score is:: <code> 3. If a review is submitted, and then the author(s) update the submission ​before the end of the current round​, it will reopen the review, and then the reviewer can go in and update the submitted review. ​ However, the previous review score that was given in the current round will count until the reviewer updates the submitted review . If only zero-weighted scores are available in the first round of review, the average of all zero-weighted scores will be shown in a gray font. <code>. If any non-zero weighted scores are available, then the score shown for the assignment should be the weighted average of the scores. For example, if Round 2 reviews are weighted 90% and author feedback is weighted 10%, and two Round 2 reviews each gave the work a score of 80%, and the only author-feedback score was 100%, then the overall score is 80%⨉90% + 100%⨉10% = 82% The score calculation was initially tested manually to verify the scenarios with multiple weights and rounds. Following file has the spec for weighted average score calculation. If a review is submitted, and then the author(s) update the submission ​before the end of the current round​, it will reopen the review, and then the reviewer can go in and update the submitted review. However, the previous review score that was given in the current round will count until the reviewer updates the submitted review. However, the previous review score that was given in the current round will count until the reviewer updates the submitted review. This feature can be broken down into the following sub-cases: 1. A submission can only be made before deadline 2. A review can edit a review only before deadline 3. Score calculation should be only done for latest submitted review <image>. describe '#scores' do <code> <code>. Test 1: Zero weighted scores shown in gray. Login as an author in expertiza and go to scores page to view the feedback. Zero weighted scores should be displayed in gray to the logged in user. Login as an author in expertiza and go to scores page to view the feedback. The information button should explain why the scores are shown in gray (“The reviews submitted so far do not count toward the author’s final grade.”) Step 4 . Test 3: Display non-zero weighted scores Login as an author in expertiza and go to scores page to view the feedback. The scores shown for the assignment should be the weighted average of the scores. The zero weighted scores have to be replaced with non-zero weighted scores. Test 4: Review Update The Review should be reopened. The reviewer should be able to go and update the submitted review. If the review is not updated the previous review score has to be retained.","Good description of testing, and also of the problem and proposed solution.  More detail on the code changes would have been welcome, e.g., how were each of the files changed, and which file contains the weighted_scores_exist method?"
E1920,"What approaches we used to resolve issues reported by Code Climate, what are the remaining issues in the Expertiza code, our suggestions for further improvements and our testing strategy used to ensure integrity of the code. We start with introduction to Expertiza application and Code Climate tool. How Code Climate is used to improve Expertiza source code. Code Climate is an analysis software used to improve the quality and security of software. The Code Climate generated results for the Expertiza project can be found <link> . Code Climate utilizes various engines to analyze the code to look for issues that may concern potential security issues, (.i.e. In order to use Code Climate via remote server, desired repository must be registered with Code Climate. Following <link> process allows to test the code for quality issues after each git commit/push to a registered repository. Our team was assigned to fix all code smells detected by <link> in the given set of Expertiza source code files. <link> ) through Z , except <link> file were targeted by our team to be Code Climate issue free files. Some of the files had no issues reported by the Code Climate to begin with, and hence were not modified. There were few such cases when we had to modify multiple files to fix one or more Code Climate issue(s). There are some Code Climate issues that were ignored and not resolved intentionally. There are also two Code Climate issues that our team decided to ignore after consulting our mentor and discussing their impact on the existing code and Expertiza project. We start with the most common issues reported by Code Climate and what approach we used to resolve them. Furthermore, we list all of the issues reported by Code Climate that we fixed. Next, we cover section with additional improvements that we have done along with fixes for Code Climate issues. These improvements do not directly relate to Code Climate issues; however, they improve overall quality of the code, its readability, maintenance and efficiency. We also list and talk about remaining issues reported by Code Climate that were intentionally ignored and left in the project. As we worked on the Code Climate issues for the Expertiza project, we noticed a set of common code smells and issues made by software developers. This is very common issue reported by Code Climate. The Code Climate reported the same issue on multiple files. For example, <code> Similar to this issue Code Climate reported ""Use find_by instead of dynamic find_by_name "" issue. Along with <link> we also fixed and verified numerous other code smells. 16. Identical blocks of code found in n locations. 26. Similar blocks of code found in n locations. While our primary task was to fix code smells reported by Code Climate, we also attempted to improve overall quality of code along the way. We added such comments in all the places where we fixed Climate Code issues. 1. Eliminate DRY code. Most of these issues were taken care by fixing ""Similar blocks of code found in n locations"" and ""Identical blocks of code found in n locations"" Code Climate issues. However, in some files Code Climate did not report such issues, although there were obvious repetitive statements. Although these code smells do not impose any problems into existing code and application, we strongly believe that all of remaining issues must be fixed. GitHub pull request is an integral part of solving Code Climate issues and delivering fixes into the Expertiza beta branch. We verified all our Code Climate fixes on the local working repositories, which we registered with Code Climate tool. Every new git commit/push was triggering new Code Climate job and we could verify if our changes fixed the issues. A typical workflow was as follows: 1. Code Climate issues were resolved and tested locally 2. Changes were pushed to local repositories registered with Code Climate 3. New git commit/push was triggering new Code Climate verification job 4. Verified that resolved issues were not reported on the latest Code Climate job All our changes are visible and can be tracked in the single pull requests we created as soon as we had one fix. To verify that the code changes we made did not break the existing application and its functionalities, we used the RSpec Testing Framework to test all the code. Based on our results, the models our interest represented 1510 lines of code and 58.54% code coverage. For example, we fixed multiple Code Climate issues in the <link> file. For example, we fixed multiple Code Climate issues in the app/models/teams_user.rb file. Therefore, we created a new <link> file to test directly our code changes and boost the code coverage on that model. More additional spec files were created to test our code changes. We concentrated our UI testing based on how changes to Code Climate issues affected the interface between callers and methods. Code Climate is a powerful tool that finds flaws in the source code of the Expertiza project. We would like to acknowledge that all issues reported by Code Climate on the files beginning with Se thru Z under app/models directory were fixed (except <link> )! There are no more Code Climate issues found!","This is an excellent description of the changes made, with rationales for each.  Will be very helpful to future developers.  The only thing I would change is the very long screenshots, which could be replaced by links to them in Github."
E1805,"<link> is a web based open source tool developed and maintained by current and past students of <link> . Instructors. The objective for this project is: Integrate Github metrics into Expertiza. The tasks required to complete this were broken down as follows. 1. Retrieve data on a Git pull request 1.1. Calculate meaningful metrics from the data for teams and individual students 1.2. Display metrics to instructors 2. Store metrics in the Expertiza database. <link> work done on this project utilized the Github statistics API, which was unable to retrieve information on individual students. The design was able to accurately fetch and display data covering a team of contributors, but could not create and display individual metrics to instructors. The proposed design utilizes the new <link> which allows for simple extraction of metrics on a pull request. The API call returns information on multiple commits with only a single fetch command. The returned data is then parsed into team level information and individual level information. Next, the metrics are calculated from the data and displayed to the user. By manipulating GraphQL API v4, we don't need to pull out all the information from GitHub, which is not customizable. Instead, we can appoint what kind of data we want to fetch so that it's much more efficient than Github Pull Requests API and also we don't need to parse bulk information in order to get the portion we need. <image> <image> <image> After having the data we want, we start to divide them based on dates and users so that reviewer can understand the contribution of each member clearly. <image>. The output of this module shows the users github data in various metrics through charts and tables. The images below show the metrics gathered, and the charts created when looking at <link> . <image> <image> <image>. To test this project manually on your local machine, you need to: 1. Clone from this repository <link> 2. Go to your GitHub account -> Settings -> Developer Settings -> Personal access tokens -> Generate new token -> name the token and check the repo and admin:repo_hook option -> copy the token generated 3. Run GITHUB_ACCESS_TOKEN=<token> rails server, then you can manually test the functionality by going to Assignments as instructor6 -> view submissions -> Show Submission Records -> Show Github Data Important note: If the project is added to the production environment of Expertiza, an access token must be created for the system and stored internally by some method!. Tests for this project include testing two methods in app/models/github_datum.rb and one method in app/controllers/github_data_controller.rb by spec/models/github_datum_spec.rb and spec/controllers/github_data_controller_spec.rb.","The writeup is not bad to read because the code is well structured and the metrics are nearly self-explanatory.  That said, I would have liked to see the writeup say more about the implementation, e.g., which parts of Expertiza were changed and why, and also how one could go about incorporating this data in report pages within the application.  It seems to me that the next team will have to figure that out just by reading the code.  It would've been so much better if there had been a description of how this team thought that their views could be used in the system (it was not their job to actually incorporate them, though)."
E1579,"The purpose of this project is to allow new users to access the system and experiment with all the features of Expertiza and make a “Demo like” feel for the new user where the user can experiment with it. This project adds a new feature of Instructor Creation over the web which is completely different from the previous way the user and instructor accounts were created by existing super administrators. The scope of this project will involve adding a new View/Page that would input all the new user(Instructor) Details which would be a signup page.The signup page will be designed in a way which would have security feature as Captchas embedded into it. There would be another new View/Page created that would act as the landing page for the newly created Demo_instructor which would contain specific instructions/ Video on how to add assignments, add students to the assignments. Also an email is sent soon after a successful creation of such user. 1. Create a new role by SuperAdmin 1.1. Fixed the drop-down menu for Based on roles option while creating a new. 1.2. Fixed add new permissions for a role functionality. 1. Allow people to request instructor accounts over the web. 1.1. Added a Link in Main Screen “Demo Instructor signup”. 1.2. Created a New Page where the User Fills the details wrt to a new Instructor Privileged access. 1. Upon Successful Creation of Instructor Account. 1.1. Redirect the New Instructor back to the Login Page. 1.2. Send an email to the super Admin notifying him of a new Instructor that has been created over the web 1.3. Send an email to new user with username and new password details. 1. Upon Successful Login of the New Instructor 1.1. Redirect the User to a Instruction Page which gives information on how to create an assignments and register students for it and other basic information needed. Basically a instructions page that can be used for providing information. 1.2. Provided a Button (Proceed) that would redirect him to the main Expertiza page. 1.4. Demo user has a general access to Expertiza and should be able to perform basic actions like adding a course, adding an assignment & assigning students for the created assignments. The demo_controller is created to support the main functionalities <code> <code> <code> <code> <code> <code> <code> Refactored code in tree_display_controller <code> For the creation of Demo Instructor experimenting with the features of expertiza In the controller admin_controller.rb, the new actions to be added and their purpose is explained below. Action added: create_demo_instructor role Purpose: create role for the demo_instructor by super administrator Action added: new_demo_instructor signup Purpose: Linked to the Signup form for creating an instructor to allow the experimenting with expertiza features Action added: Display instructions page for demo user Purpose: Show case all the instructions for a new instructor. Upon Demo Instructor Login into the account created In the tree_display_controller.rb, goto_instructions action is added and instructions.html.erb view is created for this action. The main objective for the project is to add the new signup functionality for the new User and also to clarify and improve code quality. We need to make sure that the new demo instructor will not be able to see all the public entities of other instructors, TA's. need to implement and change all the necessary files to make sure unnecessary items are not showcased to the demo instructor. The role creation page by super administrator. <image> The instructions page will have few instructions and a Simple Video Tutorial. <image> The Expertiza Home page with the Demo_Instructor. <image>. 1.Sign-up as new Instructor : New users can signup to view all features(except the public entities). 2.View instructions page : New instructor can view an instructions page for a walk through of the features. 3.Super-admin gives access: Super-admin gives access to all public entities for the newly created instructor. 4.New instructor-private items The demo instructor can access all the private items. 1.Sign-up Test Case : We will be checking if the demo user provides all the inputs needed for proper signup along with passing the Captcha . 2.Landing Page Test Case : Will be checking on if all the demo users land on the same Instruction page and if other Users like TA/SuperUser/Instructors do not land on the Instruction page. 3. Accessibility Test : The Demo User should be only be able to access his only entities and not the Public entities of other users(TA/SuperUser/Instructors). 4. Adding Entities Test Case : Will check if the Demo user is able to 1) create Assignments, 2) Add students to Assignments, 3) Make Questionnaires and have access to these entities.","They implemented what they were supposed to, but didn't have many, if any, tests.  They set up role in Goldberg, but that's probably not their fault.  However, they didn't add code to the action_allowed methods, and they would've needed to touch a lot of them."
E1972,"<link> is an open source project based on <link> framework. Students can also peer review other students' submissions. Each of the options for Manage>Questionnaires> does not appropriately link you to the Questionnaires tab with that section of Questionnaires expanded. Currently, the homepage shows 3 tabs: Courses, Assignments and Questionnaires. Suppose a user clicks on the ""courses"" tab and then from the ""Manage Content Tab"" -> ""Questionnaires"", clicks on any of the options, then it will redirect to the same page and not the one which was selected. This needs to be fixed such that upon click, it opens up the corresponding rubric page with that particular rubric section expanded and also the respective tab (courses/assignments/questionnaires) must be highlighted. The Manage Content page has three tabs in it namely: ""Courses"",""Assignments"" and ""Questionnaires"". And the application has a feature of storing the 'Last open tab' in its session. Suppose a user was in 'Assignments' tab under 'Manage Content' Section, and when the user switches to some other tab (By clicking on Home for instance), and comes back on 'Manage Content' section (by clicking on 'Manage...' menu button), he is directed back on the 'Assignments' tab only (the tab that was opened before leaving the 'Manage Content' section). The problem however, with this feature is that it dominates the natural flow of the application in the following scenario: Lets say after leaving the 'Manage Content' section as mentioned above, the user clicks 'Manage...>Questionnaires', but even at this point, the user is directed again directed to 'Assignments' tab under 'Manage Content'. If you are on the assignment tab and select to Manage…>Questionnaires> [some option], this will send you to the assignment tab. Change the tab to course or questionnaire and then it just sends you to that tab instead. The 'last_open_tab' holds on the tab clicked under 'Questionnaire'. For e.g., if the Questionnaires tab is clicked then a value of 3 will be passed as a parameter since the position of the Questionnaires tab is 3 on the page. Currently, rubric lists show all public rubrics and there is no option to restrict the view as in assignments and courses. This should be fixed by only displaying the option to edit (pencil) when the rubric belongs to the user. This clearly indicates that the user has the ability or not to edit this rubric. This raises an issue that one instructor can if they want to edit other instructor's surveys when they were only supposed to view them Currently, if a non-authorized user clicks on edit he is redirected to the same page with an error. Log in and Manage…>Questionnaires>Rubrics. Then click on one of the rubric types to show a list of rubrics and click through the edit options to reveal the flash error when you try and edit a rubric that is not yours. 2. Username: instructor6 3. Password: password. 1.2 Login as an instructor(username:instructor6, password:password) 1.3 In the Menu Items Goto: 'Manage...>Questionnaires>Team Review Rubrics' (Goto here means pointing your mouse to that particular option and the following the sub-options, the click only takes place at the last option, here at ""Team Review Rubrics"") Expectation : The 'Manage Content' page should be loaded with 'Questionnaires' tab active and 'Teammate Review' rubric expanded. Test Case 2 (Regression) 2.1 In continuation with the Test Case 1, when you are on 'Manage Content' section's 'Questionnaire' tab, click on the 'Assignments' tab. 2.2 Move away from 'Manage Content' section by clicking on any of the menu Items, lets click on 'Profile' Menu Item here. 2.2 After 'Profile' section is loaded, Go back to the 'Manage Content' section by clicking on the 'Manage...' menu item. Expectation : The 'Manage Content' page should be loaded with 'Assignments' tab active since this was the last active tab before leaving this section. 1.2 Login as an instructor(username:instructor6, password:password) 1.3 In the Menu Items Goto: 'Manage...>Questionnaires>Team Review Rubrics' (Goto here means pointing your mouse to that particular option and the following the sub-options, the click only takes place at the last option, here at ""Team Review Rubrics"") 1.4 Scan through the list in the rubric. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.","For Issue #1186, I did not understand how the fix to tree_dsiplay.jsx actually solved the problem.  The description could have been clearer on that point.  The same is true of Issue #696.
I do think that the changes you made behind the scenes could be tested by automated tests, even if the actual UI pages were not.."
E1927,"In Expertiza, students are able to perform reviews on work contributed from students by filling out a review form on Expertiza. Instructors and TAs for the course should be able to submit a review in the same manner as a student. Only instructors or TAs who are participants in the assignment should be allowed to leave reviews. However, the instructor and TA reviews should be distinguished from other student reviews so the student knows the review was written by the instructor. In the current Expertiza, instructors and TAs are able to leave a review for a submission only if they are a participant of the assignment. Also, there is not an easy way for instructors to leave a review at any time. Instructors typically need to leave a review during the established review window. Once an instructor leaves a review of a submission, the student does not know if the review was left by an instructor or by another student. The tasks associated with this project was completed by students from previous semesters. Note: The description of the project's task vary from the description provided in the project description. These are the tasks that were verbally given to the project team directly from the instructor. Note: The yellow boxes drawn in the figure below do not appear as a student or an instructor. Icons (Enlarged Size) (• Left: Current TA Icon • Right: New Instructor Review Icon): <code>. Problem: Each submission on the submissions page should link to ""Perform Review"" instead of ""Assign Grade"" if the due date has not passed. If the due date has passed, the link should change to ""assign_grade"". The goal of this task is to reduce the number of links in the shown on the page on the instructor side. The following images illustrate the desired appearance for the View Submissions page. Current View of View Submissions (Instructor Side): <image> Revised View (Before Assignment Due Date) of View Submissions (Instructor Side): <image>. Problem: The instructor should have the ability to create a review for any submission at any time. The instructor of the course should not be required to be a participant to leave a review. The link to leave a review should always be available on the View Scores page. Solution: The response.html.erb file needs to be checked to make sure there are no restrictions that would prevent an instructor or TA from submitting a review. Modifications will be needed to the files associated with the View Scores view. The images below show the current and desired appearance of this page. Current View (Instructor Side): <image> Revised View with Added Review Link for the Instructor (Instructor Side): <image>. Problem: An instructor icon should be used to indicate an instructor review and this icon should be seen on the review page read by the student. The instructor review, if completed, should appear as the first column in the reviews for the assignment on the student side. When the student reads an instructor review, it should have the same icon present on the review so the student knows it was completed by an instructor. Solution: Modify response.html.erb to distinguish reviews done by the instructor. The logic that is used to build the table of completed reviews will need to check if the review was completed by an instructor. To distinguish an instructor review from a student review, a table will need to be created to track the review_id numbers that are associated with instructor reviews. Revised View Scores Page with Review Link (Student Side): <image> Revised Review Page from the Instructor with Instructor Review Icon (Student Side): <image>. Problem: Similar to the calibration report from the Design Exercise assignment, create a view that would allow the student reviewers differ from the reviews completed by the course staff. Solution: Review the code from the Design Exercise calibration assignment. From the assignment page student_task/view.html.erb, add a new link for reviewers to the show the calibration report (_calibration_report.html.erb) only if the student and the instructor have submitted a review to the same assignment. The following shall be tested: For a given assignment, the instructor or ta should see the ""Perform Review"" link if the last due date for the assignment has not passed on the View Submissions page. Otherwise, the ""Assign Grade"" link will be shown. A review submitted by an instructor/ta should be accepted as any other review. The score for the review should not change the score calculated from student reviews. The existence of the Instructor Review icon will be tested as a student user on the View Scores page and when the student looks at a review from an instructor. 1. Project Document: <link> 2. Github Repo: <link> 3. Host Site for the Project: <link> 4. Demo Video Task 1 and Task 2: <link> 5. Demo Video Task 3: <link> 6. Information on the Responses Schema: <link> 7. Previous Work, Project E1824: <link> 8. Previous Work, Project E1855: <link>.","Very good coverage of the design.  Your screenshots are very effective in showing the changes, and they are motivated well. But the doc was not updated to say which code is changed.  That is one of the most important needs for teams that follow after you."
E1766,"Expertiza is a peer review based system which provides incremental learning from the class. This project has been developed together by faculty and students using Ruby on Rails framework. Expertiza allows the instructor to create, edit and delete assignments, create new assignment topics, assign them to a particular class or selected students, have students work on teams and then review each other's assignments at the end. For the students, they can signup for topics, form teams, and submit their projects and assignments. Students then review the work done by other students and give suggestions to improve. Teams after reviews are allotted scores and they can refer to the peer comments to further improve their work. It also supports submission of different file types for assignments, including the URLs and wiki pages. The purpose of this task is to write functional tests for team functionality. Once an assignment is out, a student can select this assignment and others can join in the team. To test this functionality we wrote functional tests for the various scenarios. One such scenario is : 1. Once the assignment is out and a student selects it, he/she can send out invites to other students to join the team. 2. Invited students can accept the invitation and join the team. Functional tests ensure that the functionalities of a software system are working as expected. To write our functional tests, we used the Capybara gem available for Ruby. Capybara gem allows a user to test their web application through simulations. In Expertiza instructor can create public assignment for particular course, define the required rubrics and add students to that assignment. The following test spec has been written to create public group assignment <code> Add topics to the assignment <code>. When student login into his Expertiza account, he can check for new assignment under ""Assignments"" tab and choose the topic of his interest. Student then can send invitation to other students who are also enrolled in same course. We have written following test spec to impersonate as a student and select a topic <code> Sending invitations to other students <code>. In Expertiza assignments, the only way for a student to join an existing team is to be invited by the leader. Following test spec has been written to accept the invitation to join the team and verify that the assignment topic is assigned to all users <code>. The tests can be run on the terminal by navigating to the /spec/features directory using the command: <code> Whether the test fails or succeeds, allows us to determine which parts of the system are functioning properly. Coverage increased (+0.3%) to 51.108% when pulling 4915488 on ankit13jain:master into 781e456 on expertiza:master. 1. link for forked repository [ <link> ] 2. Github link for original repository [ <link> ] 3. Github link for Capybara [ <link> ].","The writeup basically consists of the tests, with a couple of lines at the start describing the scenario.  This is good, but a more complete prose description of the approach would make it easier to grasp what the tests are doing."
E1733,"This project will facilitate few text metrics to evaluate student's peer reviews. The text metrics will provide a result about the amount of text written in peer-reviews, the number of suggestions given, the number of errors pointed out by the reviewer, and whether the peer-review contains any sort of offensive or improper language. The tasks that have to be completed as part of this project can be identified as follows: 1. Create DB table [review_metrics] to record all the metrics to include the number of: different words, suggestions, errors/problems pointed out by the reviewer and offensive words used in the review text. 6. Make sure the code updates the review text metrics table when the peer reviews are updated. 7. Sort the reviews based on the text metrics on the “Your scores” pages of students’ view 8. Create tests to make sure the test coverage increases. In the current implementation, reviewers can view the reviews they have given via use of a view link in the Other's work section of each project as shown in the screenshot below: Instructors can see the response of the reviewers. However, in order to analyze the quality of review given by the students, the instructors have to manually go through all the reviews given by every student one at a time. In order to ease the process of evaluating the reviewers, metrics which can analyze the text written by the reviewers can be added. This will give more information about the reviews given by the reviewers to the instructors evaluating them. <image>. This model will include all the metrics as follows: 1. metric_id → int(11) → primary key 2. metric → int(11) → # initial values in database would be {volume, suggestions, problem_identification, offensive_term}, but more could be added 3. suggestion → int(11) → if suggestion is given in the peer-review There will also be a review_metric_controller which will include all the necessary CRUD operations for review_metrics . This model will include all the metrics as follows: 1. response_id → int(11) → foreign key 2. metric_id → int(11) → foreign key 3. value → int(11) → metric value There will also be a review_metric_mapping_controller which will include all the necessary CRUD operations for review_metrics_mapping . The icons from left to right, will be indicative of the following metrics. TASK 6 - We will be defining an RSpec file in review_metrics_controller which will check that the metrics table is updated when a review is updated. Updating a review will effect a change in the review metrics table, therefore this will dynamically change the order if the metric has changed. TASK 8 - We will create new test in order to increase the overall test coverage. We need to create new view and new rspec test cases for the same. Iterator pattern is used as the design pattern. In our case, the collection is the different responses given by a reviewer in one single feedback. Since we will be iterating over the different responses in a given feedback by a reviewer (where the different responses in a given feedback are the elements of the collection) in order to collect the text metrics, the design pattern used will be an iterator pattern. Added label or pop up which will indicate the metrics as icons, as shown below. These icons will directly summarize the review in terms of predefined metrics. The reviews will be sorted according to the text metrics and will be displayed to the student on the 'Your Scores' page. 1. When an instructor views all Assignments and clicks on the Review Report, this is the view that pops up <image> 2. When an instructor clicks on View Review Metrics, the popup containing the Metrics for all the responses done by the particular reviewer are displayed in a tabular format. <image>. 1. When a student clicks on Other's Work after clicking on a specific Assignment, this is the view that pops up, containing a View Text Metrics for each review that the student has done. <image> 2. When the student clicks on View Review Metrics, the popup opens which displays the metrics for the specific review. <image>. For user/reviewer, the steps will be as follows 1. Login to Expertiza with your credentials 2. Open the Assignments , click on Other Work 3. For every review entered, hover the mouse on the icons beside the review 4. The review will be summarised by caption texts on the icon like ""Good Content"" or ""Obscene Word usage"" or ""200 words reveiw"" 5. View the metrics for each review. Few of the Test cases added to the test file for Review Metric. Click on the icon 'View Reviews' 4. Depending on the stage of the assignment , the reviews will be listed in the order they were filled. 5. Metrics will be displayed on hovering the mouse over each icon.","Though there are elements of the design I don't like, it is hard to argue with the way the design doc presents it.  All of the necessary features are present.  Perhaps the list of files changed should have explanations of why they were changed.  Perhaps the screenshots should be sized so that they fit within a text column."
E1799,"The purpose of the project is to improve self-review, link self review and peer review, to device a strategy to come up with the composite score. 1. Implementation of the concept to see self-review scores juxtaposed with peer-review scores. Designing a way to show them in the regular “View Scores” page and the alternate (heat-map) view 2. Implementation of the methodology to combine self-review and peer-review scores to derive a composite score 3. Checking if the author has submitted the self-evaluation(s) before seeing the results of their peer evaluations(already implemented). It should be possible to see self-review scores juxtaposed with peer-review scores. The way to show them in the regular “View Scores” page and the alternate (heat-map) view should be designed. Then implementation of the way to combine self-review and peer-review scores to derive a composite score should be done. The result of the formula should be displayed in a conspicuous page on the score view. Of course, there would be no challenge in giving the same self-review scores as the peer reviewers gave if the authors could see peer-review scores before they submitted their self-reviews. <image> The instructor has to login and create an assignment by checking allow self review option. Now, the student has to login and submit the assignment. The self review link is visible in the page. The student should give the self review. After giving the self review, the student should be able to see the peer review, self review and the composite score. Student: This actor is responsible for submitting, self-reviewing and viewing the scores. All the other use cases are implemented except “View Scores with self-review column and composite score” Use Case: View score with self-review column and composite score Pre Conditions: 1.The Student should submit the assignment and self-review. 2.The student should browse and upload the assignment. 3.The student should submit the assignment. 4.The student should submit the self-review. 5.The student should choose your scores to view the score. 6.The student should be able to see the peer-review score with the self-review scores and composite score. Post Conditions: 1.The self-review and composite score will be visible on the page. 1.The self-review data is getting stored in the existing table. This data is fetched from the table and shown in the view with the other peer-review columns. 2.The peer-review data and self-review data is fetched from the existing table and passed to the method. The method computes the composite score and is shown in the view. We considered Mean, Median and Mode to calculate the composite score. 2.The weighted average is calculated by dividing average by maximum score. 3.The weighted self-review is calculated by dividing self-review score by maximum score. 4.Difference value is calculated by subtracting weighted average and weighted self review. 5.The sum of differences of all the criteria is calculated which gives the deviation from the total of review scores(Difference score). 6.The difference between the number of questions and the Difference score gives us the composite score. And divide the composite score by the number of questions and multiply by 100 to get the final composite score. <table>. We have used the existing classes to incorporate the self review, hence there are no class level changes. In app/views/grades/view_team.html.erb, the html code to display self review column has been added beside the peer review scores. The final self review score has been displayed below the table. In app/models/vm_question_response.rb, the method to calculate the composite score has been added. In app/models/vm_question_response_row.rb, the method to calculate the weighted average, which is used to calculate the overall composite score has been included. After logging in as a student, the user should select the assignment. The user can see the attributes related to the assignment. The user selects ""your scores"" option to view the below page. The last column has the self review scores. The composite score(self review score) is calculated and is displayed at the bottom of the table. <image> After logging in as a student, the user should select the assignment. The user can see the attributes related to the assignment. The user selects ""alternate view"" option to view the below page The composite score(self review score) is displayed beside the final review score. <image> After logging in as a instrcutor, the user should select the assignment. The user can see the attributes related to the assignment. The user selects ""your scores"" option to view the below page. The same page ""your scores"" which is used for student view has been used in the instructor view as well. The composite score(self review score) is displayed beside the final review score.","The document contains little prose beyond the problem statement.  It is mostly a set of lists.  This causes readability problems, especially in the section on calculating the composite score.  I have read through it a couple of times and I simply don't understand the algorithm.  When you say, ""Mean, median, and mode"" to calculate the score--mean, median & mode of what?  Peer reviews, self-review, some combination? The test plan shows a lot of work.  The diagrams and screenshots are useful."
E2082,"The Expertiza project takes advantage of peer review among students to allow them to learn from each other. Tracking the time that a student spends on each submitted resource is meaningful for instructors to study and improve the teaching experience, and also in evaluating the quality/sincerity of the reviews. Previous work done in Fall 2019 enables tracking time between successive time tag assignment. <image> However, there are several problems with their solution: 1. There is no automated tests using mocked data to test their implementation. 2. The previous team added a tagging interval chart to each row (representing each participant) in the Answer Tagging report. However, the chart will be hard to read if there hundreds of tagging interval. The following links are the deliverables from the original implementation in Fall 2019. 1. <link> 2. <link> 3. <link> 4. <link>. 1. Display the tagging interval information as a number alongside the graph in order to make it more intuitive to read 2. Add test cases regarding new changes Example Mockup of Added Column <image>. helpers/review_mapping_helper.rb The method calculate_key_chart_information(intervals) was added to calculate the average, min, max, variance and standard deviation from the tagging intervals recorded. These key analytics were then returned as a hash. <image> views/reports/_answer_tagging_report.html.erb This view was modified to print an additional column for the answer tagging report. The column added was ""Key Graph Info"" which prints the hash that is returned from the method display_key_chart_information(). The hash is printed as a bulleted list. <image>. We were able to display key information from the generated graph as an additional column to the answer tagging report. <image>. We propose a method that aims to perform: 1. Query the database for details on reviews and their tags 2. Update the existing chart logic to process these numbers 3. Update the report format to include these times 4. Add tests for internal logic and manual UI-testing too HOW: We'll create an independent method for our logic and append it to the existing logic without necessarily modifying it. To manually reproduce the scenario on the UI and test the results on our new/modified time reports 1. Manually impersonate the process of tagging reviews for a dummy assignment 2. Test that the tag times are recorded and displayed properly 3. Compare it with previous logic to check that values/logic is consistent 4. Regression test just to see that the existing charts aren't broken. 1. Logged in as Instructor 6 with username = instructor6 and password = password 2. Click ""Manage..."" -> ""Assignments"" from the top-left menu item <image> 3. Create a new assignment by clicking the + button <image> 4. Filling the necessary information in ""General"" , ""Rubrics"" , and ""Due Dates"" sections indicated in the following screenshots. Then click Create button. <image> <image> <image> 5. Edit Tagging Assignment and click add new.. under Tag prompt dropdown list <image> 6. Click the green + on the top-right of the popup window. Enter the value for prompt and desc as shown in the screenshot below. Click green + button at the right most column. <image> 7. Select Criterion for apply to question type . Click Save button. <image> 8. Click the Add Participants button, then add student7339 and student7430 . <image> 9. Logged in as student7339 with password= password and make a submission from Your work <image> 10. Logged in as instructor6 and modify Tagging Assignment due date for Round 1: Submission to be two days before today. <image> 11. Logged in as student7430 with password= password and submit review from Others' work <image> <image> 12. Logged in as instructor6 and modify Tagging Assignment due date for Round 1: Review to be one day before today. <image> 13. Logged in as student7339 and tag the review from <Your scores> <image> <image> 14. Logged in as instructor6. Go to manage...->Assignment and click View Reports button. <image> 15. Select Answer Tagging Report and click View button. <image> 16. The highlighted column in blue rectangle is the new feature we added. Tests were added to test the accuracy of calculating the statistics of the timings we have tracked in this project. The comprehensive test can test all the math logic involved in our design. <image>. <link>. <link>.","The document did not describe all changes in the project; specifically, there was no discussion of changes that were made by the previous team that they were building on.  This is very unfortunate, because someone who wants to understand what has been done would have to read about a project that has not been merged, and then try to understand which parts you kept and which you discarded.  Manual testing is described very well."
E1644,"<link> is a peer review based system which provides incremental learning from the class. This project has been developed together by faculty and students using <link> framework. Expertiza allows the instructor to create, edit and delete assignments, create new assignment topics, assign them to a particular class or selected students, have students work on teams and then review each other's assignments at the end. For the students, they can signup for topics, form teams, and submit their projects and assignments. Students then review the work done by other students and give suggestions to improve. Teams after reviews are allotted scores and they can refer to the peer comments to further improve their work. It also supports submission of different file types for assignments, including the URLs and wiki pages. Teams_Controller primarily handles the team creation, deletion and other behaviours. Most of those are called from the instructor’s view. When manual testing is done, most of the methods can be called by clicking the “Create teams” icon from both assignments and courses. The following tasks have been performed as per the requirements. As a part of the project, some GUI's changes had to be made because they did not work the way they should have, some minor issues in the code were fixed and tests were written in RSpec for the methods delete, create, create teams, list and inherit. The method Create is called when an instructor tries to create a team manually. This works for both, creating assignment teams and course teams . Assignment teams are teams made to do a particular assignment together and Course Teams are teams which are made for the whole course. Following Test Cases were written and executed in RSpec to test this method: 1. To verify that the Instructor is able to create course teams. 1. To verify that the Instructor is able to create assignment teams. The method Delete is called when an instructor tries to delete a team manually. This works for both, deleting assignment teams and course teams . Following Test Cases were written and executed in RSpec to test this method: 1. To verify that the Instructor is able to delete course teams. 1. To verify that the Instructor is able to delete assignment teams. The method List lists all the team nodes and the instructor is able to expand each team node to see the user nodes as well. Following Test Cases were written and executed in RSpec to test this method: 1. To check that all teams are being listed in the view. The method Inherit inherits teams from course to assignments, but the “Inherit Teams From Course” option should not display when either 1) we are editing a course object or 2) the current assignment object does not have a course associated with it. Following Test Cases were written and executed in RSpec to test this method: 1. To check that inherit teams is displayed while creating an assignment team. 1. To check that inherit teams is not displayed while creating a course team. 1. To check that inherit teams is not displayed while creating teams for an assignment without a course. <link> is restructuring of code without the need of changing any external behavior. It reduces complexity and improves readability. It also becomes easy to extend the application with respect to different modules and their functionalities. Some common techniques to refactor are: 1. Moving methods to appropriate modules 2. Breaking methods into more meaningful functionality 3. Creating more generalized code. 4. Renaming methods and variable. 5. Inheritance As the part of the project, the variable @signUps in the delete method in the teams_controller was changed to snake case, to improve readability of code. To fix the view for inherit teams functionality, changes to the view were made. Initially, the code was: <code> Which was changed to: <code> To fix the view, in the new.html.erb file of teams, we enclose the inherit teams section in an if condition that checks that the parent of the team is not a Course and it is not an Assignment whose course is nil. 1. <link> link to the project. 2. <link> to the project description. 3. <link>.","Good description of what is done by all the test cases, and why.  Changes to view, however, were not similarly described."
E1761,"This project uses assignment.rb. It contains a lot of methods that are long and hard to understand. These methods need to be broken down into simpler and more specific methods that are easier to read/understand. Also, the few instances of code duplication that exist should also be removed. This is the course of solution we followed throughout our project: 1. Complete the pending tests in assignment_spec.rb, and write unit tests for newly-created methods. Please finish one set of pending tests before refactoring the corresponding methods. Refactor scores, self.export method. 1. Write failing tests first 2. Split into several simpler methods and assign reasonable names 3. Extract duplicated code into separate methods. Rename method and change all other places it is used 1. Write failing tests first (not only for renamed method, but also for other methods calling renamed method) 2. has_topics? Use find_by instead of dynamic method 1. Write failing tests first 2. search in lines L136, L300, L315, L542, L610. Code refactoring is the process of restructuring existing computer code—changing the factoring—without changing its external behavior. Refactoring improves nonfunctional attributes of the software. Typically, refactoring applies a series of standardised basic micro-refactorings, each of which is (usually) a tiny change in a computer program's source code that either preserves the behaviour of the software, or at least does not modify its conformance to functional requirements. Clean code means three things for your program: quality, clarity and maintainability. Clean code is code whose intention and behavior is immediately apparent to other developers. . Clean code survives into the future because it accommodates change and growth. Above all, though, clean code is a pleasure to write and a pleasure to work with. Refactoring is a controllable process of improving code without creating new functionality. It transforms a mess into clean code and simple design. Clean code is code that is easy to read, understand and maintain. Clean code makes software development predictable and increases the quality of a resulting product. Test-driven development (TDD) is a software development process that relies on the repetition of a very short development cycle: Requirements are turned into very specific test cases, then the software is improved to pass the new tests, only. This is opposed to software development that allows software to be added that is not proven to meet requirements. Advantages of using TDD: 1. Narrowing Problem Focus 2. Tidier Code 3. Not worrying about dependencies 4. Easier refactoring 5. Better Test coverage and fewer bugs. Model controller file, assignment_spec.rb in spec folder was completed with tests written for all the methods in the assignment.rb file. These are tests are failed before the development as a part of our Test First Development approach to the problem. There were 55 tests to be written from scratch. All the pending tests were completed as a part of our first plan of action. You can simply run command ""rspec assignment_spec.rb"" command on linux terminal to get the output. For the second part of our plan of action we had to refactor the scores and self.export method and remove the duplicate code throughout, which were extremely tricky. As these changes also had to be incorporated in the assignment_spec.rb file for updating the tests withe same. For doing this we broke the method into two parts and then passed the required parameters through them. Code for this as follows in assignment.rb file, these changes can be seen between L561 to L567 <code> <code>. For the third task in our plan of action we had to change the method names throughout the code. These changes meant that the test for the same methods needed to be altered too. Our fourth part of the plan of action called for change in assignment.rb file. In this we needed to replace multiple dynamic methods with find_by while keeping the functionality of the method same and that means the altered code needed to run the already written tests without any error. These changes can be seen in L142, L306, L321, L548 and L621 in the updated files. In addition we had to write new test for the find_due_dates method which was not defined in spec model. L142 in this method <code> L306 <code> L321 <code> L548 <code> L621 <code>. These tests were all written by us. The description of few tests can be seen in the video. You can simply run command ""rspec assignment_spec.rb"" command on linux terminal to get the output. Code for the tests and changes in the assignment_spec.rb file are shown below this includes the solution to Problem 1 and Problem 2 : <code> <code> <code> <code> <code> <code> <code> <code> <code> <code>. When the spec tests are run we get the desired output on the terminal: <image>.","In Task 4, code segments are pasted without any description of what they are doing.  That's not adding much value compared to just referring readers to Github.  What would be useful is a 1 or 2-sentence descripton of what the code segment is doing.  Then with regard to the tests, large amounts of code are pasted without any description at all."
E1734,"Expertiza used to have functionality for conducting surveys. Therefore, there are parts of survey functionality that are broken or are totally unfinished. As an instance of a broken feature, take survey deployments for example. 2) Use of inheritance so that survey questionnaire is a subclass of the questionnaire class. Also, course evaluation questionnaire and global survey questionnaire should be subclasses of survey questionnaire. 3) Use response_controller to implement the survey functionality. 4) Use the same code to display existing survey responses as to display the responses in peer reviews. 5) For each course or assignment, the admin/instructor should be able to create a survey and have some (or all) of the participants receive the survey. The instructor should have the option to not include some questions from a global survey. The quiz takers can take the global survey and course survey consecutively. The surveys are as follows: 1) Course Survey: All the participants in a course can take the course survey. File: course_survey_questionnaire.rb 2) Global Survey: Any Expertiza user can take the global survey. Appended to another survey. File: global_survey_questionnaire.rb 3) Assignment Survey: All the participants in an assignment can take the assignment survey. <image>. We've added Survey Response Map, Assignment Survey Response Map, Course Survey Response Map and Global Survey Response Map classes to complement the questionnaire functionality above and mimic the Single Table Inheritance implementation. <image>. It is inherited by Classes Quiz, Survey, etc. We can reuse this class's functionality to create, edit and delete surveys. This project will introduce a new class called Survey Questionnaire. This class will inherit from the Questionnaire class and it will be a superclass for the three different kinds of survey classes. This class will also have the statistics_generation functionality to be used to provide statistics for any kind of survey. This class will inherit from class Survey Questionnaire. This class will be set the display_type for the survey to be global. So, while assigning participants all the users of Expertiza will be able to see this particular survey. This kind of survey can only be created by admins of the Expertiza system. This is also another type of survey and will inherit from class Survey Questionnaire. Surveys of this type, however, will only be available to the class to which this survey would be assigned. That is, Course participants receive the course survey questionnaire. This class will also inherit from the class Survey Questionnaire. All participants in the assignment receive the assignment survey questionnaire. <image> The student can view pending surveys and can then take those surveys. <image>. There are database tables that are used to track the deployment of the surveys, that are used to help keep track of the participants for each survey and that keep track of all the responses for the surveys we create. Table: Survey Deployments <table> Table: Response_Maps To incorporate the survey functionality, we have made the following mappings: REVIEWED_OBJECT_ID corresponds to COURSE_ID / ASSIGNMENT_ID REVIEWER_ID corresponds to PARTICIPANT_ID ( id in Participants table ) REVIEWEE_ID corresponds to SURVEY_DEPLOYMENT_ID ( id in Survey_Deployments table ) <table> Table: Participants Participants in the survey are present in this table. ( Note - FIELDS THAT ARE RELEVANT TO SURVEY FUNCTIONALITY are mentioned below ) <table> Table: Responses Responses table contains a map_id which is the id in Response_Maps table <table>. The following list provides a summary of the tasks we have performed to implement the survey functionality. Make survey questionnaire the child of questionnaire. Global survey questionnaire, Assignment survey questionnaire and course survey questionnaire are subclasses of survey questionnaire. 2) Creation, editing and deletion of questions, is a functionality that would be inherited into class Survey(which is a kind of questionnaire) and so into all its children surveys, from the Questionnaire class. 3) Add a new class called Survey Questionnaire and include functionality to assign(which is in the survey_controller currently) to this model. 4) In the survey deployment class, add functionality to generate statistics. 5) The three kinds of surveys can be assigned to students an assignment, a course, and a global survey which is appended to one of the other two surveys. 6) Use the Pending Surveys (newly added) tab on the Expertiza homepage to display any pending surveys instead of just the course evaluation surveys. The course evaluation tab’s functionality was removed because it was broken, it was replaced with the pending surveys functionality. 7) ""Survey deployment"" functionality was broken. We made survey deployment of all forms of surveys functional. It included the following tasks: <code> 8) Remove the class Survey Response and replace its' functionality with Answer. 9) Make use of Response and Response Map to link survey deployments with answers (survey responses).","Document much improved in second round.  I agree with the comments about too much of the testing being manual, and also there could be a more detailed description of how the various surveys were intended to be used.  Other than that, I think it's great."
E2085,"<image> As discussed in the <link> section, a bidding system similar to the bidding system used in topic selection is preferable to the current review selection system. <image>. <image> Source: <link>. The Review topics does not have any preferences. Our Expertiza controller sends this webservice bidding information and the algorithm returns the matched topics to be assigned. These are the methods that render the bidding pages and review listings. <image> Method: show This method renders the bidding page in which participants can select from a table of topics the topics they would prefer to review. It collects the necessary information about the user, Assignment, Topics, and current Review Bids to render this page. It is used in conjunction with <link> where the users bidding information is stored, and the page updated. To see the bidding page that this function renders, visit the view <link> <image> Method: set_priority In the view file <link> there exists a line the calls this method when the page is updated or accessed. This method stores the user's bidding information in the schema database. <image> <image> Model The model contains 5 methods that are utilized by the controller to save bidding information per user or all users, retrieve bidding information per user or for all users, and assign topics to review to participants. Method: get_bidding_data This method is called by the <link> controller method. <image> Method: assign_review_topics This method is called by the <link> controller method. <image> Method: assign_topic_to_reviewer This method is called by the method <link> and assigns a single topic to a single user to review given an Assignment ID. <image> Method: reviewer_bidding_data This method is called by <link> . They are for bidding and for showing assigned reviews after the bidding algorithm has been run. <image> <image> <image> <image> View rendered by above: <image> View: show.html.erb This view file renders the Review Bidding page where participants can select which topics to review. <image> <image> Page rendered by above: (This rendering is an instructor view, the student view is the same without the ""Edit Topics"" column.) <image> <image> <image> Class Topic The Topic class is the one that does the proposing to the students during the runtime. The Review topics does not have any preferences. Our Expertiza controller sends this webservice bidding information and the algorithm returns the matched topics to be assigned. These are the methods that render the bidding pages and review listings. <image>. <image>. This method renders the bidding page in which participants can select from a table of topics the topics they would prefer to review. It collects the necessary information about the user, Assignment, Topics, and current Review Bids to render this page. To see the bidding page that this function renders, visit the view <link> <image>. This method stores the user's bidding information in the schema database. <image>. <image>. <image> <image>. The model contains 5 methods that are utilized by the controller to save bidding information per user or all users, retrieve bidding information per user or for all users, and assign topics to review to participants. This method is called by the <link> controller method. This method is called by the <link> controller method. <image>. This method is called by the method <link> and assigns a single topic to a single user to review given an Assignment ID. <image>. <image>. This method is called by <link> . <image>. They are for bidding and for showing assigned reviews after the bidding algorithm has been run. <image> <image> <image> <image> View rendered by above: <image>. This view file renders the Review Bidding page where participants can select which topics to review. <image> <image> Page rendered by above: (This rendering is an instructor view, the student view is the same without the ""Edit Topics"" column.) <image>. <image>. <image> <image> <image>. <image>. <image>. <image>. 1. test that an instructor can allow review bidding for an assignment 2. test that server routes correctly when review bidding is allowed 1.1. test that task box links to bidding page before algorithm is run 1.2. test that assignment->others work links to bidding page before algorithm is run 1.3. test that task box links to review page with bidding information after algorithm is run 1.4. test that assignment->others work links to review page with bidding information after algorithm is run 3. test that the bidding UI is implemented as expected 4. test that a participant can bid on projects to review 1.1. test that a participant can move projects into the bidding column 1.2. test that a participant can reorder projects in the bidding column 1.3. test that a participant's bidding preferences save 1.4. test that a participant can't bid for their own topic 5. test that run algorithm button calls webserver with correct information and returns review assignments for each user. and Has topics?","The code is described in detail and very well.  Motivation is provided for major design decisions.  Automated testing could be described in more detail.  It's not clear why ""Algorithm"" is capitalized.  Other random nouns are capitalized too.  "
E1643,"It also makes it easy for the instructor to add a new topic to an assignment/project, create a new project and add students to it. There is also an option for the student to not work on it. One can also submit the suggestion anonymously. Once a student submits the topic, the instructor can check that in the view suggestions tab, and can either approve or reject. Once the instructor approves, the student gets a mail regarding the approval. This mail is sent only if the student doesn’t submit the topic anonymously. In the process of assigning the given suggestion as a project topic to the student, it automatically gets assigned to the whole team if the student is part of a team. These are the cases considered: Instructor starts a new assignment with some topics 1. Student signs up for one topic, suggests a new one but doesn't want to work on it. Then the student receives a mail once the instructor approves. 2. Student doesn't sign up for a topic and suggests a new one. If the student opts to work on it, then on approval, a mail is sent. If the student doesn't want to work on it, then no mail is sent even on approval. 3. It is a team project - if there is already a team and they come up with a new topic and want to work on it, then a mail is sent on approval. If there isn't a team and a student suggests a new topic, a topic is assigned on approval and also a team of students who choose that topic. 4. A team project - there is a team and they suggest a topic but choose not to work on it and also they haven't signed up for a topic. In this case, upon the acceptance of topic by the instructor, there is no email sent and they are supposed to sign up for a topic from the given set. Irrespective of teams and topic, if someone suggests a topic anonymously, there won't be any email notification on approval of the topic. All the scenarios uses the following: 1. Instructor6 2. Student2064 3. Assignment 1. This automatic test case checks the following steps: 1. User (Instructor6) logins in. 2. On successful login, the instructor clicks the tab for Suggestions list for a particular assignment (Assignment 1). 3. On visiting that tab, a page with content ""Suggested topics for Assignment 1"" is rendered with the topic name. We have considered Student2064 for this case. We test for all the following cases: 1. Student2064 logs in, visits Assignment 1, clicks on new suggestion and submits a new topic. Upon submitting the topic, a page with the content saying ""Thank you for your suggestion! Suggested topics for Assignment 1, ""Topic title"" initiated"", should be rendered. 2. And if view is clicked, a page with the content ""View Suggested topic Computer Vision"" is displayed. This scenario accounts for the testing the following: 1. Student2064 logs in and suggests a topic (Computer Vision) under Assignment 1. 2. Instructor6 logs in and checks on Assignment 1. 3. After logging in, instructor checks that “Computer Vision” is submitted by student2064 4. Also the comment by the student can be viewed. 5. After looking at the topic, the instructor approves the suggestion. 6. Then, when the Student2064 logs in and visits Assignment 1, he/she can check that the suggestion “Computer Vision” has been accepted. The steps mentioned below are tested in this scenario: 1. Student2064 logs in and suggests a topic (Computer Vision) under Assignment 1. 2. The Instructor6 logs in to check that “Computer Vision” is submitted by student2064 for Assignment 1. 3. After checking the comment by student2064, Instructor6 rejects the suggestion. 4. The Student2064 logs in, visits Assignment 1 to find out that the suggestion “Computer Vision” has been rejected. This scenario accounts for testing the following steps: 1. Student2064 logs in and suggests a topic (Computer Vision) under Assignment 1. 2. Instructor6 logs in and should be able to check that “Computer Vision” is submitted by student2064 for Assignment 1. 3. After checking the comment by student2064, Instructor votes for the suggestion. 4. Then the Student2064 logs in, visits Assignment 1 to check that Instructor6 has voted for the suggestion. The scenario comprises of testing the following steps: 1. The Student2064 logs in and visits Assignment 1 to suggest “Computer Vision” topic. 2. After suggesting, the student selects “No” for suggestion signup preference and submits suggestion. 3. The Instructor6 logs in, visits Assignment 1 suggestions to approve the suggestion “Computer Vision”. 4. On approving the suggestion, a page saying ""suggestion approved successfully"" is rendered for the instructor. '.","The project was a refactoring project, but the writeup doesn't say anything about how the code was refactored.  Instead, the writeup talks about how to set up the project on a local machine ... which is not specific to this project, but was covered in instructions given to all teams.  For testing, the headings are of the form, ""Scenario 1"", ... , ""Scenario 6"", which are not informative of what the tests do.  And only the first three tests are shown."
E1998,"However, the same functionality is not present for quiz questionnaires. Quiz questionnaires are essentially a way to ensure that students review others' work genuinely. The flow which is followed from quiz creation to score evaluation is as follows: <image> While creating this quiz, a student is supposed to ask questions related to his/her work which ideally a reviewer must be able to answer. Once it is created, reviewers are able to answer these quizzes and the corresponding scores are evaluated for each quiz separately. Ideally, each question should have a weight associated with it which a student creating the quiz should be able to specify, which in turn should be used while calculating scores for those taking these quizzes. However, currently, there is no way to specify weights for individual questions while creating quizzes and hence scores are being calculated by giving each question equal weightage. Goal of the Project The goal of this project is to understand the cause of the aforementioned issue and to ensure that the weights associated with questions are taken into consideration when grading all types of questionnaires involving weights. Our main focus will be to implement weights for quiz questionnaires, To achieve this, first we will have to introduce a way for a student creating a quiz to be able to enter weights for individual questions. Once weights for each question are being successfully stored, we can proceed to change how scores for each reviewer(for a particular quiz) are being calculated such that these newly added weights are also being taken into consideration. This view has a column named question_weight which is populated by the user entered weights for weighted questions and is set to null for non-weighted questions. Currently, for questionnaires other than quiz questionnaires, an instructor creates a rubric for the questionnaire where he/she can specify weights for each weighted question that exists for that questionnaire. This method for specifying weights is non-intuitive and cumbersome. For quiz questionnaires on the other hand, there is no way to enter weights for newly added questions at all. The weights are set to 1 by default for all the weighted questions and are not modified henceforth. As a result, scores are calculated for each quiz for a particular reviewer by giving equal weightage for each question. This calls for a complete overhaul of how scores for quiz questionnaires are being calculated to include weights which will need to be accepted from the student creating the quiz. We have utilied the Facade Design Pattern to hide the complexity of quiz score calculation and provided a single method quiz_score to calculate and return the score of the quiz considering weights on each question. The method encapsulates the entire logic and returns the total weighted score for the corresponding quiz instance. This method creates new questions when creating questions in questionnaires of types such as review questionnaire, author feedback questionnaire, teammate review questionnaire, etc. save_new_questions This method saves questions when a student creates a quiz questionnaire. There was no way to associate weights with questions in quiz questionnaire earlier, we've made changes to allow adding weights to questions in a quiz questionnaire. The corresponding changes are present in this method. 1. _new_question_template.html.erb The input field for adding question weights at the time of creation of questions in a quiz has been added to this file. This functionality was not present earlier, all questions in a quiz were associated with a default weight of 1. The weights entered in this input field are used by the save_new_questions method in questionnaires_controller.rb 1. _questionnaire.html.erb The input field for adding question weights at the time of creation of scored questions for questionnaires of all types except quiz questionnaire has been added in this file. This functionality was not present earlier, as questions had to be created first and then edited to change the default weight (1) associated with it. This code ensures that the field is displayed only if the user is trying to created a question with which weights can be associated - questions of type Criterion and Scale. The added logic incorporates the weights which the user can now input corresponding to questions when creating quizzes. We then proceed with quiz questionnaire creation and associate weights with questions created. We create all three types of questions that can be created in a quiz questionnaire - True/False questions, Multiple Choice Radio questions and Multiple Choice Checkbox questions. Further, we login as student B who has reviewed student A's work and take the quiz. Finally, we submit the quiz and ensure the that the quiz is scored after taking the weights associated with the questions into consideration. 3. An input field will appear at the right of the has quiz checkbox, please enter the number of questions in the quiz in that checkbox. 7. This will enable the create quiz link in the your works section, please go ahead and create a quiz. 10. Click on the take quizzes link, a radio button with the quiz created by participant A should appear, go ahead and take the quiz. 11. The quiz will be graded taking into consideration the weights you used for creating the questions in the quiz as participant A.","Well-written report, with good descripitions of the changes that were made. Tests should be a separate section, though.  Automated testing should be addressed in a separate section."
E1967,"Find our PR here : <link> Team members : 1. Bin Patel (bpatel24) 2. Omkar Kulkarni (oskulkar) 3. Pranav Gaikwad (pmgaikwa) Mentor : Mohit Jain To test our code in a real Expertiza environment, please see instructions on <link> page (Expires Nov 9, 2019). In Summary report for assignment (grades/view_team?id=xxxx) for instructors, the author feedback section list a different set of users than the reviewers. It should list the team's feedback to all its reviewers to this particular assignment. Currently, the Author Feedback section for a team shows the feedback the team received from other Authors they reviewed earlier. The Author Feedback section, however, should display the feedback the team gave to their reviewers. To explain these ideas in more detail, let's consider the following scenario : Team 22 has two members in the team : Team Member 1 , and Team Member 2 . This team reviewed assignments of Team 29 and Team 30 . Currently, the author feedback section displays feedback given by Team 29 and Team 30 to Team 22 . See following figure. <image> Now, consider that the Team 22's assignment was reviewed by members from Team 23 and Team 24 . Then, the Author Feedback section should display the feedback Team 22 gave to the members of Team 23 and Team 24 . <image>. List of files with code relevant to this issue : 1. Controller : <link> 1. View : <link> 1. Model : <link> 1. Helpers : <link> <link> method in grades_helper.rb is responsible for providing information about reviews, metareviews, author feedbacks, etc. We do not need to make changes in this file. 'Author Feedback' tab in the UI contains tables for each team member with detailed breakdown of their feedback. The method <link> is called before the review table is rendered in the view. This method does different things based on which tab we are on. In this function, we only have to change the if block for 'Author Feedback' tab. Apart from these, we need to change the heatgrid view in the UI. Current view cannot be used for Author Feedback for following reasons : 1. The heatgrid is configured to use Reviewer id as column title. In case of Author Feedback, we want Reviewee id as column title instead. <image> 1. The row title in detailed scores is not appropriate for Author Feedback. We need Reviewee Id there. <image> 1. Logic to show total number of feedbacks in the title row doesn't work. <image>. 1. File : <link> 1. Line Numbers : #61-#70 We only need to change the if block responsible for Author Feedback tab. Logic : 1. Get the list of all FeedbackResponseMaps where current Participant is a reviewer. The participant id is already passed to the add_reviews() method. 3. Pass the list of Responses to the heatgrid view. def add_reviews(participant, team, vary) <code> end. 1. File : <link> 2. Line Numbers : #117-#119, #185-#189 As discussed in the previous section, we need to change UI elements specific to Author Feedback tab. First, we change the title of each column to show Reviewee Id instead of Reviewer Id . To achieve that, we only add a simple if condition in the view to check whether the current tab is 'Author Feedback'. We change the title to use 'reviewee_id' whenever the current tab is Author Feedback. <code> Secondly, we change the Title of each row in the detailed score view (when the dropdown of review is opened). Here, we need the Id of the reviewee. <code> 1. File : <link> 2. Line Numbers : #6 At last, we need to change the count of Feedbacks displayed at the top of each row as shown in the figure. <code>. The code we changed is very specific and only applies to cases where 'Author Feedback' is to be shown. File : <link> 1. There is a fundamental change in how Author Feedback is tested. In existing implementation, we test for the feedback received by a participant. However, in the new implementation, we are interested in testing feedback left by current participant to other team members. Therefore, variable @list_of_reviews should contain the list of reviews (feedbacks) left by current participant. 2. Impersonate as student7189 and for assignment Madeup Problem, click on Alternate View, then click on show reviews and save any review. 5. Click on View Scores under Madeup Problem Assignment. 6. expand Madeup problem_Team22. 7. click on tab ""Author Feedback"" and you will see all reviews made by that authors(all participant of Team22). To test our code in a real Expertiza environment, please see instructions on <link> page (Expires Nov 9, 2019).","1. Explained their task and solution well.
2. I'm confused when you say, ""This team reviewed assignments of Team 29 and Team 30."".  In Expertiza, teams don't review submissions; users do.  Looking at the diagram clarifies that you only consider the submissions reviewed by the first member of the team.  The prose should be changed to reflect that.
3. I assume that your diagrams are ""before"" and ""after"" you have changed the behavior.  But the wiki doesn't identify them as old and new.
4, Created mock test data and explained how to test from UI.
5. No code is shown for automated tests, only a single sentence that overflows a text box.  The test plan needs to be much better defined.  How do you know that the right reviews appear on the right user's heatgrid?




"
E1932,"The language that we would work with is Hindi. This project also adds the ability for an instructor to choose a default language for the course. Students will see this language by default if they are enrolled in this course. This allows students to view their course landing page in the default language set by the instructor. Moreover, each assignment of a course can now be viewed in the course's default language. This NoMethoderror also occurs when we tried to change language from pages other than the Assignment landing page. Another issue was that if the selected language is Hindi, and we navigate back using the back button on the pages, expertiza reverts the language change to english. English is the default choice. 1. A student's assignment list page will display the default language of the course associated with them. English is default if no course is associated. 1.1. If multiple courses are associated with a user, the display language is set to English unless all the courses have the same default language. In that case, we chose that default language. 1. Each of the student's assignment pages will be displayed in default language of the assignment's course. If assignment doesn't have a course, English is the default language used. A1 will be displayed in English and A2 in Hindi. THe student's assignment list page will be displayed in English. 1. A student has an option to change the display language at any time during their session. 1.1. User Selection Preferred: If a student changes the language manually using this dropdown, then all the pages including assignment pages will be displayed in this language. The user's selection is preferred over the course's default language. The use case diagrams for our current project show the approach of changing the language in the assignment landing page as well as changing the language of the view when you select a particular assignment. <image> <image>. When the participant is added to that particular course where the language is set, they will view their default student view pages in selected language. Default should be english. A new dropdown option was created in the instructors view to enable language selection during course creation. Moreover, if a student has multiple assignments belonging to different courses having different default languages, then each assignment will be displayed in its course's default language. Default language for each assignment based on its course is decided in this file. <image> Fig 7: Instructor sets language <image> Fig 8: Default view of student. Files edited: <code> Code snippet from the view: Before: <code> After <code> <image> Fig 2: Assignment page when locale is set to english It can be observed that the parameter id and locale persists after making the change from english to hindi <image> Fig 3: Assignment page when locale is set to hindi 1. The previous team's implementation changed the url to include the locale (for ex: en or hi_IN). We have also translated dynamic strings as well. 3. It should show different language for assignments based on their course : Tests assignments to be displayed in their course's default language. 2. Go to language dropdown in the navigation bar and choose Hindi. 3. Check if language is changed in the URL from en to hi_IN 4. Check to see if the English strings on the page are translated to Hindi 5. While still logged in as a Student, check if the other Assignment related pages are also translated. 2. Go to language dropdown in the navigation bar and choose Hindi. 3. Check if language is changed in the URL from en to hi_IN 4. Check to see if the English strings on the page are translated to Hindi 5. While still logged in as a Student, check if the other Assignment related pages are also translated. 6. Go back to the main Assignment page and choose English from the dropdown. 7. See if the language was changed in the URL to en. 8. See if the strings are translated back to English for all Assignment related pages. 2. Go to URL and change the language from en to hi_IN. 3. Check to see if the English strings on the page are translated to Hindi. 4. While still logged in as a Student, check if the other Assignment related pages are also translated. 2. Go to URL and change the language from en to hi_IN. 3. Check to see if the English strings on the page are translated to Hindi. 4. While still logged in as a Student, check if the other Assignment related pages are also translated. 5. Now change the language back from hi_IN to en in the URL. 6. See if the Hindi strings are translated back to English for all Assignment related pages. The default language is english and the conversion of static strings to hindi was done using Google translate. If none, it defaults to the default locale file (which is english). 1. <link> <link> 2. <link> <link> 3. <link> <link> 4. <link> <link> 5. <link> <link> 6. <link> <link> 8. <link> <link>.","For design doc: This is a very good description of the changes to be made, and the rationale for making them.  But it has not been updated to reflect how the code was actually written, and that is one of the most important needs for programmers who follow on later."
E1845,"In order to test all functionality, a super-administrator account is needed. The following account can be used in a standard Expertiza deployment: - Super_administrator2 : password Following the installation and setup of the Expertiza system with the scrubbed database, testing of the project functionality can be done as follows. A. User Deletion 1. Sign in as a Super-Administrator (see above for sample account) 2. Navigate to Administration>Show>Instructors i. Select one of the instructor accounts ii. On the account page, click the delete link at the bottom iii. Assuming the instructor account is not tied to any assignments or other associations, the account will be gone from the list. If there is an issue, an error will be displayed at the top of the page. 3. Navigate to Administration>Show>Administrators i. Select one of the administrator accounts ii. On the account page, click the delete link at the bottom iii. Assuming the administrator account is not tied to any assignments or other associations, the account will be gone from the list. If there is an issue, an error will be displayed at the top of the page. 4. Errors may appear on the page when an account to be deleted still has relations to other assignments, teams, etc. The content and quality of these error messages is outside the scope of this project; some may show an English error, others may return an SQL error. This is the intended functionality as of the time this project was written - this project only concerns successful deletion in situations where deletion should be working. Role Creation 1. Sign in as a Super-Administrator 2. Navigate to Administration>Setup>Roles 3. Ensure that there is no link on the page to create a new role 4. Ensure that manually navigating to /roles/new results in an error message on the page. The majority of the project was related to solving issues regarding the deletion of Administrator and Instructor accounts. Administrator and Instructor are both account types that inherit behavior from User but are handled and deleted in different codepaths. Furthermore, properties are used on a User that aren't on an Administrator, such as team ids or course associations. The first step towards fixing the deletion functionality was to sort out the routing issues. No listing in the routing table existed for administrator deletion, and no controller method existed for neither administrator nor instructor deletion. With both of those in place, the only issue left was the deletion functionality. Because of the varying properties on Users and Administrators, and due to some database table migrations that were put into effect earlier, the rails system was unable to find user_id columns in the Users table when trying to delete the Administrator and Instructor accounts. The earlier migration had renamed it to team_id when team functionality was changed, but since Administrator and Instructor don't join teams, that id was invalid. A new migration was created to re-add the user_id column to the table as a blank column just used for SQL matching. In order to maintain DRY principles and support future code maintenance, a helper method was created for use with deleting Users, Administrator, and Instructor. By using a static class method, both UserController and AdminController could use the same underlying functionality for deleting User objects while customizing the flash message and the redirect url. The code segments only show the destroy method for the users controller, as the code is nearly identical in the administrator controller for both Instructor and Administrator deletion, with the only changes being to the name of the position being passed and the redirect_to path after the deletion. <image> Before: (users_controller.rb) <code> After: (users_controller.rb) <code>. In Expertiza, each user has a role in the system which dictates the availability of functionality to the user. The current roles in the system are Administrator, Instructor, Student, Super-Administrator, Teaching Assistant, and Unregistered User. The other focus of this project was to remove the ability to add new roles to the system. The functionality was previously available only to Super Administrators, but the functionality was deemed unnecessary and a potential issue to keep around. The solution simply involved removing the New button from the Roles list view and preventing any new functionality in the Role controller. Before: (roles_controller.rb) <code> In the controller, the above was changed to the following in order to prevent the functionality on the GUI side. In order to develop test cases for the functionality added and removed in this project, both an admin_controller_spec.rb and a roles_controller_spec.rb file were created and added to the RSpec test environment. The admin tests include building and deleting both Administrator and Instructor accounts using Capybara for testing the front-end web functionality. To test the role creation, Capybara was again used to check that the web page did not have any button for ""New Role"" and that navigating to the page manually resulted in an error.","The write-up is short but precise. it has pretty much everything needed for understanding the issues and what they have done. It will be  better if they could show the code for test and include some UI screenshot. Also, they wrote their implemented solutions in ""Changes"" and even in ""Background"" and it would be easier for reviewers to find them if they are seperated in a new subsection."
E1810,"<link> is a web based open source peer reviewing tool developed and maintained by current and past students of <link> . Peer review is a great way for a student to learn how to approach a project and get ideas for their own projects. Currently, there is no way for a student to view another student's work, unless they are reviewing the other student's work. The objective of this project is to: 1. Add a feature to allow teams to publish their work for other students to see. 2. Add a feature for a student to view sample submissions for a given assignment made available by other students: 1.1. In the same assignment, available after deadline. 1.2. In an old assignment, selected by the instructor from sample submissions made in an old assignment. 3. Add a feature for instructor to select a previous assignment to show sample submissions for a new assignment. The proposed features will involve two kinds of users : Students and Instructors. Students will use the application to make their submissions public and view published reviews. <image> Instructors will use the application to make submissions from a previous assignment available as sample submissions for a current assignment. Only those submissions will be visible which were previously made public by the students. <image>. The tasks that need to be completed as part of this project can be listed as follows: 1. Add checkbox against each assignment in student_tasks/list view to allow student to publish their work 2. Add column make_public to table teams for storing user permission (published or not) for each project. 3. Add controller for Sample submissions and implement corresponding methods. 4. Add views for sample submissions 5. Make changes to page student_task/view which would have link to sample submissions for each project. 6. Add drop down in assignments/edit/_general view. 7. Add controller code for the drop down. 8. Add column sample_assignment_id to table assignment. 9. Add test scripts for all the functionality. All tasks mentioned in Project tasks are completed. 1. Add checkbox against each assignment in student_tasks/list view to allow student to publish their work <code> 2. Add column make_public to table teams for storing user permission (published or not) for each project. <code> 3. Add controller for Sample submissions and implement corresponding methods. <code> 4. Add views for sample submissions <code> 5. Make changes to page student_task/view which would have link to sample submissions for each project. <code> 6. Add drop down in assignments/edit/_general view. <code> 7. Add controller code for the drop down. <code> 8. Add column sample_assignment_id to table assignment. <code> 9. Add test scripts for all the functionality. <code>. 1. The first screenshot of the application is taken when the deadline for the current assignment has not crossed and the instructor also has not given any sample assignment for this assignment. <image> 2. The second screenshot of the application is taken when the deadline for the current assignment has not crossed but the instructor has selected a sample assignment for viewing against this assignment. <image> 3. The third screenshot of the application is taken when both the deadline for the current assignment has crossed and the instructor has selected a sample assignment for viewing. <image>. Many of our changes are reflected on views (user interface). So we build tests with rspec/capybara. Following is the list of tests that conduct: 1. it ""is able to make an assignment public"" 2. it ""is able to view sample submissions page"" 3. it ""should not see current assignment submissions if deadline is not met"" 4. it ""should see current assignment submissions if deadline is met"" 5. it ""should not see instructor selected submissions if instructor has not selected them"" 6. it ""should see instructor selected submissions if instructor has selected them"" <code>. 1. Publishing sample reviews made by students: This feature will require students to allow their review to be published as a sample review. This can then be made available to future students. 1. link to forked repository <link> 2. link to the git pull request <link> 3. link to the deployed application <link>. 1. Link to expertiza website: <link>.",Very good job of describing the functionality and presenting the code.
E1960,"Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. E1960. Create new late policy successfully and fixing ""Back"" link. An instructor can create late policies for any assignment, wherein the instructor can specify the points per unit and the maximum penalty that can be applied for any assignment submission. If an instructor while creating a policy, clicks on “Create” (Step 5), following error message is displayed on the top of the page “The following error occurred while saving the penalty policy:” and the policy is not created and added to the list of policies. If an instructor, while creating a policy, clicks on ""Back"" link (Step 6) and wants to go back to the previous page, (s)he is directed to the list of policies instead of “Due Date” tab of assignment edit page (Step 2 above). The create button on the new page of late_policy is not working. Whenever the data for the form is filled and submitted by clicking on the Create button, an error message is shown saying “The following error occurred while saving the penalty policy:” and the policy is not created and added to the list of policies. An instructor can choose to go back to the previous page from the create new policy page. When the Back button on the create new late policy is clicked, it should be redirected to the Due Date tab of the assignment it came from but it is redirected to the index page of late policies. Solution There was no provision to handle the validations of the form in the new late_policy page. A new late policy would not be created if any of the validations fail and the user would be notified of the errors by a flash error message. Updated File: app/views/late_policies/new.html.erb <code> A new Rspec File has been written to carry out the automatic testing. A new late policy must not be created if any of these validations fail. File created: spec/models/late_policy_spec.rb <code>. An instructor can choose to go back to the previous page from the create new policy page. When Back button on the create new late policy is clicked, it should be redirected to the Due Date tab of the assignment it came from but it is redirected to the list of late policies page Solution We tried to store the assignment id of the page from where the create new policy was clicked. This way when we have to redirect after the back button, we can send it to this particular assignment with the help of assignment id. This session variable gets overwritten every time whenever an edit page for the new assignment is opened. So the bug in the back link is fixed. <image>. <image>. <image>. <image>. <image>. 2. Click on Assignments under Manage Notifications. 3. Click on Edit icon under any of the Assignments. 4. Navigate to Due Dates Tab. 5. Scroll Down and click on ""New Late Policy"". 6. Create/test new Late Policy!. A new late policy must not be created if any of these validations fail. 1. Late Policy Name 1.1. Late Policy Name must not be blank 1.2. Late Policy must be unique 2. Penalty Points per unit 1.1. Penalty points must not be blank 1.2. Penalty points must be a number 1.3. penalty points must be less than total penalty points 3. Maximum Penalty 1.1. Maximum Penalty must not be blank 1.2. Maximum Penalty must be less than 50 All these test cases have been automatically tested by writing a new RSpec file: spec/models/late_policy_spec.rb. <image>. There are three different cases covered under the back link testing on the new late policy page. Flow: Assignments -> Edit Button -> Due Dates Tab -> New Late Policy -> Back. It is redirected to the due dates tab of that assignment. Flow: Assignments -> Edit Button -> Due Dates Tab -> New Late Policy -> Click on create without Entering values -> Back. An error message is shown regarding the validations when the create button is clicked. When the Back button is clicked at this stage, it is redirected to the due dates tab of that assignment. Flow: Assignments -> Edit Button -> Due Dates Tab -> New Late Policy -> Submit a policy -> Create New policy -> Back Once a policy is created we are redirected to the index page of the policies which lists all the policies available. Now if we try to create a new policy from here and click on the Back button after that, we are redirected to the due dates tab of that assignment. Following tasks were accomplished in this project: 1. Corrected the code for the late_policies controller and new late_policy page. 2. Improved the code for the Back button inside the new late_policy page.","The description of the problems is separated from the solution.  Would have been better to just list the problems (in one line), and then juxtapose the problem description with the solution.
The code in spec/models/late_policy_spec.rb should have been explained, like the changes in other files were. 
The automated test cases were just listed.  Ideally, the test code should have been shown, and the tests explained.  Actually, this was done for the tests for the back link, but not for testing the creation of penalty policies."
E1842,"In Expertiza, an instructor is responsible for adding a participant to his course or assignment. The user (instructor, TA or admin) has to click the Add button on the course or assignment page to add a new participant to the course or assignment. 1) Login as Instructor4 . Add a new assignment Assignment_Instructor4 under the course Course 617, Spring 2016 . 2) Make student6400 as the participant of that assignment and logout. 3) Login as Instructor6 . Add a new assignment Assignment_Instructor6 under the course Course 517, Spring 2016 . 4) Make student6400 as the participant of that assignment and logout. 5) Click on Manage -> Impersonate User and enter student6400 as the user to be impersonated. 6) After impersonation, Instructor6 will be able to see only his/her assignment details and not of any other instructors. 7) We need to login as Instructor4 and verify that Instructor4 is not able to see other assignment details of the other instructors. 8) Login as Instructor4 . Click on Manage -> Impersonate user. Enter student6400 as the user to be impersonated. 9) After impersonation, Instructor4 will be able to see only his/her assignment details and not of any other instructors. 10) Login as TeachingAssistant1274 who is a TA for the Course 517, Spring 2016, who is a TA under Instructor6. 11) Create an assignment TA_Assignment and make student6400 as a participant. 12) Click on Manage->Impersonate user and enter student6400 as the student to be impersonated. 13) After impersonation, TeachingAssistant1274 will be able to see all the assignment details of all courses for which (s)he is the TA and not the details of the other assignments. 14) Now suppose Instructor6 logs in and impersonates the student student6400 , he will be able to see all the assignment details under his/her course i.e. all the details of the assignment that was created by Instructor6 himself as well as the assignments created by his TA's. 15) Next, login as student6400 and click on assignments. The student will be able to see all the assignments of all the courses to which he/she is assigned to. 1) Login as an Instructor or Admin or Super-Admin or TA . 2) Click on Manage -> Assignments. In the Actions column click on Add Participant . 3) After the list of all the participants you will be able to see Enter a user login text box. 4) Enter the user login in the text box (Ex: student9000) and click on Add button. 1) Login as Instructor4 . Add a new assignment Assignment_Instructor4 under the course Course 617, Spring 2016 . <image> 2) Make student6400 as the participant of that assignment and logout. <image> 3) Login as Instructor6 . Add a new assignment Assignment_Instructor6 under the course Course 517, Spring 2016 . <image> 4) Make student6400 as the participant of that assignment and logout. 5) Click on Manage -> Impersonate User and enter student6400 as the user to be impersonated. <image> 6) After impersonation, Instructor6 will be able to see only his/her assignment details and not of any other instructors. <image> 7) We need to login as Instructor4 and verify that Instructor4 is not able to see other assignment details of the other instructors. 8) Login as Instructor4 . Click on Manage -> Impersonate user. Enter student6400 as the user to be impersonated. <image> 9) After impersonation, Instructor4 will be able to see only his/her assignment details and not of any other instructors. <image> 10) Login as TeachingAssistant1274 who is a TA for the Course 517, Spring 2016, who is a TA under Instructor6. 11) Create an assignment TA_Assignment and make student6400 as a participant. <image> 12) Click on Manage->Impersonate user and enter student6400 as the student to be impersonated. <image> 13) After impersonation, TeachingAssistant1274 will be able to see all the assignment details of all courses for which (s)he is the TA and not the details of the other assignments. <image> 14) Next, login as student6400 and click on assignments. The student will be able to see all the assignments of all the courses to which he/she is assigned to. 1) Login as an Instructor or Admin or Super-Admin or TA . 2) Click on Manage -> Assignments. In the Actions column click on Add Participant . 3) After the list of all the participants you will be able to see Enter a user login text box. 4) Enter the user login in the text box (Ex: student9000) and click on Add button.",The wiki document is detailed. It would have been helpful if they explained how they have used the variable related to impersonation and an overall view of how they solved this problem.I wish they had added screenshots while explaining how they fixed the issues. The format of the document is not very intuitive.
E1817,"In order to solve the above problem, we intend to add Supplementary Review Questions to the existing Review Questions already added by the instructor. 1. When a student wants to create/edit Supplementary Review Questionnaire 1.1. If the instructor has enabled a particular assignment to have supplementary review questionnaire only then a student can create a supplementary review questionnaire. A student can click on the ""Your Work"" tab and see a link to the add/edit Supplementary Review Questionnaire. This link directs the student to the create review questionnaire(same as instructor). 1.2. When a student creates a Supplementary Review Questionnaire (SRQ), the entry in the SRQ column added to the Teams table will contain the questionnaire id to link the SRQ with the team that generated it. If the SRQ column of a team is empty it means no supplementary review questionnaire was created. If its not empty, it will indicate that a supplementary review questionnaire was created. <image> <image> 1. When Reviewer wants to access the Review Questions. 1.1. When a reviewer requests for a review, first the entry of the SRQ column in the Teams table is checked to see if supplementary review questionnaire was added. If the field is not empty, the supplementary review questionnaire is appended to the existing review questionnaire created by the instructor. Otherwise the reviewer only sees the default review questionnaire. This view should contain the responses for both the default review questions as well the supplementary review questions added by the student. So if the entry of the SRQ column in the Teams table is not empty the responses of the supplementary review questions is appended to the responses of the default review questions. NOTE : The responses of the Supplementary Review Questions will not be added to the review scores of the project. <image>. 1. Assignment Page 1.1. An assignment will have a checkbox that the instructor can ‘check’ to enable a student to add supplementary review rubric. <image> 1. A link called ""Supplemantary Review Questionnaire"" will appear in the student's ""Your Work"" section when the Instructor has allowed students to create supplementary review questions. <image> 1. The page where student will be directed to when he/she clicks the Supplementary Review Questionnaire link. Students can add Questions to the created Supplementary Review questionnaire here. However, the set would now have a review rubric and a supplementary review rubric (two items in the set instead of one) if the Supplementary Review rubric has been added. Thus, now the reviewer will be able to see the Supplementary Review questions along with the existing review questions. In order to do that, the students must explicitly set the weight of these questions to 0 while creating the supplementary review questionnaire. <image>. Firstly, we need to add tests for the following: 1. To check the link for ""Supplementary Review Questionnaire"" appears in the ""Your Work"" section of a student. 2. To check if the link for ""Supplementary Review Questionnaire"" redirects to page which allows to create questionnaire. 3. To check if the reviewers can see the supplementary questions that were added by the team as part of the review questions. 4. To check if the responses of the Supplementary Review Questions have been added to the responses of the existing review questions. Supplementary Review Questionnaire Testing : supplementary_review_rubric_spec.rb : In this test, we are testing the addition and editing of the supplementary questionnaire. <code>. <code> 2. db/migrate/20180419210958_add_srq_id_to_teams.rb 1. Added a migration which will add the Supplementary Review Questionnaire id column to the ""Teams"" table. This is to link the team which created the supplementary review questionnaire to the created questionnaire. <code> 1. Obtained answers for the supplementary review questionnaire from the responses. <code> 1. Appended responses of the supplementary review questionnaire in the edit method. <code> 1. Append questions of supplementary review questionnaire in create method and set content method. <code> <code> 5. app/controllers/grades_controller.rb Added supplementary review responses to ""Your Scores"" section. <code> 6. app/views/assignments/edit/_rubrics.html.erb 1. Add a checkbox called ""Allow students to create supplementary review questionnaire"". <code> 7. app/views/submitted_content/_main.html.erb 1. Created a link "" Create Supplementary Review Questionnaire"" to appear in the student's ""Your Work"" section if the instructor has enabled student generated Questions for this assignment. <code> 8. app/controllers/questionnaires_controller 1. Added a method to create Supplementary Review Questionnaire. 10. app/models/response.rb 1. Added supplementary review responses to be visible in the ""Show Review"" section. <code> 12. app/views/response/response.html.erb 1. Added the following code section to append supplementary review to existing review. <code>.","This is a good step-by-step description of how supplementary questions would be used.  It should also describe how they are implemented, and it does not.  Many of the code files are pasted into the documentation.  They show up in monochrome, and in general, are not easy to read.  I would have preferred prose descriptions of what they do.  In the test plan, it doesn't seem that the included code tests for the 4 items listed as tests."
E1656,"Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.4. <link> 1.5. <link> 1.6. <link> 1.1.1. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.2. <link> 1.1.3. <link> 1.7. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.8. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.9. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.10. <link> 1.1.1. <link> 1.1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.11. <link> 1.12. <link>. <link> is an open source project based on <link> framework. In Expertiza, various kinds of data may be imported from <link> , including users, participants in an assignemnt, topics and teams. This project focuses on implementing following tasks about data import functionality: 1. When a team with a duplicate name is imported, one of the options is to rename the new team. There should also be an option to rename an existing team. See Issue 110. 5. Create a way to export a list of teams that have signed up for topics, and who are waitlisted for topics, as well as participants in an assignment who have not signed up for topics. See Issue 719. 2. When teams are imported in order to insert new members, the members are not inserted. The deployed link for remote access is: <link>. When a team with a duplicate name is imported, one of the options is to rename the new team. There should also be an option to rename an existing team. See Issue 329. The current implementation allows the user to handle duplicates, by the following techniques 1. ignore the new team 2. replace the existing team with the new team 3. insert any new members into the existing team 4. rename the new team and import 5. rename the existing team and import. The above set of functionalities do not allow User to ever rename an existing team, rather force him rename his own team. Thus the above requirement provides the necessary freedom to the User by providing him the option to rename an already existing team. To implement this feature we have also made use of the functionality for generating team names, that is already present within the Team model. The Above feature has been tested from the UI using the both course Teams and Assignment Teams, where new teams were added with conflicting names and the rename existing team option was selected, which lead lead to the desired behavior, that is the team that was extant was renamed and new team was imported with the same name as that specified in the CSV file The feature can be tested from Add teams option in manage assignments. Creating a new 'Instructor-Selected' assignment and add some participants to it is also applicable. The ‘Contributor’ here is the name of a team in this assignment. <link>. Some edge cases are also taken into consideration in this method to prevent importing a non-existing team in this assignment, a non-existing user or a user who is not a participant of this assignment. If a imported user does not have a team, he will be automatically assigned a team and sign up for the topic. <link>. Current Implementation just allows users to Export the set of all Assignment Participants, of a given assignment. The current functionality is very rigid and doesn't allow the user to know any more than the set of assignment Participants, which is also a major drawback. The new implementation allows user to export Assignment Participants in four ways. 1. List of All Users mapped with team number and topic name who have signed up for an assignment topic 2. List of All Users mapped with team number and topic name who are wait-listed for an assignment topic 3. List of All Participants who haven't yet signed up for a topic and haven't formed teams yet 4. List of All Participants The functionality is present as a set of Radio buttons, which is checked by default to the fourth option that is to export all Participants. 'Signed Up Team' gives all the participants who have signed up mapped to their teams and respective topics. We unpack the values like Team Member1,2...N by returning the maximum number of Team Members. Then select to add teams to any assignment -> import teams. Here you would need to create a CSV file with the Team name and team members - separated by comma. Following are screenshots of the UI tests <link>. 1. <link>.","The writeup covers a lot of issues, but the organization was not clear to me until I went back to the table of contents.  Different Github issues are main headings. Ideally, the main headings would be about the functionality added.  One of the points is called an ""extra issue""; it's surprising that it is in the middle of the list of issues.  The low-level discussion is clear; it's just not clear how it all fits in together."
E1603,"This page provides details about the changes made to Expertiza under project E1603. Refactor user, course_participant and assignment_participant model. The users of the expertiza are modeled using the user model. A participant signs up for courses and assignments. A user can have multiple participants and all participants belong to a user. The participant model is inherited by the course and assignment participant model. 1. Moved the export_fields method to the User model from CourseParticipant model to remove redudancy. 3. Refactored the get_user_list method into smaller methods, one method for each if condition in User model. The user model stores details of the user like name,email,role,timezone and his preferences on how expertiza should behave to him. A user can have many roles like student, instructor or administrator. The user model is used for logging in, participating in courses, assignments and creating teams. The user model maintains parent child relationship, a user will have one parent and can have many children. Expertiza uses a participant abstraction for modeling the participance of a user in any of the activities like courses and assignments. A participant belongs to a user and it represents a connection between a user and an activity. Assignment_participant, which is a child class of participant models the association between users and assignments. This association also needs to be mapped to other activities performed by a user related to the assignment. The assignment_participant model is related to models which is responsible for all the mentioned activities. The course_participant is a child class of the participant abstraction and it represents the association between a user and a course. The model also stores fields required for the association and supports bulk importing and exporting. The method export_fields occurs in various models with different implementations. However, the implementation for this method had been duplicated in course_participant and user models. User model represents the base class and other models inherit from this class. Hence, deleting the method from User model made little sense. The refactoring invoked the User models export_fields method from within the export_fields of course_participant. Since the export_file controller calls this method on the course_participant object, there wasn't a choice to delete the method completely. This refactoring has the advantage that code is reused and the proper object is tied to the header fields instead of just the generic User object. This method contained a lot of if-else statements that executed different codes depending on the type of user. The refactoring broke the large method into smaller methods, one for each user type. The average of the score for a question in the review given by all other students who reviewed an assignment needs to be calculated in the average_question_score method in assignment participant model. It also consumes more bandwidth since the application fetches all the data from the database but returns only one value to the user. In participant.rb model, there is a method topic_name. However, this method doesn't seem to be required here. A course participant cannot have a topic. Hence, the refactoring involved deleting this method altogether. We have included test cases for all the refactoring that we have done. The earlier version of Expertiza did not have an rspec for the CourseParticipant model. The following is the code snippet of the test case. This refactoring was done in the CourseParticipant model. The duplication is removed and the export_fields method is kept only in the User model and a call to the User model is made from CourseParticipant. To test this method, we test the functionality of this method as there is no test case for this method in the previous version. The export_fields method takes an argument of options which is a list of all the fields that the end user wants to export as course participant data and it returns the corresponding fields by making a call to User model. The ideal test case will test only the export_fields in the course_participant model and not the one in user model. We expect that the returned list of fields will match the ones the method asked using the options field. Below is a sample test snippet. In order to test get_user_list, we create a dummy object of User and set its role as instructor and fetch the user list of that instructor which returns the list of participants of that instructor’s course. The list could be empty or non empty depending on the user object. The files method takes an argument of a directory path and returns all the files present in that directory. In the original repository, there was no test case for this method. We have added a test for this method in the file_helper_spec.rb file. The test case takes an example directory like /tmp/expertiza1603/ and returns the files present in that directory. Since the test cases can be run in any environment, the result of the test case is dependent on the presence of such a directory structure.",Basically a good job.  Would have been nice to see a few more short code sequences
E1774,"Dynamic assignment of metareviews does not work. <code>. New Feature: Metareviewer should be able to see author feedback. Currently, the metareviewer can only see the review and doesn't have access to the author feedback. Meta-reviews do not show the review to be reviewed. When I am assigned the meta-review, the original review I'm supposed to critique is not shown, only the link to the wiki article and the review rubric. Now the actual review is displayed by calling an action of response.controller to show the original review which metareviewer is supposed to critique. Old Code <code> New Code <code>. Student selected a new meta review they get their own project to metareview This functionality is working fine as per the requirement. When a user selects a new metareview, a review is assigned to the user to be reviewed, which have the different author other than the User. Test Case: If review found, assign new metareview. Edge case: If no review found redirects to same page. Code snippet: <code>. Code snippet: <code>. Test case: show original review to be reviewed to meta-reviewer. Code snippet: <code>. 1) Login as Admin, create an assignment with all the necessary details like maximum no of users per team, add topics for the assignment, enroll users(students) in the assignment. 2) Select checkbox ""add metareview deadlines"", select dates and add metareview rubric for the same. 3) Go back to manage assignment and add select Assign reviewers. 4) Add meta-reviewer to a particular review submitted by students. 5) Impersonate the meta-reviewer assigned above and go to others work for the same assignment. 6) Select the option ""request a new metareview"" and a new review will be dynamically assigned for meta-review. 1) Login as Admin, create an assignment with all the necessary details like maximum no of users per team, add topics for the assignment, enroll users(students) in the assignment. 2) Select checkbox ""add metareview deadlines"", select dates and add metareview rubric for the same. 3) Go back to manage assignment and add select Assign reviewers. 4) Add meta-reviewer to a particular review submitted by students. 5) Impersonate the meta-reviewer assigned above and go to others work for the same assignment. 6) Select the option ""request a new metareview"" and a new review will be dynamically assigned for meta-review. 1) Login as Admin, create an assignment with all the necessary details like maximum no of users per team, add topics for the assignment, enroll users(students) in the assignment. 2) Select checkbox ""add metareview deadlines"", select dates and add metareview rubric for the same. 3) Go back to manage assignment and add select Assign reviewers. 4) Add meta-reviewer to a particular review submitted by students. 5) Impersonate the meta-reviewer assigned above and go to others work for the same assignment. 6) Select the option ""request a new metareview"" and a new review will be dynamically assigned for meta-review. 7) click begin button and show review option should be visible on the top to view the origin review to be reviewed. 1) Login as Admin, create an assignment with all the necessary details like maximum no of users per team, add topics for the assignment, enroll users(students) in the assignment. 2) Select checkbox ""add metareview deadlines"", select dates and add metareview rubric for the same. 3) Go back to manage assignment and add select Assign reviewers. 4) Add meta-reviewer to a particular review submitted by students. 5) Impersonate the meta-reviewer assigned above and go to others work for the same assignment. 6) Select the option ""request a new metareview"" and a new review will be dynamically assigned for meta-review. 7) Select begin button. 8) The submitted work is different from the work submitted by the metareviewer. 1) Login as Admin, create an assignment with all the necessary details like maximum no of users per team, add topics for the assignment, enroll users(students) in the assignment. 2) Select checkbox ""add metareview deadlines"", select ""Staggered deadline assignment?"" checkbox in general tab and update the deadlines for metareview in ""due dates"" tab. 3) Go back to manage assignment and add select Assign reviewers. 4) Add meta-reviewer to a particular review submitted by students. 5) Impersonate the meta-reviewer assigned above and go to others work for the same assignment. 6) ""Request a new metareview"" option should be visible to the user if the deadline is the future date for that particular assignment.",Write up is straighforward and well structured.  A few grammatical errors but no other weaknesses at all. Could be enhanced with some screenshots so that the reader could understand the problem and fixes just by scanning it real quick.  
E1721,"Currently, to add/remove/update records, the entire page is submitted to save the record and the entire page is re-loaded back again to reflect the changes on the page. So, another task is to add this functionality such that review status is seen for each review and to unsubmit a submitted review without reloading the page. For the review status part, responses to the corresponding reviews on the page can be checked in the Response table and the review status shown as the status of the latest response. Unsubmitting a review can be done using AJAX without reloading the page. 1. Add Participant in the assignments section using AJAX 2. Add/Remove TA in the courses section using AJAX 3. Edit Questionnaire by using AJAX for adding questions in the Questionnaire section 4. Show Review Status on assign reviewers page and allow to un-submit a review using AJAX. Earlier scenario: When an instructor goes to ""Manage Assignments -> Add Participants"" page, he/she can add/remove new Participant to the assignment. The add page also displays list of participants above the form for new participant. Every time a new Participant is added, the page reloads to reflect the changes and render the updated list of participants, even in case of non-existing userid. Updates/Changes: This page has been updated such that an instructor can add a new Participant using <link> . After adding AJAX changes, the list gets updated without reloading the entire page. Earlier scenario: When an instructor goes to ""Manage Courses -> Add TA"" page, he/she can add/remove new TA to the course. Every time a new TA is added or removed, the page reloads to reflect the changes, even if the userid used does not exist. Updates/Changes: This page has been updated such that an instructor can add a new TA or remove a new TA using AJAX. With these updates, the changes are reflected on the page without reloading the page, thus saving time. This is done so that when a new TA has been added, AJAX call can be used to render the format required for the new TA in the list append to the already existing list without reloading the page. Then it redirects to the edit.html.erb page which causes page refresh while adding questions. So, ""Response Status: Saved"" is shown for that review. So, ""Response Status: Saved"" is shown for that review. So, ""Response Status: Submitted"" is shown for that review. Clicking on this link changes the is_submitted attribute to false and updates the Response Status to Saved on the page by using AJAX call, without reloading the page <image> 1. Added a new method ""unsubmit_review"" to the review_mapping_controller.rb file. After this, unsubmit_review.js.rb file is rendered which updates the response status for the corresponding review on the page to Saved, without reloading the page <image> 1. Added a new file review_mappings/unsubmit_review.js.erb to views. <image> 1. Added a new line to routes.rb page for unsubmit_review action <image>. These can be used while adding new Participant or TA as described below. 3. Switch to Assignments tab incase you are on some other tab 4. For any assignment, click on the 'Add Participant' icon to go on add new participant page 5. Enter userid of the participant and click on Add to add the participant Expected Output: When add button is clicked with valid userid, new participant should be added to the list without the page getting reloaded. In case of an attempt to add invalid user, the error should be displayed on top without page getting reloaded. 3. Switch to Courses tab incase you are on some other tab 4. For any course, click on the 'Add TA' icon to go on add new TA page 5. Enter userid of the TA and click on Add to add the TA 6. Click on 'remove_ta' link for any TA in the list to remove the TA Expected Output: When add button is clicked with valid userid, new TA should be added to the list without the page getting reloaded. In case of an attempt to add invalid user, the error should be displayed on top without page getting reloaded. When remove_ta link is clicked for any TA in the list, that corresponding TA should be removed from the list without the page getting reloaded. Create a new Review Questionnaire by clicking on the ‘New public item’ button for ‘Review’. You will now be navigated to page where you can add new questions to the questionnaire. 5. Click on add button in ""Questions"" section. For submitted reviews, when unsubmit button is clicked, that review should be unsubmitted and status should change to Saved without page getting reloaded.","It contains info how it's implemented, what was the problem, and how they approached the solution. however, I'd expect more high level logic explanation using UML or similar diagram rather than many screenshots which can directly be seen from a pull request page (had they added it).  The structure of the test plan is good, however they only define test plan for the main scenario, the alternative scenarios are not defined e.g., what if the TA is already added"
E1651,"For users intending to view the deployed Expertiza associated with this assignment, the credentials are below: 1. Instructor login: username -> instructor6, password -> password 2. Student login: username -> student4340, password -> password 3. Student login: username -> student4405, password -> password. Expertiza is an educational web application created and maintained by the joint efforts of the students and the faculty at NCSU. It’s an open source project developed on Ruby on Rails platform and it’s code is available on Github. It allows students to review each other’s work and improve their work upon this feedback. The current project deals with the functionality of managing teams in Expertiza. There are 2 types of teams, Course Teams and Assignment Teams. Course teams stay same for the whole course, while assignment teams can be different for different assignments within a course. An instructor has the functionality to copy an assignment team to make it a course team and vice versa. Few issues with current functionality are - 1. No test cases to check copy team functionality 2. UI is not intuitive as User has to go through ""Create teams""->""Create team""->""Inherit teams from course"" to copy teams 3. Duplicated code in ""create_team_and_node"" method for assignment and course teams The objective of the project is to - 1. Write test to check if the current functions work properly. 2. Debug the code for copying teams. 3. Improve the UI. 4. Refactoring the code to leverage polymorphism. 1. Models 1.1. team.rb 1.2. course_team.rb 1.3. assignment_team.rb 1.4. assignment_node.rb 1.5. sign_up_sheet.rb 1. Controllers 1.1. review_mapping_controller.rb 1. Views 1.1. teams/list.html.erb 1.2. teams/new.html.erb 1.3. tree_display/actions/_teams_actions.html.erb 1. Specs 1.1. models/assignment_team_spec.rb. 1. Team Model In the team model, we refactored the method create_team_and_node to remove an unnecessary argument teamtype, and inferred the teamtype from the Class. We also created a new method parent_model_for_id to fetch the related Assignment or Course object. 2. Sign up sheet, Team, Review Mapping Controller, Assignment Team, Course Team All of these files called the create_team_and_node method. Since we changed the signature, we changed the respective method calls in these classes. 3. teams/list.html.erb, teams/new.html.erb Moved the inherit teams functionality from new.html.erb, an internal page, to list.html.erb. List page, thereby removing 1 user click. 1. Course and Assignment Team Model We created the parent_model_for_id method to return the related Course/Assignment object and also fixed the copy method, which earlier had an undefined local variable. 2. Assignment Node Model In the Assignment node model, we created a new method to check if the related assignment object has a course associated with it. This is then used in a view. 3. tree_display/actions/_teams_actions.html.erb This is the partial to show actions related to teams. The option to copy teams from assignments to course should not be visible if there is no course associated with the assignment. Added a condition to the if statement to check for the same. 1. Assignment Spec Wrote test cases to check if an assignment belongs to a course. 2. Assignment and Course Team Spec Wrote test cases to check the method to copy assignment teams to course teams and vice versa. 3. Team Spec Wrote test cases to verify create team and node functionality for course team and assignment team.","They explain what was done, and show the UI that they updated.  But they didn't explain the code they wrote or changed to do this."
E1604,"Our contribution to this project is a suite of functional tests for the assignment calibration function. These tests are designed to provide integration, regression, and acceptance testing by using automation technologies. Expertiza has a feature called Calibration that can be turned on for an assignment. When this feature is enabled an expert, typically the instructor, can provide an expert review for the assignment artifacts. After students finish their own reviews they may compare their responses to the expert review. The instructor may also view calibration results to view the scores for the entire class. While this is a preexisting feature within Expertiza, there currently exist no tests for it. The goal of this project is to fully test the entire flow of the calibration feature using the RSpec and Capybara frameworks. A more detailed description of the calibration may be found <link> Before analyzing code, one must familiarize themselves with the steps involved in calibration on Expertiza. The steps involved are: 1. Login with valid instructor username and password 2. Click on ""Assignment"" 3. Click on ""New public assignment"" 4. Input all the information needed, check the “Calibrated peer-review for training?” box, click on Create 5. Select the review rubric in “Rubrics” tab 6. Go to “Due dates” tab, make sure that this assignment is currently in Review phase, also, make the submission allowed in review phase. 7. Add a submitter to the assignment. 8. Go to the list of assignments, click “edit” icon of the assignment 9. Go to the “Calibration” tab, click on the ""Begin"" link next to the student artifact for the expert review, and click “Submit Review” 10. Go to “Review strategy” tab, select Instructor-Selected as review strategy, then select the radio button “Set number of reviews done by each student” and input the number of reviews 11. Login with valid student username and password who is a reviewer for the assignment 12. Click on the assignment 13. Click on “Other’s work” 14. After clicking “Begin”, Expertiza will display peer-review page 15. Click “Submit Review” 16. Click “Show calibration results” to see expert review 17. Login with valid instructor username and password 18. Click on ""Assignment"" 19. Click on the “view review report” to see the calibration report. It does this by accepting test scenarios called specs.<ref> <link> </ref>. WebKit is supported through an external gem.<ref> <link> </ref> To control the environments in which the scenarios are run, it provides before and after hooks.<ref> <link> </ref> 1. before(:each) blocks are run before each scenario in the group 2. before(:all) blocks are run once before all of the scenarios in the group 3. after(:each) blocks are run after each scenario in the group 4. after(:all) blocks are run once after all of the scenarios in the group. Factory Girl <ref> <link> </ref> is a factory gem meant for use in testing. The following scenarios were considered when writing tests for the calibration use case: An instructor creates a calibrated assignment An instructor authenticates to expertiza They select to add a new assignment While creating the assignment, the instructor selects to turn calibration on After creating the assignment the instructor sees a calibration tab on the assignment page An instructor edits the calibration configuration An instructor authenticates to expertiza They select to edit an existing assignment The instructor clicks on the calibration tab and sees it is populated with submitted artifacts An expert submits a review for calibration An expert has been added to an assignment to provide the expert review The expert authenticates to Expertiza and begins the expert review The expert finishes and submits the review Student Calibration A student has submitted a response for the assignment and it is currently in the review phase The student authenticates to Expertiza and chooses to view calibration for the assignment The student sees their own answers compared to the expert review. Instructor Calibration It is currently the review phase for an assignment An instructor authenticates to Expertiza and chooses to view calibration The instructor can see the student and instructor responses for the assignment. Code for the tests exists in two locations 1. <link> 2. <link>. The following are steps required to run the test 1. Clone the repository in a new directory <code> Create and then prepare the test database <code> 1. Type the command to run tests for assignment submission <code>. 1. All test cases are green, which means there are no currently failing tests. 2. Test cases are run through the Selenium driver on Firefox for javascript support. Because they are full acceptance tests they are slower than regular unit tests, but still beat evaluating the feature by hand. 3. Tests are independent and repeatable. 1. <link>. 1. <link>.","""You used a nonstandard page name.
Too much of the page consists of lists.  Using lists is fine, but there should have been narrative describing them."""
E1773,"<link> is a open-source ruby-on-rails project on <link> . <link> is a online debugging tool for rails projects that is currently incorporated in Expertiza. Thus, Expertiza production errors at run time are tracked and reported statistically to Airbrake for reviewing and debugging. Our goal for this OSS project is to fix <link> ranked by occurrences reported to Airbrake. By investigating into the top 10 errors from airbrake, we can divide them into different categories by the root of their causes. 1. NoMethodError: undefined method for nil:NilClass (4 out of 10) 2. AbstractController::ActionNotFound (4 out of 10) 3. ActionController::InvalidAuthenticityToken (1 out of 10) 4. ActiveRecord::RecordNotFound: Couldn't find Participant without an ID (1 out of 10) As we have discovered, the same or similar fix can be used to fix all exceptions in the same different category, which is how we categorized these exceptions initially. From the Airbrake issue page, we could find out that the problem is actually caused by a gem called passenger. Although we couldn't find any sign of passenger gem in the recent master branch, but there is a clear sign we found during our review of other errors that some developers had used passenger. For more information, please check <link> NoMethodError: undefined method 'role' for nil:NilClass is one similar error that occurs during run-time <image> <link> pic1 <image>. <code> NoMethodError: undefined method 'uniq' for nil:NilClass is one similar error that occurs during run-time <code>. In most of the cases, the error is caused by an abusive use of RESTful routing provided in rails. In the middle of somewhere of the app, an index or show action is considered ""called"" when the redirect url matches such an action which is undefined in the controller. By using resources:auth, rails actually creates index and show actions by default. Somewhere in the app, a redirect is made available to the user to an index or show view page which does not exist. Thus, in order to save the trouble finding the redirect, we simply redirect anything points to those invalid pages to a valid page, which is the root.The modified code is below: <code> Following the same principle, we have modified /config/routes.rb for routes that have caused the most exceptions due to exposure of invalid url redirection to the user. <code> There are 10 similar errors in Top 40 errors involved 5 controllers, which are ResponseController, AuthController, AdminController, ImpersonateController and PublishingController. If a controller mentioned above never uses a method declared by resources, we delete the relevant resources and add the routes of method separately, otherwise we use except expression to exclude methods we don't use. <code> The error was raised in config/initializers/request_forgery_protection_mod.rb And the error actually happened in response#create The background of this problem is that The authenticity token is a random value generated in your view to prove a request is submitted from a form on your site, not somewhere else. The expertiza problem could be the user session expired and the solution can be delete the code in the config/initializers/request_forgery_protection_mod.rb , and redirect or just refresh the page, which would not raise an error. This error is not necessarily a bug in the code, but rather a protection masochism. As said before, it is a matter of choice to get rid of this error or not. The error was raised in app/models/review_assignment.rb:171 And the error actually happened in review_mapping#assign_reviewer_dynamically The intuition is that the review to a topic should be assigned dynamically and ""too many reviews"" problem should be handled by action revew_mapping#assign_reviewer_dynamically . So we could add the below condition in the above controller action to handle this problem. Instead of raising an error, we could simply handle this problem, which can make ""flash danger message"" unnecessary. First, follow the instructions given on <link> . Clone the repository which is also the submitted <link> . In this project, we will mainly use airbrake to do testing. Expertiza has already implemented the airbrake gem. You need an airbrake account to begin test. In /config/initializers/airbrake.rb , change the following line <code> You will get your project id after you registered an airbrake account and created a new project on it. where project key will be at the same location with your project id. Once you have the right key and id pair, you can start testing the run-time exceptions. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.",Excellent job of explaining the errors and what is responsible for them.  One of the most readable writeups.
E1726,"The project requires us to remove the cache column from the roles table in database. Expertiza's 'roles' table has a 'cache' column, used by the superfish-rails gem to display different menus for different roles (super-administrator, administrator, instructor, teaching assistant, student, and unregistered user). There is a Role model which makes use of the long text string data stored in the roles table under the cache column to load the menus (e.g., Users \n Questionnaires \n Courses …) for a particular role at the top of the page after login. The Design plan followed here is as follows: 1. Move the cache column value to YAML files for each role. 2. Load the YAML value on environment/server startup. 3. Use the corresponding YAML values for the corresponding role for the user logging in. The reason for using this design is to have a pre-defined menu list for each roles. 1. Create YAML files containing the cache column data for each role from roles table in database. 1.1. Create YAML files under 'config' folder named 'role_admin.yml' and put the 'cache' column value in it split across rails environment 1.2. Create ruby script under 'config/initializers' folder named 'load_roles.rb' - to load the corresponding YAML values once the environment is set up 2. Change the role.rb model to facilitate the use of above defined YAML files 3. Remove the cache column from the roles table by migration 4. Write rspec unit test for 'role.rb'. 1. 6 new files (role_admin.yml, role_instructor.yml, role_student.yml, role_super_admin.yml, role_ta.yml, role_unreg_user.yml) each corresponding to specific role are created 2. Content of cache column from roles table are added for development, production and test environments <image>. This code loads content of ""/config/role_admin.yml"" file and assigns to CACHED_ADMIN_MENU. Similarly, fields corresponding to different roles are populated from corresponding ""/config/role_[ROLE]_.yml"" file <image>. Rebuid_credentials and rebuild_menu method are modified to load content from yml file. Here ApplicationHelper exposes get_cache_roles method to retrieve cache content corresponding to role id. <image> <image> In rebuild_cache method, role.save line is removed as cache field is not saved in database now. Since cache field is removed from roles table, this field is added to role model using attr_accessible. It’s getter and setter are also created <image>. Before removing cache column in roles table <image> Roles table after removing cache column <image> Migration file to drop cache column <image>. The test plan followed here is done across 3 roles namely, student, administrator and instructor. The scenarios covered here are as follows: 1. Check for the cache field and see if we get the expected value. 2. Check if the role is valid role. 3. Check for the cache field mismatch, that is, invalid cache field match. 1. Login into Expertiza as one of the roles - super-admin or admin or student or instructor 2. Check the menu tabs on the top and you can find the respective drop-downs according to the role logged in 3. On clicking the option from the drop down you will be able to navigate to the respective pages 4. This ensures that the code change done by us didn't break the code and it delivered it's expected functionality. Unit tests have been written to check whether the modules work as it did earlier before. We have written rspec unit test for ‘role.rb’ which can be found here: ‘spec/models/role_spec.rb’ which tests 10 cases 1. Evaluate the cache value with YAML values for student 2. Evaluate the cache value with YAML values for instructor 3. Evaluate the cache value with YAML values for admin 4. Validation of name for student 5. Validation of name for instructor 6. Validation of name for admin 7. Check the mismatch for cache values for the student in factories.rb 8. Check the mismatch for cache values for the instructor in factories.rb 9. Check the mismatch for cache values for the admin in factories.rb 10. An invalid check for role object <image> <image>. For instance, in the present situation, the YAML files have the database data corresponding to menu_items hard coded. We could define YAML file for menu_items table and load the menu_item YAML into the corresponding role YAML during environment setup. This would eradicate the use of menu_item table from the database.","The page title needs to be changed (i.e., the page needs to be copied over to a new page with the requisite title).  It should be named after the project,, E1726, not the author.  But other than that, it is a very informative writeup."
E2068,"This project contributes to <link> , an open-source project using <link> . The student creating a quiz is supposed to ask questions related to their work, which, ideally, a reviewer should be able to answer. 2. Change the error message on line 78: 3. Consider lines 259-265, different methods are called with the same parameters (question, choice_key, q_choices) to create different types of questions, depending on q_type. The final score of a quiz is calculated by multiplying the weight of the question by the score and summing the value of each question. Currently, minimum and maximum values cannot be set in a custom way per quiz. The value is set per quiz, not per question. The original error message stated ""Your quiz has been taken by some other students, you cannot edit it anymore."". This error message is vague and can be easily misunderstood. The error message now states ""Your quiz has been taken by one or more students; you cannot edit it anymore."". When creating a quiz, there are currently three different methods for each of the three different question types: true-false, radio, and multiple choice. Radio and multiple choice implement very similar, almost duplicated, functionality in both methods. Radio and multiple choice questions have been combined into a single method so as to remove the duplicated functionality. True-false questions will remain separate, because the functionality is significantly different. <link> <link> <link> <link> <link> <link>. The image below shows the addition of the min_/max_question_score fields to the quiz questionnaire form. <image> The image below shows the values from the form used in the controller. <image> The image below shows the creation of a single function to handle both types of multiple choice questions. <image> The image below shows changes necessary for assigning the correct answer for radio button multiple choice questions after making the changes from the previous image (the changes to the functions in the controller). <image>. 1. min_question_score and max_question_score score being negative 2. max_question_score score being less than min_question_score. 1. Create test for raising an error if min_question_score is less than zero 2. Create test for raising an error if max_question_score is less than one 1.1. Testing based on less than one since: 1.1.1. min_question_score should be less than max_question_score 1.1.2. min_question_score must be greater than zero 1.1.3. therefore, max_question_score must be greater one 3. Create test for raising an error if max_question_score is less than min_question_score. <code> 1. This test verifies that a quiz with valid parameters can be created and saved correctly 1.1. This test case verifies that min_question_score and max_question_score error <code> 1. This test verifies that quiz_questionnaires_controller.rb flashes an error when max_question_score is less than min_question_score 1.1. This handles an edge case scenario <code> 1. This test verifies that quiz_questionnaires_controller.rb flashes an error when max_question_score and min_question_score are less than 0 1.1. This handles an edge case scenario <code> 1. This test verifies that the questionnaires.rb model raises an error when max_question_score is less than min_question_score 1.1. This handles an edge case scenario. <link> The instructions below can also be found <link> with screenshots to follow along. Click on ""Assignment."" 3. Click on the plus sign on the right side of the page to create a new assignment. 6. Once the assignment is created, a new field called “Number of Quiz questions” will be created on the right side of the page. (Note: There are three different kinds of questions: Multiple Choice (four answer choices), Radio (four answer choices), and True-False. In order to test all answer possibilities, you can set this value to 17.) 7. Click on the Due Dates tab. 9. Click ""Save."" 10. Under editing the assignment, click on the Other Stuff tab. 3. On the assignment page, click on ""Create New Quiz"" under “Quiz.” 4. Fill out the form. (Note: If you only provide one potential answer for the “Multiple Choice - Checkbox” option, the quiz will not be created and the entire form will clear.) 5. Once you have filled out the entire form, click ""Save"" at the bottom of the page. There will be new options under “Quiz.” Click on “View Quiz.” 7. This page should show all of the settings of your quiz, including correct answers, weight, and minimum and maximum question score.","The wiki page is very well structured and explains the changes that have been made.  However, I think the descriptions of the code modifications are too terse, e.g., ""shows the values from the form used in the controller"" doesn't explain why two different groups of two lines were changed.  Test descriptions are adequate."
E1508,"3. Functionality that should be in models is incorporated into the controller. It fetches all previous versions of a response (which is to say, all previous review versions by the current reviewer of the current author for the current assignment). A “response” is created when someone submits a review, a partner evaluation, a survey, etc. 3. The rereview method is 98 lines long. Sorting review versions is really not a controller responsibility; it would be better to do this in a model class (which class?) Ditto for determining whether a review is current (i.e., was done during the current assignment phase). This is a query that is made about a review (actually, about a response, which may be a review, author feedback, etc.). It should be placed in the appropriate model class. 4. rereview contains special code to check whether an assignment is “Jen’s assignment”; this was the first assignment we ever created with a multipart rubric. It is probably impossible to remove this code without breaking that assignment, but it should be done in a separate method, and commented appropriately as a kludge. 5. Again in rereview , creating a new version of a review is a model responsibility, and should be moved out of the controller. 6. There are two (consecutive) copies of the edit method. The second appears to be the newer one, and, according to the rules for method definition, is the one that is currently in use. method at the beginning of the class definition. For example, someone should be allowed to view a response if they wrote the response, or they are the person or on the team whose work the response applied to, or if they are an instructor or TA for the class. The person who wrote a response should be allowed to edit it, but not the person/team who was being reviewed, nor the instructor or TA for the class. method. <table>. <table>. The latestResponseVersion method is misnamed. It fetches all the previous versions of a response and its current name does not reflect its actual functionality. The method was renamed as previous_responses since it better suited the actual functionality. <table>. <table>. method, however the un-refactored code did in the redirect_when_disallowed method. Moreover, once this code was moved to the action_allowed? method, all of the references to redirect_when_disallowed were removed (action_allowed? <table>. The get_scores method was being implemented in the controller. As such, the method was moved and changed to retain the functionality of code that uses it. <table>. The code to sort response versions has been moved from rereview method to a separate method. This was done because the rereview method was becoming very long and confusing. <table>. The rereview method had some special code to check if the current user is jace_smith and uses a custom hard-coded rubric instead of a rubric from the system. Removing this code will break the assignment and so the code was moved to a separate method and commented as a kludge. <table>. Action allowed is called before every method call to confirm whether or not the currently logged in user has the required privileges to complete the requested action. To test the functionality of this method one has to attempt to complete an action that they have privileges to complete, and confirm that they're allowed to complete it. One also has to attempt to complete an action that they don't have the privileges to complete, and confirm that they're not allowed to complete it. Log into the application with the user having a student's role ( User Id: user5072, Password: password) 1. Click on Assignments, and you should see the following: <image>. Log into the application with the user having an instructor's role ( User Id: user6, Password: password) 1. Click on Assignments, and you should see the following: <image>. Log into the application with the user having a student's role ( User Id: user5072, Password: password) 1. Click on Assignments 2. Click on Writing assignment 1b, Spring 2013 3. Click on Others' Work 4. Click on Review done at --2013-03-01 23:57:55 UTC Successful loading of this page confirms the get_scores method. Rereview manages the versioning of multiple reviews for the same assignment. To test the correct functionality of review, one should attempt to update a review (i.e. Log into the application with the user having a student's role ( User Id: user5072, Password: password) 1. Click on Assignments 2. Click on Writing assignment 1b, Spring 2013 3. Click on Others' Work 4. Click on Update (beside Metaprogramming in dynamically typed languages) Successful loading of this page confirms the rereview method.","Very well organized, explains changes well.
"
E1956,"Contents 1.1. <link> 1.1.1. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.3. <link> 1.3. <link> 1.4. <link> 1.1.1. <link> 1.5. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.6. <link> 1.7. <link> 1.8. <link>. <link> is an open-source project based on <link> framework. E1956. There is no shortcut to get free review points: Review Assignment Bug. Each assignment contains an review strategy. We can generally submit 'n' reviews according to the review strategy. 1. The number of reviews done by any student is not checked in the back-end with the maximum number of submissions allowed as per the review strategy. 1. There is no check on the number of outstanding reviews a user can have. Currently, there is no check in the backend that limits the number of reviews a student can be assigned. Students can get more peer reviews than review strategy. Also, there is no check to see if the user has submitted enough reviews for that assignment before getting a new review. Problem 1: No limitation on the maximum number of peer reviews. 1. There is no check in the backend that limits the number of reviews assigned to a student. Problem 3: There is no check on the number of outstanding reviews 1. A user can request for submissions even if the current outstanding ones are pending. review_mapping_controller.rb 1. The is_reviews_allowed method checks the number of reviews assigned to a student and then compares it with the maximum number of reviews allowed as per review strategy. If the student is asking for more reviews than the review strategy then it returns False. <code> 1. The check_outstanding_reviews checks the number of outstanding assignment reviews a user can have at a time. The check_outstanding_reviews keeps a count of the number of reviews in progress as well as the number of reviews currently completed by the user and returns a Boolean value depending upon whether the former is less than the maximum outstanding reviews allowed as per the review strategy or not. This check fetches the number of reviews done by a student currently from ReviewResponseMap table. 2. ReviewResponseMap is mocked to return 0. This is the number of reviews that a student has done so far. 3. Assignment is mocked to return 1 as number of reviews allowed for the assignment. 4. To test number of reviews, we added new tests. Empty list indicates that student has not done any review and therefore must be allowed. List of values is returned to check if the size of list is greater than allowed number of reviews according to review strategy. 5. To test outstanding number of reviews, we added new tests. The code works on number of reviews completed. If the number of reviews completed are less than assignment's max outstanding reviews, then student must not be allowed new review. 6. For one of the test cases we mocked the assignment's max outstanding reviews to be 0, which means without doing even a single review he can request as many reviews as he wants. For the other test case we mocked assignment's max outstanding reviews to be 2 and hence without doing two reviews he can't ask for more. 6. It would be noted that the request would never exceed the number of submissions mentioned in the review strategy. To test outstanding number of reviews: Follow the steps above, you will get 2 reviews at first. 3. It should be noted that despite continuous request, user will not get any more reviews than difference of max outstanding review and completed reviews. All the test cases have been automated in the review_mapping_controller_spec File 1. Student has done reviews less than review strategy: <code> 1. Assign Review Dynamically. 2. Redirect to Student review page. 2. Student has done reviews more than the review strategy: <code> 1. Redirect to Student review page. [flash[:error] = ""You cannot do more than "" + assignment.num_reviews_allowed.to_s + "" reviews based on review strategy""]. All the test cases have been automated in the review_mapping_controller_spec File 1. Student has pending reviews less than review strategy [default 2 pending reviews at most]: <code> 1. Assign Review Dynamically 2. Redirect to Student review page 2. Student has done reviews more than the review strategy [default 2 pending reviews at most]: <code> 1. Redirect to Student review page. 24.317%. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.","Explanation of the problem statement where the student is allowed to do more reviews than the specified number in the assignment poilicy could have been better
.  However after that, the explanations of the changes are very complete and understandable.  There is also a good description of the changes that were made to each file.

It would have been clearer to cut and paste test from the Github diff view than to use the textboxes in the wiki, which are monochrome with fixed-width characters."
E1903,"1. The questionnaires_controller.rb has multiple methods to handle quizzes. Some of these methods cater only to quizzes. The controller has to be refactored into 2 controllers by moving the functions related to quizzes and the dependencies into a new controller called quiz_questionnaire_controller.rb. 2. Some methods in the questionnaires_controller.rb are long or have hardcoded parameters. These methods have to be refactored into shorter functions rid of hardcoded parameters. 1. Creation of new controller A new controller called quiz_questionnaire_controller.rb was created using scaffold. The methods in the questionnaire control pertaining to quizzes were moved to the new controller. Certain methods such as create_questionnaire which are to be needed in both classes were refactored as explained in later sections. The routes.rb file was edited to reflect the new routes to the new controller's actions as shown in image below. <image> The views for the controller were not created or moved from questionnaires controller. Instead, every action in the quiz_questionnaire controller renders a view from the old controller itself. However, the links and redirect was edited multiple controllers and views (as stated in affected files), so that the action in the right controller was called. to be filled 3. Refactoring current controller Problem : Due to multiple refactoring over the years, there are few redundant methods in questionnaire_controller.rb. Additionally, a few of the methods like update_quiz, create contain the redundant piece of code and multiple switch statements. Refactoring of create_questionnaire method : The create_questionnaire method from questionnaire_controller.rb is used to create a questionnaire based on the type of questionnaire. The implementation corresponding to the quiz is irrelevant in the context of questionnaire_controller.rb. Newly created quiz_questionnaire_controller.rb undertakes the task of creating a questionnaire of type Quiz and the original method handles the creation of all other types of questionnaires. The control was delegated based on the type of questionnaire and the corresponding method is called. Refactored create_questionnaire method <image> Refactored create_quiz_questionnaire method <image> Refactoring of create method : The create method is used to create a questionnaire in the questionnaire_controller.rb. Based on the type of questionnaire, the name in the view is changed. Solution: The implementation was changed to check if the display type matches with the available type and when matched, uses Regex, split and join methods to evaluate the same in a single line. <image> Refactoring of update_quiz method : The update_quiz method is used to update the quiz when the user edits the existing quiz. The implementation for two of these types can be changed and can be used as private methods. <image> Refactoring of save_choices method : The save_choices method contains a lot of redundant hard coded data that is not accessed/used in the application. These hardcoded variables were removed and the relevant code is refactored to work seamlessly. 4. Creation of new route for quiz_questionnaire_controller and updated the affected links in views Created a new route quiz_questionnaire for quiz_questionnaire_controller in ""routes.rb"" and moved the custom created ""get/post"" routes for quizzes from questionnaires route to it. <code> Then changed the controller name and route in all the following views which are accessing quiz_questionnaire_controller while keeping the application flow intact - /app/views/questionnaire/view.html.erb <code> /app/views/questionnaire/new_quiz.erb <code> /app/views/questionnaire/edit.html.erb <code> /app/views/submitted_content/_main.html.erb <code>. The following files were created or refactored 1. /app/controllers/questionnaires_controller.rb 2. /app/controllers/quiz_questionnaire_controller.rb 3. /app/views/questionnaire/view.html.erb 4. /app/views/questionnaire/new_quiz.erb 5. /app/views/questionnaire/edit.html.erb 6. /app/views/submitted_content/_main.html.erb 7. /config/routes.rb 8. /spec/controllers/questionnaires_controller_spec.rb 9. /spec/controllers/quiz_questionnaire_controller_spec.rb. The refactoring of code was done in a manner as to not affect the functionality or the code flow. Therefore, the test plan has not been modified from the original spec file apart from moving quiz_questionnaire relevant tests from questionnaire spec file to quiz_questionnaire spec file. The code is not hosted as there are no new functionalities created. 1. <link> 2. <link> 3. <link>.","Starts out very well, with good explanations and code snippets.  Further down, the code snippets are pasted in with raw text and the commentary is less complete."
E1951,"The Expertiza project is software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. Expertiza has Assignment objects, which represent an assignment that is done by some number of users. For some assignments, students need to select a topic before submitting work. Topics associated with an assignment be reached as follows: 1. Log in as an instructor or a TA. 2. Select Manage->Assignments, which will bring up a list of assignments. 3. Click on “edit logo” under the “Action” column of an assignment. 4. Click on “Topics” tab in edit assignment page. If an instructor or a TA wants to delete topics, he has to delete one topic at a time and has to wait for the page to refresh and then (s)he can proceed to delete the next topic, topics can only be deleted one by one. 1.There should be a checkbox column, along with other columns in “Topics” tab, where a user can select the topics (s)he wants to delete. 2.There should be a delete button/link at the end of the topic table with the name “delete selected topics” to delete the selected topics after a confirmation, prompted post clicking the button/link. 3.There should be a button/link alongside “delete selected topics” by the name “Select all” so that a user can select all and delete them in one go after clicking on “delete selected topics”. 1. Beside ""Home"", click ""Manage..."", then click ""Assignments"". 2. Choose an Assignment ( Final project (and design doc) is recommended).Then click ""Edit"" below Actions. 3. Click ""Topic"" tab. 4. Create some topics by click ""New topic"" on the bottom line. 5. Select them and click ""Delete selected topics"". Then click ""Yes"". (It may take a while!) 6. Then you shall see they are deleted. (For some reason we don't know, it failed when editing a staggered deadline assignment.). File: app/views/sign_up_sheet/_add_topics.html.erb Add bottoms of 'Delete select topics' and 'Select all' <code> File: app/views/sign_up_sheet/_table_header.html.erb Add 'Select' header <code> File: app/views/sign_up_sheet/_table_line.html.erb Add selected checkbox <code>. File: app/assets/javascripts/signup.js Select All function checks all checkbox of topics. <code>. File: app/controllers/sign_up_sheet_controller.rb Define delete all and get selected topics methods. <code> File: app/views/sign_up_sheet/_add_signup_topics.html.erb <code> File: app/views/sign_up_sheet/_add_topics.html.erb Delete function destroys all selected topics. <code> File: app/views/sign_up_sheet/_table_line.html.erb <code> File: config/routes.rb Add url. <code>. Before clicking 'Select all' bottom, there are checkboxes that could select each topic. <image> After clicking 'Select all' bottom, all checkboxes are selected. <image> After pushing 'Deleted selected topics', there's a confirmation alert. After clicking yes could delete all topics. <image>. File: spec/controllers/sign_up_sheet_controller_spec.rb Select assignment with id '834' and topic with id ['E1732'] as params. Post params to delete_all_selected_topics. Expect success flash with 'All selected topics have been deleted successfully.' and redirect to '/assignments/834/edit#tabs-2'. <code>.","The wiki page does not provide background to what topics it is talking about, and does not explain where in the UI the change would be made.  I have added the description by copying it from the project specification, so future readers will understand what it is about.
The solution should be described before manual testing.
Seems like the ""Select all"" link should precede the ""Delete selected topics"" link.
The png files have really large text, and code text is tiny.  This makes the page hard to read.
But, the changes have been described quite well."
E1873,"One of the fantastic features that Expertiza provides is for each assignment, it allows students providing reviews for others' jobs. This is done by offering a pre-defined questionnaire for the whole assignment, which is called the rubric for this assignment. One of the problems for the review system is that for each assignment, different topics are included. Students can choose the one topic they like, and those topics fall into different categories. That is, an assignment always include different kind of projects. In Expertiza, the topic can be refactoring projects, testing projects, Mozilla projects, etc. Apparently, for different kinds of projects, we have different criteria to evaluate their performance. However, due to the current design of the system, all projects belong to the same assignment can only have the same rubric, which may lead to unnecessary criteria for some projects and inadequate criteria for other projects. To make sure all kinds of projects can be evaluated properly. We plan to refactor the system to allow assigning different rubies for different projects in a specified appointment. To realize such purpose, we have the following tasks need to be done: For current design, the rubric used for a specified assignment is set at the following page. To make sure users can choose to set different rubrics for different projects, we need first add a checkbox at this page. Therefore, users can use this box to indicate if they want to use the same rubric for all the projects or set some different rubrics for some projects. <image>. To make sure users can choose rubrics for each project, we should add a new dropdown list beside each project in the following page. The number of dropdown list should decide by review round number. Therefore, each time users choose to identify different rubrics for different projects, the list will appear and users can choose proper rubrics. The default rubric set at last page will be overwritten in this case. <image>. Make changes to the controller so that these functions can work. logic flowchart: <image>. Add questionnaire_id in sign_up_topics table to make sure the projects can always relate to correct rubrics <image>. Test what we changed to make sure it works as intended and not influence the original system. 1. edit the file views/assignments/edit/_rubrics.html.erb 2. add a checkbox at the top of the page which says ""Vary rubric by topic"" 3. set the default state for this checkbox as unchecked. 1. edit the file views/assignment/edit/_general.html.erb 2. add a variable to indicate if the checkbox said in Task 1 is checked 3. create a new file under views/sign_up_sheet called ""_rubrics_list.html.erb"" to store the code for the dropdown list 4. edit the file views/sign_up_sheet/_table_line.html.erb 5. add the code to render the dropdown list 6. making a judgment before rendering the dropdown list, only if the checkbox in Task 1ist checked to render the page. Change the update method in sign_up_sheet_controller.rb to make sure when new rubric is chosen for a specific topic, it can be stored in the database properly. 1. create a new migration to add questionnaire_id in sign_up_topics 2. the questionnaire_id is a foreign key which references to questionnaires 3. change the file models/sign_up_topic.rb, and add the relations with the questionnaire, the relation between them is one-to-one. 1. make a test plan for the features that need to be tested 2. follow the test plan to write automatic test codes 3. evaluate the results and refactor codes. 1. go to the rubrics page under the assignment 2. we can see the checkbox says ""Vary rubric by topic"" shows on this page 3. the initial state of the checkbox is unchecked. 1. the checkbox ""Vary rubric by topic"" is unchecked 2. go to the topics page under assignment 3.there are no dropdown lists beside topics. 1. the checkbox ""Vary rubric by topic"" is checked 2. go to the topics page under assignment 3. the table to show the topics have a row called ""rubrics"" 4. under this title, each topic has a dropdown list. <image> <image>. For testing update_topic_questionnaires. 1. when attributes are nil <code> 1. when attributes are not nil and at least one topic_questionnaire's id is nil or blank <code> 1. when both save and update_attributes method do not work <code> 1. when both save and update_attributes method work well <code> For testing review_by_rounds, check the number of rounds which decides the rounds of the questionnaire that each assignment needs. 1. when used in round is nil <code>.","The document gives a good overview of how the code is implemented, but it would be good if it included links to the code, e.g., in Github.  The screeshot of the implemented signup page is not very clear.  On the tests, instead of just saying ""when"" they are used, it would be good to see what conditions cause them to pass or fail."
E1826,"The navigation for an instructor follows the below structure. 1. Home 2. Manage... 1.1. Users 1.2. Questionnaires 1.3. Courses 1.4. Assignments 1.5. Impersonate User 1.6. Anonymized View 3. Survey Deployments 4. Assignments 5. Course Evaluation 6. Profile 7. Contact Us And that for a student follows the below structure. 1. Home 2. Assignments 3. Pending Surveys 4. Profile 5. Contact Us For an instructor, the menu item 'Assignments' is present in 2 places - in the main menu as 'Assignments' and in the sub-menu as 'Manage.../Assignments' ( italicized above). This could potentially be confusing. 'Manage.../Assignments' sub-menu item allows the instructor to create/edit assignments. The menu item 'Assignments' allows an instructor to participate in assignments. This is typically something that the instructor wants to do in a student role and hence there needs to be a student view for instructors to act as students without impersonating them and thus reducing confusion. The same needs to be implemented for admin and super admin as well. Create a student view for instructors so that they can perform student operations without impersonating them. When an instructor logs in, he/she is in the default view with corresponding menu items (with the exception of the 'Assignments' menu item). There should be an option to switch to and revert back from the student view. When in student view, an instructor is presented with the student menu as listed above. This file is shared between all views and is responsible for rendering all the elements on the navigation bar including the menu items. In order to switch between default view of the user and student view, the following code was added. When in default view, the instructor is presented with a link, Open Student View , to switch to student view and when in student view, the Close Student View link can be used to switch back to the default view. <code>. A new role_switch_controller.rb file has been added. This controller contains the actions to open/close student view. <code>. New post methods are added in config/routes.rb . The routes are directed to the role switch controller's open_student_view and close_student_view actions. <code>. A new menu node with the below format is added under 'Manage...' node in the yml configuration files for admin, superadmin , teaching assistants and instructor. <code>. 1. Login as an instructor. Enter 'instructor6' as username and 'password' as password. 2. Click on Open Student View below username to switch to student view. <image> 3. Click on Close Student View below username to come back to default view. <image>. The following lines are added to spec/features/student_view_spec.rb file. 1. Check whether Assignments is absent in the menu in default view and there is an option to Open Student View This test case is to check if the menu item Assignments is absent and 'Open Student View' link is present when an instructor is in default view. Also on clicking the 'Manage...' button the 'Student View' sub-menu item should be listed. <code> 2. Check whether Assignments is present in the menu in default view and there is an option to Close Student View This test case is to check if the menu item Assignments and link Close Student View are present when the instructor switches to student view. The following lines are to be added: <code>. 1. Link to forked repository [ <link> ]. Expertiza 1. <link> Expertiza Github 1. <link> Expertiza Documentation 1. <link> RSpec Documentation 1. <link>.","Duplicated code is not explained on the wiki page.  In general, the documentation shows code snippets with a two-line description before them.  Except for one snippet, the code does not contain comments.  The overall strategy does not seem to be explained."
E17A4.1,"However, the instructor needs to create a separate assignment just for calibration purpose of a project . Then the instructor and students can start doing peer reviews for the project with the newly created assignment . However, calibration should become one part of the normal assignment. This project proposes a solution to include the process of calibration in a regular assignment. “Calibration for training?” feature of an assignment in Expertiza provides a solution for the Instructor of a course to effectively add a calibration to a newly created or existing assignment. After students finish one peer review , there will be a link named “Show calibration results” to show the calibration report. <image> Picture above is ""Calibration for training?"" 1. The instructor shall be able to add calibration process to an newly created or existing assignment. 2. In student_task/list page, current stage column shall display calibration when assignment is in calibration period. 3. The added calibration of an assignment shall have it owns type of due date. 4. The added calibration of an assignment shall have the same behavior as the current working calibration process. <image> 1. Edit/Create Assignment Use Case Id: 1 Use Case Description: Instructor can click to edit an existing assignment or create a new assignment. Post Conditions: Instructor can edit the assignment. 2. Enable Calibration Use Case Id: 2 Use Case Description: Instructor can select the option - ""Calibration for training?"" and save the assignment. Actors: Instructor Pre Conditions: Instructor is in the editing or creating assignment page. Post Conditions: The assignment becomes a calibration assignment and the deadline for calibration now appears in the due dates tab. 3. Add calibration due date Use Case Id: 3 Use Case Description: Instructor can set due date for calibration under due dates tab. Actors: Instructor Pre Conditions: Calibration for training? Post Conditions: The deadline for calibration is now updated. 4. Expert Review Use Case Id: 5 Use Case Description: Instructor can do expert reviews for works. Actors: Instructor Pre Conditions: The assignment is a calibration assignment and the work is submitted. Post Conditions: The work has the expert review. 5. Calibration review Use Case Id: 6 Use Case Description: Students can do calibration review. Actors: Student Pre Conditions: The assignment is a calibration assignment and the current stage is in calibration review. Post Conditions: Students have done the calibration review. 6. View calibration result Use Case Id: 7 Use Case Description: Student can see the comparison between their reviews and the experts' reviews. Post Conditions: NA 7. Submit work Use Case Id: 4 Use Case Description: Students can submit their works when the current stage is ""submit"". Actors: Student Pre Conditions: Current stage is ""submit"". You can refer to a youtube video to see how's calibration function working after our implementation: <link> Below are the screenshots for the important parts: 1. After enable calibration for training function, the instructor can see a calibration due date in ""due date"" tab and can assign a due date for this calibration training: <image> 2. When the current stage is in ""Calibration Review"" we can only do the calibration reviews and show calibration results after submitting. <image> 3. When the current stage is in ""Review"", we can see the calibration reviews and do the regular reviews. <image>. in assignments#edit page 2. This feature test check for when Calibration for training? <code> 2. When current assignment is calibration stage: 1. To check it shows current stage of the assignment to be ""Calibration"" on student_task#view page when current assignment is in calibration stage 2. To check it shows ""Calibration review 1,2,3..."" instead of ""Review 1,2,3..."" on student_review#list page 3. To check it allows students to do calibration review and the date can be saved successfully 4. To check the student is able to compare the results of expert review by clicking ""show calibration results"" link 5. Since the test contained duplicate code, we load the code in load_work method and set the stage of the current assignment as ""calibration"" state so the review contains Calibration Review 1, 2, 3 and student can view their calibration result when clicking on View link. <code> 3. When current assignment if in review_stage: 1. To check it excludes calibration reviews from outstanding review restriction and total review restriction 2. To check it shows ""Review 1,2,3..."" instead of ""Calibration review 1,2,3..."" on student_review#list page 3. When the project is in review stage, the number of review allowance will not affect by the number of calibration review numbers, so we check the number of review allow is still the same after changing the stage to review stage and the page should contains Calibration Review 1 and Review 1. <code>.","Most of the document is quite readable.  There is still room for improvement.With so many use cases, I think there should've been a prose paragraph preceding them explaining how they all fit together.  In the TDD section, you don't need to explain what TDD is, but you should give an overview of the tests.  ""Write feature tests for the calibration function"" is much too general.  The test plan is reasonable, but would be better if (1) it had an easily rememberable name for each test, and (2) covered edge cases."
E1667,"<link> is an open source application developed on the <link> framework. It allows instructors to create assignments, set deadlines and give grades to the assignments. In this application, students can submit their assignments by providing links to their sites or repositories or upload files and folders. The students can also review assignments submitted by their peers. Goal: The aim of the project was to write a feature test that mocks the Heat Map that a student views for an assignment of his. The following tasks were performed to accomplish the goal: 1. Understanding the flow of the creation of Assignment by instructor. 2. Understanding the flow of the submission of an assignment by a student and then the flow of submitting reviews to an assignment uploaded by a student. 3. Understanding the flow of viewing the Heat Map related to an assignment by a student. 4. Mock the above steps using capybara. 1. <link> 2. <link>. <code> Repository URL can be found by visiting this <link> . Go to your cloned expertiza directory in terminal and run the following command: <code>. 1. Run the Expertiza database migrations. This should populate your database with the current tables of the schema. <code>. 1. Go to your cloned expertiza directory and run the following command for the tests: <code> Note : Travis CI build fails because we are directly using the development database for our tests, thus Travis CI is not able to locate the login information. This was done because it was not possible to create factories or fixtures for our tests. So, please don’t consider the build failure in the pull request to be a valid error. The heat_map_spce.rb contains the feature tests written to test the creation of the heat map viewed by the user. The rails_helper is copied to spec/ when you run 'rails generate rspec:install'. All the rspec-expectations config goes into the spec_helper_file. The testing has been done using Capybara and RSpec. Capybara helps in testing web applications by simulating how a real user would interact with the application. We selected Capybara to write our tests because it has an intuitive API which can mimic the language that an actual user uses while using the application and also we the tests can be run from a fast headless mode to an actual browser without changing our tests. <image>. <code>. We faced the following issues and hence were not able to complete the project: 1. We could not find any documentation about how to use the factory related to our task and couldn’t figure out its implementation in other tests. 2. We tried to solve the problem by using previously implemented test but were unsuccessful. 3. So we (Mahesh Masale) contacted you and you provided us with a new approach for the problem. What we were asked to do was to write a test that would simulate everything from scratch. There were multiple points where we struggled in this approach but the major ones were: 1.1. While adding questions to rubric the question field’s id is auto generated so there is no way to assume an id for that field in test. We overcame this problem by searching a specific text to find the all text fields but this will be a problem if that test is present at a location other than the test field. 1.2. While trying to select a rubric which is a dropdown there was no id provided to the select tag. So we googled but to no success and then we found a piece of code in the assignment_creatiion_spec.rb but that code also failed in our solution. 1.3. We also tried to add a participant to an existing assignment through test and struggled with it because the id to the button was dynamically generated and the url could not be accessed through “visit” command. 4. So we switched back to the old method due to lack of progress after investing a lot of time. We used the factory and were able to create assignments and reviews but our user was not able to view those reviews in heat map. We even tried previously implemented code but that also did not show reviews for our test. 5. We communicated with other teams for help but they also could not solve our issues.","The writeup is not sufficiently detailed.  There is a huge flow diagram, and then the code is pasted in.  Nothing describes the testing that is carried out (you have to read the code).  Also, it is not explained why the test that you have written is a sufficient test for the heat-map functionality."
E1698,"Scenario: An instructor using Expertiza wants to do an experiment comparing anonymous review with identified (non-anonymous) review. In this experiment, Approx ½ the class will conduct two rounds of formative reviews in small groups (4-5 students/group). The groups will stay the same for both rounds. The students in the groups should be able to see who they are reviewing and who is reviewing them. For the non-anonymous groups, I'd like the students to be able to request group members, so I would want to be able to have some control, perhaps with an option to use random assignment to groups if they had no preference for group members. Approx ½ the class will conduct two rounds of formative reviews anonymously (using the normal method we used this fall) What needs to be done : The Review Strategy tab of assignment creation needs have a new checkbox for anonymous reviews, which would be checked by default. If it is checked, student views would be the same as at present. If it is not checked, students would see their reviewers and grades in the same way as the instructor now sees them; thus, instead of seeing “Reviewer 1”, “Reviewer 2”, the student might see, “Anthony Adams”, “Bessie Brown”, etc. It’s hard for me to know, without studying the code, whether this would simplify the code or clutter it, but please give some thought to what is the clearest and most robust way to code both anonymous & identified reviews, from the student’s and the instructor’s perspective. The other piece of the project is to enable review within groups, which means that every student in a group will review every other student in the group (but no students outside the group). This can be configured on the Review Strategy tab when the review strategy is set to “Instructor-Selected”. Under the “Set number of reviews done by each student” box, there could be another one, “Review done in groups of [ ] students”, where “[ ]” is a small text box. The project provides instructor a functionality to make assignment reviews to be anonymous or non-anonymous. In addition, instructors have authority to create and assign review groups (students assigned same review group will review each others work) randomly.This scenario will be valid for individual assignments only. In case of non-anonymous groups, students may have the option to invite other students to join their group provided group size is not exceeding the maximum limit. <link> is a peer review system which provides incremental learning from the class. This project has been developed together by faculty and students using <link> framework. Expertiza allows the instructor to create, edit and delete assignments, create new assignment topics, assign them to a particular class or selected students, have students work on teams and then review each other's assignments at the end. For the students, they can signup for topics, form teams, and submit their projects and assignments. Students then review the work done by other students and give suggestions to improve. Teams after reviews are allotted scores and they can refer to the peer comments to further improve their work. Assignment Creation: Providing a checkbox in ""review strategy tab"" to mark an assignment to have anonymous or non-anonymous reviews. By default, every assignment will be having anonymous reviews but an instructor can change it by unchecking the checkbox (Anonymous would be boolean field present in the group model). Group Formation: The instructor has the authority to create and assign groups randomly. In this case, students can not drop the group they have been assigned and only an instructor can change their group if needed. In case, a group has not been assigned by an instructor, students will have the functionality to invite other students to join their group. Students in the same group can review work of their group members only. For this, we will be creating a separate model for groups and will store all the group information into the corresponding database table. In order to follow the DRY principle, we will try to integrate the group code with the code written for teams. <image> Non Anonymous Reviews In the case of non-anonymous reviews, students will be able to see the names of all the group members who have graded their individual work. In addition, students can also see whose work they are going to grade so that the non-anonymity is maintained from both sides. 1. This is the view of the review strategy tab where the checkbox for anonymity has to be added <image> 1. This is the view where names would be visible to ensure non anonymity of reviews <image>. This project is part of an experiment to test whether anonymity makes a difference in reviews of students, thus to implement it one assignment would be made as anonymous and another as anonymous and the quality and the review scores would be tested to say if there is a change in quality and values of control and test.","The titles are not too long and got repeated from section 2 to 7. The design pattern discusses about the planning on making changes, but not really related to design pattern."
E1632,"<link> is an <link> developed on <link> framework. It is primarily developed as a platform for instructors to create, assign and grade assignments and quizzes and for the students to view, submit assignments and take quizzes. Other activities involved in a course can also be done via Expertiza, like creating teams, reviewing assignments among others. Collusion detection is a feature that Expertiza needs. Collusion detection is supposed to detect when peer reviewers “return favors” to each other by giving each other higher scores than they deserve. There are 2 types of collusion that instructors may worry about: small-circle collusion and pervasive collusion. Small-circle collusion refers to the practice that a few teams/authors reach an agreement that they give each other high scores if they get chances to review each other’s work. The number of the teams/authors could be any number. Pervasive collusion refers to the practice that giving each other high scores becomes a trend in some assignments. This practice has been observed by Dr. Luca de Alfaro in his paper: ... Once a nucleus of students starts to assign top grades to all the submissions they review, other initially honest students see what is happening, and join the colluders, both to save work in reviewing, and to avoid being penalized in the review precision as the only honest students who disagree with their colluding peers. 1. The code in collusion_cycle.rb is not called anywhere. Even it were called, the code would not work (due to some nasty refactoring done previously). The algorithm was badly designed - creating separate methods for detecting x-node cycles. The following tasks need to be accomplished at the end of this project: 1. Remove all the methods in this model. Redesign and recode the whole model from scratch. 2. In the new model we will create a new collusion cycle detection method which will take x as an input. Given the parameter x, the algorithm then can detect any collusion cycles consisting of x nodes. 3. We will use spread and the ratio spread/(# of peer reviews done) to measure the pervasive collusion in one assignment. Here spread is the peer-review score difference a reviewer (max peer review score given - min peer review score given) A higher spread is better, because it indicates that the reviewer is discriminating between good and bad work. [Dr. Gehringer’s survey, 2014] Spread/(# of peer-review done) should work better than spread alone if the # of review done varies between reviewers. 1. We will consider each student in an assignment a node and each peer-review record (namely, user A reviews user B, which is recorded in review_mappings table) as a directed edge. So finding small-circle collusion becomes a task of finding cycles within x nodes in a directed graph. 2. This algorithm can use depth-first search. 3. The idea of having a threshold : If A gives B a low peer-review score (less than min_collusion_peer_review_score), we prune this A->B edge. 1. We will create a report page (small collusion cycles report) under “view review report” icon for instructors. The instructor can input x and run this algorithm to detect small collusion cycles. The instructor can also set the min_collusion_peer_review_score on this report page. The default of min_collusion_peer_review_score can be 95%. 2. We might also need a similar report page (pervasive collusion report) for pervasive collusion. The Use Case diagram for such design is: <image>. We are planning to implement the modified DFS for finding a cycle of size ""n"". The basic algorithm for this looks like: <code> This algorithm has to be implemented in ""collusion_cycle.rb"", and the implementation will roughly look like: <code>. The test case will be written as ""rspec"" 1. We will need a test case, which returns the cycles detected in the graph, and confirms that the size of the cycles is no less or no more than the user specified size ""n"". 2. We will need to check the performance of this algorithm. In some cases when the graph becomes too large the algorithm should still perform in acceptable time frame. This is a soft commit for the project. We are planning to have a visually asthetic way of representing the collusion detected. For this purpose we have identified a few ways: 1. Visulization tool called <link> 2. <link> 3. <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. <link> 9. <link>.","The cycle detection may miss come cycles.
There should be UI which allow instructor to input the k.
There should be some visulization, or at least table of cycles in the report page."
E1745,"Expertiza is an open source webapp built on Ruby on Rails stack. The file response_controller.rb handles the operations on responses based on user permissions and redirects the user to the appropriate place after the action is complete. The responses here constitute of peer reviews/questionnaires/survey. The controller takes care of tasks such as creating, saving, editing, updating and deleting these responses. 1. Refactoring response_controller.rb Included: 1. Breaking down large methods into smaller chunks of readable reusable code. 2. Changing code to adhere to latest Ruby conventions 3. Creating functions to reuse chunks of code that were previously written multiple times 2. Testing response_controller.rb Included: 1. Writing stubs and mocks 2. Writing integration test cases to ensure that response_controller redirects to the right places with a given parameter set. The pull request for this task can be viewed at <link>. Without wasting much time, lets jump into the refactoring by describing code which existed previously followed by the changed code. Previous Code :- <code> The view case is extracted into a separate method and some common variables have been extracted out of the cases <code> This has extracted an independent functionality and enhanced readability apart from sticking to guidelines of short methods. <code> Moving on with latest Rails conventions, function is being modified as <code> This will avoid any unexpected behaviour when further upgrading the Rails framework. <code> has been replaced with <code> This is the way to sort based on an object attribute. <code> This method involved a lot of code which violates guideline of short methods. Moreover, the lines of code can be reduced along with readability enhanced as similar functionalities in multiple lines can be combined. 53 lines of code have been reduced to 32. The refactored method is given below:- <code>. 23 integration tests were written to ensure the functionality works and also to make sure the refactoring does not break any of the existing functionality. These tests check for the basic functionality of the controller response_controller.rb and whether these function calls redirect to the right place with the correct status code. <code> The above given test checks that if the instructor wants to view a review, he is given permission to go ahead and view it. This is checked by setting params = {action: ""view"", id: review_response.id}. To do so, we set these params and expect the function action_allowed to return true. The current user is set in the before(:each) part of the test file because that is used commonly by a number of test cases. We tested the existing functionality of the controller like view, edit, action_allowed, redirection, etc since we are changing only the implementation of the code. And a general rule of writing test cases is that changing the implementation should not have any effect on tests. Test case scenarios were provided by our mentor and our job was to write the integration tests for those scenarios. the test cases were pretty exhaustive. We didn't have to write extra cases for the parts we refactored as the refactored portions are an extraction of an existing function in smaller ones, in which case the existing function is already calling the new written code. So in a way writing the test cases for existing parts automatically tests the new refactored code. We wrote a number of stubs for the test cases. We separated out stubs into two parts, the ones that are being commonly used by multiple tests and wrote them in the before(:each) part. The other uncommon ones are written in the respective test cases to avoid extra computation. Stubs allowed us to replicate the behaviour of the database without actually calling, thus avoiding cost of accessing the database and avoiding the pitfall of having a test case fail because of an incorrect database layer logic rather than the controller logic. First let us understand how a mock object is created. Have a look at the following piece of code: <code> This will build a response object (whose specifications are provided in the factories.rb file) with an id 1 and make it available through out the test process. We are therefore using this object as the object returned from a database without actually interacting with the database, thus ""mocking"" an object. To understand how stubs work, consider the following piece of code in before(:each) block of the testing controller: <code> What this stub does is that when Response.find is called, instead of going into the database and finding an object and returning it, Rails will blindly return review_response mock. So this line tells Rails that if find is called on Response, return the pre created about review_response. This reduces the dependency on the database. We wrote stubs and mocks required to successfully test all the pieces of the controller. All of it can be viewed in response_controller_spec.rb. 1. Expertiza Main Repo <link> 2. Expertiza Documentation <link> 3. Pull Request <link> 4. Screencast for E1745 <link>.","As one of the reviewers noted, ""The author has just mentioned what they have done but not mentioned as to why it was done in any instance except one ""Replaced find_by_map_id with find_by"". There is not mention of the design pattern used although it is understood by the Title of the assigned task.""  The Test Plan section is better on that score."
E1812.2,"The project aims to write a unit test for on_the_fly_calc.rb. However, there was no corresponding unit test and the coverage was only 15.45% after running all test cases. Test-driven development (TDD) is a software development process that relies on the repetition of a very short development cycle: Requirements are turned into very specific test cases, then the software is improved to pass the new tests, only. 1.Add a Test: TDD begins by writing succinct test cases to test each of the features. This is opposite to traditional software development paradigm where code is written first and then test cases are later written to test the application. 2.Run all tests and see if the new test fails: This step validates that the test harness is working correctly, shows that the new test does not pass without requiring new code because the required behavior already exists, and it rules out the possibility that the new test is flawed and will always pass. The new test should fail for the expected reason. This step increases the developer's confidence in the new test. 3.Write the code: The next step is to write the minimum amount of code that causes the test case to pass. 4.Run tests: In this steps the test cases are run.If all test cases now pass, the programmer can be confident that the new code meets the test requirements, and does not break or degrade any existing features. If they do not, the new code must be adjusted until they do. 5. Refactor code: In this step, refactoring of code is performed by following good design principles like removal of duplicate code, improving the readability and maintainability of the code. 6. Repeat: Starting with another new test,the next step is to repeat the cycle to push the functionality forward. <link> is a software testing method by which individual units of source code are tested to catch errors early in the development process. Model testing is bounded to the functionality of only the model under test and doesn't test how its collaborating models get affected based on this query. 1. Finds problems early: Unit testing finds problems early in the development cycle. In test-driven development (TDD), which is frequently used in both extreme programming and scrum, unit tests are created before the code itself is written. When the tests pass, that code is considered complete. The procedure is to write test cases for all functions and methods so that whenever a change causes a fault, it can be quickly identified. Unit tests detect changes which may break a design contract. 5. Design: When software is developed using a test-driven approach, the combination of writing the unit test to specify the interface plus the refactoring activities performed after the test is passing, may take the place of formal design. Each unit test can be seen as a design element specifying classes, methods, and observable behavior. There is no corresponding unit test for on_the_fly_calc.rb. We need to test all those methods. Privately methods are tested when testing public methods instead of tested directly. The task is to write test cases for testing the on_the_fly_calc model file. After developing different objects by this method, the objects get used in test cases to either avoid the implementation of the methods specified in the model or make it return a value which can be used to test if conditions. Here are methods provided by this module: The compute_total_score method is to compute the total score of a given assignment. The method collects all questionnaires of the assignment and calls the get_weighted_score method of Questionnaire Class to calculate the total score. First, the method will check whether the assignment varies rubrics by round and deal with the two cases separately. The class method varying_rubrics_by_round? The last method score calculates scores of a question. Like previous methods, it deals with two cases. That is for different cases of varying_rubrics_by_round?. being used as an if statement, test cases have been made for the behaviors if it returns true and false. For the compute_reviews_hash method located in the model,varying_rubrics_by_round? Creating test examples which return true and false for the method call varying_rubrics_by_round? For the compute_avg_and_ranges_hash method, the get_assessments_for method of ReviewResponseMap and compute_scores of Answer are tested for both cases. For varying_rubrics_by_round case, the review_questionnaire_id method of Assignment is tested. For the last method score, the majority of the method is included in private methods. For the varying_rubrics_by_round case, we tested the built-in calculate_score method of Assignment. After writing the unit test we managed to increase the coverage of our rails application. The difficulty of the test is that it involves lots of different classes and methods from different classes.","Too much space is spent describing Expertiza, TDD, and unit testing--issues which relate to most or all projects, not this one in particular.  The functionality of the class being tested is explained, but not the tests themselves.  This seems like a serious deficiency."
E1660,"In Expertiza, there are two ways of assigning reviews to reviewers: either the instructor decides who reviews whom (“instructor-selected”), or “auto-selected,” in which case reviews are not assigned until a student seeks to choose something to review. To allow reviewers a larger set of topics to choose from, the instructor can set the threshold (on the Review Strategy tab of assignment creation/editing) to some integer k > 0. Then any submission that has within k reviews of the fewest number can be chosen by a new reviewer. Let’s say that all submissions have at least 1 review. If k = 3, then the reviewer can choose any topic where there is a submission that has 4 or fewer reviews so far. Suppose that the minimum number of reviews for any submission is 2, but that I have reviewed all the submissions that have only 2 reviews. Then I’m not allowed to review at all (unless k > 0). That’s wrong; I should always be allowed to review the work with the least reviews that I have not already reviewed. And that should generalize to situations in which k > 0. Another issue is that there is no way for Expertiza to tell a reviewer how many reviews are required. In the case of instructor-selected reviewing, that’s not a problem, but for auto-selected reviewing, there is no way to specify how many reviews are required (or even how many are allowed, in case students are allowed to do extra reviews). The purpose of this task is to solve the above mentioned issues collaboratively. The assignments table now contains the Max reviews required and allowed field which can be set from Review strategy tab. This allows the admin to set the threshold value for required number of reviews for the assignment. Another feature implemented is, now students can check how many reviews he/she needs to write which helps students determine how many reviews to write and also how many reviews he/she has already written. Another issue resolved was the reviewer who finished reviewing all submissions with least number of reviews, should be able to review the next set of submissions with greater number of reviews. That is, the threshold rule was more relaxed. Implemented the necessary test cases for the new features implemented. 1. app/views/assignments/edit/_review_strategy.html.erb 2. db/schema.rb 3. Added two new unit tests in RSpec file in spec/models/assignment_form_spec.rb 4. Added two new columns in Assignment table as shown below 5. app/models/review_assignment.rb 6. app/controllers/review_mapping_controller.rb 7. added new file review_assignment_spec.rb in spec for testing the above functionality. <code> 1. add new RSpec tests in assignment_spec.rb <code>. The new RSpec test added to the assignment_spec.rb is used to verify that the reviewer who submits their assignment should not be allowed to review their own work. The test mainly simulates mouse click on the webpage and tries to find certain content. One student account is created to submit the assignment which is stored by the system. Since this submission is the only one for the existed topic, the system is supposed to not to assign reviewer anything, which is equivalent to have the correct output for code, expect(page).to have_no_link ""view"". The test file shows desired result and the issue resolved. <link>.","Hardly anything was done, except to rewrite the project specs, tell about the new fields, and paste in the testing code.  The app code changed was not included or described."
E1635,"This page provides a description of the Expertiza based OSS project. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. Expertiza supports submission across various document types, including the URLs and wiki pages. The following tasks were accomplished in this project: 1. Renamed the ""invitation_controller.rb"" to ""invitation_controller.rb"" 2. For simple if nested in else, we changed it to elsif and thus decreased number of layers in the if nest. 3. For added comments to explains what each method does and explaining important variables 4. refactored the create and update methods 5. changed the wordings of the flash messages to make them more meaningful. 1. Rename to invitations_controller.rb, in accordance with current naming convention. 2. Convert if nested inside else to elsif. 3. Add comments explaining what each method does, and comments on how important variables are used. 4. Refactor create and accept methods. Shorten and clarify them by adding private methods (e.g. extract a ready_to_join? method and call it from accept method) 5. Change awkward flash messages. 1. Convert if nested inside else to elsif, and add comments explaining what each method does, and comments on how important variables are used. <image> The if else can extract from multiple nest to one. There have two different functions in one nest, one is flash and another is invitation check. Divided two different purpose to two if else nest. <image> 2. Refactoring the accept method <image> <image> <image>.","The writeup is created by taking screenshots, which means that the code is not searchable.  Low-level changes are enumerated, but the high-level changes are not explained (they are stated, at the beginning of the document, but the changes are not pointed out in the code).  Also, there is no explanation of how to test."
E2059,"The purpose of this project is to improve and test the email handling systems in Experteiza. The project's primary goals are to solve the following issues; unreliable student email receipts, and unreliable instructor email notices. Expertiza is intended to send students email notices when they receive a project submission for review, when their own work is reviewed, or when their reviews are reviewed. Additionally, instructors are intended to receive email copies of all emails being sent from the system. The following are identified tasks to be accomplished for the project: Email Queue Appropriate tests for the following: 1. Check queues to ensure that emails are being sent out. 2. Check to see that the recipient of this message is the correct recipient 3. Check to see that the body of the message has the correct content. Instructor Email Notifier 1. Appropriate tests instructor should be able to get copies of emails: 1.1. Rails message that queues the email to the instructor 1.2. Check to see that emails sent by the system are also sent to the professor. <code>. A list of all files changed are found at the bottom of the report and the following section explains each test. This method is used to send a generic email to user by passing the email, subject and the contents of the message. The RSpec test for this method first creates an generic_message object and verifies if the correct parameters were passed. Then the next test was to test if the ActionMailer successfully sent the email using generic_email. This was done by using the ActionMailer::Base.deliveries to check the outbox of the ActionMailer and ensured the contents of the outbox mached that of the mailer. Setup <code> Test <code>. This method is used to request_user_message to a user by passing the super_user details, user name and the email subject. The RSpec for this creates a User object to be passed into generic message. Once done, the first test was to ensure that request_user_message received the correct parameters that were passed, the next test was to ensure that the ActionMailer successfully sent the email by checking the outbox in Setup <code> Test <code>. The send_mail_to_all_super_users method is a method that uses the request_user_message method to send emails. For this we wrote a proxy test to ensure that it and request_user_message were correctly sending emails by creating user object and passing the necessary fields to the send_mail_to_all_super_users and ensuring the ActionMailer::Base outbox had the correct outputs. Setup <code> Test <code>. This method is used to notify_reviewer_for_new_submission to a user by passing the user object, partial name and the message to be sent. The RSpec for this creates a User object to be passed into notify_reviewer_for_new_submission message. Once done, the first test was to ensure that notify_reviewer_for_new_submission received the correct parameters that were passed, the next test was to ensure that the ActionMailer successfully sent the email by checking the outbox to see if the contents of email matched that of the outbox. Setup <code> Test <code>. The submission_mail_to_reviewer method is a method that uses the notify_reviewer_for_new_submission method to send emails. For this we wrote a proxy test to ensure that it and notify_reviewer_for_new_submission were correctly sending emails by creating user object and passing the necessary fields to the submission_mail_to_reviewer and ensuring the ActionMailer::Base outbox had the correct outputs. Setup <code> Test <code>. Tests in this portion ensures emails are being sent upon a submission via the sync_message protocol. Feedback Response Setup Feedback review response submission is being tested to ensure emails are sent upon a feedback submission. <code> Feedback Test <code> Metareview Response Setup This test ensures that an email is sent upon a review of a review being submitted. <code> Metareview Test <code> Response Survey Setup This set of tests ensure that an email is sent upon an assignment or course survey submission. <code> Response Survey Tests <code> Teammate Review Response Setup This test ensures an email is sent upon submission of a teammate peer review. <code> Teammate Review Response Test <code>. Suggested Topic Approved Test This test ensures an email is sent upon approval of a suggested topic. <code>. Notify Grade Conflict Notification Setup This test ensures an email is sent when a score is outside the acceptable value. <code> Notify Grade Conflict Notification Test <code> Notify Instructor On Difference Setup This is a proxy method that calls the Mailer method to send e-mail to the instructor when a score is outside the acceptable value. This test verifies that the Mailer method is called with the expected arguments. <code> Notify Instructor On Difference Test <code>.","The documentation should cover more than the tests. The documentation is little more than a listing of the code for the tests, with an occasional one-paragraph description of what it does.  There really needs to be more narration.  For example, when you list appropriate tests, explain how the tests are performed.  The document should give a rationale for what you have written, and an overall description of how it works."
E1866,"Currently Expertiza only supports the English language. So, we aimed to allow them to view their pages in another language. This is done by internationalizing static strings in Expertiza for Student Assignment related pages to another language (ex: Hindi or Chinese). Students had the ability to change the language through a dropdown located in navigation bar at the top of the page. We did not affect any strings that are dynamically shown. We focused on adding the Hindi language as a lot of students are Indian. 1. We added a dropdown in the navigation bar for a student to use 2. They are able to choose from English or Hindi 3. <image> 4. When the language is clicked on it changed all the static strings in the Student Views related to Assignments to the newly selected language. 5. Students could also manually change the language in the URL themselves by. The language is put before the page name. 1. For this project, we added support for one language, Hindi. 2. We used Google Translate to convert the strings to Hindi. 3. We used the <link> to help us add multi language support. 1.1. One for English, which will be the default language used, and another for Hindi. 1.1.1. en.yml 1.1.2. hi_IN.yml 1.2. These yaml files contained the translated strings for their respective language. <image>. <image>. username: student1016 or student[4000-8000] password: password. 1. When going between pages, use the Back button link located on the bottom of pages, not on the browser 2. When going to the main Assignment page, use the Back button link to get there to test out the scenarios below, not the link in the navigation bar. 1. Log in to Expertiza as a student. 2. Go to language dropdown in the navigation bar and choose Hindi. 3. Check if language is changed in the URL from en to hi_IN 4. Check to see if the English strings on the page are translated to Hindi 5. While still logged in as a Student, check if the other Assignment related pages are also translated. 1. Log in to Expertiza as a student. 2. Go to language dropdown in the navigation bar and choose Hindi. 3. Check if language is changed in the URL from en to hi_IN 4. Check to see if the English strings on the page are translated to Hindi 5. While still logged in as a Student, check if the other Assignment related pages are also translated. 6. Go back to the main Assignment page and choose English from the dropdown. 7. See if the language was changed in the URL to en. 8. See if the strings are translated back to English for all Assignment related pages. 1. Log in to Expertiza as a student. 2. Go to URL and change the language from en to hi_IN. 3. Check to see if the English strings on the page are translated to Hindi. 4. While still logged in as a Student, check if the other Assignment related pages are also translated. 1. Log in to Expertiza as a student. 2. Go to URL and change the language from en to hi_IN. 3. Check to see if the English strings on the page are translated to Hindi. 4. While still logged in as a Student, check if the other Assignment related pages are also translated. 5. Now change the language back from hi_IN to en in the URL. 6. See if the Hindi strings are translated back to English for all Assignment related pages. 1. Problems: 1.1. When a student goes back to the main Assignment page, views/student_task/list, by clicking the link in the navigation bar, the language locale doesn't appear in the URL. This means that if you did change the language from the dropdown or manually, it will go back to the default locale language. See the URL below: 1.1.1. <image> 1.2. If you try to use the language dropdown in a page other than the main Assignment page, it will give an error like the one shown below: 1.1.1. <image> 1.3. But if you manually change the language in the URL, it works fine and persists as you navigate through the pages. 2. Feature: 1.1. We also have translated keys for many course pages, but did not implement the actual translation code in the view files for them. What looks like a natural break in sentence structure in one language may not look natural in another. 1.4. The student16 login used to test Expertiza needs more work. Some student views are inaccessible due to a lack of inbuilt data. 1. Pull Request: <link> 2. Github: <link> 3. Video: <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 1. <link> 2. <link>.","The design document does a good job of describing how the changes were implemented.  Perhaps in response to peer reviews, the team has added a good deal of graphical information describing internationalization.  There is a helpful section on future work. "
E1833,"In Expertiza, instructors (also admin, super admin and TAs) can create rubrics (they are called questionnaires in DB, there are different types like review rubric, teammate review rubric, etc. Each rubric may have one or many criteria (called questions in DB). Issue Description: Instructors and TA’s under the same instructor can make changes to each other’s rubric. Only the owner (an instructor) and his/her TA(s) should be able to edit the corresponding rubric. The first step towards solving this issue was to retrieve id of current user and check its authorization with regards to questionnaire.To achieve this, we are checking if current user is a 'Teaching Assistant' and his/her 'instructor' has access to current questionnaire. If the instructor has access of questionnaire, his/her Teaching Assistant should also have access to the respective questionnaire. This is implemented by checking the instructor id of the TA against the question's instructor id. To get the instructor id of a TA, the assign_instructor_id was reused. <code>. <code>. <code>. When logged in as super admin. At the bottom of the rubric, we will find links to import it and export it. The Export Details does not work and is not relevant to the context. Export page does not display the names of the rubric. When a rubric is exported, the headers on each column were incorrect and not related to the rubric. It seems to be headers from an export of information on users. Export page needs to give the name of the rubric When a rubric is exported, the column names should be proper. And then could rename ""export details"" to ""export advice"". In order to implement export functionality for questionnaire, two functions were added to question_advice model namely export_field and export. Export_fields returns an array of model fields and Export returns the advice data for current questionnaire. A new route has also been defined to handle the question advice export request. Views were also changed to display “Export Advices” instead of “Export Details” in the case of the Question model. You can find similar export functionalities in other modules as well including question model. <code>. <code>. <code>. <code>. We have made changes in questionnaires_controller_spec.rb which covers testing scenarios to check access over questionnaire module as per the role defined in the system i.e. for roles Instructor, TA and admin. Below are the test Scenarios covered: 1. when the role name of current user is super admin or admin. 2. when current user is the instructor of current questionnaires. 3. when current user is the ta of the course which current questionnaires belongs to. 4. when current user is a ta but not the ta of the course which current questionnaires belongs to. 5. when current user is the instructor of the course which current questionnaires belongs to. 6. when current user is an instructor but not the instructor of current course or current questionnaires. Issue 577 There was no implementation in place to export question advice associated with questionnaires. Test case is created to test both the methods i.e export_field and export. Issue 696: 'Teaching_assistant520' has access to review 'review/517 F09 wiki' 1. Step 1: Login as teaching_assistant520/password 2. Step 2: Navigate to path manage->Questionnaires-> Review rubric 3. Step 3: Select questionnaire named Review from the list, which Teaching Assistant has access to. 4. Step 4: Choose question 517 F09 wiki and click on edit question button(pencil symbol). 5. Step 5: Teaching Assistant should be able to edit the questionnaire. (If Instructor/Teaching assistant does not have access to current questionnaire, system will show an error message). Issue 577: 'Teaching_assistant520' and 'Instructor' has access to review 'review/517 F09 wiki' 1. Step 1: Login as instructor/password or teaching_assistant520/password 2. Step 2: Navigate to path manage->Questionnaires-> Review rubric 3. Step 3: Select questionnaire named Review from the list, which Instructor/Teaching Assistant has access to. 4. Step 4: Choose question 517 F09 wiki and click on edit question button(pencil symbol). 5. Step 5: Click on the link 'Export questionnaire' at the bottom of the page. 6. Step 6: Top of the page shows Export Questions. When clicked of export, you will be able to export questionnaire for current rubric. 7. Step 7: Bottom of the navigated page will show 'Export Advices'. When clicked on Export, you will be able to export advices for current rubric. Issue 696: <code>. Issue 577: <code>.","Very good write-up. it covers almost all the aspect of the work done by them and most reviewers gave them the highest score. One issue is that the ""Problem statement"" should actually be included in ""background"" since it barely explains what the problem is, and more explanations are needed for the description of the first issue. Also I'm not sure why they included the modifications of questionnaires_controller.rb and questionnaires_controller.rb in the section ""Modified Files"" of the first issue since they are supposed to be included in that section of the second issue. A minor mistake: section ""2.1.3.1.1"" shoule be in the same level with section ""2.1.3.1"" in ""Contents"" And I'd suggest they include the links to the videos in Wiki."
E1944,"<link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. Students can also peer review other students' submissions. Link to the Pull Request Submitted: <link> Link to the Repository <link> <image>. This controller will map the submissions made by the teams to the students for facilitating peer-reviewing. A couple of long and complex methods such as peer_review_strategy and automatic_review_mapping were refactored from this controller along with the removal of some non-related methods such as add_calibration and assign_quiz_dynamically . Variable names have been changed and code has been modularized and helper methods were separated from the important methods into a module and were included in the class. Test Cases were created for the newly created controllers such as assign_quiz_controller etc. After refactoring the Review_Mapping_Controller.rb , there were some tests still present in the spec file of this controller. So, we removed such tests from the review_mapping_controller_spec.rb to the appropriate spec file. Hence this was moved into a separate controller. Tests related to assign_quiz_controller were moved into this file. Add_Calibration is a nuanced method and has seemingly different functionality than Review Mapping Controller. Methods having a different purpose than review_mapping or helping review_mapping should not be present in this controller. So we moved this method into a separate controller . Tests related to review_response_map were moved into this file. New routes were added to newly created controllers. <code>. Routes were changed in the views and partials. 1. Changed 'instructor = build(:instructor)' to ‘@instructor = build(:instructor, id: 1)’. *Replaced the one in the before(:each) loop by @instructor = build(:instructor, id: 1) and used @instructor class variable, wherever required. before: <image> after: <image> 4. Created a variable named ‘allowed_actions’ in method choose_case(action_in_params) *Switch case in above method from review_mapping_controller.rb contained all the actions having the same output for around 70% of cases. So this has been put into a helper method with an expressive name to increase readability. <code> 7. Modularized helper methods into a module and was mixed in the ReviewMappingController Class. *Only some of the methods written in the class have external usage i.e called by another controllers, views etc. *The other methods are just helpers and as such moved into a Helper method module and mixed in the class Before Modularization <code> After Modularization <code> 8. Abided to the principles of Magic Tricks of testing and did not test any internally used methods, The other tests are written were already following this principle. *Internally used methods were not tested *Tests for newly created controllers have been moved into a separate spec files. 9. Isolated AssignQuizDynamically method into a separate controller as the functionality was not related to ReviewMappingController. *This method is not related to ReviewMapping functionality, so it was made into a new controller. *The controller paths present in the views/partials have to be changed to not to break the functionality *The controller paths in views/partials/routes have been changed for the newly created controller of AssignQuizDynamically View File Affected by the creation of AssinQuizController <image> 11. student_review_num sounds like a number or an id associated with a student review, while it actually stores the number of reviews that a student can perform. 12. submission_review_num sounds like a number or an id associated with a submission review, while it actually stores the total number of reviews that can be performed on a single submission. 13. calibrated_artifacts_num sounds like a number or an id associated with the calibrated artifacts, while it actually stores the number of calibrated artifacts. 16. add_calibration is a method that changes the attribute of a ReviewResponseMap and has little to do with Review Mapping. So it is now put in a separate controller named ReviewResponseMapController. Since this is a Refactoring Project, We made sure that the changes made did not break any functionality. <image> Note: Tests have been run for three controllers (one existing and two new). As the controller routes have been modified in the routes.rb and the other view files, there are potential chances of failures in Integration tests. <image> <image>. Code Coverage for Controllers section climbed up. <image>. Assign Reviewer Manually Demo <link> Regression and Unit Testing of Controllers Demo <link> Automatic Assignment of Reviewer Demo <link>.","1. The ""Files created/modified"" list should be described in conjunction with the changes made.  As it is, one has to flip back and forth to see what changes were made.
2. The changes that were made are described apart from the code that makes them.  This would requre more looking back and forth to understand what was done.
3. Mentor had asked the team to remove code snippets that have been extensively used all over the document.  If the snippets were shorter, with descriptions of each step, they wouldn've been easier to understand.
4. A list of 17 changes is much too long to be comprehended.  More organization is needed.  The changes should be associated with particular issues, or divided into a few types.
5. The team has given test results and code coverage screenshots and have provided a video to test the feature in expertiza deployment and regression testing."
E1911,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.4. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.1.1. <link> 1.1.1.3. <link> 1.1.1.1.1. <link> 1.1.1.4. <link> 1.1.6. <link>. <link> is an open source project based on <link> framework. The bulk of the code in criterion is HTML. This code needs to be moved to a partial file, and the partial file needs to be called in all appropriate places which call the criterion’s model methods. Once the logic for the view is moved out of the model, the model should only be left with business logic. This business logic code can also be refactored. As of now, the criterion model holds 4 methods that are called from different places in the application. <link>. This method is one of the several other methods in other files like criterion.rb which gets called when the type of the question being created in the respective model. In the case of this problem, which deals with criterion type questions, the edit method defined in criterion.rb is called when the question.type is equal to ""Criterion"". This method allows for a user to create the criterion question and enter the necessary details. The outcome of this method's refactoring will completely remove this method from the model file criterion.rb as there is no business logic involved here. This method has the same explanation as the edit method except the fact that this method is called only during viewing of questionnaires by an instructor. We observed that this method is also called by in student_quiz view. The outcome of this method's refactoring will completely remove this method from the model file criterion.rb as there is no business logic in this method and is completely html code. This method is one of the several other methods in other files like criterion.rb which gets called when the user responds to the question being created in the respective model. In the case of this problem, which deals with criterion type question responses, the complete method defined in criterion.rb is called when the question.type is equal to ""Criterion"". This method allows for a user to respond to the criterion question and enter the necessary details. This method is called only from one view file i.e. This file is in response view. The outcome of this method's refactoring will completely remove this method from the model file criterion.rb as there is no business logic involved here. <code>. No changes were made to this method as this method wasn't being called from a view. Instead, it was being called by a model response.rb which was also creating an html string. All the code in the model was just html and thus was completely removed from there. 1. views/questionnaires/edit.html.erb - This file calls the edit method for all types of question objects and the object type takes care of invoking the right overridden method. We modified this file to call the partial instead of edit method only for Criterion type of question objects. Same logic and changes as above. 3. views/questionnaires/_criterion_edit.html.erb - This file has all the html code that was earlier in the edit method of the criterion model. This method did not contain any business logic and thus all code was formatted and moved to a new partial file (views/questionnaires/_criterion_view.html.erb). All the code in the model included html thus was completely removed from there. 1. views/repsonse/response.html.erb - This file calls the complete method for all types of question objects and the object type takes care of invoking the right overridden method. We modified this file to call the partial instead of the complete method only for Criterion type of question objects. Here are the changes: <code> 2. views/response/_criterion_complete.html.erb - This file has all the html code that was earlier in the complete method of the criterion model. This method returns a constructed html string that is used to display a particular criterion question. A partial cannot be rendered halfway through the computation of ""code"", neither can it be called from a model. Refactoring response model would require changes to other question subclasses like scale along with changes to the model itself. Thus, this method has been left untouched and still remains in criterion.rb itself.","You described your changes well.  I would suggest a couple of enhancements that could've made the presentation easier to follow: (1) Juxtapose the old and new code for each modification.  In your organization, one needs to flip from the ""problems"" to ""solutions"" section to understand each change that has been made.  (2) Show code snippets pasted from Github diffs, where the changes are highlighted in color, and the code is more readable."
E1861,"The information is displayed with attributes like name, ID, due date etc. This project works on improving the search facility by adding search criteria in existing search bars, making it look elegant and adding search bars if not present. 1. An instructor or administrator can search for a user by name, user-ID, or other characteristics. 2. An instructor should be able to search for assignments by name, due date, or other characteristics. 3. An instructor should be able to search for rubrics (or other questionnaires) by name, or by the courses or assignments they have been used in. It should be possible to search or click somewhere to bring up a list of questionnaires used in the course, expanding only the applicable questionnaires in the list of questionnaires. 1.2. One should also be able to search for questionnaires by words used in questions that belong to the questionnaires. 4. There should be a way to search all reviews of a particular team’s work for particular scores or text strings. 5. An instructor or administrator should be able to search for all the assignments that a particular user has participated in. In the current system workflow the user is able to search for a particular user by entering a partial or a complete text that matches with the user name. In the proposed workflow searching by name, searching by User ID will also be supported. The user will be able to apply multiple filters at a time and the output of the query will match all filter applied. In the current system implementation, searching via the name of the assignment is supported. In the proposed system, the user will be able to search for an assignment using additional filters such as date created, date updated. The user will be able to apply multiple filters at a time and the output of the query will match all filter applied. To search for an assignment by creation date, the user can enter a time duration within which the assignment was created. All assignments that were created within this date range and which match other filters will be returned. The procedure is same for searching by date of update. Steps to reproduce the proposed workflow: 1.1. Log in to expertiza to view the home page 1.2. Go to Manage > Assignments 1.3. Type the name of the assignment in the search box available below the ‘Assignments’ tab 1.4. In the dropdown list that opens up, click on the ‘Advanced Search’ button if you wish to apply more filters ( date of creation, date updated). The existing system does not have a search functionality under Questionnaires. The proposed system will implement a search functionality for searching via the name of the questionnaire, the text in the question within a questionnaire, date of creation, date updated. The user will be able to apply multiple filters at a time and the output of the query will match all filter applied. To search for a course by creation date, the user can enter a time duration within which the course was created. All courses that were created within this date range and which match other filters will be returned. The procedure is same for searching by date of update. All the above will be available under Manage > Questionnaires. The existing system does not have a search functionality under Reviews. The proposed system will implement a search functionality for searching using the attributes like team name, score, reviewer, comment etc. We though about 2 ways of adding the search functionality in the system 1.1. Adding a search controller to the system 1.2. Adding search functionality to individual models. Setup create an assignment with name=""assignment"" and set a due date Action : Instructor clicks on Manage -> Assignments, in textbox enter ""assignment"" in relevant tab Response : Relevant assignment should be displayed Action : Instructor clicks on Manage -> Assignments-> drop down and apply filters for due date and enter date and click ""ok"" Response : Relevant assignments should be displayed. Setup : Create a Questionnaire, add questions to it Action : Log in as instructor, Manage -> Questionnaires, in text box enter text Response : Questionnaires matching text are shown Action : Log in as instructor, Manage -> Questionnaires, click advanced search and check creation date and enter value Response : Questionnaires matching text are shown. Setup : Setup review for an assignment, login as student and then add review Action : Log in as instructor, Manage -> Assignments, Click on Review Report icon on corresponding assignment Result : Review should be seen Action : Click Advanced search, check review by text and enter text Result : Matching review should be visible. Test Details 1. User Model ( spec/models/user_spec.rb ) 1. Search by user name 2. Search by user name that does not exist 3. Search by user email 4. Search by user email that does not exist 5. Search by user email containing a substring 6. Search by user full name 7. Search by user full name is empty 8. Search by user name and email.","This document describes the project in several relevant ways: discussion of the design approach, usecase diagram, classes and methods changed, changes to database schema, and test plan.  Each one of those is described in reasonable detail.  There are no major weaknesses."
E1834,"Deadline reminders should include a link on where to go to perform the needed function. We added a method in the assignment_participant.rb file (model) to send mails when a participant is added to an assignment on the assignment page by importing a CSV file. We have also added a method in the course_participant.rb file(model), to send the mail when a Course participant is added by importing a CSV file. <link> 2) Sending email to reviewer when new submission is availble: Added functionality to send email to the reviewer when new submission is available by making changes in the submitted_content_controller and assignment_participant model.The method handled boundary constraints like checking whether the round was valid and disabling email notification after the last round of review. <link> Extra functionality of specifying the current review round and providing the direct link to reviewer in the mail itself also implemented in the submitted_content controller using the ReviewResponseMap and Response class. <link> 3) Including a specific link for the deadline reminders email functionality for reviewers : Added a review_reminder_email method and mail_reviewers method in the delayed_mailer.rb file which implemented the functionality for sending deadline reminder mails which includes a link on where to go and perform the specific task. Prepared a hash named email_list using the email and participant_id, for each participant who is a reviewer. Notice that the link in the instructor's email will contain the '?id=' field of the last participant fetched. <link> Bonus Functionality Implemented below:- 4) Including a specific link for the deadline reminders email functionality for submissions : Added a submission_reminder_email method in the delayed_mailer.rb file which implemented the functionality for sending deadline reminder mails which includes a link on where to go and perform the submission. <link> In the background_email_reminder.rake file, for the assign_type=""submission"", we fetch the assign.id which is to be passed as the suffix to the url to be sent in the mail for submission reminder. The team members can click on this link in the email and get redirected to the submission page of the particular asssignment. Additional Links 1.1. Git pull link: <link> 1.2. VCL deployment: <link> References 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> Team <link> <link> <link>. 1) Email sent when user is added as a participant to assignment : When students' accounts are created by importing a CSV file on the Users page,they receive e-mails but not when user was added as a participant to the assignment. We added a method in the assignment_participant.rb file (model) to send mails when a participant is added to an assignment on the assignment page by importing a CSV file. We have also added a method in the course_participant.rb file(model), to send the mail when a Course participant is added by importing a CSV file. <link> 2) Sending email to reviewer when new submission is availble: Added functionality to send email to the reviewer when new submission is available by making changes in the submitted_content_controller and assignment_participant model.The method handled boundary constraints like checking whether the round was valid and disabling email notification after the last round of review. <link> Extra functionality of specifying the current review round and providing the direct link to reviewer in the mail itself also implemented in the submitted_content controller using the ReviewResponseMap and Response class. <link> 3) Including a specific link for the deadline reminders email functionality for reviewers : Added a review_reminder_email method and mail_reviewers method in the delayed_mailer.rb file which implemented the functionality for sending deadline reminder mails which includes a link on where to go and perform the specific task. Prepared a hash named email_list using the email and participant_id, for each participant who is a reviewer. Notice that the link in the instructor's email will contain the '?id=' field of the last participant fetched. <link> Bonus Functionality Implemented below:- 4) Including a specific link for the deadline reminders email functionality for submissions : Added a submission_reminder_email method in the delayed_mailer.rb file which implemented the functionality for sending deadline reminder mails which includes a link on where to go and perform the submission. <link> In the background_email_reminder.rake file, for the assign_type=""submission"", we fetch the assign.id which is to be passed as the suffix to the url to be sent in the mail for submission reminder. The team members can click on this link in the email and get redirected to the submission page of the particular asssignment. <link>. 1. Git pull link: <link> 2. VCL deployment: <link>. 1. <link> 2. <link> 3. <link> 4. <link>.","Excellent job!  Describes all of the functionalities, and shows how they were implemented.  The only thing I would change is to put a space before each open paren :-)"
E1943,This page gives a description of the refactoring done in the sign_up_sheet_controller.rb as part of the OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.2. <link> 1.3. <link> 1.4. <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. Clean Code: A handbook of agile software craftsmanship. Author: Robert C Martin.,"There are not enough comments describing changes to the code.  Simply providing before and after snippets is not enough.  For example, ""Fixed the if-else ladder in signup_as_instructor_action action"" does not describe what was wrong, and how the fix was structured.  The document would thus not be very helpful in understanding the code.
There is a youtube video provided for testing that shows that the code has not been regressed
Appreciate the results/conclusion section in the doc which describes how their code change impact and what they bring to the table
It would be much clearer to cut and paste code snippets from Github rather than to use the formatting available in the wiki."
E1916,"<link> is a web application developed using Ruby on Rails Framework whose creation and maintenance by students and the faculty of NCSU. The code is available on Github <link> . In Expertiza, instructor can create new assignments and customize new or existing assignments. The instructor also can create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. All the team member will show under the team member list. A Student can comment on his teammate's performance of the project. Students can also peer review other students' submissions and give tag comment by other's peer review. Students can submit their work by URLs or multitype file submission. Project E1916. Fix Code Climate issues in controllers with names beginning with A through N. There is some code smells of expertiza app/controllers detected by the code climate. These violate many of the ruby/rails best practices and needs to be rectified. Our team is to fix all code smells except： 1. Assignment Branch Condition size for [method name] is too high 2. Perceived complexity for [method name] is too high. 3. Cyclomatic complexity for [method name] is too high. 4. Method [method name] has a Cognitive Complexity of XX (exceeds 5 allowed). Consider refactoring. 5. File [file name] has XXX lines of code (exceeds 250 allowed). Consider refactoring. 6. Class [class name] has XX methods (exceeds 20 allowed). Consider refactoring. 7. Method [method name] has XX lines of code (exceeds 25 allowed). Consider refactoring. 8. Mass assignment is not restricted using attr_accessible. 9. Potentially dangerous attribute available for mass assignment. In all files in app/controllers/ with names beginning with A through N, except assignment_controller.rb. 1. [MAINTAINABILITY C] app/controllers/assessment360_controller.rb 2. [MAINTAINABILITY B] app/controllers/automated_metareviews_controller.rb 3. [MAINTAINABILITY B] app/controllers/grades_controller.rb 4. [MAINTAINABILITY C] app/controllers/impersonate_controller.rb 5. [MAINTAINABILITY F] app/controllers/import_file_controller.rb 6. [MAINTAINABILITY C] app/controllers/lottery_controller.rb. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. 1. Example <code> 1. Solution <code>. Our task is to fix code smell issues for some of the controller files. In order to prove that our modification did not break the application, we ran all the controller tests to make sure they all pass. We firstly set up the environment through VCL. Then we cloned our repository and simply ran: <code> Then we get the following results which represents that we passes all the controller tests. <image>. 1. Our Team GitHub Repository: <link> 2. Our Team Code Climate: <link> 3. The Class GitHub Repository: <link> 4. The Class Code Climate: <link> 5. The testing video: <link>.","On the micro level, you have described your changes well,  But rather than look at them one by one (which I could do through Github's diff), I'd like to see a summary of what were the issues that cropped up frequently, so we can advise future students to avoid them.  "
E1757,"In Expertiza, instructors can act as students, but they do so by using different pull-down menus. This is potentially confusing, especially for Assignments, which appear both in the admin and student menus. An instructor sees the following menus across the top (if his/her window is wide enough; otherwise, the menus show up when the menu icon is clicked on): Home Manage Survey Deployments Assignments Course Evaluation Profile Contact Us A student sees these menus: Home Assignments Course Evaluations Profile Contact Us On the instructor’s Manage menu, one of the options is “Assignments”. Having Assignments appear in two places in the menu is potentially confusing. Manage > Assignments allows the instructor to edit and create assignments. The Assignments menu that both students and instructors see allows them to participate in assignments. Hence, to avoid confusion, a new view is introduced. To create a Student View that would make the instructor view the system the way (s)he would view it if they were a student. Once the instructor is in student view, the menu items are same as a student would view, so to come back as the instructor, a button should be visible to the instructor that would exit the Student View and take the instructor back to his/her home page. A new controller is created app/controllers/student_view_controller.rb to handle the new student view functionality, which sets and instructor to student view and reverts the view back to instructor. <code>. A new view is created for the instructor in config/role_instructor.yml which will show the view under the Manage menu item. The view id is 25. <code>. A new session variable (:student_view) will be used to check if an instructor is in student view or not and will be used to exit the Student view, code changes in app/views/shared/_navigation.html.erb <code> <code>. The different menu items are shown for particular roles, we check the new session variable to show or hide the various menu items accordingly for the instructor in app/views/menu_items/_suckerfish.html.erb <code>. The new controller methods are added in config/routes.rb <code>. The user needs to log-in as instructor to view the developed functionality, this won't be visible for other user roles- 1. Go to Manage > Student View 2. Instructor views Expertiza as a student. 3. A revert button appears at the top right corner, to exit the Student view. 4. Clicking the button takes you back to the instructor view. 1. link for forked repository [ <link> ].","Writeup is quite short, but also fairly easy to read."
E1702,"It will also motivate other students to perform better academically. The aim of this project is to implement a badging system for expertiza where certain students are awarded with badges based on their exceptional academic performance in assignments, project submissions etc. We have used Credly to make Badges. We are asked to make four badges now. The four badges selected by the instructor Zhewei Hu and our Team are: 1 Top Score 2 Dream Team 3 Good Reviewer 4 Consistency. We have decided on four badges which will be awarded to students who fulfil certain conditions explained in detail below. <image>. For every assignment in Expertiza, we have students perform differently on a scale of 100 based on the reviews their projects receive from their peers. The topper badges will be used to honor the team(s) which scores the maximum for a assignment. For example: <image> If we take the same example, the following Team will win the Top Score reward for OSS assignment <image>. The motive behind choosing this badge is to honor the hard work of team(s) who scored the maximum in class. This way, we can motivate other students to score better in the next assignment and score the best. <image>. In Expertiza students are required to give reviews to the work of other teams. The Good Reviewer badge will be awarded to the student(s) who receive at least 95% score in the peer reviews awarded by the teaching staff for a project. For example: <image> If we take the same example, the following students will win the Good Reviewer badge as each of them got at least 95% in peer review score for OSS assignment <image>. Good reviewer badge will motivate students to give good reviews to fellow students on their work. Second, it will motivate the student to give good reviews and go through the work of other students which will give him/her the opportunity to learn. <image>. The performance of students across assignments vary. The Consistency badge will be awarded to the student(s) who receive at least 90% score in all the assignments. This badge will help the instructor also to know the consistent performers of the class. For example: <image> If we take the same example, the following students will win the Consistency badge as each of them got at least 90% in Assignment score for all the assignments. <image>. The motive behind choosing this badge is to motivate students to perform consistently throughout the semester. This is how the student page will look like. <image>. This is how the instructor page will look like. <image>. <image> The above diagram shows the implementation of badges for students. 1. The badge.rb is the Model class. It will contain the business logic for various badges. <image> The above diagram shows the implementation of badges for instructors. The data flow is same as that of students. 1. As per requirement, the badges need to be displayed in the list view for both instructors and students. 3. All business logic regarding badge assignment criteria will be put in badge.rb, a model class created for the specific purpose. 5. Since all business logic will be in the model class this class can be easily expanded to include more badges in the future. 1. We have logged in as instructor6 and identified the top scorer of a particular assignment. Next, we impersonated all the students of the top score team to make sure all of them have received the top score badge for that particular assignment. 2. A Team in which each member has got more than or equal to 95% from all team mates review should receive the dream team badge. 3. We have logged in as instructor and given 100 points and 90 points to 2 students respectively as review scores for a particular assignment. Then we impersonated the 2 students to check that one of them has received a good reviewer badge and the other hasn't received the badge for that assignment. 4. Logging in as instructor, we have identified a student who has scored more than or equal to 90% in all the assignment for that course. Next we logged in as that student to make sure (s)he has received the consistency badge. We have further checked that instructors can see the badges the student has received for a particular assignment by visiting the participant_list/list view page. The page shows all the assignment specific badges (Top score, Dream team and Good reviewer badge). Currently, the average score of all the reviews for each assignment is computed dynamically and not stored anywhere in the database. This is the reason why ""Review Score"" page from instructor view takes long time to load. For the topper badge, we need to query the average score of all the teams for all the assignments in a particular course and decide whether the current user is the member of the team having the highest score in any of these assignments. Once this task is completed, we can refactor our Top Score method to take advantage of this change. This will significantly reduce the latency of the Top Score badge for both student and Instructor view.","Very good job, including all the major elements: prose descriptions, screenshots, code snippets showing what was changed, and testing."
E1675,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link>. <link> is an open source project based on <link> framework. In Expertiza we accept hyperlinks as well as files submitted by students, which makes it harder to track the updates for student's submission. In this project we were required to keep track of timestamp records for student's submissions and updates of artifacts (submitted files or hyperlinks). Authors can delete or re-submit files and hyperlinks, those activities were also recorded. What needs to be done: 1. Record the timestamps for file/hyperlink submissions. 2. Add code to keep all those time stamps tracked and updated. 3. Change the view of 0.0.0.0:3000/assignments/list_submissions view (by clicking the “View submissions icon”) to display the submition histories of each team. 4. Make the available submissions clickable (some submitted items maight be deleted, so they are displayed but not clickable). 5. After this project, the ResubmissionTime model (and related code) will not be used anymore. Please remove related code and db table. We created a set of new controller, model and views to implement the functionality of timestamps. We added a model named SubmissionRecord that contains the following attributes. 1. Hyperlink - hyperlink that could be uploaded - String. 2. Upload File - file that could be uploaded - File. 3. Team id - id that links the model to the team that created it. 4. Created at - timestamp for time of creation. 5. Operation - Description of operation performed. - create, update and delete. 6. User - User who change the status of current table Get this from current user id. 7. Content - String, the file name or the hyperlink. 1. In present code, the application has the control to decide which kind of user could have access to the specific page. In order to let the instructor see the submission_record, we need to add action_allowed method in submission_record_controller. Below is reference code : <code>. 1. After we created the table, there isn't a specific page for us to fill in the submission_record database table. This page had information about the hyperlinks and files which were previously submitted by the student. We add functionality to fill in submission_record table once a hyperlink or file is submitted. Below is a code snippet for reference : <code> <code>. 1. When students want to delete their hyperlinks or files which they had submitted before, the data in submission_record table should not disappear. As a result, we added specific functionality in the existing delete function to reserve the data in submission_record table. <code> <code>. 1. In order to make the student submitted hyperlinks clickable, we check if the operation performed is 'Submit Hyperlink' in database. <code>. We then use a WHERE SQL query that matches the team_id from the submissions record table. <code>. The testing for this project has been done using several advanced ruby features. Below are a few of the features which were used : 1. <link> 2. <link> 3. <link> Using these techniques, the project was thoroughly tested. Models were tested for their validation. We had to verify each of the parameters which we received in our model. This was done by developing a Ruby Factory which had sample data. This sample data was fed into the models. Using RSpec, we then checked for validity for each of the parameters received in the models. This validity check is important since this information is prerequisite for having a perfectly working controller and view. Below is a code snippet which describes the testing methodology. <code> Controllers were tested to make sure the rendering, redirection and views are proper. Steps for testing the project using the User Interface. 2. Click on submissions view of an assignment. 3. You will see all the items submissions. 4. Click on ""Show Submission Records"". 5. You will see a history of the submission along with the timestamps for each submission. 6. You can also see when the submission was added, updated and removed. 1. <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. Clean Code: A Handbook of Agile Software Craftsmanship.","Good job of enumerating the changes made.  Good prose description the code snippets that you have included.  However, the code snippets themselves should contain comments."
E1620,"- 1 1.2 - Create a link to create a survey for a selected users of a course. - 2 2.2 - Create a link to the results distribution page for a particular survey in the page where the survey is listed. - 2 2.4 - Create a new page to display each question of the survey and the distribution of results of each question. Select the course for which you want to create the survey. Create the survey and add the questions to the survey. Post the survey as a course survey. This survey should be available to all the participants of the course. Select the course for which you want to create the survey. Create the survey and add the questions to the survey. Once the survey is created select the participants of the course to whom this survey should be sent and the post the survey. The survey should be sent to the selected participants. Select the course for which you want to create the survey. Create the survey and add the questions to the survey. Once the survey is created select the participants of the course to whom this survey should be sent and the post the survey. Create the survey and select the checkbox to include the questions from the global questionnaire. The questions from the global questionnaire should be added to the survey. Choose an existing survey. Check if a link exists with the survey which will lead to a results distribution page. Choose a survey which is assigned to this user. Fill out the survey questions and click on submit. 1. Only instructor or admin can create the survey. UC 1.1 Name: Ability to create a survey for a particular course. - There is at least one course in the system for which the survey can be created. Detailed Steps: - The user selects the course for which the survey needs to be created. - The user creates a survey and adds the questions to the survey. - The user posts the survey as a course survey for all the participants of the course. Post conditions: - A course survey is sent to all the participants of the selected course. UC 1.2 Name: Ability to create a survey for some selected participants of a course. - There is at least one course in the system for which the survey can be created. Detailed Steps: - The user selects the course for which the survey needs to be created. - The user creates a survey and adds the questions to the survey. - The user selects the participants from the course participants list to whom the survey should be sent. Post conditions: - A survey is sent to the selected participants of the selected course. - There is at least one course in the system for which the survey can be created. Detailed Steps: - The user selects the course for which the survey needs to be created. - The user creates a survey and adds the questions to the survey. - The user posts the survey. UC 1.4 Name: Ability to not include global survey questions in the survey. Detailed Steps: - User selects to create a survey. - User unchecks the global survey questions checkbox to not include global survey questions. (By default the global survey questions checkbox is checked) - User submits the survey. Post conditions: - System does not include the global survey questions if the checkbox is unchecked. UC 2.1 Name: View distribution results for questionnaire as instructor/admin Preconditions: - User must login to the Expertiza system as instructor/admin - A questionnaire already exists which the user has access to Detailed Steps: - User selects the questionnaire which (s)he has access to - User selects the link ‘Results Distribution’ for that questionnaire - User views the results for each question of questionnaire Post conditions: - The system displays the result distribution for each question belonging to that questionnaire. UC 2.2 Name: View distribution results for survey as instructor/admin Preconditions: - User must login to the Expertiza system as instructor/admin - A survey already exists which the user has access to Detailed Steps: - User selects the questionnaire which (s)he has access to - User selects the link ‘Results Distribution’ for that survey - User views the results for each question of survey Post conditions: - The system displays the result distribution for each question belonging to that survey. UC 2.3 Name: View distribution results for review questionnaire as student Preconditions: - User must login to the Expertiza system as instructor/admin - User must have submitted an assignment which has been reviewed Detailed Steps: - User selects the assignment which (s)he has access to - User selects the link ‘Results Distribution’ for that assignment review - User views the results for each question of review questionnaire Post conditions: - The system displays the result distribution for each question belonging to that review questionnaire. Detailed Steps: - User takes the survey and submits answer for the questions in the survey. 5. View survey response distribution feature - When students have answered questions in the survey, the instructor should be able to view the distribution of the responses for each question of the survey.","There are old code related to suvey which are not removed.
The video did not show how can students fill in the survey. It was not showed in the demo either.
Limited test done."
E1750,"Expertiza is an open source project base on Ruby on Rails framework. It allows students interact with each other through different assignment. It provide service as bidding on project topics, reviewing your teammate for different categories, and submitting assignments online. Expertiza also allows instructors to create assignment with different rubric and creating different topics for assignments that student can bid on. A software development process begin by writes an (initially failing) automated test case that defines a desired improvement or a new function, and generate the minimum amount of code to pass that test. It help the developer to focus on a smaller portions of functionality at a time. Also the refactoring process is safe since it happens after the test is written. Test can also serve as a documentation to a developer. review_mapping_controller.rb handles peer review response, and author-feedback response which is a complex file. It contains long methods that would be hard to understand. This project focused on breaking down some of the method in a form that would be easier to read/understand. Before starting the refracting task, failing test cases needs to be completed for the corresponding method in the review mapping controller. After completing the refactoring certain method if the review mapping controller then failing test should have a new status of pass. 1. Complete pending tests in review_mapping_controller_spec.rb, and write integration tests for newly-created methods. 2. Refactor automatic_review_mapping method 1. Refactor response_report method 1. Use find_by instead of dynamic method (L135) 1. Use sort_by(&:name) instead of sort { |a, b| a.name <=> b.name } (L275). 1. review mapping controller 1. Refactor methods 2.review mapping_controller spec.rb 1. Finished corresponding test for exiting method as well as created new test for newly added method. Here are two of the examples of the test cases. Tests on assign_metareviewer_dynamically method which assigns a assignment to the corresponding student. The describe section of the test introduce the controller method this test focus on. Followed by an description of the result on would be expecting from this test for developers to follow. The different expect conditions expressed as each test should make only one assertion which helps us finding different errors in the code. <code> Here is another example tests on add_reviewer and get_reviewer method which assigns reviewer to student's work. The test is divided into two different sections, and each section specifies one (and only one) behavior. This way will delivery a test that test all different possibilities and give the exact location of the error when it happens. This test followed the same step as the above test. <code>. In this example, we divided automatic_review_mapping method into 4 different simpler method so the code will be easier to follow. As before, the whole method is filled with nested if else statements when testing for certain conditions. We started by dividing the code from the if else statement, so an nested if else statement occurs we would divided the code into 2 method each performs a different set of function. We further divided the code by categorized their functions so that each method can perform the same kind of function or function belongs to the same controller. By doing this, our code is successfully divided into 4 simpler method with a name that describe their functionalities. 1. Original Code <code> 1. Refactored Code <code>. Response Report method had different switch statement testing different conditions. We split it into simpler method in different model to achieve a better cohesive in our code. We place different portions of code in models that related to their function. By just calling the corresponding method decreased the length of the review mapping controller. Updated the test after the code is completed. <code> 1. Original Code <code> for example this portion of the code summarizes the reviews of each reviewee by each rubric criterion. Which is placed in the summary class with a method name def self.response_report_by_review_and_criteria. <code>. 1. 39 examples, 0 failures, 39 passed 2. Finished in 12.099842971 seconds 3. Randomized with seed 22837 4. Coverage report generated for RSpec to /home/expertiza_developer/RubymineProjects/expertiza/coverage. 1400 / 4988 LOC (28.07%) covered.","In refactoring, we were interested in what principles they enforced, or which design patterns they used.  The comments are pretty general and do not give a good sense of what is done.  There should be more whitespace and more comments in the code.  Just showing original & refactored code doesn't indicate clearly how it was changed."
E1705,"The knowledge gained can be measured by assignment score and reviewing score of the reviewer. GitHub and Youtube use cases 2. Design a database schema for logging the time a reviewer spends on each submission link 3. Modify Review report (views/review_mapping/_review_report.html.erb) to display the response time summary report for each reviewer. The task is to know how much time a reviewer spent reviewing other teams. But, entry in the responses table is created only once the response is either saved or submitted. 2. We primarily needed reviewer and reviewee specific data. We need to record start and end time per link . Start and end time of each link viewed in one session needs to be recorded. The following are the steps that will be followed to keep track of the time: 1. Log the start time when a user clicks on a submitted link (a new entry in the response_times table gets created) during new review or while editing his saved review. An AJAX call is made from the view to ResponseTime controller action record_start_time to save start time details to database. 2. End time of all open links (where end time has not been recorded yet) for that session get recorded in the cases mentioned below. In this, an AJAX call is made from the view to ResponseTime controller action record_end_time to save end time details to database. The end time will not get affected in this case 3. Next time the reviewer opens the links again to review: 1.1. New entry gets created in the response_times table and start time gets recorded for this new session 1.2. The above procedure for end time remains the same 4. In case there is no user activity on the expertiza reviewing page for more than 5 minutes, there will be a pop up asking the user if he is still reviewing the submission. 5. As soon as the pop up is shown, the end times of all open links get updated to this time. If the user clicks on 'okay', then the above links for which we just updated the end time, need to be added as new entries again in this new session with start time as the current time. 6. This way we have individual entries for each link corresponding to each session with both start and end times recorded in the database. Instructor can now view the total times taken by reviewers in the Review report summary. We shall modify this view to record the times spent by the reviewer per review round for each team reviewed for this particular assignment. For example - 15.32, 12.67 indicates that reviewer spent 15.32 minutes on round 1 review and 12.67 minutes on round 2 review as shown below. Modified View : <image> Now, we can see that this report is simply an overview. If the instructor wishes to view fine-grained details, he can click on the reviewer link in the report. This view shows reviewer details and details of time spent per link per round by that particular reviewer. Note - total time represents total time spent by the reviewer over all rounds over all links. If the user clicks on ""alternate view"" for a particular round, a pie-chart representation of the same data for that round appears above the details table. The user can toggle this view off by clicking ""hide details"" and ""show details"". 1. What happens when the user clicks on the same link twice in the same session: 1.1. It may so happen that once the user clicked on a link, by mistake he/she closed it or lost the link and wishes to view it again. If the link is again clicked, a second entry gets created with the current time as start time. 1.2. We account for the previous entry by updating its end time as current time. 2. What happens when the user downloads the submission: 1.1. If the user downloads any submission, the start time will be recorded on click link and end time will get recorded as above or when he submits the review. To test if the time spent by the reviewer on the submitted links shows up in the response_report in Instructor View. 1. Login as a reviewer, for example (student5930). Click on the submitted links to start reviewing. Once review is done, the time spent is recorded in the background and saved in our database 2. Login as an instructor. Click on assignments tab. Click on 'View Review Report' under actions for the particular assignment. In the view rendered we expect the total time spent by the reviewers for each to be visible 3. Click on the reviewer in order to see detailed information of time spent by each reviewer 4. Click on alternate view for each entry in order to see link wise time spent in form of a pie chart. To record the starting and ending time of a person looking at the submission, we call 'record_start_time' and 'record_end_time' respectively. We create a stub student user and a record in response_times database to imitate the real data entry.","Includes all the major elements, in a very readable format.  The one weakness is that it does not go into detail about how the project will be implemented.  It discusses changes to the db but not to the code."
E17A9,"The <link> page contains lists of courses, assignments, and questionnaires. A more common way to accelerate this is to load the first few records that show up in the screen, and load more records as the user scroll down which is called lazy loading. We would like you to optimize this page by implementing such lazy loading using Jscroll or other plugins since the original tree_list code is written in ReactJS. Moreover, the tree_display lists have some bugs that you should fix: 1. It always goes to assignment page first, so when a user is editing a course then click browser’s back button. It goes back to the assignment instead of the course tab. The same applies when a user is editing a questionnaire, then click back, it goes back to the assignment, instead of questionnaire. We want you to enable “back” to the correct tab. 2. Secondly, when “Include others' items” checkbox has been checked, then the user is editing an assignment or courses, then goes back. The checkbox is unchecked again. It should remember the last state and load the assignment or courses accordingly. Therefore, we need to use infinite scroll to load a certain number of the record at one time e.g., record #1-#10 <image> The instructor page load extremely slow due to too much backend Database query ran before loading the front end. The frontend can use infinite scroll to reduce the render consumption. At first, we tried to solved the problem using jscroll. Therefore, because the instructor said we do not have to use jscroll to implement infinite scroll, we decided to use a react plugin called ""react-infinite"" instead. <image> In ""Questionnaires"" table, after the user click one row to expand the table, he cannot click again to close it. We need to organize it first by ""Instructor"" and then by ""Creation Date"". So we need to take the following steps: 1. 1. Install the dependencies we need to add infinite scroll functionality to ReactJS. 3. 3. Add react-infinite to the tree_list. 4. 4. Modify the corresponding functions in assignment, course, questionnaire controllers to support lazy loading. <code> <code>. react-infinite <link> react-infinite is A browser-ready efficient scrolling container based on UITableView. Here's a demo <link>. 1. When a user first navigate to the page, there are 10 records and he can scroll down to see more records. 2. When a user edits a course, he will go back to course tab after clicking browser's back button . 3. When a user edits a assignment, he will go back to assignment tab after clicking browser's back button . 4. When a user edits a questionnaire, he will go back to questionnaire tab after clicking browser's back button. 5. When ""Include others' items"" checkbox has been checked, then the user is editing an assignment or courses, then goes back, the checkbox remains checked. 6. When ""Include others' items"" checkbox has not been checked, then the user is editing an assignment or courses, then goes back, the checkbox remains unchecked. The first one is jscroll, we had load jscroll into vendor directory using bower, and able to required in the project, but it turns out that jscroll doesn’t work in ReactJS. Thus, we tried to find third party React Plugins to achieve the function of infinite scroll. The first React Plugin is react-infinite, We were also able to load react-infinite into vendor directory using bower, and has no error occurred while adding to the react component. add dependency ""react-infinite"" to bower.json <code> run setup.sh to load ""react-infinite"" into /vendor/ modify ""app/assets/javascript/application.js"" to require the plugin <code> add ""react-infinite"" tags to ""app/assets/javascript/tree_display.jsx"" <code> However, it also didn’t work out because of the main content is html table. People recommended another plugin called react-infinite-scroller, this plugin couldn’t find by bower package manager, so we have to load this package by another package manager like webpacker, but webpacker needs Rails 5 to load React, however Expertiza is based on Rails 4.2.6. We’ve also tried sprockets but we were unable to import. Our last try is <link> <link> <code> But we still stuck at this bug. <code> This project turns out to be really complicated to implement. <code>. <code>. <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code>. 1. <link> 2. <link>.","The team had a hard time completing the project, and tried to update the design doc to reflect their new direction.  This makes it a bit disjointed, but that is to be expected.  There are a few issues mentioned by reviewers, like the tests should have been better documented.  Just showing the code is not very useful."
E1672,"This project mainly focuses on removing duplicated codes in feature tests and using Code Climate Chrome Extension and Travis CI to evaluate the modified code. It’s an open source project developed on Ruby on Rails platform and the code is available on Github. 3. Make changes according to user reviews 4. Allows the instructor to create new assignments and customize new or existing assignments. The goal of this project is to attempt to make this part of the application easier to read, maintain and improve the quality of the code. The existing redundant codes, use of long methods, incorrect method invocation and other errors are pointed out by the Code climate extension which are modified in this project. The code climate extension also provides a rating for all files as well as an overall score for the entire application, to help us make proper modifications. The following tasks were accomplished in this project: Install the Code Climate Chrome Extension, and when you go to Expertiza repo, you will see the extension will highlight the duplication code. Improved the clarity of code by improving the variable and parameter names. Remove the duplicated code by extracting a new method, moving code to before(:each) block, etc. Improve the Code Climate rating of classes whose original rating is F. Do not delete existing test cases and keep them pass TravisCI after refactoring. Files modified in current project Six files in spec/features that are to be modified are : 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>. Code Climate is a open and extensible platform for static analysis and works on the principle: healthy code ships faster. Code climate platform leads to healthier code by clear and actionable static analysis regardless of the technology used. The static analysis engines and all the static analysis code used are published under Open Source licenses. This paves way for the users to dig in and understand how the code is being evaluated. The rating and GPA provided by Code Climate extension is an estimate of the quality of the code. The ratings vary from A to F and the GPA varies from 1 to 5. Code with a higher GPA is expected to have higher quality. Getting started with Code Climate To get started with Code Climate the following 4 steps are to be followed 1. <link> 2. <link> 3. <link> 4. <link>. 1. <link> and allow the extension to be used with your browser 2. Sign into your Github account and add the repository to be checked by clicking the extension from your browser. <image>. Similar code found in 1 other location (mass = 50) Duplicated code can lead to software that is hard to understand and difficult to change. Do not use DateTime.now without zone. The files in the project include duplicated code which violates DRY concept and is to be removed. The various changes that can be made to the files are explained. When there is duplicated code within the file or between files of the same project, the code can be created as a function with variables that are assigned based on the different cases. This makes the code more readable and in fact, much easier to understand. By writing similar lines of code again and again, we only increase the number of lines and decrease the efficiency of the code.For example, the following error was pointed out by Code Climate Extension in <link> Similar code was found <image> <link> code similarity New functions were added to remove duplicates <image> <link> code similarity. In the different spec files, find_by_name function is used to identify variables according to their name. For example in file <link> , find_by_name was detected: <image> This was corrected to find_by <image> The grade of the code improved when find_by_name was changed to find_by. Refactoring is the process of improving a source code without altering the external behaviour. We can implement refactoring using one of the methods mentioned above. A common code that is present across files can be added to rails_helper.rb and called across files when needed. One example of this is the cod in integration_test_instructor_interface function which was typed out without being encapsulated as a function in both <link> and <link> . <image> <code> <image>. Same variables may be assigned values through the program which may not be used later. These assignments are said to be useless as the new value never gets used anywhere. These lines can be removed from the program as they do not implement anything and are of no use. <image> And another example: <image> <link> Useless assignment These assignments were removed. To use the current time in the program, we need use Time.zone.now instead of DateTime.now. Example is as given : <image> <image>. Indentation improves code readability and makes it easy for the user/programmer to understand what happens within the program. The grades of the 6 files changed after the duplicates were removed Before modification : <image> After modification: <image>.","Please title your page after the topic, so that it can easily be located by a search.  I would also have liked to see you enumerate more of the changes you made, rather than just give examples of them.  (I wouldn't expect you to describe every change, though.)  But the idea of describing different kinds of changes was good.  The huge screenshots are annoying; did you try to find a way to shrink them?"
E1816,"For an instructor, expertiza allows to create and customize new or existing assignments. A previous team has worked on creating this visualization graphic for Instructors, which can be found <link> . We want to allow the instructor to dynamically generate graphs with the data they request. To that end, we would like to integrate review performance by compiling various feedback data that is collected. 1.3. Another useful feature would be the ability to visualize class performance on a certain rubric criteria. Below you can see a flowchart representing the graphical flow of an instructor visiting the visualization page we are modifying. <image> Once the instructor visits the visualization page, they will already see a bar graph displaying how all the teams scored on each rubric criteria. Below this will be buttons or some other method by which to select the data that you want. The whole process flow involves being able to traverse the visualization page in a quick and efficient manner, since oftentimes the instructor will visit the page often. Here is a mock-up of our intended page: <image> As you can see, we will have menu options by which the instructor can choose which data members to show and likewise the type of graphic visual they would like to produce. We plan on using the flot javascript library to implement the graphic visuals, which will provide an easy and clear visual of the requested data. Another mock-up of how the UI could be designed, is that by visiting the visualization page, the instructor will see a graph followed by an array of buttons. <image> The source for this graph is at <link> The chart above shows stacked bar charts of a single submission. <image> As you can see, we plan on implementing an array of buttons to carry out simple manipulations to data and to display only the data the instructor wants to. We plan on implementing buttons to change the graphic that is displayed, so that if an instructor wishes to see a pie chart or histogram, they can click the button and see the data in a different form. We may also create new view files. As we will use Javascript to achieve an interactive visualization, we will test the functionality of Javascript codes manually. In order to Improve the visualization of the rubric question data, we decided to use the flot javascript library instead of highcharts. In order to accomplish this, we constructed an adapter that took the already generate highchart data by the previous team, and converted it to a representation required by our flot graph. This was inputted into the data series as per the correct format flot requires. You can also see the result below, in the picture of the graph provided. To implement this, in the adapter we formed the data series such that different review rounds would be separated and clustered among their own review questions. This allows an easier viewing of different review rounds in order to determine how the class improved. The data passed to the _team_charts.html.erb view file contains all of the questions for all review rounds associated with the assignment. In addition to implementing the flot graphical representation, we also created a tooltip which allows the instructor to see the percentage of people who scored a certain value on any rubric questions of any round. Here is a picture of what the completed flot graph looks like: <image> The source for this graph is at <link>. <code> Also, javascript code was added in order to produce the stacked bar chart as shown on the webpage. The Class Performance visualization allows the instructor to view a histogram of 0 to 5 scores for a particular assignment. Furthermore, the visualization allows the user to switch between the preliminary round and the final round as well as view a combined view. As with the rubric criteria visualization, hovering over a bar in the class performance visualization brings up a tooltip indicating the score and frequency of teams that earned that score. <image> The source for this graph is at <link>. The JavaScript code also added the radio buttons to switch between the individual rounds and all rounds as well as the tooltip for the class performance visualizaton portion of this assignment. The new review table allows the instructor to sort the result by more options, like the number of reviews completed, the average volume and the average score. The page is given as below. <image>. A test is performed for rubric criteria that vary by round and one is created for an assignment where the rubric does not vary. One consideration to improve upon the work we have done, is to make it so that the visualization graph that shows participant performance on every rubric question in each round can handle assignments which vary the number of rubric questions between rounds. It would also be more useful to have a two-level breakdown of the radio button options, and thus the six-element frequency array data, for rounds then questions. The remaining challenge is to integrate the author feedback to the review report page. Some reviews have 3 rounds. The feedback of each round has multiple questions. Some are scored questions but some are not. Here is our project <link> Here is our created <link> Here is our video <link>.","This is still a good document; however, the monochrome code listings just show the code and don't explain in general terms how it works.  That doesn't meet the goal of explaining how features are implemented.  Also, the buttons shown in the document (Team breakdown, etc.) do not seem to be implemented in the project."
E1843,"Expertiza is an open source project based on Ruby on Rails framework and the code is available on Github. Expertiza allows the instructor to create new assignments as well as edit new or existing assignments. Instructors can also create a list of topics the students can sign up for and specify deadlines for completion of various tasks. Students can form teams in Expertiza to work on various projects and assignments as well as peer review other students' submissions. Expertiza supports submission across various document types, including the URLs Wiki pages. 1.There is no deadline that specifies when a team can drop their topics. Due to this, few problems occur: The team might drop a topic later on which is close to the submission date and this results in topic not being assigned to any other team on time such that they can submit their assignment. Also, if one team was wait listed for the same topic which the other team dropped closer to the submission deadline, then the first wait-listed team will be assigned to the dropped topic which is not desirable as they might be working on their assigned topic for long time. 2.There are different topics on which students can work during different times. This type of assignment is known as Staggered- deadline assignment in which different topics have different submission and review deadlines. For these assignments too, there is a need for ""Drop Topics Deadline"". In the current implementation, the drop topic deadline is same for all the topics in a Staggered Deadline assignment which is not desirable. 1. The instructor can specify a Drop Topic deadline date now. After a drop topic deadline passes, the ""X""(signup option) in the Sign-Up sheet disables so that the student cannot drop the topic and the wait-list for that topic is cleared, which will resolve the issue of the topic being assigned to a wait-listed team very close to the submission deadline. 2. Staggered deadline assignments now have different drop deadlines for different topics in that assignment.The above resolution also works for Staggered Deadlines Assignment. 1. app/controllers/assignments_controller.rb 2. app/controllers/sign_up_sheet_controller.rb 3. app/models/student_task.rb 4. app/views/assignments/edit.html.erb 5. app/views/sign_up_sheet/_add_signup_topics_staggered.html.erb 6. app/views/sign_up_sheet/_due_dates.html.erb. 1. Clearing the waitlist after Drop Deadline passes is implemented in sign_up_sheet_controller.rb where it is checked if the current time is greater than the time mentioned in Drop deadline. If the deadline has been passed, the 'update_is_waitlisted' method of SignedUpTeam model is called to delete all the waitlisted teams for that topic. 2. Changes are made in Assignments View to add an additional column for Drop-Topic Deadline for Staggered Deadlines Assignment. The code snippets for corresponding changes in controllers and models are as below: (i) app/controllers/sign_up_sheet_controller.rb <code> (ii) The 'update_is_waitlisted' method is implemented in app/models/signed_up_team.rb as follows: <code> (iii) app/helpers/sign_up_sheet_helper.rb <code> (iv) app/models/student_task.rb <code> (v) app/views/assignments/edit.html.erb <code> (vi) app/views/sign_up_sheet/_add_signup_topics_staggered.html.erb <code> <code> (vii) app/views/sign_up_sheet/_due_dates.html.erb <code>. It was discussed that project does not require any Unit Test cases to be implemented as the changes are mostly visible in views. 1. Expertiza on GITHUB: <link> 2. GitHub Project Repository Fork: <link> 3. The live Expertiza website : <link> 4. Demo link: <link> 5. Expertiza project documentation wiki: <link>.","Good description of the work to be done, but I think that the code snippets need to be accompanied by an explanation of what they are doing..  In this document they are just pasted in, with no comments."
E1934,"After an instructor gave a grade to an assignment, there is no way to track who gave the grade. A grading audit trail must be created and the following information needs to be stored: 1. When a grade is assigned by an instructor, there needs to be an indication of who did it and when it was done. 2. Comments previously provided by other instructors must also be preserved. This information needs to be stored every time an instructor edits a grade/comment and clicks the save button. Currently, there are two places need to add grading audit trail: 1. Review grade : Log in as instructor -> Manage -> Assignments -> View Review Report 2. Submission grade : Log in as instructor -> Manage -> Assignments -> View submissions. We created a database called grading_history in the system which stores elements of instructor id, assignment id, grade type, student id, grade, comment, and timestamp. We used MVC design to create a model, a controller, and a view for both of Review Grade and Submission Grade . Model: grading_history.rb. Has a list of attributes contains instructor id, assignment id, grade type, student id, grade, comment, and timestamp. Controller: grading_history_controller.rb. Saves a new entry into the database every time a review grade or submission grade is saved View: index_html.erb. Displays current submission or review's grading history. An existing example of this is a submission record in the system. We modified grades controller, so that every time, a grade is submitted or edited, grading_history_controller.rb will call a method to create an entry saves into the database. <image>. <image>. <image>. Functional testing: 1. Test if SubmissionGradeHistory.create is being called when a submission grade is changed. <code> 2. Test if ReviewGradeHistory.create is being called when a submission grade is changed. <code> 3. Test if GradeHistory.where is being called when grading history button is clicked. <code> Feature Testing: 1. Test if the grading history is visible and shown in chronological order <code>. 1. app/controllers/grades_controller.rb <code> 1. app/controllers/review_mapping_controller.rb <code> 1. app/views/assignments/list_submissions.html.erb <code> 1. app/views/reports/_review_report.html.erb <code>. 1. app/controllers/grading_histories_controller.rb <code> 1. app/models/grading_history.rb <code> 1. app/models/review_grading_history.rb <code> 1. app/models/submission_grading_history.rb <code> 1. app/views/grading_history/index_html.erb <code> 1. spec/features/grade_histories_spec.rb <code> 1. spec/features/helpers/grade_histories_helper.rb <code>. <link> <link> <link> <link> <link> <link>.","The design document is supposed to give a rationale for the design, but this design doc is mainly screenshots and a list of files that were changed.  The screenshots could be described (e.g., why did you add a column to View Submissions) and you could have shown, or linked to, code snippets and described what the snippets were doing."
E1961,"1. E1961 Project aims to fix the problems of making the email notification function more reliable. 1. The forked git repository for this project can be found <link> 1. Deployed on VCL: <link>. The following tasks were accomplished in this project: 1. Issue1: Fix the problem that the author(reviewee) cannot receive the email notification about the review from someone else. The Expertiza is supposed to email authors each time a review of their work is submitted. 1. Issue2: Fix the bugs to make Expertiza emails reviewers each time an author that they have reviewed submits new work. 1. Issue3: The instructor could get a Blind carbon copy every time. 1. Issue4: The users can turn off those email notifications by unchecking boxes on their profile page. 1. Add a method in both ""update"" and ""create"" functions to call the email function to make the Experiza send the email to reviewee when reviewers submit the reviews Changed files: app/controllers/response_controller.rb: 1. previous version <code> 1. current version <code> 1. refactor the email method, which is called by send_email_to_reviewee. Changed files: app/models/review_response_map.rb: <code>. 1. Add new function to email all reviewers a new submission is ready to review: 1.1. In the first round, there is no reviewer before they take a request 1.2. Except the first round, reviewers get an email every time when there is a new submission Changed files: app/controllers/submitted_content_controller.rb: <code> <code> Changed files: app/helpers/mailer_helper.rb: <code> 1. Changing the email content, which is the message content send toward the receiver. Changed files: app/views/mailer/new_review_message.html.erb: <code> Changed files: app/views/mailer/partials/update.html.html.erb: <code>. 1. The instructor is able to get copies of emails that are sent to students by the system. Also the instructor could cancel the function by editing the checkbox on the profile page. Changed files: app/controllers/submitted_content_controller.rb: <code> Changed files: app/models/review_response_map.rb: <code> 1. Add a new attribute: bcc_mail_address Changed files: app/helpers/mailer_helper.rb: <code> <code>. 1. Fix the problem that the users cannot choose to uncheck the email options. Changed files: app/views/users/_prefs.html.erb: <image> 1. previous version: <code> 1. correct version: <code> 1. fix issue disable email_on_review is not working on profile Changed files: app/models/review_response_map.rb: 1. previous version: <image> 1. correct version: <image>. We manually tested our functions including the mentioned issues. Please check our video test. 1. <link> 1. instructor6 create a new assignment 2. student10, student11 submit a hyperlink as the first submission 3. nstructor6 modify the due date of first submission(For the test, the student only can do the review after the due date of the first submission) 4. student 11 does the review for student 10 ---->the student 10 and the instructor6(Blind carbon copy) should receive the email to notify that there's a new review 5. student 10 resubmit another hyperlink as the second submission --->the student 11 and the instructor6(Blind carbon copy) should receive the email to notify that he needs to update the review Database: 1. we modified the email address of instructor6, student10 and 11 to do the test in the video <image>. 1. test function: if the user unchecked the box of email_on_review(When someone else reviews my work) option, he should not receive the email. 1.1. We create a new student2 with email_on_review options is false (default is true) Changed files: app/spec/models/review_response_map_spec.rb: <code> <code>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.","The documentation was not submitted, though it could be found by searching the wiki.  The description essentially just consists of before and after versions of the code, with almost no explanation of the changes.  There is a video, but it does not contain audio, so it is very difficult to follow.  It apparently shows email being sent and received."
E1844,"In Expertiza, teams are created for every homework. Somewhere in the bidding code, or the code that assigns topics based on bids, team names are generated. In this case, team names are not appended to the name of the assignment, like they are when teams are created elsewhere in the code. The team names should be of the form ""Team_random_number"". Also currently, the usernames can have spaces in them but then you cannot impersonate that user. The expertiza should prohibit spaces in usernames. Issues as described by the problem statement: Team names created by bidding are incorrect Somewhere in the bidding code, or the code that assigns topics based on bids, team names are generated. In this case, team names are not appended to the name of the assignment, like they are when teams are created elsewhere in the code. Team names generated everywhere must be standardized. Usernames can have spaces in them. And currently, if you create a user with a space in the username, you can't impersonate that user. Expertiza should prohibit spaces in usernames. Implementation should probably just include a format check in the user model, and tests to validate a username. 1) app/controllers/lottery_controller.rb 2) app/controllers/suggestion_controller.rb 3) app/models/team.rb 4) spec/models/team_spec.rb. 1) app/models/user.rb 2) spec/models/user_spec.rb. Teams are generated within Expertiza in various scenarios. Teams are generated for every assignment, course and team names are generated in various formats at several places in the bidding code. Also, automatic generation of teams for assignment follows a different team name format. A single team name format was fixed, i.e. Team_51) and all the automatically generated teams were assigned a team name with the standardized format. Standardizing team names is a good way to avoid discrepancy in team names irrespective of the source of team generation. This approach has been chosen because changing the parameter value (string of the team name) is the simplest way to standardize names of the auto-generated team names. We preserved the existing functionality of the functions and removed the use of unnecessary variables keeping the code DRY. Pseudocode standardizing auto-generated team names throughout expertiza <code>. Expertiza allows spaces in username. But, if a user has username with spaces then that user cannot be impersonated by an instructor. Thus, the task is to prohibit users from having spaces in usernames. By doing so, it increases the user-friendly quotient of Expertiza. Even if the username is created by using spaces, the white spaces are removed from the string by the following pseudocode. Thus, the username can now be impersonated in the same way as any username having no white spaces at all. 1.) Login as instructor, <code> 2.) Login as student, <code> <code>. Following are the identified team creation methods and corresponding code changes: <image>. <image>. The validation check has been added to the model of the user class so that no white spaces are present in the username : <image>. 1)Login as Instructor, create an OSS assignment for bidding with all the necessary details like maximum no of users per team, add topics for the assignment, add participants(students) in the assignment. 2)Login as a Student(say Student7348), whom you have enrolled in the assignment. You should be able to see the assignment now in the Assignment section. 3)Click on the assignment and then click on 'Your team'. 4)Invite a student(say Student7349) whom you have also added as a participant in your assignment, to be your teammate. 5)Login as student7349 and accept student7348's request to join his/her team. 6)Now, the team name would appear on the top section of the webpage. The team name would be of format : Team_RandomNumber ( say Team_21 ). <image> 2. Click on copy assignment icon and edit the information as per requirement. A new assignment would be created. <image> 3. Now login as student7609 and click on 'Test Assignment'(assignment that you have created as an instructor) under Assignment tab. <image> 4. Click on 'your team' and send teammate invitation to another student7508. <image> 5. Now login as Student7508 and accept the teammate request of student7609. You can view the team name 'Team_7' at the top of the page which is the required standardized format. <image>. The existing Rspec test is modified so that the expected value of the team name is modified to the new format. The existing Rspec file user_spec.rb is modified in order to add another test case to validate the use of white spaces in the username. <image>. <link> <link> <link> <link> <link>.",Most reviewers think the writeup is great. It has been structured very well and clearly explains what was done. The only issue I can see is that they have used images to display code instead of code snippets.One reviewer comments that the screenshot could have been of a 'standard' size.
E1933,"When reviews are marked 'public', instructors will have the option of adding them as a 'sample review' to any assignment. When reviews are marked 'private' they will not be shown to other students as a sample. 2. Add a feature for Instructor to select a subset of 'public' reviews and make those reviews visible as sample reviews of any of their assignments in the course. 3. Add a feature for instructors to select a subset of 'sample' reviews and set those reviews as sample reviews for a particular assignment. 4. Create a view where the student can see a list of sample reviews of the assignment and have a detailed view of each. Thus the students will be able to see good reviews that one student has submitted for another student's work. 1) Creating a checkbox : When a student submits a review, they should be able to choose if they want to make their review public or private. Checking this checkbox will make the review public. Unchecking it will make the review private. 2) Allow students to make a review private : Students should be able to change the visibility of their review even after they have submitted it. If a review has been made private after an instructor has selected it as a sample review, it is still not displayed to students as an example review. 3) Allow instructors to select (remove) sample reviews : If a review has been made public by the reviewer, the instructor is able to select that review to be made a sample review. If the review is already a sample review, the instructor is able to remove from the set of example reviews. If the review was private, the instructor is shown a notice that 'This review is private.' and they are not allowed to select it as a sample review. This selection can be done when the instructor is viewing the review. 4) Set some of selected reviews as sample for an assignment : Sample reviews can be identified by the assignment, reviewer (a participant) and the reviewee (a team). When editing an assignment, the instructor is able to select past assignments, select a reviewer and select the reviewee. The way in which the instructor selects the assignment is to select the from a dropdown. When the assignment is selected, the reviewer dropdown will then be populated with the names of the reviewers whose reviews have been made public and have been selected by the instructor. This will identify the selected review. The instructor will be able to set it as sample review for the current assignment. This means that the instructor can even set a review from any of their earlier assignments as a sample. 5) Allow students to see sample reviews : When a student wants to review other team's work, they will be shown a list of sample reviews that the instructor has selected for them. In the list each review is a link to the full review. To allow students to mark their reviews as public. 1. The instructors will select sample reviews from a set of public reviews. 1. Students will be able to view sample reviews. This means that all the selected reviews in an assignment will be shown as sample in the other assignment. 1) We did not want the all selected reviews in an assignment to be shown. Instead we added a facility for instructors to select individual reviews and set them as sample. The assignment_id is the id of the assignment for which the sample is to be shown. The response_map_id is the id of the sample review. 5. Displays a list of reviews submitted by students. 7. Displays the summary of reviews submitted by that student, with a ""Make as sample"" button on the right of every review. 9. From this list select all assignments for which the review has to be shown as a sample. 11. Navigate to view reviews of that particular assignment and click on ""Sample Reviews"". 12. A new page is opened that lists out all the sample reviews of the assignment. 5. Click on the review tab. 6. Select an assignment from the dropdown 7. Select a reviewer from the second dropdown. 9. Click 'Add' button to add the selected review to be shown as a sample for this assignment. 10. Add as many sample reviews as you want in the same way. 4. Click on any assignment for which the review has to be submitted. 5. Assignment task page is displayed. 7. Below the heading ""Reviews for ..."", click on the ""Show sample reviews"" link. 8. This opens a page where the student can view all sample reviews for that assignment. 4. Click on any assignment for which the review has to be submitted. 8. Select a team for review and fill in the review. Students are able to toggle between private and public visibility of their review. <image> Once the review is marked as sample, the instructor will be given an option to Remove as Sample . <image> The instructor is able to select a review to be shown as sample by selecting from assignment, reviewer, reviewee dropdowns. <image> Students are able to see the sample review for an assignment.","For design doc: This is a very good description of the changes to be made, and the rationale for making them.  But it has not been updated to reflect how the code was actually written, and that is one of the most important needs for programmers who follow on later.This is a very good description of the changes to be made, and the rationale for making them.  But it has not been updated to reflect how the code was actually written, and that is one of the most important needs for programmers who follow on later."
E1966,"Expertiza is a open source project currently for CSC517 instructor and students forming groups, submit work, review, and view grades. 1) On student end, Expertiza uses grades/_reviews.html.erb partial file to display reviewers, scores and review details; on instructor end, it uses Response model methods to construct html file for review pages. We need to use the same kinds of partials in instructor-end and student-end. How to get the view of reviewers, scores and review details on student end? Click ""Alternate View"" button, and click ""show reviews"" link. The reviewers and scores pop up on the top and review details are below them. How to get the view of reviewers, scores and review details on instructor end? Click ""Scores"" for a certain assignment and choose a team. Click ""Statistics"" tab and then reviewers and scores table show up. Click ""Reviews"" tab and then click one of students' name link in the table head. And a new page pops up with review details. 2) Give Feedback link at view_my_score at student-end should not appear at folded view. Where to find Give Feedback link? On student end, click ""Alternate View"" button and click ""show reviews"" link. At the bottom of a certain review, a give feedback link shows up. 1) We need to use the same kinds of partials in instructor-end and student-end. So we decide to use grades/_team_statistics.html.erb to display reviewers and scores and to use grades/_tabbed_reviews.html.erb to display review details for both student-end and instructor-end. 2) Give Feedback link at view_my_score should appear at the bottom of expanded view. For student end, split reviews.html.erb into two partial files. One is grades/team_review_statistics.html.erb for reviewers and scores. The other one is grades/tabbed_reviews.html.erb for review details. For instructor end, it used to use response model methods to construct html files for review details, now we use grades/tabbed_reviews.html.erb to display review details. So student end and instructor end both use grades/team_review_statistics and grades/tabbed_reviews to display reviewers, scores and review details. <link>. 1. In student end, render grades/team_review_statistics and grades/tabbed_reviews two partial files instead of grades/reviews partial file. app/views/grades/_participant.html.erb <code> 1. Add statistics view to student end by using the team_review_statistics.html.erb file. app/views/grades/_participant.html.erb <code> app/views/grades/_team_review_statistics.html.erb <code> <image> <image> 1. Add feed back link in student end view. app/views/grades/_tabbed_reviews.html.erb <code> <image> 1. Add javascript to tabbed review so it can be hidden or shown by clicking the show/hide reviews. app/views/grades/_tabbed_reviews.html.erb <code>. 1. Create new method view_instructor for response_controller app/controllers/response_controller.rb <code> 1. change the url jumping to after clicking to a certain reviewer. app/views/grades/_view_heatgrid.html.erb <code> 1. render grades/tabbed_reviews for review details at instructor end app/views/response/view.html.erb <code> 1. show right round according to which round user click at instructor-end app/views/grades/_tabbed_reviews.html.erb <code> 1. Create construct_instructor_htm_helper in respond model in order to not show review number app/views/grades/_tabbed_reviews.html.erb <code> app/models/response.rb <code> 1. Show just one review in instructor-end app/views/grades/_tabbed_reviews.html.erb <code> <image>. 1. The rspec test plan is written such that each requirement(for student-end and instructor-end) will have at least 1 different test. 3. The test file can be manually executed the by running ""rspec ./spec/features/tabbed_reviews_spec.rb"" on rails terminal. 4. Use Unit test to test all the codes mentioned above with respect to views, models and controllers. 1. tabbed_review_spec.rb created and added 3 test cases for alternate view of reviews spec/features/tabbed_review_spec.rb <code>. 1. <link> 2. <link> 3. <link> 4. <link>.","In the ""What to do"" section, it is not clear whether the two partials you name are new partials.
It is also not clear whether more or less code is being duplicated than in the current system.
It is not clear how the two different partials are used.  How do they interact?
I also find the ""Student end"" section confusing. For example, what is in the ""statistics view""?
When you give a code snippet and say that it does something, you should point out the changes made to accomplish them.  Github diff view would be good for this.  In the current document, I'm left with just the code, and I need to try to figure out what it does and how you changed it.
To summarize, too much code is shown with too little explanation.
"
E2069,"1. Move the method create_new_team (on line 94) to a more appropriate class. (Ex: Team.rb or AssignmentTeam.rb ) 2. Move the method approve to SignupTopic.rb , since it is modifying fields belonging to SignupTopic directly. 3. There are two methods named similarly: approve and approve_suggestion . Add appropriate comments. 4. Move the send_email method to the Mailer class in app/mailers/mailer.rb . Issue : Move the method create_new_team to a more appropriate class. This method was moved to assignment_team.rb since it is appropriate. <image> We pass the required variables inside the scope of this function as method parameters. Then we call the new method as a method of the AssignmentTeam class. <image> Issue : Move portion of the method approve to SignupTopic.rb , since it is modifying fields belonging to SignupTopic directly. <image> First, we moved everything in the approve method from suggestion_controller having to do with a sign up topic to its own new method in sign_up_topic.rb now called new_topic_from_suggestion . In doing so, we also delete the entire approve method from suggestion_controller , since refactoring for that method happens concurrently as a result of another issue in this project. Issue :There are two methods named similarly: approve and approve_suggestion . Add appropriate comments. <image> Here, we changed the name of approve_suggestion to approve_suggestion_and_notify , since it really seems like this method is both to handle approving a suggestion as well as calling the notification method from elsewhere in the controller class. We also add in the first part of the original ""approve"" method here, so that we can set the instance variables that suggestion_controller might need ( @user_id, @team_id, and @topic_id ) as well as calling our newly created new_topic_from_suggestion method in SignUpTopic with the proper suggestion passed as a parameter. Issue : Move the send_email method to the Mailer class. This method was moved to the Mailer.rb file which seems to have many built-in functionalities for mail services. <image> Next, the required variables for this method were passed as parameters from suggestion_controller and is called as a method of Mailer class <image> Issue : Merge app/views/suggestion/show.html.erb and app/views/suggestion/student_view.html.erb into one view. Modify student_view method in suggestion controller to provide @current_role_name and render show template. <image> Migrate code from student_view.html.erb to show.html.erb and wrap in an if statement that will display view only if user role is a student. <image> Move the rest of the remaining code from the original show template to the else block. <image> Delete the student_view.html.erb file since all of it's contents are contained within the show.html.erb file. <image>. Since only the code style/process was changed, the expected functionality before and after, will be the same. Student should be able to create a suggestion for an assignment, just like before. <image> 2. Create a new assignment. 1. Click the Assignments link. <image> 1. Click the + icon. <image> 3. Fill in the following fields in the ' General' tab. 1. Provide Assignment name . <image> 1. Page will reload and have an additional checkbox, Has topics? . <image> 4. Make the following selections in the Topics tab. <image> 5. Assign this assignment to a student belonging to this instructor 1. Select Add participant link within the Other stuff tab. This will bring you to a new page. <image> 1. Find student of interest (we recommend using student1876 ). Select Add button. <image> 1. You should receive confirmation of successfully adding the student to the assignment. <image> 6. Impersonate the assigned student. <image> 1. Fill in field with student username and select Impersonate button. <image> 7. Let the student view this assignment (may need to register too) 1. Select the created assignment from the table seen at the bottom of the page. <image> 1. Select Suggest a topic link. <image> 1. Create new suggestion, provide a title, description, and click the Submit button. <image> 1. Select View link for the suggestion created. <image> 1. This will bring the following page (information previously provided by student_view.html.erb). <image> 1. The corresponding page for an instructor would appear as such. <image> Please refer to our short videos to get more context on what was done. This test ensures the working of the mailer method for approved suggestions <image> This test ensures the working of the team creation method <image>.","Very good description of changes, and appropriate code snippets are shown.  Manual testing is shown with annotated screenshots, which are very useful.  In an Rspec test, sending email to an actual person's address is not a good practice."
E1727,"This project was completed as part of a greater open source project called Expertiza. Expertiza is a web application platform, similar to wikipedia, which offers teachers and students a way to organize for group assignments and porjects. By using Expertiza, students have the ability to submit and coordinate peer-review learning objects (articles, code, web sites, etc). The Expertiza project is supported by the National Science Foundation. Expertiza offers several features which are useful to a classroom-style learning environment. Among those several features, this project represents a contribution to the organization of the code used for assignment signup sheets. The work for this project was completed by a group of three students from NC State. However, the project was completed according to guidelines provided by a coordinator who works with Expertiza. Following the guidelines provided, the group worked to clean up a portion of the Expertiza project code through refactorization and reorganization. More specifically, logical code needed to be separated from portions of the project which were not responsible for containing code for the functionality of the application. The motivation for this project was to make the project code easier for programmers to read by compartmentalizing portions of the code to separate locations in the project according to the functionality of the code. The scope of this project was limited to functionalities associated with the signup sheet. This meant that logical code that was embedded in ""view"" (a folder containing html formatting and design code) should be moved to a more appropriate location, the ""helpers"" folder (this folder contains compartmentalized auxiliary functions that ""help"" with other parts of the project). <code> 1. Move javascript code to assets (folder): There was some javascript at the bottom of the file _add_signup_topics.html.erb. This was moved to a new file app/assets/javascripts/signup.js. The functions were modified to pass in the number of teams that needed to be toggled (since it is now in a separate file without access to that information). The javascript from the file _due_dates.html.erb was also moved to the new signup.js file. This functionality can be tested by logging in as an instructor, making sure you are managing assignments, then click the ""Edit"" button of an assignment (the little pencil icon on the right), then choose the ""Topic"" tab. If you click ""Hide all teams"" link, all team names and team member unity ids will be hidden. Click the link again and the content will be shown. If you click individual top names, it should hide/show only one team's info. <code> 1. Move logical code to helper file and assign self-explanatory method names. <code> 1. Move logical code to helper file and assign self-explanatory method names. Testing: 1. Create a test file named sign_up_sheet_helper_spec.rb in spec/helpers 2. Write test cases for all methods in sign_up_sheet_helper.rb using factories. 1. sign_up_sheet_helper.rb 2. sign_up_sheet_helper_spec.rb. <code>. <code>. <code>. <code>. <code>. <code>. Implemented positive and negative test cases for all the methods in sign_up_sheet_helper.rb. We have hosted our forked repo so you can review our changes here: <link> Suggested login for Instructor privileges is 'instructor6' with password 'password'. To login as a student, you can use 'student5000' with password 'password'. This functionality can be tested by logging in as an instructor, make sure you are managing assignments, then click the ""Edit"" button of an assignment (the little pencil icon on the right), then choose the ""Topic"" tab. If you click ""Hide all teams"" link, all team names and team member unity ids will be hidden. Click the link again and the content will be shown. If you click individual top names, it should hide/show only one team's info. 1. get_suggested_topics : Retrieve list of topics suggested by signed in user for an assignment. 2. get_intelligent_topic_row : Render Intelligent Row in bidding based topic selection. 3. get_topic_bg_color : Render background color for row based on signed in user and status of the topic. 4. render_participant_info : Render Participant Info based on topic, assignment and participants. Unit tests were required per the project assignment for helper methods which previously had no associated unit tests. The tests were written using RSpec/FactoryGirl and are listed above. A summary of the test cases is shown below. <table>. 1. Navigate to the expertiza home folder 2. Run `rspec spec/helpers/sign_up_sheet_helper_spec.rb`.",The introduction does not give a good picture of what the project is about.  It should describe a signup sheet and state why it is important to get complicated logic out of the main view file.  It would be very useful to show the changes (e.g. using a Github diff).  Good test plan.  
E1772,"<link> is a peer review based system which provides incremental learning from the class. 1. Replace class variable with a class instance var, and change all other places using these variables. 2. Refactor method db_query 3. Use zero? method instead of == 0 4. Use find_by instead of dynamic method 5. Delete lines which is wrong or useless. <link> <link> <link>. In ruby, class variables are started with '@@'and this class variable are shared in the whole inherit chain, and class variables are shared by all objects of a class. For instance variables, in Ruby, instance variables are started with '@' and instance variables belong to one object, can not be used by sub-classes. In the project, we are asked to replace the class variable with a class instance variables. So, as the figure 1 shown, in variables declaration part, we changed all class variables to instance variables. <image> Next, we need to change all other places using these variables. In action send_post_request <image> <image> <image> <image> <image>. In the Reputation_web_service controller, the action db_query is important, because it implements the query of peer review grade.To refactor the db_query method, we need to firstly focus on the input variables of this method, there are 4 variables need inputs. The db_query method is shown as follow: <code> There is a problem: Optional arguments should appear at the end of the argument list, in this method, another_assignment_id is a optional arguments, but in the original version, the optional arguments -- another_assignment_id just appear right behind the argument-- assignment_id , so we need to refactor it. <image> And the same problems occurs when we assigns value to variable @results . We also need to change it. <image> There is another problem in the db_query method, we can see there is a input variable named hasTopic , but actually that's not follow the ""good Ruby and Rails coding practices"" , so we need to refactor it which shown as follow: <image> Finally, The project asked us 'Move Line 26-50 before this method' , it's important for code refactor, because it's very inelegant if you put the comments inside the method. Simply, we can just move the whole comments before the method, and that will make the codes easily for reading. <image>. instead of ' ==0' or ' !=0' , which shown as follow: <image> <image>. This issue is replacing the find_by_id to find_by(id: id). The only difference of this change is syntax and their function worked in the same way. But if the customer want to change the way to find assignment, find_by(id: id) would be easier to change because programmer only need to change the parameter, while find_by_id need to change the whole method and its parameter. <image> <image>. In Line 111, the variable inner_msg has never been used, so it can be deleted <image> From line 164 to 201 and line 204 to 241, cases for reputation value and do not need to handle the case for assign id. <image> <image>. So puts should not appear in controller <image> <image>. Our test plan is to test if db_query(assignment_id, round_num, has_topic, another_assignment_id = 0)(in line 51), db_query_with_quiz_score(assignment_id, another_assignment_id = 0)(int line 82), json_generator(assignment_id, another_assignment_id = 0, round_num = 2, type = 'peer review grades')(in line 101) work in the right way. These are in controller/reputation_web_service_controller.rb <code> The above codes is to test if get query can parse id and some other variables and return the correct review grade. Our test make sure the review grade are array and array contains data which is not null. <code> The above code is to test if we can query quiz score by given assignment id and another assignment id and return correct quiz score array. Our test make sure that the the result is array and not a null array But when we try to test json_generator(assignment_id, another_assignment_id = 0, round_num = 2, type = 'peer review grades'). There is a wrong report which is no method. the line 106 that is no method is: @results = db_query(assignment.id, round_num, has_topic, another_assignment_id) And the report is that: <image> Because this method can't be called for some reason and this is not the part that we need to refactor, we can't test this part.","Very good job of describing chages that were made.  Reasonable job of describing test plan, though more detail would have been useful.  I didn't understand, "" it's important for code refactor, because it's very inelegant if you put the comments inside the method. If others want to read your codes, it will cost their much more time so that it needs to be changed."""
E1650,"The purpose of given topic is to sort the Instructor views on the basis of Reviewer's Last Name (by default) without refreshing the existing page. Current Model: 1. Currently Instructor can view the Reports in non-decreasing order, sorted on the value of an 'Average Overall Volume' for the Reviewer. However, instructor does not have any option to sort the list manually. 2. Hence, we are adding a functionality to instructor's view of reviewers' list that can sort the list as per his/her choice. 1. Functional Requirement: Instructor should be able to sort the Reports according to the Reviewer's Last Name in either descending or ascending order. 1. Solution approach: We are using a JavaScript library <link> for sorting the elements in the instructor view's table. TableSorter provides support for both kinds of ordering - ascending or descending. Implementation of sorting algorithm for Instructor views using <link> . TableSorter is a <link> plugin for turning a standard <link> table with table-head and table-body tags into a sortable table without reloading the existing page. TableSorter can parse and sort many data types linked with the table column. To integrate the table sorter into any view two things are needed: i) Include a gem in Gemfile <code> ii) Including jQuery-tablesorter in app/assets/javascripts/application.js <code> The above code loads only the core-widgets. TableSorter is applied to the table which needs to be sorted. For example, in the below code table sorter is applied to the ""myTable"" id. 1. Added in _review_report.html.erb <code>. 1. Added in _review_report.html.erb Custom parser script is created to sort the table according to 'Average overall volume'. It accepts an input that contains a string with a numeric value (percentage) and the table should be sorted on the basis of that. It firsts splits and tokenize the data according to space and return required value which is passed to tablesorter function. <code>. Kindly follow the steps below: 1. Go to <link> to access expertiza 2. Login credentials- Username: instructor6 Password: password 3. Go to 'Assignments' tab > From any assignment, select 'view review report' option (it is next to 'star' option) 4. Now, you must be viewing some list with students name (currently, all the users have name as 'some_number,student') 5. In the column heading 'Reviewer', there is sorting arrow, click on it to sort the list. 6. Similar sorting is implemented on 'Metrics' header 7. If you want to try the functionality on the students with alphabetical name, add student from 'Assignments' > 'Add Participants', and then test it We have added styles on column-headers (as arrows) to show the sorted order: ascending, descending or unsorted. 1. Added in _review_report.html.erb <code>. Below is the screenshot for the above given style: <image>. 1. <link>.","Wiki is well written. It's clear and to the point. I would expect there'd be a comparisson of several libraries on the solution approach, their pro and cons e.g., easiness to program, performance etc. "
E1720,"Expertiza is a web portal which can be used to manage assignments related to a course. It provides a platform to view assignments, manage teams, select topics and work improvement through anonymous peer reviews. For the instructor it provides complete control to create assignments, view reviews submitted and provide feedback. 1. Issue #702: Add another institution_id to course table and The Create Course page needs to be fixed to tell the creator to specify the institution (course/_course.html.erb). This task was pretty involved and called for integrating an institution_id into the course table and updating the Course pages to specify the institution. On the controller app/controllers/course_controller we edited the update definition and the create definition to store the institution_id into the course table. <code> On the model app/models/course.rb we created a relationship where course belongs to institution. <code> On the model app/models/institution.rb we also created the relationship where institution has many courses. <code> On the view app/views/course/_course.html.erb we added the collection box to display the linked name from the institution table to the institution_id in the course table. <code> In order to properly display the institution_id associated with the courses on the view app/views/tree_display/list.html.erb it was necessary to understand the Factory Method design pattern. <code> app/assets/javascript/tree_display.jsx was also modified to show different rows between courses and assignments, since only courses were required to show the institution_id. This was added in order to show the institution_id which is displayed on app/views/tree_display/list.html.erb : <code>. <code>. We overcame this issue by creating a new view (app/views/tree_display/confirm.html.erb), and redirecting the deletion link to the view for confirmation. The part of the code that redirected deletions for assignments or courses to the confirmation page is in ' app/assets/javascripts/tree_display.jsx' . (Item in bold was modified) <code> Original code (Delete link without confirmation.) <code> Here we see that the code inside of the new view ' app/views/tree_display/confirm.html.erb' . <code>. It necessitated adding a table to the database called notifications. Therefore, when conducting peer reviews, a migration must be performed to add the new table. Then we used scaffolding to add notifications (controller, model, and views). Next we added a link on the view (app/view/tree_display/index.html.erb) to go to the view (app/view/notification/index.html.erb) in order to manage notifications. A migration to create a notifications table was added. <code> Using scaffolding, a new index was added app/view/notifications/index.html.erb . <code> Added link on page for managers to manage notifications app/view/tree_display/list.html.erb . <code> When any type of user successfully logs in, flash notifications called from the controller app/controllers/auth_controller.rb . <code> Flash notifications are displayed once at login due to a line in the view app/view/layouts/application.html.erb which is used by all other views. <code> The notifications are displayed on whatever page the login screen goes to first depending of the type of user logging into the system. Follow the instructions below to check the tasks: 1. Issue #702: Add another institution_id to course table and The Create Course page needs to be fixed to tell the creator to specify the institution (course/_course.html.erb). It will automatically go to the manage courses page. 2. Click the ""New Public Course"" or ""New Private Course"" button. 4. Create a new course, and the UI will automatically return to the list which displays the courses. You will see the institution listed. 5. Click on the edit button and you will be able to modify the institution for the course. 2. Go to the assignments list. Note: this is not the manage assignments for instructors. 3. Click into a finished assignment. 4. Click into a current assignment. It will automatically go to the manage courses page. 2. Click the Assignments link to switch the view from courses to assignments. 3. Add a new assignment. 4. Click the delete button for an assignment. Note: please add an assignment first. It will automatically go to the manage courses page. 2. Click on the ""Manage Notifications"" link above the ""Courses"" and ""Assignments"" links. 3. You will be directed to a creation page for notifications. The notification will display on the first page the user is shown. Note: instructors on the management page will retain the notification if they switch between Assignments, Courses, and Questionnaires.","It contains info how it's implemented, what was the problem, and how they approached the solution. however, lots of it is copied pasted from the code, instead of trying to explain using UML or other diagrams. They only defined manual UI test, no rspec tests defined. It's a shame, the group should have consulted the notification design with users before it's implemented, but in the end they delivered the expected design.  "
E1793.2,"For team-based assignments, it always takes time to find suitable team members. We already have bidding, which could help you to join in a team with other team members hold similar bidding preferences. However, you may not be satisfied with automated team formation and want to switch to another team. In this project, we will build a new feature to help students find teams to join. Currently, there are 2 ways to find other students to join your team: 1.If your team is not full, you could invite people by inputting his/her UnityID. If s/he accept your invitation,s/he will leave original team and join your team. 2.You could create an advisement by clicking “Your team” link and then clicking “Create” link under “Advertisement for teammates” section. In this way, all classmates could see your advisement. Someone could send a request to join your team. If you accept their request, s/he will leave original team and join in your team. It would be better for students who do not have team yet or whose team is not full yet to be able to see a list of students who don’t already have teams. Fix the second way to find other students to join your team. For student end: Display a list of students who do not have a team with invitation links in student_teams#view page You could invite students to your team by clicking invitation links. If s/he accept your invitation,s/he will leave original team and join in your team. For instructor end: Display a list of students who do not have team in teams#list page Write feature tests to verify your modifications: Create team_invitation_spec.rb file in spec/features folder. I found currently when you sent join team request in the ad,the team received that request would see invite and decline button on their student teams#view page.if they are willing to add the student who send request as member ,they have to send invitation and wait for reply. what should happen is that when the student send join team request,the team members could see accept and decline button ,After they click accept button ,the student would leave his/her original team and join the new team. What I have done is that I add accept method in join team request controller.The method is below: <code> Here @invited_userid is acquired from the student who sent join team request. inviter_userid is from the team members who received the request. team_id is invited student's team id. We build a new feature to help students find teams to join. Students who do not have teams or whose team is not full are able to see a list of students who do not haven a team.The code for this issue is showed below: <code> In the code above, if @student.assignment.max_team_size > 1 we then execute the below code ,this is because our new feature is only available when assignment team size greater than 1.we use if @student.team==nil|| !@student.team.full? to allow students who have no team or whose team is not full to see this list.Next we found all participants ,we use if statement to sample those who has no team , their role are students and they won't see themselves if they do not have teams.We then put these sampled participants on the list .these achieved by the code below <code> We also need to add invitation links next to students without teams,before adding links , we need to know whether students who want to invite the students on the list have team or not .if they do not have their own teams. we will automatically create a team for them ,this mechanism is called team lazy initialization.the code for this part is below <code> Finally we just use form_tag to create invite button which is related to invitation controller and create method in it . we also display a list of students who do not have team in teams#list page for instructor.This part of code is showed below. <code>. <image> <image> 2)Received request from advertisement and the changed team members after clicking accept button. <image> <image> 3)For student end ,the list of students who do not have a team with invitation links <image> 4)For instructor end ,the list of students who do not have a team. Some edge cases: 1) The owner of a team can accept or decline the request sent by other students, if the team is already full, the team will remain the same even the request is accepted. <code> <code> <code> 2) In the student_team#view page, students should see a list of students who don't have teams and can be invited at present, if the invitation is declined, the team remains the same. And the invitee can only join the team when it is not full. <code> <code> <code> <code> 3) Testing advertisement features. <code>.","A test plan was added, evidently, after the last review deadline.  But the main issue I see is that it is not a very readable description of what is to be done and why.  It's necessary to reread the prose an ponder it to determine what the changes are and the reason for them.  The explanation is more important than seeing the code."
E1602,"Expertiza has a quizzing feature which allow student authors to create quiz questions and test the peer reviewers. 1. Following three different types of questions are supported in quizzing feature of Expertiza 1. Multiple Choice Radio 2. Multiple Choice Checkbox 3. True/False 1. The current implementation of Quizzing feature is not consistent with the current questions and questionnaires. Since Quiz questionnaire is one sub type of questionnaire, so it should follow the design of other type of questionnaires. 2. In order to create a quiz, the existing code is written in the views which has a series of if-then structures to implement the functionality of each different question type. 4. Code is repeated for different question types. 2. When questionnaire author creates a quiz, edit is called. To call this on UI, you can login as a student, click 'create quiz' / 'edit quiz' on 'Your Works' page. The edit method is now called from /view/questionnaires/_quiz_question.html.erb 3. When questions are viewed by the author or the instructor, view_question_text method is called. To call this on UI, you can either login as a student, click 'view quiz' on 'Your works' page or login as an instructor, find an assignment with quizzing feature and click the icon 'view quiz questions'. The 'view_question_text' calls view/questionnaires/view.html.erb 1. When the quiz takers tries to take the quiz, complete is called. To call this on UI, you can login as a quiz taker, request a quiz to take on “Take quizzes” page, then click “begin”. This method is now called on view/student_quizzes/take_quiz . 2. When the quiz taker finished taking a quiz and wants to view the quiz result again, view_completed_question is called. To call this on UI, you can login as a quiz taker, find a finished quiz and click “view”. This method is called on view/student_quizzes/finished_quiz . The view_question_text method is called when the author of the quiz or the instructor views the quiz. The method is responsible for generating the HTML to display the question along with each of its choices. The edit method is called when the author creates or edits a quiz. It makes every element of the quiz editable. Logic is written in multiple_choice_checkbox model for multiple choice checkbox question type. Similarly, same process is followed for remaining question types. To begin a quiz, complete is called from the model. We used a single construct which determines question type and answer type by calling view_completed_question method declared in quiz class as shown below. Following code snippet shows view_completed_question for true/false question type. You may want to use the following information to make UI testing easier if you are using the link in the Expertiza submission: Assignment : Quiz Assignment Instructor : super_administrator2 Students : student15, student16, student17, student18, student19, student20 If you are using the link in the Expertiza submission, you do not need a password. 1. Login as a student. 2. Select an assignment that has quizzing enabled (e.g. Quiz Assignment). 3. Select ""Your Work"" 4. If you haven't created a quiz yet, go ahead and create one by clicking the ""Create Quiz"" link. 5. Select ""View quiz"". 6. You should see each question, followed by the choices. 1. Login as a student. 2. Select an assignment that has quizzing enabled (e.g. Quiz Assignment). 3. Select ""Your Work"" 4. If you haven't created a quiz yet, go ahead and create one by clicking the ""Create Quiz"" link. 5. Select ""Edit quiz"". 6. You should see each question, followed by the choices, each in an editable text field. 1. Login as a student. 2. Select an assignment that has quizzing enabled (e.g. Quiz Assignment). 3. Select ""Your Work"" 4. If you haven't created a quiz yet, go ahead and create one by clicking the ""Create Quiz"" link. 5. Select ""Take Quizzes"". 6. Click 'Begin'. 7. You should see each question, followed by the choices. 1. Login as a student. 2. Select an assignment that has quizzing enabled (e.g. Quiz Assignment). 3. Select ""Your Work"" 4. If you haven't created/taken a quiz yet, go ahead and create one by clicking the ""Create Quiz"" link and take the quiz. 5. Find a finished quiz and click on 'View'. 6. You should see each question, followed by the choices.","Some of the explanations are rather dense (which is to say that they could explain it more clearly by going into more detail).
Some of the code sequences are too long (more than a page) without any commentary.  Could explain the code more fully."
E1657,"Few of the notable features include: 1. Instructor can control most of the stuff that is related to each course. 2. Student can control who he/she wants to team up with etc. 4. Instructor can make use of the various submission phases available. Our project is to introduce a Student view to the instructors.The goal of this project is to provide instructor with a functionality using which an instructor can switch to student view and see how the student view looks like. The instructor will also be able to go to future date and see how student view looks like in future date. 1. Introduce a ""Student View Button"" on Instructors UI to switch to student view. 2. Introduce a Revert to instructor View"" on Instructor's Student UI 3. Time travel in Student View. On the right top, left to the logout button , anyone having access to view as instructor gets a textbox and a button saying ""Student View"". in-order to view as a student you have to type in the students ID and press Student View button. You can exactly see what the student's page looks like. <image> If you need to revert back to instructor view you just have to leave the text box empty and press the Revert button. This takes you to the instructors view again. Else if you need another students view, just type in the students ID and press Revert . <image> We also have implemented a time travel feature where you can go to a particular date and see what a student see on that day. You can find this feature as soon as you go to a student ID. You have to select a day you need to travel to, type in the student ID and submit. you got he student view as on the date given. <image>. 1. Introduce a ""Switch to Student View Button"" on Instructors UI A 'Student View' button was added in the top right portion of menu-bar for instructor. This button allows instructor to see the student view. This button is linked to impersonate action of <link> . The button was simply added in menu-bar view. When the button is clicked, it calls impersonate method in impersonate controller which loads new view as student for provided student id. Required changes in 1 files : <link> <code> If student ID is not provided, the system will randomly select an student ID from all the students in the database, and impersonate the selected student view. This is useful when the instructor doesn't remember the specific student ID. Required changes in 1 file : <link> <code> 1. Introduce a Revert to instructor View"" on Instructor's Student UI Once instructor impersonate to a student view, a Revert button appears which when clicked revert back to instructor view from impersonated student view. Once the student view is loaded by instructor, session[:superuser] is set and based on this flag a revert button will be displayed. 1. Time travel in Student View. Required changes in 4 files : <link> <code> First, we introduced a date box where you can select a date from the UI. Thus you can access this date through out the sessions. 1. Login in as Instructor. 2. Create assignment. I have created one with name Test_Changes with submission deadline Nov 09 and review Deadline Nov 14. Add all the student in course for this assignment. <image> 1. Switch to student view. Once switched to student view you can see the assignment with submission deadline Nov 09. <image> 1. Go to future date and view the assignment list. I went to Nov 10 in future and we can see that the current phase for our assignment is review. <image> <image>. 1. Requirement: Add a “student view” button for instructors. As we were required to add a button , it makes more sense to add a similar button used across the application. 1. Requirement: Introduce a revert button to go back to instructor: After an instructor enters a student ID of a student and enters student view, there should be a way to go back to instructors . Thus we have introduced a revert button. Also if the instructor wants to go to a different student’s view he should be able to do so as well. Making these two tasks possible with single textbox and button was better instead of an extra button to go back to instructors view. Now to go back to instructors view, instructor has to leave the textbox blank and click “revert”, if the instructor wants to go to a different student’s view he just need to enter the new student’s id and click on “revert”. 1. Requirement: View on specific date: We decided to include a date box which on clicked on the date field a data picker pops up. We have added this picker as it makes sense to just click on which date instead of typing the whole date. <link>. Screencast <link> to our demonstration.","The writeup explains the functionality of the project, but doesn't explain enough of the underlying design decisions.  For example, how is changing the current time implemented?  Do functions that ordinarily look at the system time look somewhere else to find the time that the user has switched to?"
E1926,"This page provides a description of the Expertiza based Semester project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link> 1.1.9. <link> 1.1.10. <link> 1.1.11. <link> 1.1.12. <link>. <link> is an open source project based on <link> framework. The Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. The Expertiza provides an option for students to self-review their submissions. In which, each member of the team gets to evaluate their project on the same criteria as the peer review. However, these scores contribute in no way to calculate the overall score for their assignment. Some of the objectives we try to achieve for this project are as follows – 1. Provide a formula that takes both the peer review score and self-review score into account for calculating the composite score. 2. The composite score should get higher as the self-review score gets closer to the peer review score. 3. Make sure that the peer review scores are not visible before the self-review submission. 4. Display the composite score on the “View Scores” page. 5. Display the self-review scores in the ""View Scores"" and heat map of peer-reviews, showing that they are a different type of review. The need for the self-review section is to know how well the students can judge their work and understand how to evaluate their flaws and rectify them. Also, if they can score themselves close to their peers, then it means that they have good self-assessment skills and they are being honest about what they think of their work. <image>. Previously, Expertiza allowed students to submit an assignment and provides a link for self-review. Once the self-reviewing was done, the submitted score gets stored in the database but was not used in calculating the overall score of the assignment for the student. Because of this, students can score themselves higher than what they should get. This helps students in no way. So, to make productive use of this score and to help students learn self-evaluating, we have made some changes in the review score calculation which is explained in the section below. We derived a new formula that takes into account the self-review score and calculates a composite score, which will be the student's final score. After we made the changes needed, now the students are able to see their peer review score, Final score and the Final derived peer review score displayed on the “View scores” page. <image> These scores will also be reflected in the ""stats"" as shown below <image> In the same way, we will make some changes to the instructor’s page as well because the instructor should be able to see the self-reviewing score from each member of the team, displayed along with the peer review score for that assignment. <image> <image> 1. The above image shows how the instructor will allow users to give a self-review on the work they have done. The instructor has to go to the review strategy tab while assignment creation to enable the self-review option. 1. User then can see the self-review option on the assignment to do tasks to give a self-review. 1. In the view scores page, a new column showing the self-review scores will be displayed. <image> <image> 1. Actors: <code> 1. Actions <code>. We have to implement a way to combine self-review and peer-review scores to derive a composite score. We have to come up with a formula to derive the composite score as below with the help of research paper: <link> . <code>. 1. Now that the set up is done, to test this, you create 6 students and 2 assignments. 2. One assignment has self-review enabled and the other assignment has self-review disabled. 3. Then student should submit the assignments and the self-review should be done for the required assignment. 4. Try giving same peer-review scores for both assignments and you should see the final score differs accordingly with the self-review score for one assignment but stays the same for the other. 5. You should be able to see the final scores for any student matching to the proposed formula. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. <link> 9. <link> 10. <link>.","For design doc: It is not clear how the score is derived.  You refer to the SPARK Plus paper that gives the formula for SAPA, but SAPA is just a measure of how much more positive you are about yourself than your teammates are.  There is no obvious way to combine this with a peer-review score.  You list files that are to be modified, but don't say anything about why they will be changed or what changes will be made to them."
E1973,"For simplification, we were allowed to assume that the teams that worked on an assignment together would review together. Each participant should be able to make individual changes to the review (while logged in from their account), but these changes should apply to the team’s collective review. This creates an issue where teammates could accidentally overwrite each other’s work if they edit the review at once. Therefore, it has been decided that the review should be locked while one edits it so that only one participant can edit it at once. Locking the review presents its own challenges. 1. Modification to Response Map Classes 1.1. A field should be added to ResponseMap which indicates whether responses are done by teams or by individuals. 2. Modification to Assignment Class 1.1. A field indicating if the assignment is to be done with team or individuals. 3. Locking Solution 1.1. Research needs to be done as to whether a rails mechanism already exists to facilitate a lock on page edits 1.2. A solution can be implemented from scratch by storing a flag in the database on the review’s table entry. 1.3. The ability to have a lock on a review requires the implementation of some kind of auto-unlock feature. If a user never unlocks a review, his/her teammates still need to be able to modify the review. 1.1.1. We should be able to use the “updated at” field to check if the lock has been held for too long and needs to be released. The locking solution we added works as a general locking solution. It adds a new table in the database called locks which create a mapping between a user and a resource. This database change does not force a lock on the resource. Just because there exists a lock between some resource and some user, does not mean that other users cannot edit that resource. <image>. Whichever model needs to be able to be locked must include this line: <code> See app/models/response.rb To check to see if a resource is locked, use <code> If the resource is nil, it has been locked. If it's not nil, the given user owns the lock over the current resource. See app/controllers/response_controller.rb#edit To unlock a resource after it is done being used, use <code> See app/controllers/lock_controller.rb#release_lock To check to see if a lock exists between a user and a resource, use <code> See app/controllers/response_controller.rb#update Because locks can time out, if user1 makes changes and stalls on a page, user2 could get the lock, make edits, and release it. If that's the case, we may not want to keep user1's changes. The way to check for that scenario is by seeing if the user still has a lock on this object. Timeout_period minutes after a user gets a lock, any user who calls get_lock on a resource will acquire a lock. The rationale being that permanently preventing access to a resource is a heavy price for forgetting to unlock a resource. <code> 1. Added lock.rb, lock_controller.rb, and lockable.rb 2. app/views/responses/response.html.erb 1.1. Javascript was added to get locks to be released when the page is exited: <code>. <image>. <image>. <image>. <image>. <image>. 1. Tests were added in response_controller_spec.rb to test that the controller methods properly handle locks and redirect when responses are locked: <code> 1. Tests were created for lock.rb to ensure that all database functionality is handled properly, locks time out, and locks correctly handle requests from multiple users: <code> 1. Since many of expertiza's tests use mocks, several lines in other tests needed to be added since previously un-called methods were now being called: 1.1. Example from review_response_map_spec.rb <code>. Our UI tests aim to capture the following core pieces of functionality: Students on the same team can view/edit the same response: Prerequisites: we use our fixture to ensure that an assignment has been created, and that students 9 and 10 are on a team together. 3. Request a new submission to review. 4. In the review, leave the comment ""Excellent work done!"" Notice that the review already says ""Excellent work done!"". 7. Go back to the review and click Edit. Notice that the review now says ""Decent work here"". Students cannot edit the response at the same time: Prerequisites: Same as the above test. However, remain on the edit page. 3. Navigate to the assignment and click ""Edit"". Verify that you are redirected and unable to edit the review response since student10 is already editing it. We have functionality that checks that 2 users on the same team cannot edit a response at the same time.","Very thorough and readable description of what was done.  The roughest edge is that the Mediawiki code boxes allow text to flow off the right edge, making it very hard to read.  Better to use the Github diff screenshots."
E1804,"To enhance topic management for instructors and students. 1. Issue 971 : Change create topic UI to AJAX 1. Issue 926 : Sort topics by topic number in assignment#edit 1. Issue 718 : Allow instructors to give feedback when accepting or rejecting suggestions,add comments on those suggestions. This issue calls for the replacement of the html table with a javascript table using jsGrid. Furthermore, replacing the html table with a dynamic table should not disrupt the html table for topic signup available to the student. 1. Log in to < <link> > using the username ""instructor6"" and password ""password"". <image> 3. Click the <image> for the ""Final Project (and Design Document)"" assignment. 4. Select the ""Topics"" tab for the assignment. <image> 5. Note the available actions(add,edit,delete) and bookmarks available for each unfinished topic. <image>. To add a topic to an assignment, 1. Select the <image> on the Topics tab of the unfinished assignment that was navigated to in the first section. 2. In the subsequent Add Dialog, enter values for the Topic id, Topic name and Number of slots and click Save. <image> 3. The newly added topic will appear in the table sorted by Topic #. <image>. To Delete a topic from the Topics tab, 1. Select the <image> for the topic you wish to delete. 2. Confirm that you would like to delete the selected topic. <image> <image> 3. Note that the topic is no longer in the table. <image>. To edit a topic to an assignment, 1. Select the <image> on the desired topic of the unfinished assignment that was navigated to in the first section. 2. In the subsequent Edit Dialog, make the desired edits and click Save. <image> 3. The newly editted topic will appear with the new value(s). <image>. 1. Log in to < <link> > using the username ""instructor6"" and password ""password"". <image> 3. Click the <image> for the ""OSS project/Writing assignment 2"" assignment. 4. Select the ""Topics"" tab for the assignment. <image> 5. Note the unavailable actions(add,edit,delete) and bookmarks absent for each unfinished topics. <image>. 1. Log in as ""student5918"" with the password ""password"" at < <link> >. 2. Select ""Final Project (and Design Document)"" from the assignments list. <image> 3. Select ""Signup sheet"" from the assignment menu. <image> 4. Select the check icon next to the desired topic. <image>. While the table is able to be sorted by the header row, whenever you make a new topic the initial list of topics is not resorted right away. This leads to say E1502, a new topic just made, to be at the bottom of the list when it would normally precede say E1700, if it were in the same topic list. We implemented the functionality for approving and rejecting any topic suggestions made by the students. Furthermore we have included comments which the instructor can give for a particular topic suggestion. The functionality of editing comments also has been correctly implemented. 2. Adding comments to the suggestions(can be multiple). 1. Editing comments in the suggestions view. 1. app/view/suggestion/show.html.erb 1.1. To see all the comments and to edit individual comments: <code> 1.1. To add a comment: <code> 2. app/views/suggestion/edit_comment.html.erb 1.1. Link to form for editing <code> 3. app/views/suggestion/_form_comment.html.erb 1.1. Form for editing: <code> 4. app/controllers/suggestion_controller.rb 1.1. For approving and rejecting suggestions: <code> 1.1. For adding a comment: <code> 1.1. For editing comments: <code> 1.1. For updating comments: <code> Images showing the jist for testing. ' The following steps should be followed to test the functionality:' ' 1. Login as a student2065/2064/2066 with password:password' ' 2. Select any assignment,for example Click on view(RHS of the assignment)""wiki Textbook"" and then click on ""suggest a topic"".' <image> <image> ' 3. Add your suggestion.' <image> ' 4. Login as instructor6 and password:password.' <image> ' 6. Click on the ""view suggestion"" icon on the right side of the screen.' ' 7. Add a comment on that suggestion and submit.' <image> ' 8. Can edit the comment by clicking on the ""Edit Comment"" button.' <image> ' 9. Login as student and you can see the comment when you go to the assignment and associated topic.' More tests need to be added to test whether an instructor can edit a comment or not.","The authors have taken care to describe all of the functionality they implemented.  

The section headings refer to issues by number, but in order to find what the issue relates to, you have to look at the ""Problem Statement"" section.  The headings should have included the same information as the Problem Statement.  To make it easier to read, I edited in this information.

The screenshots are huge, requiring the window to be maximized.  It would have been much better to scale them down.  That would have made it possible to see more of the steps at a single time, and helped avoid ""tunnel vision.""

The code snippets don't contain enough description of how the code works.  There are just bullet points about what is done, not how it is done.  It would actually be more elucidating to view the code in Github."
E1921,"The PopupController is responsible for preparing data that will be displayed in popup views. To render the data, which mostly concerns assignments, the controller makes many accesses to database tables such as Response, ResponseMap, Question, Questionnaire, Answer, and Participant. Before our project, there were only two tests implemented that together only achieved a statement coverage of 7%. Our changes have brought the statement coverage to 96%. popup_controller.rb popup_controller_spec.rb. What we need to do is to set up the environment and complete the 'popup_controller_spec.rb' to finish the integration tests for popup controller. This rspec test file can be run by calling the following code: <code>. 1.Write RSpec integration tests to make the statement coverage above 90%. 2.Cover as many edge cases as you can. 3.Achieve as high branch coverage as you can. Teaching staff will use the mutant-rspec gem to measure test thoroughness and fault-finding capability of tests. In total, we wrote tests to cover all 10 methods in the popup controller. We mocked many different objects involved in the controller. The code of the controller can be found <link> . The methods are: 1. action_allowed? 2. author_feedback_popup 3. team_users_popup 4. participants_popup 5. tone_analysis_chart_popup 6. view_review_scores_popup 7. build_tone_analysis_report 8. build_tone_analysis_heatmap 9. reviewer_details_popup 10. self_review_popup. Based on the controller, we mocked models to test different conditions. Models have complex and interdependent relationships, but the Expertiza project already includes a factory to build many of the models. This factory can be seen <link> . Additional database information can be accessed <link> . As you can see from our setup below, most of the objects we created relied on the factory with the exception of the final_versions array, which is not used in enough tests to warrant its own factory statement. Other objects are just built with additional/overwritten attributes, such as the student object. <code> We made one change to the factory.rb file to build an instance of Team. We assume that the Team class may be used in other tests globally, so this should be added to the factory file and thus can be built more easily in future tests. Our addition to the factory.rb file is: <code>. Since it's integration test, we need to test basic logic and return value in both methods in the controller and related methods in the controller. However, some of the methods have been tested in other rspec, all we need to do is to test the methods that haven't been tested. For 'action_allowed?', 'author_feedback_popup', 'team_users_popup', 'participants_popup', 'reviewer_details_popup', 'self_review_popup' methods, we test it separately. With 'tone_analysis_chart_popup', 'view_review_scores_popup', 'build_tone_analysis_report', 'build_tone_analysis_heatmap', we test them together since they both need to get each assignment'answer. Also 'tone_analysis_chart_popup' and 'view_review_scores_popup' all get 'build_tone_analysis_report' and 'build_tone_analysis_heatmap' in their method. The following section shows the Rspec outline of the tests we created. The full test code can be found <link> PopupController Check action permission with four different roles. <code> Get feedback when feedback exists. <code> Get response stats when the response map exists, otherwise only find the team and users. <code> Calculate scores depending on the existence of the response. If a review questionnaire is present, calculate scores with a max. <code> All tone analysis tests are run together. Both popup_* methods set instance variables before calling a build_* method. build_* methods are responsible for actually creating tone analysis tests and returning JSON information/graphics. <code> Test showing details about the reviewer. <code> Get reviews done by self. <code>. The total coverage of the test is 96.41%, meeting our coverage requirement. A video of all tests running can be seen <link> . The main repository can be found <link> The forked git repository for this project can be found <link>. The testing framework in the assignment_team_spec.rb used integration tests to test the methods in the controller. The mock instances are created at the beginning and the method logic is tested in each 'describe'. In addition, we used the Byebug gem to debug our test code. The key to building successful tests is to understand the logic in the method and understand the input and output value for the method.","Good description of what needed to be done, and how it was accomplished.  A little more rationale on why you wrote the tests you did (and no other ones) would've been helpful."
E1803,"Currently, when an instructor logs into Expertiza, he/she sees the following menu items across the top: Home Manage content Survey Deployments Assignments Course Evaluation Profile Contact Us And, a student can see the following menu items across the top: Home Assignments Pending Surveys Profile Contact Us On the instructor’s “Manage content” menu, one of the options is “Assignments”. “Manage content > Assignments” allows the instructor to edit and create assignments, whereas the “Assignments” menu (that both students and instructors) see allows the instructor to participate in assignments. Therefore, it makes sense to create a student view for instructors, which will enable them to see menu items that are only related to students. Create a student view for instructors. When in student view , an instructor must not be able to view ""Manage content"" and ""Survey Deployments"" menu items, and must be able to switch back to the instructor view (the default view that an instructor first sees when he/she logs in). When in instructor view , an instructor must not be able to view the ""Assignment"" and ""Course Evaluation"" menu items. (i.e Displaying the menu items, the logout button etc.) In order to switch between instructor view and student view , the following code was added. When the user is in instructor view , there is a link named ""Switch to Student View"" to switch to student view and when the user is in student view , 'here is a link named ""Revert to Instructor View"" to switch back to the instructor view . <code>. This file is responsible for rendering all menu items and their children (if any). A condition was needed to check if the current menu item that is to be rendered is in the list of hidden menu items. The hidden_menu_items session variable holds the IDs of menu items that must not be rendered. This applies only when the type of user currently logged in is an instructor. Hence, the following condition was added. <code>. A new instructor_controller.rb file has been added. This controller currently contains the actions to switch to student view and revert back to instructor view. <code>. This is a helper for deciding what menu items must be hidden. The update_hidden_menu_items_for_student_view method is used to hide the Survey Deployments and Manage Instructor Content menu items. It does this by including the menu item IDs of these two menus in the hidden_menu_items session variable. (The hidden_menu_item variable will be used by _suckerfish.html.erb to decide whether or not to render a given menu item). Similarly, the update_hidden_menu_items_for_instructor_view method is used to hide the Assignments and Course Evaluation menu items. The set_hidden_menu_items method is used to set check if the given user is an instructor. This method is used to ensure that only those items that must be visible to an instructor view are visible to an instructor when he logs in for the first time. The method has been designed in this way because, in the future, other menu items may need to be hidden based on the user type. <code>. The after_login method in this controller sets up the session object after the user logs in, so it is a good candidate to include the initial set up of the hidden_menu_items session variable. The following lines were added to the after_login method. This call is intended to set the 'hidden_menu_items' variable in the session object when an instructor logs in for the first time. This is done so that the instructor is by default in Instructor View when he logs in. (i.e Assignments and Course Evaluation are hidden). <code> The following lines were added to the clear_session method. <code>. The routes are directed to the instructor controller's set_student_view and revert_to_instructor_view actions. <code>. The user needs to log-in as an instructor to view this functionality. 1. Log into Expertiza as an instructor. 2. Click on Switch to Student View below username to switch to student view. <image> 3. Click on Revert to Instructor View' below username to come back to instructor view. <image>. 1. Check whether Assignments and Course Evaluation are hidden when in instructor view. This test case is to check if the menu items Assignments and Course Evaluation are hidden when an instructor is in instructor view. The following lines can be added to a spec/features file: <code> 2. Check whether Manage content and Survey Deployments are hidden in student view. This test case is to check if the menu items Manage content and Survey Deployments are hidden when the instructor switches to student view. The following lines are to be added: <code>.","Generally does what it is supposed to. Good comments explaining the code changes.  The first two screenshots are in the wrong order.  Wiki refers to a test plan, but no automated tests have been written."
E1856,"Students currently are able to “bid” for the projects that they want to do as an assignment. In this project, we update the “first-come-first-serve” policy for assigning projects to reviewers, to the “bidding” policy. The bidding policy for project topics that students want to work on is already implemented. Students can currently bid on project topics for their team assignment. There’s also reviewing work for each assignment. Students that choose to review a project first will get that project. A similar bidding policy for assigning projects to reviewers can help students who want to review a project the most to be most likely to receive that project. The completion of this project will allow students to also bid on what projects they are interested in reviewing. We need to alter the “first-come-first-serve” to the “bidding” policy. In this policy, students will be matched to review a submission up to the maximum reviewers. <image> 1. When an assignment is released, an instance of Assignment is created and corresponding topic instances of SignUpTopics are also imported, indicating that different topics are available for students to choose from within this assignment. 2. Students are assigned as instances of AssignmentParticipant to this assignment and form up their teams(Model Team). After topics bidding, some of the candidate teams become an official signed-up team of a particular topic. 4. After assignment submission, participants choose their preferred topics and response mappings between assignment(reviewed object), assignment team(reviewee) and assignment participant(reviewer) are created. For now, expertiza employs FIFO strategy on review assignment. When it is done, a new mapping is created, that is why review assignment is in FIFO style. If reviewers are allowed to bid on what to review, the procedure of topics bidding implemented by LotteryController is a good reference. Here is the basic workflow of topics bidding: First of all, teams have different preference towards the topics. The peerlogic service runs top_trading_cycles algorithm to have a fair bidding over the topics and teams. A similar bid can take place on peer review assignment. The following diagram illustrates the similarity of the two bidding model. <image> As for topics bidding, a few available slots of a particular topic are open for teams contending. 2. The size of bidding data is different, since the number of teams are usually 1/2, 1/3 or 1/4 of the participants. 3. The policy of bidding may be slightly different. Participants are not allowed to review a response submitted by themselves. However, the topic bidding doesn't have this constraint. Almost all of the functionality for our project has already been implemented in the review portions of the Expertiza system. Because of this, we will approach this project by first using delegation pattern to add biding capability to the review mapping controller for choosing topics. Then we will duplicate the view for choosing project topics and modify it so that it interacts with the review mapping controller. To maintain the original functionality of Expertiza as well as to add review bidding, we decide to add a new model to handle the data of the bidding. ReviewBid contains the information of bidding assignment and its biddable topics as well as the participants' preference. ReviewBid is served as the input of the bidding algorithm. We decided to let participant to bid on assignment teams rather than topics for simplicity. Construct new new Controller ReviewBidController. Here we try to refer to the pull request #778 to generate the view code for the review bidding. 1. StudentReviewController: provides a topic-team bidding list to participants; and receives bidding requests from participants so that they can modify their preference. 2. View of Assignment: add a new option of review strategy so that the instructor is able to allow participants to bid on what to review; add a new icon on tree list of assignments to allow instructor to start bidding. For each submission that has received bidding, we keep a record of the interested reviewers, with their preference level. When the bidding is finished, we use the bidding algorithm to assign each reviewer with a submission, according to their preference level, which are stored in each record. So in this example, for assignment A, D and F are equally interested in the submission. Similarly, we have designed the topic bidding algorithm, for reviewers to bid for the topics that they are interested in reviewing. This serves as an alternative for the submission bidding, as one topic sometimes have several different submissions from different teams. Allow Instructor to set review strategy to be bidding: <image> After setting the review strategy to be bidding, participants are assigned with a default bidding list, ordered by topic's name. <image> Instructors can start bidding by clicking the following icon. <image> After the bidding is done, participants can login and see what they are assigned with. <image>. 3. When a participant is ask for a comprehensive bidding list include topics, teams, a bidding items list is provided.","This document describes the strategy in a good deal of detail.  Most of it is clear, but there are some exceptions, e.g., ""Slots can be left unoccupied if no team is willing to response. However, every response needs to have at least some reviewers.""  The code changes are not described, though models, views, and conroller are listed.  The Models section precedes Workflows, but really, both sections talk about workflows.  Revised titles would be better.  Testing is not described, as noted by practically all reviewers."
E1642,"It is essentially an educational tool that allows an instructor to create and modify assignments, add topics to assignments, grade students,create evaluation rubrics, etc. Students use Expertiza for submission of their assignments, forming teams, reviewing other students, choosing topics etc. Expertiza also has a bidding feature where students can bid for different topics for an assignment and then it assigns topics to students depending on their priorities and also automatically forms teams. 1. P1: Code Climate shows import method is complex, because of lots of checks. This method can be fixed by adding private methods for raising import error. However, you need to check if this functionality is called anywhere. 2. P2: Get_assessments_round_for method can be renamed to get_responses_for_team_round. Team_id private variable is not needed. 3. P3: metareview_response_maps rename, refactoring can be done. No need to do second iteration. 4. P4: Assignment Branch Condition size for final_versions_from_reviewer is too high. 5. P5: Assignment Branch Condition size for get_assessments_round_for is too high, try to get rid of the nested if. 6. P6: Use find_by instead of where.first, e.g. line 60, 65, etc. 7. P7: Wrap the over-long lines: 58, 62 and 181. 8. P8: Write missing unit tests for existing methods. 1. review_response_map.rb 2. assignment.rb 3. on_the_fly_calc.rb 4. vm_question_response.rb 5. factories.rb 6. review_response_map_spec.rb (created). We could find a call to the import method from 4 relevant places in the importFile method in the ImportFileController. Of them 2 are for different models and the other 2 are having different number of parameters. Therefore we concluded that the import method in the review_response_map.rb is not called from anywhere and so we dropped the method. 1. Get_assessments_round_for Method is refactored to get_responses_for_team_round as required. We do not need a separate private variable for Team_id as we can directly use Team.id for the same. <image> Get_assessments_round_for refactoring examples. There is no need for the inner iteration as for every review for a particular round, there is only one metareview. The second iteration was redundant hence is removed. <image> Second Iteration Removed. Assignment Branch Condition size for final_versions_from_reviewer is too high: This function returns a map containing the final versions of a reviewer. The function has duplicate code for scenario with varying rubric and non varying rubric. We moved this code into a new function with method name prepare_review_response. As we removed the duplicate code, this will reduce the Assignment Branch Condition size. <image> Assignments section refactoring examples(code in the red is the ""before"" version and green is ""after"" editing version). <link> method can be used instead of where.first. Although here it wasn't used since the lines of code that used where.first were redundant and were removed to solve other problems. Over long lines can be hard to read in a small screen. Hence proper use of refactoring the lines can save the overhead of reading and understanding long lines of code. In this problem we have wrapped the overlong lines. In an IDE such as RubyMine we can use custom methods such as ""Use Soft Wraps in editor"" to ease the process. There were no tests present for review_response_map. New unit tests were added to test the functionalities and the test coverage result shows that the coverage is now 71.43 % New Added Code <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code>. New Test Cases were created and the test coverage results are as shown. <image> Test coverage increased to 71.43% from 0. This functionality is used for viewing assignment scores for different teams and a detailed analysis for the same. In order to test from UI follow the steps: 1. Login as instructor6 2. Click on Manage... tab and then on the Assignments section 3. Go on Wikipedia contribution assignment and then click on the View scores button. (This will call the above method) 4. Then for any one team, click on Alternate View (This is another call to the method via a different route.). This functionality is used to check the final review summary of a assignment In order to test from UI follow the steps: 1. Login as instructor6 2. Click on Manage -> tab ->Assignments section 3. Click on view review report for any assignment 4. Click on reviewer summary for any reviewer.","This is an excellent writeup, clearly explaining the reason for changes, and highlighting them in the side-by-side source-code display.  It is also helpful to include Code Climate metrics, something I haven't seen any other team do yet."
E1813.2,"<link> is a software testing method by which individual units of source code are tested to catch errors early in the development process. Model testing is bounded to the functionality of only the model under test and doesn't test how its collaborating models get affected based on this query. Unit Testing provides several benefits which can be summarized in the below points. 1. Finds problems early: Unit testing finds problems early in the development cycle. The procedure is to write test cases for all functions and methods so that whenever a change causes a fault, it can be quickly identified. 3. Simplifies Integration: Unit testing may reduce uncertainty in the units themselves and can be used in a bottom-up testing style approach. By testing the parts of a program first and then testing the sum of its parts, integration testing becomes much easier. Each unit test can be seen as a design element specifying classes, methods, and observable behavior. It is to test all class and instance methods used in this file. The task in hand was to write test cases for testing the menu_items model file. 5. Writing testing conditions for different functions and cross checking with the expected outputs. cd/expetiza/app/models <image> The menu_item_spec.rb test file is present in this directory expertiza/spec/models/ The menu_item_spec.rb is the main file where test cases have been written. <image>. 4. Sequence id :- It gives sequence numbering for determining the way the attributes are ordered within a parent. Different instance methods and class methods exist in this models . Brief description of each of them are : - 1. find_or_create_by_name(params) :- Class Method This method finds or creates a new entry with the given name obtained in params 2. delete :- Instance Method This methods deletes the entry and all the child entries ( entries having the same parent id ) lined to it 3. above :- Instance Method It returns the entry that is above a present sequence number for a given parent id 4. below :- Instance Method It returns the entry that is below a present sequence number for a given parent id 5. repack(repack_id) :- Class Method It modifies the sequence numbers, making them in order, removing the skip entries present in it. repack_id tells the parent id under which these changes are to be made 6. next_seq(parent id) :- Class Method It returns the next possible sequence id corresponding to a given parent id entries. This function would be helpful if we wish to add a new entry and find out which sequence id is to be given to it. 7. items_for_permission :- Class Method It returns the set of items that are possible to be displayed for a given permission id and also based on controller action id and page id being present for it. Mock/dummy objects are needed to be created for any unit testing criteria.These objects are loaded freshly and deleted after every testing condition. Several methods exist for creating such a objects, whose parameters need to be designed to satisfy the conditions under test. For testing menu_items, we created required entries into the database using ""MenuItem.new()"" method, giving different values for each of the test inputs to cover the required testing conditions. <code> The above is an example entry used for creating objects. 6 such test objects were created with entries giving combinations of parent_id and sequence numbers. Before each test, all the objects are created, which is done using ""before(:each)"" key word. Also several objects of 'ControllerAction' and 'ContentPage' had to be created for testing one of the methods which acted based on those values. A total of 16 testing conditions were required to be performed for testing all the functions in menu items model file. The conditions that needed to be tested are as below: 1. .find_or_create_by_name : <code> 2. #delete : <code> 3. #above : Test cases were written to check if the below conditions are satisfied: <code> <code> 4. #below : Test cases were written to check if the below conditions are satisfied: <code> 5. .repack: Test cases were written to check if the below conditions are satisfied: <code> 6. .next_seq: Test cases were written to check if the below conditions are satisfied: <code> 7. .items_for_permissions: Test cases were written to check if the below conditions are satisfied: <code>. Edge case testing is a kind of testing where we check if the intended functionality works in non-trivial cases. After writing the test cases we used SimpleCov to measure the C0 coverage of our rails application. After running rake spec to run the test cases, SimpleCov creates a directory called coverage in our rails application folder. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.","Too much of the document introduces TDD and unit testing, which the readers can be expected to know..  Also, it shouldn't be necessary to discuss setting up Expertiza on your machine.  Preliminaries occupy about 40% of the documentation.  The time could have been better spent on other tasks.

The presentation is better after this.  However, it would've been good to describe what the table and methods did in general before embarking on a list of them.  Essentially the reader needs to read the list and ponder it to come up with a coherent picture; the author could have helped by saying that at the start.  For example, you might say, ""Each command that can be selected from one of the menus is represented by a record in the menu_item model.""

I think the description of the test cases is very good.  It would even have been better if the tests were summarized above each listing."
E2084,"E2084 is concerned primarily with the different reports (review report, author feedback report, and teammate review report) that can be viewed for a specific assignment. Issue 2: For Author feedback reports, when no feedback has been submitted by any student, the names of the participants appear in a strange horizontal format. Fix this so that the formatting is correct, regardless of how many participants have done author feedback. Issue 4: For “Author feedback report” table, change the header name “Review response rejoined” to “Review responded to” and “Last rejoined at” to “Last responded at”. Then, sort “Rejoinder” and “Review responded to” as string (alphabetically), sort “# author feedbacks done” by the first number then the second number (same as “Review done” in the “View review report” table) and sort “Last responded at” as date. Issue 5: For “Teammate review report” table, sort the first 3 columns as string and sort the last column as date. Issue 6: Refactor previous implementation. Our goal is to add a header to every “Review Report” view page that will show the name of the assignment that is being viewed. Our goal is to format the Author Feedback Report to resolve a formatting issue when no feedback has been submitted by any student. We must resolve this so that the formatting is correct regardless of how many participants have done author feedback. Our goal is to change the header name “Review response rejoined” to “Review responded to” and “Last rejoined at” to “Last responded at” within the author feedback report table view. Our goal is to refactor the sorting mechanism for sorting the author feedback report table. This will consist of four different ways to sort: Sort “Rejoinder” as string (alphabetically) Sort “Review responded to” as string (alphabetically) Sort “# Author Feedbacks Done” by the first number and then the second number Same as “Review done” in the “View review report” table Sort “Last responded to” as date. 1. app/views/reports/_feedback_report.html.erb (issue 2, 4) This file contains the code which generates the author Feedback reports table. This is a form that is rendered by the response_report.html.haml file when the Feedback report is requested from the dropdown. 1. app/views/reports/_teammate_review_report.html.erb (issue 5) This file contains the source for displaying the teammate review report. <image>. All changes for this issue were make in the file /views/reports/_feedback_report.html.erb The changes required for Author Feedback table were - 1. Changing the header name “Review response rejoined” to “Review responded to” and “Last rejoined at” to “Last responded at”. <image>. Hence, no changes were made for this issue. Previous: <image> Current: <image> 2. Formatting issue in the author feedback report table: 1. There was a problem where assignments that had two different rubrics across rounds appeared with some graphical bugs. 4. A graphical error happened causing poor layouts to appear, which was fixed by altering some model logic (<= to <) Previous: <image> <image> Current: <image> <image> <image> 3. Formatting issue in review report: 1. The review report table was previously created with a different style and format than the other tables; however, it seems that this problem only occurred when opening within a Chrome browser. 2. We edited _review_report.html.erb to ensure the review report table matched the formatting of the other tables. Thus, in author feedback report and teammate review report, we removed the background color code, and included the Zebra Jquery widget which dynamically stripes the rows even when sorting. Previous Implementation: <image> Fixed Implementation: <image>. 1. From the dropdown, select Author feedback and click View Verify the following changes: 1. Header name “Review response rejoined” -> “Review responded to” 2. Change “Last rejoined at” to “Last responded at”. 3. Verify sorting works as expected: 1.1. Sort “Rejoinder” and “Review responded to” as string (alphabetically) 1.2. Sort “# author feedbacks done” by the first number then the second number (same as “Review done” in the “View review report” table) 1.3. Sort “Last responded at” as date. Original Implementation: <image> Fixed Implementation: <image>.","The prose is good.  I think the organization of the ""What needs to be done"" section is confusing.  The issues are listed, and then your goals for each are described.  It is not easy to see which problem is related to which solution.  It would be much easier if each problem and solution was juxtaposed.  The organization of subsections is inconsistent. Section 3.1 would have been clearer if there had been a subsection related to each file.  In general, varying styles and sizes of section headings make it hard to grasp the structure of the document."
E1735,"Both students and instructors using Expertiza have the ability to view the reviews and the scores associated with the reviews for each assignment. The instructor will be able to see all review and score information for all teams on the assignment whereas a student will only be able to see the review and score information pertaining to them. The reviews and associated scores are available on the scores report. 4. Click on the 'Your scores' link to see the standard view or click on the 'Alternate View' link to see the heatgrid view. To see the heatgrid view, click the 'Alternate View' link on the team headings or click the 'view heatgrid' beneath the 'Final Score' when the team is expanded. A student user can see all the reviews of his/her team’s project. The instructor can see all the reviews of everyone’s project. We would like to have a single way of displaying reviews that would be visible to students (reviews that they did, and reviews that their team received), and instructors (reviews that each time received, sorted by team; and reviews that each student did, sorted by student). They both display graphs, reviews on team submissions, author feedback, and score metrics. The primary different between them is that the instructor view (shown above) displays information for all teams in a collapsible accordion widget format while the student view (shown below) display the information only for a single team. For example, the student cannot access the heatgrid view from within the scores report page. This view is only accessible from the assignment page for students. For instructors there are two ways to access the heatgrid view from a single page. Both students and instructors have access to the author feedback format shown on the left in the student view. This format is identical to the format of the review scores and is displayed on the scores report for both instructor and student. The format on the right is shown on the heatgrid view yet it is only available to instructors. The scores report view has a bar of graphs and charts at the top of the page for both students and instructors. The instructor view has titles beneath each item but the student view does not. <image>. We will create a standard hierarchy which works for both students (who only need to see a single team's scores) and instructors (who need to see all teams' scores). The heat grid will no longer be coupled with the author feedback and there will be a standard author feedback view which encompasses all information needs. New Scores Report With Multiple Teams and Collapsed Reviews <image> New Scores Report With Multiple Teams and Expanded Reviews <image>. The goal of this project was to standardize the student and instructor scores report views into a single view and have it display the information appropriately. Currently, only the instructors scores report view (grades/view) has the tabbed interface. The student scores report (grades/view_my_scores) contains much the same information as the instructors scores report (grades/view). Students will see information pertaining to their team and to themselves (as a participant) whereas instructors see similar information pertaining to all teams and all participants. We suspect that the student report is simply a subset of the instructor's view which lists only a single team and only a single participant on that team. On the Author Feedback, Metareviews, and Heat Grid tabs, the information should be specific only for the student (i.e. the student should be the only participant listed). The Teammate Reviews tab will display nothing as student's should not be able to see their feedback and scores. There are heat grids for submission reviews, author feedback, metareviews, and teammate reviews. All of these heat grids are displayed on view together (grades/view_team) for each participant. Also, if there are no teammate reviews, metareviews, or author feedbacks available for the participant then those heat grids are not displayed. Currently, in the instructors view, the heat grids are linked for each participant on the team on the Heat Grid tab. Our intention was to render the submission reviews heat grid within this tab as its own partial and then render the participant specific heat grids in collapsible table rows for each participant on the team. We suggest that a better option would be to get rid of the heat grid view (grades/view_team) and the Heat Grid tab and instead render the heat grids in the remaining tabs with their related information. For example, the submission reviews heat grid can be rendered at the top of the Reviews tab and the Author Feedback heat grids can be rendered for each participant within the collapsible table row for that participant. One of the problems with the instructor's scores report view is that it takes a long time to pull back all of the data for every team and participant for an assignment. VmQuestionResponse is a custom object created by the team which created the heat grid view. Also, the information used to build the heat grids such as rounds, questions, scores, and participants is already present within the scores report view.",Very good overview of the changes you were going to make.  Diagrams and screenshots are useful.  Prose is easily understandable.  Would be good to update the mockups with real screenshots now that the project is done.  I concur with the reviewer's comments about the class diagram having room for improvement.
E1645,"Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.1.8. <link> 1.5. <link> 1.6. <link> 1.7. <link> 1.8. <link>. <link> is a peer review based system which provides incremental learning from the class. This project has been developed together by faculty and students using <link> framework. Expertiza allows the instructor to create, edit and delete assignments, create new assignment topics, assign them to a particular class or selected students, have students work on teams and then review each other's assignments at the end. For the students, they can signup for topics, form teams, and submit their projects and assignments. Students then review the work done by other students and give suggestions to improve. For this project, our team refactored the TreeDisplayController class in the <link> OSS project. This class provides access to questionnaires, review rubrics, author feedback, courses, assignments, and course evaluations. The main objective of the project was to refactor the controller to follow good Ruby practices and improve the grade given by <link> by fixing issues detected without breaking any of the existing test cases or functionality of Expertiza. As part of the refactoring task, we had to resolve the issues detected by Code Climate for enhancing code readability and maintainability. Some of the issues detected were: 1. Similar code found in other locations. 2. Cyclomatic and Perceived complexity for get_children_node_ng is too high. 8. Line is too long. In order to make the code DRY, similar code was moved to a new method, and that method was called from the remaining part of the code wherever the same set of lines of code were required. <code> Since only the parameter in find_by_name method was different , we have passed this as an argument in goto_controller method which then executes the same set of steps wherever required with different parameters. Changed to ⇒ <code>. Code Climate has a predefined maximum cyclomatic complexity and raises Cyclomatic complexity too high issue whenever a method exceeds this predefined maximum complexity.This cop tries to produce a complexity score that's a measure of the complexity the reader experiences when looking at a method and raises a Perceived complexity too high issue whenever a method exceeds a preset maximum. The new function looks like this: <code>. Following were removed from the two places: <code> <code>. Before: <code> After: <code>. The following for loops were replaced by each, as follows: Before: <code> After: <code>. eval() executes a string of characters as code. Before: <code> After: <code>. Hence `===` has been replaced by `==` in the following manner: <code> has been changed to ⇒ <code>. Very long lines needs to be made short so that it is more readable, which was done in the following manner: <code> Changed to ⇒ <code> <code> Changed to ==> <code>. git clone <link> 2.) cd expertiza 3.) 3. When you click on either of the parent nodes - Assignments,Questionnaires and Courses , all the Assignments , Questionnaires and Courses concerned to the Instructor are displayed. 4. To test the changes made in get_children_node_ng and get_children_node_2_ng methods, click on the sub categories under each of the parent tree displays (Courses and Questionnaires) and all of them will further expand to show the details (Click on the name of the Course/Questionnaire to expand them), i.e when you click on a particular course , all the assignments that belong to the corresponding course are displayed. 5. To test the changes made in filter method,enter a keyword in the search bar and you can see that only the courses or assignments containing that particular word are being displayed. For example, if you enter 517 in the courses search bar , only the courses with number 517 are displayed. Direct access to sub categories in tree display <image> Checking the direct access tabs from navigation bar <image> Checking the sub categories in each parent Tree <image> Filter courses in tree display <image>. Since a lot of duplicated code was removed, the overall test coverage of Expertiza has also been incresed. We have fixed all the issues detected by Code Climate Chrome Extension and refactored the code to make sure it followed good ruby practices and in the end were able to improve the Code Climate score from F to A while not breaking any of the Rspec tests related. From: <image> To: <image>. <link> <link> <link> <link>.","Really good job of describing the changes made.  A few formatting and grammatical errors; otherwise, great."
E2083,"Revision planning has been implemented twice before, once in <link> and once in <link> . 3. Revision planning responses and responses to the other items are not distinguished in heatgrid view. To implement revision planning, <link> added is_revision_planning_enabled (Boolean) to Assignment and team_id to Question . We will use this new questionnaire to separate the revision plan responses and responses to other items in heat-grid view by creating a different table for each. column to indicate whether the assignment accepts a revision plan along with review rubric. This will map to a questionnaire of type revision plan that will be created by the revewee. Revision plan? <image> <link> Wireframe of Enabling Assignment's Revision Planning. <image> <link> Create New Assignment page in the UI, with added Revision Planning checkbox. 1. Added a Boolean field is_revision_planning_enabled to Assignment that saves whether revision planning is enabled. As shown in the wireframe, by clicking Revision Planning students would be redirected to the ‘Revision planning page’. <image> <link> Wireframe of Assignment Overview Page. <image> <link> Submit or Review Work page demonstrating added Revision Planning link. 1. Show link to revision planning page when revision planning is enabled for an assignment, round 1 has passed and current stage is submission. After creating the Revision Plan Questionnaire, it must be edited. Questions can be added by specifying the amount of questions and their type. <image> <link> Wireframe of Editing an Assignment's Revision Plan. <image> <link> Edit Revision Plan page demonstrating added view. /app/models/revision_plan_team_map.rb <code> /db/migrate/20201106020642_create_revision_plan_team_maps.rb <code> 1. Create a Revision Plan Questionnaire Model and Controller <link> Added a model for revision plan questionnaire. <code> This method returns the team associated to a revision plan questionnaire. <code> 1. Add a view to edit Revision Plan <link> <code> 1. Refactor code to display questions into a partial. It has functionality to display questions and some functions that are not needed for revision plan questionnaire. <link> 1. Add code to allow users to delete questions from revision plan questionnaire. app/controllers/questions_controller.rb Update authorization code to allow a user to remove questions from his teams revision plan. <code> 1. Add code to allow users to access show/edit advice functionality for revision plan questions. app/controllers/advice_controller.rb Update authorization code to allow a user to update advice his teams revision plan. Once the Revision Plan Questionnaire and its resubmission round have been finished, the Revision Plan Questionnaire is appended to the Assignment Questionnaire for that round. <image> <link> Wireframe of Completing a Review for an Assignment. <image> <link> Review page demonstrating added Revision Plan questions. 1. Add Revision Plan questions to Response app/controllers/response_controller.rb This methods gets questions sorted by sequence from review and revision questionnaire, and merges them in a single list. <code> This method gets questions from a response instead of questionnaire. <code> This method gets all the questions for a response. <code> 1. Separating questions by their questionnaire type app/models/response.rb construct_review_response method has been updated to create separate tables for review questions, revision questions and additional comment. <code> app/models/revision_plan_questionnaire.rb Overriding the method defined in questionnaire.rb to display heading for revision plan questionnaire. The results of the questions created by the team are shown under Improvement Plan. <image> <link> Wireframe of Summary Report for an Assignment. <image> <link> Summary Report page demonstrating added Revision Plan heatgrid. 1. Show revision plan questions in heat grid. All functionality of this view model has remained in place, and additional responses are passed to it to create the additional heat grids for revision plan responses. When assignment.vary_by_round , an additional heatgrid is added for each round of Revision Planning. When !assignment.vary_by_round , only one heatgrid is added for the Revision Plan used in the most recent round of review. <code> app/views/grades/view_team.html.erb Print round number headings for Revision Plan heat grids. <code> 1. Separated Review and Revision Plan questions in response app/models/response.rb Created separate arrays for ReviewQuestionnaire questions and RevsionPlanQuestionnaire questions. Added headings for Review Responses and Revision Plan Responses. <image> <link> Control Flow of the Revision Planning Function. enables revision planning. <code>. Manual testing aims to verify the following: 1. Create an assignment with revision planning enabled. 3. Is revision plan editing disabled when assignment is in review stage. 5. Are participants shown summary of score for revision plan after review deadline has expired.","This is quite a long document, which covers the changes in detail.  However, I thought the parts of the document could have been better connected to each other.  For example, the modified and added files are just listed.  This is not very useful.  It would be better to divide them into categories and describe why each category is needed. When you describe the user interface, it would be very helpful to describe how the five modifications help achieve project goals, instead of expecting users to figure it out themselves. Migrate files are just shown, rather than explaining the need for a particular field in the db.  Automated tests are well described. For manual testing, it is helpful to include a few screenshots."
E1732,"Currently, Expertiza doesn’t log anything, beyond the events in the console log. But often there is a need to know when a student logged in, reserved a topic, dropped off a team, reviewed etc. But it is also important to describe which data to log and why. Users activity may not be used for testing or debugging purposes, but can help an evaluator or admin to make sure the authenticity of student submissions and check the timelines. It sure can be used in future to read those logs and report back to users about their action timeline if required. 2. Extend the existing UI or create one separately if needed along with the required fields as described in the project description. This same project was assigned to another team last semester and a lot of code was written to log the given accounts. A lot of additions were added to many controllers wherever the events are to be tracked. The code was not merged anyways. We came up with an idea that doesn't modify or add any code to controllers. Logging model shouldn't be a burden to the UI at all. Public Activity Gem The gem we used is <code> According to the documentation: Public_activity provides easy activity tracking for your ActiveRecord, Mongoid 3 and MongoMapper models in Rails 3. Simply put: it records what has been changed or created and gives you the ability to present those recorded activities to users - in a similar way to how GitHub does it. 1. It tracks our events because every event type we need to address has some change or access models. 2. No modifying or adding code in controllers. (Except some session logins and logouts need to be added). We need to read the activities based on the search options added and put onto the user interface to make anyone view based on the filter they provide. Filters include user name, from time and to time. The look of the UI part would be a simple view that contains 1. User : {Textbox} 2. Date From: {Date Filler} 3. Date to: {Date Filler} The results after the querying would be populated in grid that makes it easy to observe. We plan to create a new table in the database for storing these activities. A new migration needs to be created to add the new table to the database. A new model will be created to add each log to the activity. The model will contain fields pertaining to a model such as a user id, type of event, event description, timestamp etc. Table: Event logs <table> Add Public Activity to Model How to add to a model? <code> This small piece of code ensures all the activities are noted when there is an entry made or changed or deleted We added to the following models: 1. assignment.rb 2. assignment_due_date.rb 3. assignment_participant.rb 4. assignment_questionnaire.rb 5. course.rb 6. course_participant.rb 7. invitation.rb 8. join_team_request.rb 9. participant.rb 10. response.rb 11. response_map.rb 12. review_grade.rb 13. sign_up_sheet.rb 14. teams_user.rb 15. user.rb Controllers that were modified, since some activities don't have any effect on a model to enable public activity record those events. 1. activities 2. application 3. auth 4. course 5. impersonate. Public Activity records the events with a trackable id, the table on which the action took place but not any details or description. We add to the public activities views the required code to get the details with the trackable id, type, model taken as parameters. All the activity views specific to each event are added under public activity folder specific to each model. We added the specific filters such as search by user name or any specific date to search for the events. By default, all the activities are shown up on the page accessed with the link ""activities/index"" <image> <image>. 1. Model Testing : Since we are adding a new database table, we need to test Rails model with Rspec that checks if the validations are working fine such as it ""is valid with valid attributes"", it ""is not valid without a user"", it ""is not valid without an event"", it ""is not valid without a timestamp"" 2. Controller Testing : Design includes the addition of a controller that takes care of storing the logs and then loading them up to fill the views if queried which requires a lot of testing. The tests include 1.1. For each event, check if the respective method in the respective controller is called 1.2. For each event, an entry is being correctly stored in the database 1.3. A feature test that checks the UI part of the flow that includes Capybara mocking the admin fills the query page and the testing whether the results are viewed correctly. 1. <link> 2. <link> 3. <link> 4. <link>.","I would like more info on what is logged, and what controllers were modified to do it.  It appears that creating courses, editing courses, creating assignments, and editing assigments are covered.  It would be good to make this explicit by giving a list.  Also, I'd want to know if there's a reason that other activities, like creating users or teams, were not logged.  Are these straightforward extensions for future work?"
E1767,"Also new features are often added. In particular, the file must be a text file and have the data separated by commas. (Issue 183) 2. There should be an option of importing teams (for a particular project/assignment) from an CSV file. (Issue 153) 3. While importing teams, if one (existing) team has the same name as a team being imported, there should be an option of renaming the existing team (Issue 329) 4. The User Interface for importing a course participant and an assignment participant should be similar 5. The Interface for exporting the list of course participants and assignment participants should be similar (Issue 1079) 6. If the file being imported does not have the required fields, the system prints ""The import process expects the following columns:"". However the required column names are not given (Issue 719) 7. Currently the system does not have the feature of exporting review mappings (Issue 1081). <code>. This deals with the addition of a new feature, hence new code needs to be added. Currently, we cannot import teams from a file. When importing assignment participants and course participants, the User Interface indicates that there are multiple fields expected. However, in fact, user can only import file with 1 column which is user names. Fixing the User Interface and also the code of importation accordingly. <code>. Exporting Course Participants and Assignment Participants neither share the same User Interface nor the same code. Assignment Participants used the common User Interface designed for export functionality. Due to this, the export feature of Assignment Participants return blank file. We decided to use a common user interface everywhere. New code is added as below so to ensure that the feature is not lost. Course Participants and Assignment Participants have same User Interface for Export feature as shown in the below image. Course Participants and Assignment Participants are derived from base class named Participants, the export feature can be generalized for both of them by moving it to Participants, which removed redundancy from the code base. Export methods added to participants.rb <image> <image>. We have the feature to import review mappings, but we simply do not have the feature to export the review mappings. 1. Login as instructor 2. In the interface which comes up, on the top menu click Manage and then select Courses. 3. Scroll down to the course you want to add a new team 4. In the right hand side of the screen, corresponding to the course, select the button ""Create Teams"" 5. In the screen which comes up note the name of any one team. Note the names of the users of this team. (The team must have users) 6. Create a text file with one line like this <code> Note that team name must be similar to an existing team name. Also user1, user2 and user3 should not be the same as above. 1. On the lower left of the screen, click the option ""Import team"" 2. Keep Delimiter as comma, and select option ""Rename existing team"", and import using the file you made 3. Now note a new team is added. The new team (with the users as in the import file) will have the desired name, but the team (formerly with the name) will have a new name. <image> <image> <image>. 1. In the case a new team is proposed without valid user names (or without any user names): The team should form, but there should be an appropriate warning message (No such user exists). 1. Login as instructor 2. In the interface which comes up, on the top menu click Manage and then select Assignments 3. Scroll to the bottom of the screen, and select the option Import assignment participants. 4. In a text file create one line like: <code> 1. Import the file 2. Even without password, the user is imported. <image> Fragment if a user with incomplete details is tried to be imported <image> Fragement after the issue was solved. 1. Login as instructor 2. In the interface which comes up, on the top menu click Manage and then select Assignments 3. Scroll to the assignment you want to check, then click Add Reviewer 4. Scroll to the bottom of the screen, and click the ""Export Reviewer mappings"". <image> <image>. 1. Login as instructor 2. In the interface which comes up, on the top menu click Manage and then select Assignments 3. Scroll down to the assignment of interest and click ""Add participant"" 4. Scroll down to the end and click Export Assignment Participants 5. Note the export interface 6. In the interface which comes up, on the top menu click Manage and then select Courses 7. Scroll down to the course of interest and click ""Add participant"" 8. Scroll down to the end and click Export Course Participants 9. Note the export interface. <image>. <link> <link> <link> <link> <link> <link> <link> <link> <link> <link>.","When you say, ""The following tasks were already implemented,"" does that mean that the bugs had been fixed?  Please clarify.  Instead of fixing the import functionality, it seems like you just wrote tests for it.  Screenshots should be scaled back so they fit on a screen."
E1917,"Expertiza is an open source project based on Ruby on Rails framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. Codeclimate is a command line interface for the Code Climate analysis platform [2]. It can detect code smells which violate ruby/rails best practices. The task is to fix certain code climate issues detected by Code Climate analysis platform in controllers with the name beginning with P through Z. These issues includes unsafe use of methods, inappropriate syntax, non-optimal code structure which violates the DRY principle and so on. There are 37 different types of issues fixed in this project. 1. Unprotected mass assignment 2. Use a guard clause instead of wrapping the code inside a conditional expression 3. Do not use Time.now without zone. Use one of Time.zone.now, Time.current, Time.now.in_time_zone, Time.now.utc, Time.now.getlocal, Time.now.iso8601, Time.now.jisx0301, Time.now.rfc3339, Time.now.to_i, Time.now.to_f instead 4. Move redirect_to ""/"" out of the conditional. 5. Block has too many lines 6. Useless assignment to variable - initheader. 7. Replace class var @@assignment_id with a class instance var 8. Avoid comparing a variable with multiple items in a conditional, use Array#include? Instead 9. Identical blocks of code found in 2 locations. Consider refactoring. 12. Line is too long 13. Extra empty line detected at method body beginning. 14. Unnecessary spacing detected. 15. Parameters should be whitelisted for mass assignment 16. Avoid using update_attribute because it skips validations. 17. end at 44, 4 is not aligned with def at 39, 2. 18. Unsafe reflection method const_get called with parameter value 19. TODO found 20. Convert if nested inside else to elsif 21. Similar blocks of code found in 3 locations. Consider refactoring 22. User controlled method execution 23. Extra blank line detected 24. Use empty lines between method definitions. 27. Omit parentheses for ternary conditions 28. Do not place comments on the same line as the end keyword. 29. Useless assignment to variable - controllers. 30. end at 135, 2 is not aligned with class at 1, 0 31. Put one space between the method name and the first argument. 33. Use the new Ruby 1.9 hash syntax 34. show, edit, update, destroy are not explicitly defined on the controller. 36. Avoid comma after the last item of an array 37. Move redirect_to view_student_teams_path student_id: student.id out of the conditional. There are many minor issues such as unnecessary spacing, extra blank line detected, extra parentheses used and so on. The focus would be on some of the important issues listed above that we fixed. Mass assignment is a feature of Rails which allows an application to create a record from the values of a hash. Protection for mass assignment is on by default. Query parameters must be explicitly whitelisted via permit in order to be used in mass assignment.This issue appears in different controller files. An example of how we fixed it in questions_controller.rb is shown below: <image>. <image>. Robocop checks for the use of Time methods without zone. <image>. Robocop checks for identical lines at the beginning or end of each branch of a conditional statement. <image>. Robocop checks against comparing a variable with multiple items, where `Array#include?` could be used instead to avoid code repetition. <image>. Robocop checks for uses of if with a negated condition. <image>. <image>. The method update_attribute will skip validation. Should use update_attributes instead. <image>. <image>. Code climate will complain when a line is too long. <image>. Using the same piece of code violates the DRY principle. We have refactored the code to avoid the repetitive usage. <image>. <image>. Show, edit, update and destroy have been explicitly defined to avoid confusion among filters between different controllers. <image>. This ruby syntax has been deprecated as of the current ruby version(2.3.7) used in expertiza. <image>. Space has been added between method name and the first argument to make the code easily readable. <image>. Adding comments at the last the line of the code is considered a bad coding practice according to rubocop standards. <image>. The Expertiza project provides 77 rspec tests under expertiza/spec and 8 of them are related to our controllers files. <image> <image>. 1. <link> 2. <link> 3. The Class GitHub Repository: <link> 4. The Class Code Climate: <link> 5. Robocop <link>.","On the micro level, you have described your changes well, But rather than look at them one by one, I'd like to see a summary of what were the issues that cropped up frequently, so we can advise future students to avoid them.  Also, when you had the long list of changes, it would've been helpful to group them into similar types so that there would've been some structure to the list."
E1942,"<link> is an assignment portal developed by faculties and students at NCSU. It provides a platform for the faculties to create assignments for the students. Faculties can assign assignments with staged deadlines. Expertiza supports creation of teams for the students, tracking the team members and reviewing the work done by the other team members. Students can also review their peer team's assignment submission. Expertiza has been developed on Ruby on Rails and is available on github. Following is an OSS project which deals with refactoring of stage deadlines in the assignment.rb file. An assignment can have incremental deadlines for different topics in a single assignment. This project involves refactoring the functions in the assignment.rb file related to stage deadlines. There existed five functions to check the kind of stage an assignment is in. However, the names of these functions were ambiguous and functionalities implemented in some of them overlapped with each other. By the end of this project we have refactored these deadline functions. 1. <link> 2. <link>. The assignment.rb file has the following functions implemented : 1. current_stage_name(topic_id = nil) 2. find_current_stage(topic_id = nil) 3. get_current_stage(topic_id = nil) 4. link_for_current_stage(topic_id = nil) 5. stage_deadline(topic_id = nil). The following is the list of refractors done in the code. It discusses the issues we found in the code with respect to Ruby conventions and the solutions that we provided for the same. In the existing code, DueDate.get_next_due_date(self.id, topic_id) has been called at numerous places. New private method next_due_date(topic_id) has been added. This function returns the next_due_date by calling the get_next_due_date method on DueDate. File: app/models/assignment.rb. <code> Following places have been refactored. <image> <image>. The condition, if @assignment.current_stage_name(@topic_id) != 'Finished', have been used at various places to check finish status of assignment by comparing with “Finished”. Otherwise it becomes difficult to refactor the code later. Assignment is said to be finished if the next due is nil. A new private method finished? has been added. It calls the above next_due_date method and returns true if the next_due_date is nil. File: app/models/assignment.rb. <code> The check with “Finished” has been replaces with a call to finished? . The code has been refactored at following places. <image> <image>. When it is staggered deadline and the topic_id is nil, “Unknown” is returned. To make the code more readable and understandable, and to DRY out the code we have added a new private method topic_missing? to check if the topic is missing in case of staggered deadline. File:app/models/assignment.rb. <code> The code has been refactored at following places: <image> <image> Topic_missing.PNG. The method find_current_stage has been used locally in assignment.rb and once in students controller. However internally, this method calls the next_due_date method for the assignment which has already been separated out. The method find_current_stage has been removed. The places where it was called has been replaced by a call to next_due_date method. File: app/models/assignment.rb , app/controllers/student_controller.rb. <code> The code has been refactored in assignments.rb and the students controller at following places: <image> <image>. The method link_for_current_stage was called once in list.html.erb. This method checks if the current assignment has any URL specified with it and would return it if present. However, the database has no such value. As a result, the if condition where the function was called always evaluated to false. The function link_for_current_stage has been removed. The call to this function has also been removed and the code has been refactored accordingly. File: app/models/assignment.rb , app/views/list.html.erb The code in list.html.erb has been refactored as follows: <image> <image>. The current stage of expertiza did not have any tests for get_current_stage. We have added the test for the same as follows: File: spec/models/assignment_spec.rb. <code>. Tests for new finished? function have been added. File: spec/models/assignment_spec.rb. <code> topic_missing method is a private method and hence no tests have been added for the same.","Very clear description of code changes, significant improvement from last spring's version.  However, the description of the tests is wanting,  What they do is not described in prose; the reader has to read the code to find out."
E1835,"The following tasks were accomplished in this project: 1. Used Sidekiq gem for asynchronous processing of email jobs 2. Created a new mailer class- MailWorker that uses Sidekiq's queue to hold and process jobs 3. Defined the perform method to extract the Email IDs of all participants of the corresponding assignment and send an email reminder 4. Replaced the code that uses the existing DelayedMailer queue to incorporate Sidekiq's queue 5. Added RSPEC test cases to test the creation of assignment deadlines and background Sidekiq email job. Sidekiq is a background processing framework for Ruby. In particular it consists of three parts: Client, Redis and Server. The client runs in Ruby process and allows us to create jobs for processing later. Once a job is created, a Hash representing that job is created and serialized to a Json String. This String is pushed into a queue in Redis. Redis provides data storage for Sidekiq and holds all the job data. Each Sidekiq server process pulls jobs from the queue in Redis and processes them. 1. Uses the 'delayed_job_active_record' gem for asynchronous processing of delayed jobs The current implementation uses Delayed::Job for implementing a Database based asynchronous priority queue system for storing the job queue of email reminders corresponding to various deadline types. 1. Email reminders were sent to users corresponding to each deadline type The DelayedMailer class includes a perform method that finds Email IDs of the target users corresponding to the deadline type. The subject and body of the email message is then constructed and the delayed_message method of Mailer class is used for sending the emails out to the users. 1. Uses DelayedJob to enqueue email jobs The DelayedMailer object is enqueued into the DelayedJob queue using enqueue method. These jobs are meant to be executed as the deadline of the corresponding Email job approaches. Problem 1 : The perform method in the DelayedMailer class contains a big case statement to check each kind of deadline The perform method in DelayedMailer class checks the deadline type individually using multiple if statements and populates the Email IDs of the target users by querying the database. <code> Solution : The implementation has been changed in such a way that all Participants belonging to the assignment under consideration receive emails irrespective of the deadline type. This is found out by querying the Participant table using assignment_id and retrieving the Email ID by linking it to the User table. 1. The Participant table is queried using assignment_id 2. For each participant, the Email ID is retrieved by linking the Participant and User table. 3. The email reminders are sent collectively to all the email addresses from the previous step. Problem 2 : Scalability Issue: Delayed Job uses SQL database for storing the jobs and processes them in a single-threaded process. It is not suitable for processing 100,000s of jobs a day. Solution : Sidekiq uses redis for storage which implements a distributed in-memory key-value database and processes jobs in a multithreaded process. It is efficient in terms of processing speed. 1. In the new implementation a new class MailWorker in app/mailers/mail_worker.rb is created that uses the Sidekiq worker for the mailers queue. The three instance variables- assignment id, deadline type and due date are used in this class as well. 1.1. The perform method takes the above three parameters and calls the auxiliary method find_participant_emails. This method queries the Participant table to extract the Email IDs of the users participating in an assignment and returns the email list. 1.2. The email reminder method is unchanged from the previous implementation. <code> 1. The app/models/assignment_form.rb is modified to make use of the Sidekiq's perform method to queue the job and process it when the deadline approaches. 1.1. The add_delayed_job method now uses Sidekiq's perform_in method to store the email job in the job queue and executes the email job after the time (in seconds) as specified in the first argument has elapsed. 1.2. The corresponding job_id is returned back for further processing. 1.3. The get_time_diff_btw_due_date_and_now method calculates the time after which the email has to be sent and is unchanged. <code>. We modified the existing test cases to replace the delayed job queue with Sidekiq, to test all modifications we have done to the code of assignment_form class. We also added RSpec test for Sidekiq mailer. <link> 3. You can see the new jobs populated here <link>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. Clean Code: A handbook of agile software craftsmanship.","This is a very good attempt to document the functionality, and is very readable.  However, some of the excerpted code sequences are quite long.  I would suggest making each method (or almost each method) a separate excerpt and juxtapose the description with each excerpt. Or you might add links to Github commits."
E1860,"Staggered Deadline Assignment is an assignment which can have different topics listed under it and each of these topics have their independent submission and review deadline. Topic's deadline can be the same as parent assignment or independent to it . Such assignments are useful when the class material is more sequential and instructor wants students to complete assignment as and when a topic gets covered in the class. If the topic is not selected for the first round of topics(assignment) or all the slots did not get filled up, It is still available for selection in the subsequent rounds. If a team selects the topic in a later round, they are not able to submit their work as the submission deadline is already over. If the topic had only one slot which remained unselected, instructor can change the deadline for that topic to match the new deadlines, but for topics with multiple slots, if the deadline is extended, the teams who worked on this topic in the previous round can submit/review the topic again. The signup option used by instructors to signup a team for a topic is visible to the students in their signup page beside every topic. This should not be visible to the students, also the above mentioned issue should be applicable to instructor signup as well. When creating a topic an instructor is required to enter review and submission deadlines for all the topics. To reduce the manual we want to allow the instructor to apply one deadline entry to a set of topics and also let the system calculate subsequent dates for subsequent project phases like review and re-submission, based on an initial deadline entry. Instructor should also have the ability to edit each of those deadlines independently incase he wants to change a particular deadline of a topic. Students can be prevented from signing up for a topic whose submission deadline has passed. user.rb /* The below code hides the instructor signup option from students and also displays it to only the Instructor or TA of the course, Below are the rules checked; Student can't signup Super Admin can signup Admin of the instructor of the course can signup Instructor and TA of the course can signup */ <code> Logic currently Implemented to prevent the students from signing up for topics whos deadlines have passed is explained by the following diagram. This is being achieved by calculating the offsets between the dates based on the offset in the dates of the first Topic of the Assignment. Once a new Assignment is created, the default dates (the parent assignment's due dates) are not being assigned to the topic. Once the user/instructor enters the first submission date, our JS function grabs the offset from the first topic and applies it to the empty fields of this topic. This function takes the table, extracts the offsets from the first topic and applies the offset to the topic currently being edited (Note: This does not happen for the first topic as we dont have any data yet) <code> <image>. Issue 1: # Don’t allow students to sign up for topics that has past due dates. 2. Edit any assignment under the General tab, mark it as staggered deadline assignment. 3. Provide deadlines for few topics in the past. 6. verify topics available for sign-up. Data and Database Integrity Testing None Functional Testing Expectations: 1. The modified topics should not be available for signup. 2. The unmodified topics with deadlines in future should be available for signup. 2. Actions’ tab should be empty for topics with deadlines in the past. Performance Testing None Issue 2: # Provide default deadline options for assignments with staggered deadlines. 3. Change assignment type to staggered deadline. 4. Type in a submission deadline for Round 1-Submission. 5. Verify that other due dates are auto populated. Case 1: Instructor wants to assign default deadlines to a staggered assignment: Steps 1. Click save. Data and Database Integrity Testing Expectations: 1. Verify all deadlines are updated in due_at field in due_dates tables for corresponding deadline types after saving the populated values. Functional Testing Expectations: 1. Deadlines auto-populated for other Round N should be in correspondence with default offset days between rounds. 2. The auto populated deadline should reflect in student assignment section. Case 2: Instructor wants to enter a custom deadline only for a particular round: Steps 1. Choose offset value from initial vale from dropdown option available against each deadline type. Data and Database Integrity Testing Expectations: 1. Verify all deadlines are updated in due_at field in due_dates tables for corresponding deadline types after saving the populated values. Functional Testing Expectations: 1. The auto populated deadline values are changed as per selected offset days from drop-down. 2. Same should reflect in student assignment section. Case 3: Entering an incorrect date when manually entering a deadline for a particular round for a staggered deadline. 4. Submit one review. 6. Impersonate Instructor. <code> Issue 2 : Check if the due_dates fields are being populated automatically once the due_date for the first submission is entered for a topic <code>.","This document does a very good job of describing the project.  The rationale for all changes is described, and flowcharts as well as screenshots are shown.  One weakness is that large blocks of code are shown in black and white; it would've been so much better to link to the corresponding diffs in Github.  But the code is nonetheless clear, as it is well commented.  It would also have helped to have a few more comments in the automated test plan, describing what mocks were created and why."
E1910,"<link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. [3]. Few of the variables names used in the method can also be refactored to make it more relevant and understandable. In addition, functions code can be optimized to ensure that it follows 'Don't Repeat Yourself' (DRY) principle. Also, most of the functions have missing code comments, which should be added to the functions. <link>. <link>. The only controller modified for this project was the: 1. AssignmentsController 2. Assignment_helper The updated method names in AssignmentController: <code> The thought process behind changing the method names was to make the names shorter and reduce redundancy. There were a few rules that we learned from our mentor; words like nil and nonexist are not allowed in method names. Then after looking at what the method does we determined that timezone_handler would be appropriate and tells the user enough at a moments glance. More information is available about the method in the form of a block comment. No one would know what that stands for just by reading it. This is why this method was changed to update_due_date_deadline_name . Some of the methods in the controller were misplaced and according to the DRY principle these methods are better suited to be in the helper method. The methods that were moved from the controller to the helper were: <code> We were asked to refactor the action_allowed? method but after discussing some reafactoring methods with our mentor it was decided that refactoring this method would not promote the DRY principle and the methods created as a result would only be for that one purpose and therefore unnecessary. ""[4] This project was about furthering this principle and keeping this controller concise and maintainable. We updated the aforementioned method names so that the naming convention follows the DRY principle. Many of the method names were far too long, repetitive or unhelpful in understanding what the method actually does. In accordance with the principle we updated the method names to be simple while also being useful in letting the programmer know what the method does. Many of these methods did not have any comments to help the programmer understand the logic driving the method. To further help the programmer in understanding what the code does we added block comments at the beginning of each method that we updated. We cleaned up the controller by moving some methods from the controller into the associated helper file ( assignment_helper.rb ). By doing this we made the controller less messy and easier to read while maintaining and furthering the DRY principle. The code is now easily maintainable and all ""helper"" methods are in one place rather than separated across many files. [5] As something extra, the create method was refactored so that the branch condition would be lower and there would be no repetition. As per this pattern we took a request from the create method and put it in a helper method called update_assignment_form . This method handles updating the id of the assignment_questionnaire and the due_date and updating the form accordingly. The create method delegates this task to the update_assignment_form . The update_assignment_form delegated a tasks to the helper method, array_traverser . This method does the job of going through the array and updates id fields to be strings instead of an integer. As a result of these changes two code climate issues have been resolved which are stated below in the Code Climate section. Below are images of the way the create method used to look and how it looks now. Old create method: <image> New create method: <image>. Code Climate checks to make sure that the code that has been written follows certain rules so that everything is legible and concise. During our refactoring we have fixed the following code climate issues. - The create method's Cognitive Complexity was too high. - The create method was too long with 33 lines of code. This has been resolved as a result of us refactoring the code. This has been resolved as a result of us refactoring the code. We have three current code climate issues but after discussing with our mentor we have been told to ignore those. The code coverage for the controller was 49% when we got the project. The code coverage when we finished was 53.32%. The create block tested just about everything. We tested the public method, create , that calls the private method, update_assignment_form and array_traverser . For the other untested public methods, we found no usage directly in the controller, therefore, we did not test them. These methods are performing the tasks of assigning values to the variables and therefore that is being tested in other methods of the controllers. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","You did a good job of explaining the rationale behind the changes made, and showed the code (albeit in pretty small font) that was affected. This will help the reader understand your changes.  It would have been even better if you had described how the ""after"" code worked (instead of just displaying the code)."
E1945,"It allows the instructor to create new assignments and customize new or existing assignments. The instructor is allowed to create a list of topics for the students to which they can sign up for. For working on different projects and assignments the students can form teams in Expertiza. The UserController is a controller used for managing the creation, modification, and destruction of users in the Expertiza system. Instructor users may be added after creating a request for a new account. A key part of our team’s work was moving methods associated with managing a new account request from the UserController to a new controller named AccountRequestController. This removed coupling between account requests and user objects. Furthermore, it allowed an account request to be properly associated with its own controller, model, and view. Additionally, the team refactored and documented some methods in the UserController. The users_controller.rb file included the standard CRUD methods for a User model along with methods for other workflows. This was problematic, as the Users controller should deal with User functionality, not requested user flows. The file also included a few methods which had a bad name or lack documentation. The functionality for paginating users did not work either, meaning that all users would be displayed on the List Users page. The following tasks were required to be done for the project by our team according to the assignment: 1. Separate all methods related to the workflow of a RequestedUser object 2. Move below-mentioned methods to a new file named account_request_controller.rb 1. created_approved_user 2. list_pending_requested 3. request_new 4. created_requested_user_record 5. roles_for_request_sign_up 6. Requested_user_params 1. The RequestedUser model should be renamed to AccountRequest and its lifetime must be managed by the new AccountRequestController 2. The form that was currently displayed when the “Request Account” button is clicked from the Expertiza login page. 1.2. All form labels had to be bold-faced 1.3. The “Self Introduction” label should be re-named to “Self-Introduction” 1.4. The textbox for the self-introduction field should include some hint (“Please include a link to your web site”) 3. Comments had to be written for the following methods 1. get_role 2. show_selection 3. foreign 1. The paginate_list method had to be invoked at the correct location (in the list method) so that it paginates the users list correctly. Currently all users are shown on a single page by default upon clicking on Manage > Users. Because there are nearly 9000 users, the page takes a minute or two to render. This is the page that was loading originally when request account button is clicked in the login page: <image>. Only the Instructor account can be created and not TA which is there as an option originally. The following methods had comments written or renamed for better understanding of the working of the methods and to reflect their actual behaviour. 1. get_role - The method was renamed to role , a comment was added explaining that it finds the role of a given user object 2. show_selection - The method was renamed to show_if_authorized , as this method should only display the users if the current user is authorized. 3. foreign - A comment was added for this method, explaining that it stores all roles possible and that it gets role id of the session’s user. Invoked the paginate_list method at the correct location(in the list method) so that it paginates the users list correctly. The number of users per-page has currently been set to 100, which was showing all users in a single page by default. Also added a section at the bottom of the list.html.erb page for navigating between the paginated list of users. <image> As it can be seen now that there are page numbers and not all the users are being showed on the same page as was the case beforehand. The refactoring of the user_controller made the view for the account request more clearer and easy to understand for the user i.e. Furthermore, the paginate users is now repaired and is working properly which lets the students list to be shown page wise instead of all the students in a single page which was not readable. Video of Account Request Process: <link>. Tests for UserController were updated to account for the fact that some methods now use the AccountRequestController. The tests for the methods that were moved to AccountRequestController were moved to a new spec in the file account_request_spec.rb . The team did this because it made sense to make a new spec for a new controller. The tests were also updated to not select the user role from the “User Role” dropdown. RSpec: <code> <code> Manual Testing <code> <code> <code> <code>.","There were minor inaccuracies on the wiki page, which I have corrected (e.g., instructors may (not ""must"") be created by requesting an account, the way to list users is to invoke Manage > Users).
The UI allows only instructor accounts to be requested.  Administrator accounts should also be requestable from this screen.  If there is only one role, then why does the foreign method need to get a list of available roles?
It would be good to explain the other code changes by pasting in snippets of those too.
They have clearly stated their contribution in the doc
They have uploaded a video that shows testing on their deployment"
E1832,"Expertiza is an open source project based on Ruby on Rails framework. Expertiza allows the students to peer review other students submission. It also allows Participant of a Team to provide feedback for the review. Apart from that, it allows the instructor to view the summary report of reviews received and feedbacks given by each participant of a team. In current system the author feedback is send by individual team members. It would be better if one team send one single rejoinder to the review and all members could see and edit it. Also there are real usability issues with regards to how students can even navigate to the place where feedback can be given to reviewers. The UI needs to be more user friendly. In Summary report for assignment for instructors, the author feedback section lists feedback from all team members. You should change this to list the team’s collective feedback to its reviewers to a particular assignment. 1. Refactor “new_feedback” actions for adding team as reviewer for Rejoinder. 2. Refactor all the actions in response controllers to pass the participant id. 3. Refactor author feedback tab in summary report view for the instructor. 4. Change in the summary report of assignment for the instructor to display teams feedbacks. 5. In the author-feedback tab on the heat grid, fixed reviewers names on top row. 6. Summary reports navigation to the page where feedbacks are given to reviewers. 1.Team rejoinder. 1. controllers/response_controller.rb 2. views/grades/_reviews.html.erb 3. views/response/response.html.erb 4. models/vm_question_response.rb 5. models/assignment_participant.rb 2.Navigation Issue fixes 1. views/response/view.html.erb 3.Author feedback tab of summary report: 1. models/response_map.rb 2. models/team.rb 3. helpers/grades_helper.rb 4. views/grades/_author_feedback_tab.html.erb 4.Heatgrid top raw reviewer name fix: 1. views/grades/_view_heatgrid.html.erb. 1. Changed per participant feedback display author feedback view to per team in app/views/grades/_author_feedback_tab.html.erb : <image> 1. Added ""give feedback"" and edit feedback functionality in the review view(app/views/grades/_reviews.html.erb). <image> 1. Edited grade helper to use a questionnaire to use team ID for reviews in case of a feedback(app/helpers/grades_helper.rb). <image> 1. Refactored new_feedback method to add team ID as the reviewer Id in the response map(app/controllers/response_controller.rb). <image> 1. Fixed a bug where a wrong assessment was being returned for a feedback because the map was searched on participant id instead of reviewee id. So added a new method which will return a feedback assessment(app/models/response_map.rb). <image>. Issue #622 Assuming a team of two students student559 and student567, and that they have gotten a review from student563. 1. Click Manage-Impersonate User, type username “student559”, then click impersonate. 2. Choose assignment Test Test, go to Your score, and click Review 1, like the screenshot shows, there is an option for giving feedback <image> 3. Now, impersonate user “student567”, choose assignment Test Test, go to Your score, and click Review 1, you can see the same feedback commit ""TESTING Feedback"". with an option to Edit Feedback <image> <image> Issue#895 1. Login as an instructor and Click Manage-Assignment, under assignment Test Test, click view scores. 2. Choose Team 1, and click Author Feedback, you can see the feedback is given by the team, not individual student. <image> Issue#1191 In the above screenshot, you can see that the top row of heat grid is fixed to show the name of Student to whom the feedback is given(in this case to student563). And the link will take you to the review. Fixed the existing test cases for the review feedback by a team instead of a team member. 1. Should test that if there is no rejoinder for the review then it redirects to new author feedback page. 1. Tests that the other teammate is able to edit. 1. The page is redirecting back to the View->review. 1. Tests that the rejoinder by a participant of a team is saved properly. Context 'when current response is nil' do <code> describe '#feedback' do <code>.",They missed the problem statement in their wiki doc. But they have done a very good job describing the changes they made to fix the Github issues.  Test plan needs more elaboration.
E1867,"The objective of this project is to: 1. Add a feature for students to make their reviews 'public', that is, allow other students to view them. 2. Add a feature for TA to select a subset of 'public' reviews, and make those reviews visible as sample reviews of the particular assignment. 3. Add a feature for Instructor to select a subset of 'public' reviews and make those reviews visible as sample reviews of any of his/her assignments in the course. 4. Create a view where the student can see a list of sample reviews of the assignment and have a detailed view of each. 5. Allow the student to toggle the visibility of a review he/she has submitted. 5. On the ""popup/team_users_popup"" page (where instructor/TA can view all reviews), we give a checkbox against every review with public visibility to allow instructors/TAs to select one or more reviews as sample reviews to be available for students. 6. Once the instructor selects and submits some reviews as sample reviews, we give a popup containing a list of assignments with a checkbox against each of them and a submit button at the end to allow instructors to make sample reviews available for multiple assignments in one go. 8. At the top of student_reviews/list page, we give an option for the student to preview all the available sample reviews. 9. Create the MVC setup for this new page to list all the sample reviews. Students will be able to click on one particular review and preview it. This means, given the intent of association as ""review"", assignment Ak was chosen as a similar assignment for assignment An. That is, while marking some review for An as a sample, the instructor opted to have reviews of Ak as samples for An as well. This is done by providing a button “Mark as Sample” or “Remove as Sample”. It only appears when there is at least one sample review for the current assignment. For example, assume that the power user is viewing the response page of assignment X. Let current assignment id be X. <image> So far, power users have marked reviews as samples and linked assignments. Now, students need to view these samples. A student would view these sample reviews before writing their review on somebody else’s work. Therefore, we have added a link “View Sample Reviews” to view the list of sample reviews. It is a list of links to sample reviews. As a Power User (TA/Instructor/Admin/Super Admin) 1. Log in 2. Click on Manage->Assignments 3. Displays a list of Assignments 4. Click View Report/Review for a particular assignment. 5. Displays a list of reviews submitted by students. 6. Click on any review in ""team reviewed"" column for a particular student. 7. Displays the summary of reviews submitted by that student, with a ""Make as sample"" button on the right of every review. 8. Click on ""Make as sample"" for the intended reviews, which opens a popup that displays a list of all assignments that are a part of the instructor's courses. 9. From this list select all assignments for which the review has to be shown as a sample. 11. Navigate to view reviews of that particular assignment and click on ""Sample Reviews"". 12. A new page is opened that lists out all the sample reviews of the assignment. 2. Click on Assignments 3. List of assignments is displayed. 4. Click on any assignment for which the review has to be submitted. 5. Assignment task page is displayed. 6. Click on ""Other's work"" to open the reviews summary page (at /student_review). 7. Below the heading ""Reviews for ..."", click on the ""Show sample reviews"" link. 8. This opens a page where the student can view all sample reviews for that assignment. 9. Use the browser's back button to go back to the Assignment review page. 10. Chose to review any of the teams' assignments that are displayed. 11. Select a team for review and fill in the review. RSpec Tests Below are the Rpsec tests that have been added to test the edge cases: 1. If an anonymous user tries to view the sample reviews page he/she will be redirected to home page. 2. If an anonymous user tries to view the details of a particular sample review, he/she will be redirected to home page. 3. If a user tries to view the sample review of a particular assignment for which there are no sample reviews, he/she will be redirected to home page. 4. If a student tries to fetch similar assignments, then he/she will be redirected to the assignments page 5. If a student tries to update any similar assignment, then he/she will be redirected to the assignments page 6. Performed some basic HTML validations -should always give the content-type as text/html"".","The wiki almost covers all the aspect of work done by them. The UML diagram they included is really good for reviewers to understand the functionalities they added. Many screenshots were used and some of them are inconveniently large.  The strings ""Marked as sample"" and ""No more a sample"" are not sufficiently descriptive.  ""This review has been marked as a sample of good work"" would be better.  The narration is generally good, but the code snippets are too large, and do not contain sufficient comments.  It would be better to link to them on Github, where there would be a multicolor view and a chance to add comments on the code."
E1626,"Expertiza will take advantage of the motivations created from badges by awarding students with new badges based off providing a variety of factors within the Expertiza system. Instructor can create badges using this service and assign to students. This feature allows instructors to assign badges to students based on their performance and accomplishments. Badges can be pre-selected while creating an assignment and automatically triggered when student finished the assignment or assignment is closed. Badges can also be awarded manually by instructor to an individual or a team. An instructor can also create new badges anytime and award to students. A leaderboard gives an account of standing of students in terms of badges earned. 1. Student Views Leaderboard 1.1. Actor: Student 1.2. Other Participants: None 1.3. Primary Sequence: 1.1.1. Log into Expertiza 1.1.2. Mouse over Home 1.1.3. Select Leaderboard 2. Instructor Views Assignment Leaderboard 1.1. Actor: Instructor 1.2. Other Participants: None 1.3. Primary Sequence: 1.1.1. Log into Expertiza 1.1.2. Select Assignments 1.1.3. Select View Badges on assignment 3. Instructor Edits Assignment Badges 1.1. Actor: Instructor 1.2. Other Participants: None 1.3. Primary Sequence: 1.1.1. Log into Expertiza 1.1.2. Select Assignments 1.1.3. Select Edit Assignments 1.1.4. Select Badges tab 1.1.5. Check enable badges 1.1.6. Check Score Threshold 1.1.7. Enter 95.5 as scoring threshold 1.1.8. Select Save 4. Instructor Creates Course Badges 1.1. Actor: Instructor 1.2. Other Participants: None 1.3. Primary Sequence: 1.1.1. Log into Expertiza 1.1.2. Select LeaderBoard 1.1.3. Select Award Badges 1.1.4. Select Create new badge 1.1.5. Create new badge using Credly 1.1.6. Select Save. 1. Create db table to store the participants with badges. 3. Add badge specification to course details and assignment details page for the instructor to specify the badges. 4. Create views for both students and instructors. Students should be able to view their badges from different courses and instructors should be able to see the badges awarded/earned for their class. Also, student can view badges of other students in the course. 6. Criteria to be followed for awarding badges: 1. Top scores for an assignment. (configured at assignment page) 2. All scores more than a threshold for an assignment. <image> Under assignment configuration, instructors may add badges to an individual assignment. They may choose to add the badges to the top N students, or based off of a given threshold. <image> After badges are awarded, an instructor may view the badges given to students on the leaderboard page. Instructors may also manually award badges to students from the page. <image>. Students may view the leaderboard for classes they have taken. For instance, an instructor may decide to reward badges to the top 3 scores on an assignment so once the assignment closes those students will automatically be given those badges. In order to use badges for an assignment, an instructor must turn on badging for their assignment upon creating or editing an assignment. Following the completion of an assignment an instructor may view the awarded badges on the assignment page. A student will be able to view their earned badges on their homepage categorized by course and assignment. In order to display the badges the application will make a call to Credly to query about student badges. In Figure 3 below an instructor may view the badges earned for a given assignment or course in which they own. They will get to his page by clicking a badges button from either the assignments or courses page. The title of the page will be the name of either the course of assignment. Like the previous figure, by clicking show badges the list of course participants will appear sorted by the number of badges they have earned. <image> Figure 2: Instructor assignment / course badge view In order to use badges for an assignment, an instructor must first enable them for the assignment. The badges will be enabled by default. Instructors may choose to automatically grant badges to students based off of their performance on the assignment. When editing or creating a new assignment they may come to the new badges tab and configure how they want the badges granted. Instructors may choose to grant some number of badges to the top scores of the group defined by the number the input, or they may decide to grant badges to anyone who may achieve a score past the provided scoring threshold. <image> Figure 3: Assignment Badge Settings Like assignments, courses also need to have some settings to configure badges. In Figure 4, instructors may automatically grant badges for students based on mean scores of multiple assignments throughout the course.","Please change your wiki page name to include the project #.
The UI needs to be improved (e.g. on the leader board).
Limited test done."
E17A8,"It also facilitates and monitors team projects. 1) Identifying the Expertiza pages which take time to load using Rack-mini-profiler and Flamegraphs. 2) Propose fixes which would improve the Expertiza project. 3) Optimizing the view, models and controllers for few of these corresponding fixes to improve the load time of these pages. 1. rack-mini-profiler :- Middleware that displays speed badge for every html page. This can be identified by using the flamegraph generation method and rack-mini-profiler statistics. This was done by using flamegraph generation and rack-mini-profiler statistics. The statistics generated by rack miniprofiler helped us to understand the time taken by each component to get loaded. From these statistics, we identified the model/controller/view/database query which is causing this latency. Optimization approach for the pages: 1. users/list :- The approach to reduce loading time on this page was by implementing pagination. Instead of displaying all users and their data all at once, we display a certain number of users on one page, and rest of the users can be viewed by accessing the later pages. This reduces loading time of the page by reducing the amount of data to be fetched. Currently, all the data for all the teams present is loaded when the webpage is accessed. Instead, data for particular teams can be loaded when the user clicks on the expand button for that particular team. Thus, data for each team should be loaded asynchronously with ajax. The following is the flamegraph for this page:- <image> The X axis of the FlameGraph represents the time taken to load the page. It can give a clear picture of where the expertiza page is getting bogged down. As we can see over here, most of the time taken over here is in the controller action. The following is the rack-mini-profiler statistics for the page:- <image> The box which is seen in the leftmost corner is the MiniProfiler statistics. MiniProfiler gives a constant notification of how long each page takes to load. The miniprofiler statistics show the time taken to render the view as well as the corresponding SQL calls. <image> This image shows the time and the number of SQL calls which are required for each rendering. <image> Here as we can see the total number of SQL calls required for children_node_ng is 1123. This is causing the latency in the entire page by 10564.8 ms. These statistics helped us to identify the method which needs to be refactored. <image> The total number of SQL calls required for 2 components here is 2 each. 1. users/list The time taken to load the page was high because the server had to access through hundreds of rows in the database .The page was rendering the entire row of database at the same time. Pagination helped to split the database into manageable chunks of data. Code added to app/controllers/users_controller.rb <code> Code added to app/models/user.rb <code> Code added to app/views/users/list.html.erb <code> 1. grades/view The grades/view is the page where the instructor accesses the grades statistics of each student. The reason for the slow down in the page is that the data for all the teams were loaded as soon as the page was loaded.The design of the page has an individual tab for each team, hence loading the entire data as soon as the page is loaded is quite redundant as the instructor needs to access the scores of each individual team at a given time. The solution to this problem is to access the individual team statistics from the database when the instructor clicks the tab specified for the particular individual. This would save redundant loading of data and thus reduce the loading time of the page. 2. We passed the required data through the Rails params hash. 3. We tried passing the hash as it is, but after doing this all the data in the hash is not retained, i.e. there is a loss of data. 6. But our hash has values as Objects, thus these methods cannot be applied 7. Thus, we are unable to access the data in the String-hash. 8. If this could be done, then our approach would result in successfully decreasing the loading time of the webpage. The project is based on optimizing the time required to load the pages which has been mentioned above,in order to test that there is an improvement in the time taken to load these pages one will have to compare the initial loading time and the time taken after the code has been modified. It however consists of the two gems required to check the loading time. 3)To login as instructor :- Username :- instructor6 Password :- password. Check the time taken to load the page localhost:3000/tree_display/list on the left corner and compare the same for the latest pull. You will notice a substantial reduction in the loading time.","This is a very different project, so a lot of sections required in other design docs are not required here and vice versa.  In essence the whole document is a test plan, for performance tests.  The document is generally readable and explains what needs to be done."
E1673,"Expertiza is an open source software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. It has following features: 1. Enables students working together in a class and a topic 2. Enables studnets to do peer review and improve both him/her and others' learn experience. The purpose of this work is to rewrite part of the codes in the Criterion.rb, Scale.rb, Checkbox.rb, Dropdown.rb, Text_response.rb, Text_area.rb, Text_field.rb. This is because some of codes have bad writing sytle, or not followingg OO language rules, which confuse others to understand these code. The detail of the requirements are list below: 1. Line is too long 2. Some code found in other location and should put them in the parent class 3. Method has too many lines 4. Some of the code will cause security risk 5. Using the old style validations 6. Using a lower efficent way to do the loop All of these requirements are based on a analysis software called <link>. <image> <image>. Although it increase the number of classes, the length of function decrease and it's easy to read than before 1. Short the long line 2. Improve security by using safe_join Previous <code> Changed <code> 3. Short long method Previous <code> Changed <code>. It makes codes more readable. We also choose safe_join instead of html_safe to prevent security risks. However, we must use html_safe to keep the character encoding. 1. Use new style validations Previous <code> Changed <code> 2. Short the long line 3. Improve security by safe_join Preivious <code> Changed <code> 4. Short long method Preivious <code> Changed <code>. 1. Use each loop instead of for loop Previous <code> Changed <code> 2. Short the long line 3. Use safe_join to be more security Previous <code> Changed <code> 4. Delete the code similar with other file and put the duplicate into parent class. 5. Modify some method that is too long Previous <code> Changed <code>. 1. Short the long line 2. Modify some method that is too long Previous <code> Changed <code> 3. Use safe_join to be more security Previous <code> Changed <code>. 1. Improve security by using safe_join Previous <code> Changed <code> 2. Modify some method that is too long 3. Use new style validations Previous <code> Changed <code> 4. Use each loop instead of for loop Previous <code> Changed <code>. 1. Use new style validations Previous <code> Changed <code> 2. Modify some method that is too long 3. Improve security by using safe_join Previous <code> Changed <code>. 1. Replace condition statements in one line Previous <code> Changed <code> 2. Improve security by using safe_join Previous <code> Changed <code>. 1. Login in as an instructor or admin using credentials (admin with password: admin or instructor6 with password: password) 1. Click the Manage in the top bar,then click the Questionnaires which is down left of the the text:Manage content 1. Add the Name and click create 1. Click the any button you want.","When you say you have ""short"" (shortened) a method, you should explain how functionality that used to be performed by the method is performed now.  The code you've given is much shorter, and couldn't output everything the old view did."
E1621,"It combs through the parameters hash received from a request and manually checks all quiz fields, all question fields, all question choice fields, and verifies that each question has a correct choice. We will refactor the method to construct a quiz questionniare and then call valid? An instructor chooses to create an assignment that has a quiz [S1]. While editing the assignment they may choose the number of quiz questions [S2] and set which phases students are allowed to take the quizzes [S3]. Checking this box creates an assignment that includes a quiz. 2. [S2] - When an assignment has a quiz there is an input field that accepts the number of questions that will be on each quiz. Setting this number appropriately changes the number of quiz questions. After an assignment has been created the instructor may choose to view student quizzes from the tree view [S1]. While on the quiz view page they see student quizzes [S2] and student responses [S3]. 2. [S2] - The instructor shall be presented with the quiz title, questions, and answer choices. The correct answer choices will be in bold. 3. [S3] - The score for each student who has taken the quiz shall be listed along with the average quiz score. A student navigates to the assignment work page and chooses to create a new quiz [S1] or edit an existing one [S2]. By doing so they are able to choose a quiz title and quiz questions [S3]. 1. [S1] - A student may only create a quiz if they have not yet done so. 2. [S2] - A student may only edit a quiz if they have previously created one. 3. [S3] - The quiz has the number of quiz questions defined by the instructor in the assignment. 1.2. One or more questions is missing text. 1.3. One or more choices is missing text. 1.4. A question is missing a correct answer choice. A student decides to take a quiz [S1] on another team's assignment that they have previously reviewed. 1. [S1] - The student may only take a quiz during a stage in which the assignment is configured to allow them to do so. 3. [S3] - The take quizzes page lists the final score for each quiz. 4. [S4] - Choosing to view a quiz will show a student each question along with their answers and the correct answers. . It now constructs a quiz from params and returns it if it is valid. def valid_quiz num_quiz_questions = Assignment.find(params[:aid]).num_quiz_questions valid = ""valid"" (1..num_quiz_questions).each do |i| if params[:new_question][i.to_s] == // One of the questions text is not filled out valid = ""Please make sure all questions have text"" break elsif !params.has_key? (i.to_s) || params[:question_type][i.to_s][:type] == nil // A type isnt selected for a question valid = ""Please select a type for each question"" break elsif params[:questionnaire][:name]=="""" // questionnaire name is not specified valid = ""Please specify quiz name (please do not use your name or id)."" break else type = params[:question_type][i.to_s][:type] if type == 'MultipleChoiceCheckbox' or type == 'MultipleChoiceRadio' correct_selected = false (1..4).each do |x| if params[:new_choices][i.to_s][type][x.to_s][:txt] == // Text isnt provided for an option valid = ""Please make sure every question has text for all options"" break elsif type == 'MultipleChoiceRadio' and not params[:new_choices][i.to_s][type][x.to_s][:iscorrect] == nil correct_selected = true elsif type == 'MultipleChoiceCheckbox' and not params[:new_choices][i.to_s][type][x.to_s][:iscorrect] == 0.to_s correct_selected = true end end if valid == ""valid"" && !correct_selected // A correct option isnt selected for a check box or radio question valid = ""Please select a correct answer for all questions"" break end elsif type == 'TF' # TF is not disabled. if params[:new_choices][i.to_s][""TF""] == nil // A correct option isnt selected for a true/false question valid = ""Please select a correct answer for all questions"" break end end end end return valid end. return questionnaire end questionnaire_errors questionnaire end.","This is a testing project, and the design doc has only 1 1/2 lines on testing! The document did not cover much detail on how this project is tested"
E1674,"Expertiza is a web application where students can submit and peer-review learning objects (articles, codes, websites, etc). Instructors add and edit assignments to Expertiza. Students can be assigned in teams based on their selection of the topics. The Expertiza project is supported by the National Science Foundation. Currently in this web application the leaderboard page does not work. As the guide of the director, we need to do the refactor and test only in this project, and the next step is to make the page work. The task of the project is to refactor leaderboard.rb and write unit tests for it. As the name of the methods are not in a standard style, we use snake_case for method names. There are also some useless assignments to several variables. 1. Refactor the leaderboard.rb 2. Create a RSpec file in /spec/models/ foler which contains unit test for leaderboard.rb. What we need to do is to deal with problems listed by the code climate. And we also need to write a new test file to test the functionality of leaderboard.rb. However, the leaderboard itself has some problems and IDE will report some problems when we want to run it. So we need to know which method in this file is broken first and just test others instead. As for this project, we use the code climate plugin to test if our code is good enough. This plugin will obviously help us with the refactor part because it can show which part of the original codes have some problems. We also search through the internet and get to know how to write the Rspec files. We also ended up using the 'rspec/collection_matchers' class of rspec which allows us to match the number of items in a collection for an object. We will list each kind of problems we solved below. As we all know the snake_case means we need to name the methods and variables in which elements are separated with one underscore character and no spaces. For example, we changed this method. <code> Both variable names and method names are not in a good manner. We changed it to the version below. <code>. We deleted those variables since we only wanted what was being assigned to them. Before: <code> After: <code>. We know that 'each' function is more in ruby style for loops. So we would like to change all our 'for' to 'each'. <code> We changed this loop to: <code> And the problem would be fixed. <code> This is the third and fourth level of the block nesting. We need to merge them together. <code> Then the 4-levels loop has been changed to 3-levels one. The Leaderboard Class did not have any unit tests associated with it coming into this project so we have to create unit tests from scratch. Upon analysis of this class, we noticed that Leaderboard did not hold any variables and was only made up of static methods. So the first round of unit tests that were created made sure that each method could be called from the Leaderboard class with the correct number of arguments. <code> Next we needed to go through the methods and create tests for them. But in order to do this we had to make objects that this class depended on since this class takes the values from other classes to output arrays and hashes. Factories were used to create these objects with a few variables being overridden <code> We tested the methods by seeing whether if we got the right amount of elements in our arrays/hashes like the following. <code> We also tested whether the code could handle invalid arguments like such. <code> We did face situations where methods were being called that were not defined anywhere so we had to use stubs to imitate their expected behavior. <code>. To explain our work in a further step, we did a video on Youtube to show the broken leaderboard page, why we did work in this way and our work for the unit tests and the refactor part. There are still some problems we need to figure out. For the code revising part, there are some methods with this problem: Assignment Branch Condition size for get_participants_score is too high. I think we cannot make too many functions in one method so that we need to make some of these be executed outside of this method. Also, some of the code lines are too long so that it is not clear enough. During the rspec testing we noticed that the methods get_participant_entries_in_assignment_list and find_by_qtype were being called but where not created in the program. To cover these tests we had to use stubs for these methods for the expected outputs. There was also no declaration of ScoreCache anywhere in the program which caused other methods to fail. Trying to stub this was a problem since we were not sure of how it was laid out. 1. <link>.",The writeup clearly explains the modifications done.  The level of detail is appropriate.
E1703,"Currently, Expertiza doesn’t log anything, beyond the events in the console log. In a production environment, logs are the best way to debug the application when something goes wrong. In the absence of logs, it is very difficult for a developer/support technician to debug and analyze what went wrong. In a production environment, logs are the best way to debug the application when something goes wrong. In the absence of logs, it is very difficult for a developer/support technician to debug and analyze what went wrong. <image> There are two parts to this project: 1. Logging the events and other information that will help in debugging 2. Creating a GUI to interpret the logs and show events for a particular user in a particular time frame. Rails makes use of the ActiveSupport::Logger class to write log information. Each log statement in the program has a level associated with it which indicates their importance. In the config file, we can specify the level of logs to be printed. A log statement in the program will be printed only if its level is equal to or higher than the level set in the config file. Currently, the expertiza code contains very little logging statement and it does not record student/instructor or TA activity. The current logs are also of little or no help to a developer/ support technician trying to debug the code when something goes wrong. We plan on improving the current log statements by adding more information to it so that it becomes more useful to the person trying to debug the code and will also record all student, TA and instructor activities. We will also be adding more log statements which will make it easier to track all student, TA and instructor activities. This view will list out the events by interpreting the logs and give an option to filter it based on user and date. <image> We are planning to standardize the log statements by giving them a predefined format. This will also help us in the second part of the project which is to interpret the logs and display student activities in a GUI. This is the format we propose: 1. INFO: <code> In the production environment, we will limit the logs to INFO mode, i.e it will print out only the errors and events. In development environment, we will set the logger mode to DEBUG. This will print out all the logs including errors, events and debug statements. This will help the developer in debugging the code when something goes wrong. This is the second part of the project. We will be creating a GUI to interpret and make sense of all the log data. The GUI will display the events for each user. We will also give an option to filter the event listing based on date and events. This is a rough sketch of what the page will look like: <image> It will have a text field to specify the user ID, a drop down menu to select the event and two date picker fields to specify the begin and end dates for the logs. Since this is defined in the application controller, it will be accessible in all the controllers and there is no need to redefine it again in the other controllers where we use it to log events. We have added a total of 45 logging statements for different events. The new code in the other controllers are simple logging statements to log events, does not affect the functionality of the existing code in any way. 1. logger_controller.rb We created a new controller for reading and filtering the log records. This has two actions, for viewing the logs and for filtering the logs based on input from the user. 1. log_entry.rb This model was created to represent each log statement in the record. It contains fields that pertain to a log entry like the time, userid, event and log description. 1. view_logs.html.erb This is the view we created for viewing the logs records. The used is also given an option to filter the logs based on time, userid, user type and event type. <image> Each log entry has a serial number, timestamp, name of the event, description of the event, type of the user involved in the event and userID of the user. We have provided the option to search the logs by user type, userID, event type and time. It does an in page search of the results that are currently loaded. Its faster if you dont want the latest logs. It will search only the records that were present in the log file when the page was loaded. If you want to search the latest logs, i.e logs that have been added after the page was loaded, you need to use the first search button. If the user having less privileges than an admin tries to access the log viewer page, then he/she gets a authentication failure message. This project can be easily extended by adding more log statements to additional or new events by simply making a log entry with our logger object in the specified format. We also had to read through all the existing controller code to insert logging statements at proper locations to log user activity.","The wiki page covers all necessary items, but ""test plan"" part can be more elaborated. And the last screenshot is useless, it will be better to show the db records, instead of table structure as mentioned during demo."
E1756,"Expertiza is a Ruby on Rails based Open Source project. It is a collaboration tool which lets users with different roles (student, instructor, teaching assistant) to collaborate on a course in an institution. A collaboration could be for an assignment where students teams up for an assignment and instructors grades them on the basis of their submission. Students could review other's works and give feedbacks as well. <code>. <code>. response.rb is the default model to interact with the responses table, which stores the answers to every questionnaire. It is basically the alternate view. The content is displayed based on the user role. There are two important views, one for students and the other for instructors. What’s wrong with it? response.rb is a fairly complex file. It contains lots of methods that are long and hard to understand. These methods need to be broken down into simpler and more specific methods that are easier to read/understand. Also, the few instances of code duplication that exist should be removed. The response_spec.rb did not contain any test cases for the response.rb model except the mocks. Refactor display_as_html method Write failing tests first Split into several simpler methods and assign reasonable names Extract duplicated code into separate methods. Refactor self.get_volume_of_review_comments method Write failing tests first Convert duplicated code into loop. Rename method and change all other places it is used Write failing tests first get_total_score → total_score get_average_score → average_score get_maximum_score → maximum_score. Use sort_by(&:seq) instead of sort { |a, b| a.seq <=> b.seq } Write failing tests first. Use find_by instead of where.first Write failing tests first. The display_as_html method has been modified. The existing logic for display_as_html method has been refactored into two different methods called construct_instructor_html and construct_student_html. Both these methods are generating html content to be displayed based on the identifier parameter passed to the function. The logic of displaying review, which was earlier in the display_as_html method has been included in another method called construct_review_response. The get_volume_of_review_comments method has been modified by putting the repeated statements in to a loop which runs on variable i. The variable names are now created based on the number of reviews. The methods get_total_score, get_average_score and get_maximum_score have been changed to total_score,average_score and maximum_score. The changes have been made in all the places wherever these methods are called. The method 'where' in significant_difference? method has been changed to find_by. The sort method which was in display_as_html method has been changed to sort_by. The sort_by method is present in construct_review_response refactored method. app/models/response.rb. app/models/response.rb. app/controllers/assessment360_controller.rb app/controllers/popup_controller.rb app/helpers/review_mapping_helper.rb app/models/collusion_cycle.rb spec/models/response_spec.rb. app/models/response.rb. app/models/response.rb. Problem 1: The method display_as_html is complex. Many functions are embedded in to a single method. The test cases of response.rb file have been implemented. All the contexts of response_spec.rb pass with the overall coverage of 27.16%. The pre conditions and edge cases for test scenarios are not applicable because the project includes refactoring and testing the refactored methods. <table>. 1. Login as an instructor. Create a new course and create a new team/individual assignment for that course. 2. Add participants to the assignment created. 3. Set the submission and review deadlines, number of submissions, rubrics for reviews, number of reviews and all the other fields for the assignment. 4. Login as a student_1, who has been added as a participant in the created assignment. 5. Now the student_1 will be able to see the assignment, form the team and submit the work. 6. After other students also submit their work, student_1 will be able to review others work and see his reviews given by others. 7. The page which displays the reviews is linked to the model which we have refactored(response.rb). In order to verify the refactoring, please perform the above steps before and after executing our code. <code>. <code>.","The section headers should be more informative.  ""Problem 1"", ""Decision 2"", etc. does not help the reader understand what the sections are about.  When you describe refactorings, it would help to include code snippets, or at least links as you have done in the next section.  Also, it is not clear how the ""Issue and Solution"" section relates to the rest of the document.  Does it cover the same problems as above?  It seems that you have done a lot of work, but the writeup leaves too much for the reader to figure out."
E2018,"Expertiza allows instructors to view kinds of reports of assignments in their courses such as submissions, scores, and review reports. To improve the report views, some table columns such as team name, score, average should be made sortable by using the same existing sort library. For the ""View Review Report"" table, the columns ""Reviewer"" and ""Metric"" are sortable. For the ""Author Feedback report"" table, the header names ""Review response rejoined"" and ""Last rejoined to"" should be changed to ""Review responded to"" and ""Last responded at"" respectively. Then all the columns in the table should be made sortable. When a user clicks on ""View Reports"" for a particular assignment a page appears with a dropdown, however the page does not say what assignments reports are being viewed. We should add a header indicating the assignment name at the top. For ""Author feedback reports"" table when no feedback has been submitted, the names of students appear in a strange horizontal format. 1. app/views/reports/_review_report.html.erb (issue 1) This file contains the code which generates the review reports table. We will add a script which makes the columns in the table sortable. 1. app/views/reports/_feedback_report.html.erb (issue 2) This file contains the code which generates the Feedback reports table. Making the columns sortable will be done in this file. 1. app/helpers/review_mapping_helper.rb (issue 2) This file has code which generates the instance variables used by the Feedback reports table and it also creates the headers used by the reports table. Changes may be needed to the header to make the columns sortable. 1. app/views/reports/_teammate_review_report.html.erb (issue 3) This file contains the code which generates the Teammates review reports table. We will add a script which makes the columns in the table sortable. 1. app/views/reports/_review_report.html.erb (issue 4) This issue requires the assignment name to be displayed for the particular review report. 1. app/views/reports/_feedback_report.html.erb(issue 5) This file contains the code which generates the Feedback reports table. We will be using tablesorter jQuery to sort the table. All changes for this issue were make in the file /views/reports/_feedback_report.html.erb The changes required for Author Feedback table were - 1. Changing the header name “Review response rejoined” to “Review responded to” and “Last rejoined at” to “Last responded at”. This was easily fixed by renaming the Headers in the Authors Feedback Table. All changes for this issue were made in the file /views/reports/response_report.html.haml Changes needed for this issue were: 1. Add a header to the top of the ""View Reports"" page for each assignment This issue was trivial to resolve. It came down to adding the following three lines of haml to the top of the aforementioned file: <code> This added a header to the top of the ""View Reports"" page reading ""Reports for <name of assignment>"". All changes for this issue were make in the file /views/reports/_feedback_report.html.erb The issues presented were - 1. For ""Author feedback reports"" table when no feedback has been submitted, the names of students appear in a strange horizontal format. <code>. No changes were made for this issue. 2. Click Assignments tab next to Courses 3. Select the ""View reports"" icon for the assignment for which you want to see the report of 4. Select ""Review Report"" from the dropdown 5. Sort the table by clicking on headers, ensure all headers are sorted properly. 2. Click Assignments tab next to Courses 3. Select the ""View Reports"" icon for the assignment for which you want to see the report of 4. Select ""Author Feedback Report"" from the dropdown 5. Sort the table by clicking on headers, ensure all headers are sorted properly and header names have been changed to appropriate values. 2. Click Assignments tab next to Courses 3. Select the ""View Reports"" icon for the assignment for which you want to see the report of 4. Ensure the header is present on the page for the assignment name. 2. Click Assignments tab next to Courses 3. Select the ""View Reports"" icon for the assignment for which you want to see the report of 4. Select ""Author feedback reports"" from the dropdown 5. Verify format for student names when no feedback has been submitted. 2. Click Assignments tab next to Courses 3. Select the ""View Reports"" icon for the assignment for which you want to see the report of 4. Verify drop down does not freeze up in any scenario.","They took into account the suggestions to replace ""Issue 1"", ""Issue 2"", etc, with the titles representing the actual problems. The also removed a lot of redundant spacing between random text elements, although, the code pasted looks a bit unformatted. It would have helped if the sections on Problem Statement and Design contained a narrative describing what was done, instead of just a list of items. The Solutions section is much better.  The UML diagram also consists of a lot of blank space. "
E1827,"Each topic can have 0 or more slots that indicate the number of students or teams that can sign up for that topic. 1. Issue #971 Change create topic UI into AJAX. 1. Issue #926 We need a way to sort topics by topic number in assignment#edit page. 1. Issue #718 We should allow instructors to give feedback when accepting or rejecting topic suggestions. Currently, when instructors manually enter topics, they have to go back and forth between the list of the topic page (views>sign_up_sheet>_add_signup_topics.html.erb) and the create topic page (views>sign_up_sheet>new.html.erb). This should be done via AJAX so that the adding a new topic can be done through an editable grid or a popup form without leaving the list of topic page. Then and the list should be automatically updated when a new topic is entered. On the file app/views/assignments/edit.html.erb we added an additional editable <tr> table element which is appended to the table when the add button is clicked in the topics table. It submits a ajax request when the 'save topic button is clicked' <code> On the file app/views/assignments/_table_header.html.erb we added an additional editable <th> table element which adds a add topic button which toggles the editable row for creating topics. <code> On the file app/views/assignments/_add_signup_topics.html.erb we initialize the new topic with max_choosers as 1. <code>. <image>. <image>. The task is to sort the Topics according to the topic number. This functionality is added using Tablesorter css, where clicking the topic# will toggle the topics in the ascending/descending order. To use Tablesorter in app/views/sign_up_sheet/_add_signup_topics.html.erb, we added this script:- <code> And made this change to the current table in html:- <code> Then to make Topic to be sortable, we added this in app/views/sign_up_sheet/_table_header.html.erb:- <code> Sorting in ascending order :- <image> Sorting in descending order :- <image>. We should allow instructors to give feedback when accepting or rejecting topic suggestions. As it is, one can give feedback on topics suggested by students only when the instructor wants the topic to be revised, not when (s)he is approving or rejecting it. Feedback should be possible in any of these cases. On the file app/views/suggestion/list.html.erb ,added an additional editable textbox and a submit button. On click of the button the feedback provided in the text box is saved to the database in a table name suggestions, column name feedback. <code> On the file app/controllers/suggestion_controller.rb ,added an additional method to save the changes in the feedback text box to database. <code> On the file db/migrate/20181027001119_add_feedback_to_suggestion.rb ,added migration scripts. Script is adding a column name ""feedback"" in the suggestions table. <code> On the file expertiza/db/schema.rb ,schema changes as effect of adding column in table suggestions. <code>. <image>. 2. Click Assignments tab next to Courses 3. Select the assignment for which a new topic has to be added 4. Click the edit icon for the assignment and go to Topics tab 5. You will be able to see the topics list in a table format. Click on add icon on the right side corner of the table header 6. Fill in the details and click save topic If a user tries to set number of slots as zero, a warning pops up and prohibits the user from doing so. <image>. 2. Click Assignments tab next to Courses 3. Click the edit icon for the specific assignment and go to Topics tab 4. You will be able to see the topics list in a table format sorted in ascending order by 'Topic# '. 5. Click on 'Topic# ' icon to sort the table in descending order based on 'Topic# ', and if you click it again after that it sorts the table in ascending order based on 'Topic# '. 2. Click Manage -> Assignments. 3. After clicking on the Assignment tab, a page will show all the assignments. 4. Click the view suggestions icon on the right bottom corner. 5. You will be able to see a list of suggestions given by the students for that particular topic. 6. Add feedback in the feedback text box and click save feedback button to save it. 7. To verify if the feedback was saved to the table, query suggestions table and match the feedback in the feedback column to the feedback given.","The write up is very well written, it includes pieces of code and screenshots of the UI both before and after changes. I think it is sufficiently detailed. They also have a test plan section explaining the cases they have tested manually."
E1872,"To track the review time that each student spend on each submitted resources is meaningful for instructors to study and improve the teaching experience. And thus records the end time. It is done using mature third-party APIs to record link review time. In this project, we require to conglomerate the details of each review given by a student on the existing Review Report page. This will ease the task for the instructor to get the insights of a review on one single page in order to grade the student based on his/her review. To accomplish this goal, here are the general solutions designed and implemented in this project: 1. Designed and implemented toggle view component using Javascript and Ruby to open students’ reviews inside the review report table 1. Used DOM to calculate and display the total time spent on the review per round. 1. Modify Review report (views/review_mapping/_review_report.html.erb) to show the total and detailed time spent on each review submissions. <image> <image>. Objective 1: The details of time spent on every assignment is displayed separately on the reviewer report page. As this is inconvenient we have to display all the statistics on the review report page. Proposed Solution: 1. We have added a link below the student ID in the first column of the review report page for each assignment. 2. This is a toggle-able link and is available to each student details uniquely as shows below: <image> 1. Clicking on the link will toggle between showing/hiding a new column containing the review details to the table. <image> 1. The table contains the details regarding the team reviewed, round number of the review, total time spent on reviewing and time spent reviewing each link in the submission. Files Changed: review_mapping/_review_report.html.erb - This is the file for the review report. We have added the functionality of a toggle link below each student id in the first column. Clicking on this link will display the details of the reviews done by this student. On clicking again the details will disappear, giving the user the flexibility of viewing these details if need be. The design makes use of the following models: 1. Participant 2. ResponseMap 3. ResponseTime 4. Assignment 5. Team First we fetch all the reviews done by the student by providing the user_id of the student to Participant which gives us the set of reviews done by that user. Then we iterate through these reviews. As reviews are based on the number of review rounds in the Assignment, we fetch the total number of review rounds for the current assignment from the Assignment model by fetching the current Assignment object using assignment id and then accessing the 'round_of_reviews' property of the object. The details of each review like the reviewer_id, reviewee_id , reviewed_object_id is stored in the ResponseMap model. We fetch the ResponseMap set for each such review from the ResponseMap by giving it reviewer_id and reviewed_object_id as the assignment id. The data for the link reviewed and the time taken for each link is in ResponseTime model which is linked to the ResponseMap through map_id. We make use of this and for each ResponseMap we put in a loop to get all possible ResponseTime for every link reviewed by the student. Finally we display this whole thing in the form of a table with the headers: 1. Team Reviewed : This is the team reviewed by the student. We get the team name by passing reviewee_id found in each ResponseMap to the Team model. 2. Total Time(mins) : This is the total time spent by the student in reviewing this team. We have written custom Javascript functions to calculate total time by adding time spent on individual links. 3. Round : This is the review round number for which this review has been performed. 4. Links : This will give you a list of links one after the other which the student has reviewed. These links are found as entries in the ResponseTime model with other information as well. 5. Time spent per link (mins) : This is the time spent in reviewing each link. Again we have written functions in embedded Ruby to calculate time in mins using the start and end times of reviewing this link. 3. Logout Login as Student who is added to the assignment - <code> 1. Go to the newly added assignment in your pending tasks(the pending task should be that of reviewing). 2. Ask for a team to review. 3. Go to each link submitted by this team and review it. If needed, note down the time spent on each link. Login as Instructor - <code> 1. Navigate to the 'Review Report' page of the assignment. 2. Search for the above student in the table. 3. Click on the link named 'Review time spent on task' below the student name. Expected - A new column should be added to the table with the information regarding the reviewed team and the time spent per link and in total.","The document does an excellent job of describing the changes to be made.  It could be enhanced by including links to code snippets in Github.  More should be said about the tests, as mentioned by several reviewers."
E1905,"The questionnaires controller had several issues; this project aimed to address some of them, including: 1. Remove or move logic that should reside elsewhere, e.g. in a model class. 2. Remove logic and references to logic that is no longer being used. 1. app/controllers/questionnaires_controller.rb 2. app/models/questionnaire.rb 3. app/views/questionnaires/_questionnaire.html.erb 4. app/views/questionnaires/edit_questionnaire.html.erb (deleted) 5. spec/controllers/questionnaires_controller_spec.rb 6. spec/models/questionnaire_spec.rb. An error occurred while attempting to extract the child content. An error occurred while attempting to extract the child content. 1. There were two methods copy and copy_questionnaire_details present in app/controllers/questionnaire_controller.rb which implemented just one functionality of making a copy of a particular questionnaire. 2. There was no need of two methods in the controller itself. Also, some parts of what was happening needed to be in the model. 1. Nothing special was happening in the copy_questionnaire_details method. Also, it needed to be placed into the model because of the nature of things happening inside it. 2. So, now we have one method copy in the controller, which calls the copy_questionnaire_details method, which is present in the Questionnaire model. The instructor_id as well as the params are passed as arguments to the copy_questionnaire_details method. 3. The other methods that the older copy_questionnaire_details methods used to call, like assign_instructor_id were removed in the changes above and they are now included in the method in the model itself. 4. The Exception (if it occurs while saving the Questionnaire object) is being handled in the copy method of the controller so that the user can be redirected easily. 1. There were parts of the code, specifically when QuizQuestionChoice was created, which was copied throughout the questionnaires_controller.rb. 1. To make the code DRYer, the repeating code sequences were added into a function called create_quiz_question_choice . 2. Calls were made to this method wherever QuizQuestionChoice was made. There is no means of testing the removal of dead code, except to run the existing suite of test cases: <code> Removal of the assign_instructor_id method can be tested by running test cases for the questionnaires controller, since existing test cases rely on the instructor ID being retrieved correctly: <code> Testing the method create_quiz_question_choice can likewise be done with this command. The logic associated with getting the instructor ID from a user is tested using <code> The additions to the questionnaires model can be tested using <code> Note: If you are having difficulties running the rspec command, try using <code> instead. This will use the gems specified in Gemfile that were installed via bundle install . Also, tests were included for the code movement from the questionnaires controller to the questionnaire model. Checks were being made for database calls in the controller rspec method, the same format was followed while writing tests for the moved methods.","Good description of what was done to address the first few issues, but making code DRYer needed snippets of the code you changed (paste in relevant lines, etc.)."
E1820,"Expertiza is an open source project that can be used by instructors to create assignments and assign them to students. Students can manage teams for the assignment and submit work for each of the assignments. After the students have submitted their work they can review other student's work to facilitate grading. The project is based on the <link> framework. You can find our <link> . Tone analysis is a tool that is used to measure the sentiment or tone of a sentence. This will be used in expertiza to help determine the tone of the review comments to determine if the feedback is useful. Since implementing a working tone analysis tool would be a project on its own we will use one that is already implemented through an NC State University project called <link> . Peer logic is going to be used to implement tone analysis throughout this project. The peer logic web service is able to provide colored HTML text based on the tone by sending a POST request of a JSON {“review”: “review comments….”} to an API endpoint <link> . The JSON data that is returned will be used to determine coloration of the cells that are displayed in the popup views as well as in the table. For reference, Peer logic assigns green to a positive tone, yellow to a moderate tone, and red to a negative tone. The basis of this project was to clean up the table in view_review_scores_popup_.html.rb . Currently, the table is very simple and unorganized, reducing its readability. There are incomplete table borders, misaligned cells, and HTML tags littered throughout the text. The other task is to create a pop up under the metrics column for the ""_answer_tagging_report.html.erb"" to show a condensed table of the tone analysis report for all the comments from one reviewer. The purpose of these changes is to help facilitate the grading of review feedback by instructors. The color coding of the tone analysis report will help see which reviews contain things like positive feedback, criticism, etc. These changes should make the grading easier for the instructors. view/popup/view_review_scores_popup.html.erb view/review_mapping/_answer_tagging_report.html.erb. The UML diagram regarding the scope of our project is included below. Overall, an existing view will be modified, and a new one will be created. Both of these views are associated with the popup_controller , which, as a result, will also be modified accordingly. We will put the code for the PeerLogic request in the controller using <link> , a jQuery API used to make HTTP requests. This request will form the majority of the backend requests we have to make in addition to the formatting that will need to be done to the data. This formatting is shown in the wireframes. <image>. These wireframes show the flow of the user to each of the updated views. You can see the implementation of the colored grid showing the tone analysis report. You can also see that clicking on one of the grid squares shows the full text of the comment. To organize each of the review rounds we felt that it would easiest to use tabs to separate them. We chose tabs over a drop-down box because of the ease of organization and also there is already a rails library that will make this easy to implement. You can also see that clicking on the summary link under the 'reviews done' column will take you to a summary of the Review Scores page which shows the highlighted text based on the tone analysis report. This is the table that will be cleaned up to make it more user-friendly. This includes removing HTML tags, adding the color coding from the tone analysis report, and general formatting issues. We have tried to illustrate all of these changes in the wireframe. <image>. We currently have one acceptance test for each of the added methods. However we believe that it should be tested more extensively. We have added some suggested tests below. <code> <code> <code> <code> <code> <code>.","The design doc unfortunately does not explain how the code works.  It just lists files modified, and does not explain how this project's code calls the web service, and how it uses the objects that it gets back.  It would be very helpful if the design doc contained actual screenshots instead of mockups.  It would also be good if the test plan had enough carriage returns to keep text from spilling over the right edge of the boxes"
E1875,"In the first round of Expertiza reviews, we ask reviewers to give authors some guidance on how to improve their work. Then in the second round, reviewers rate how well authors have followed their suggestions. We could carry the interaction one step further if we asked authors to make up a revision plan based on the first-round reviews. That is, authors would say what they were planning to do to improve their work. Then second-round reviewers would assess how well they did it. In essence, this means that authors would be adding criteria to the second-round rubric that applied only to their submission. We are interested in having this implemented and used in a class so that we can study its effect. 1. Develop UI for authors to create new questions to add to the second round-rubric. This should be a form that includes the following: 1.1. A description of the revision plan. Eg: We will add feature X to address issues a,b and c. We will modify feature Y and expect it to resolve errors d, c and e. 1.2. One or more questions for every proposed improvement. Example: 1.1.1. How effectively did feature X address / solve issues a, b and c? 1.1.2. Did modification of feature Y resolve error d? 2. The new questionnaire must be linked to the second-round questionnaire. 3. The new questionnaire must be part of the team's submission records. In the 2nd round of reviews, the Author should be able to add a statement to direct towards Author selected improvements from Round 1 to Round 2. The OSS and Final projects are different for every team. From a reviewers perspective, not all questions make sense for all projects. The motivation behind this project is: 1. Questions unique to each project gives the reviewers a perspective on the author’s objectives. 2. Allow the Author to get feedback on whether or not they accomplished their self-directed goal. This project has been extended and reworked under Independent Study in Spring 2019. 1. Direct user to Revision Planning Questionnaire. 2. Create a form for the Assignment Team to add Questions to a Questionnaire that are specific to that Submission in the second round of submission. 3. Append Revision Planning Questionnaire to 2nd Round Review Questionnaire. The first image shows a mockup of what the Author will see on the submission page to submit new additional questions for review. <image> Second is a view of what the reviewer will see. It should blend in with the review questions submitted by the instructor for all similar projects. <image>. 1. <link> 2. <link> 3. <link>. 1. <link> 2. <link> 3. <link>. 1. <link> 2. <link>. 1. <link>. 1. <link>. 1. <link>. 1. Login as 'super_administrator2' with password 'password'. 2. Make an assignment with the name 'Assignment1'. 3. Make the following selections: 1.1. Review Strategy: Allow authors to add to rubric. 1.2. Rubric: Rubric varies by round. 1.3. Add participants: Add existing students - student1, student2 1.4. Due Dates: Add deadlines for rounds. 1.5. Add topics to the assignment 4. Set 2 rounds of submissions and reviews. 5. Impersonate student1. 6. Signup for topic and form team. 7. Make submissions in round 1 submission. 8. Move to round 1 review stage. 9. Impersonate student2. 10. Make submissions in round 1 and review it. 11. Move to round 2 submission stage 12. Impersonate student1. 13. Submit a revision plan in the 'Your Work' handle. 14. Repeat above two steps for student2. 15. Move to round 2 review. 16. Impersonate student2. 17. Verify that revision plan questions are added to the review by student1'team and submit the review. 18. impersonate student1. 19. Repeat the above two steps for student1. 20. Verify that review has been received on the revision plan questions after assignment is finished. 1. <link>.","This document is fairly short.  It does not describe how the code has been changed, but rather just links to files in Github.  That is good, in the sense that the Github display is much easier to read than snippets pasted into the design doc.  But just reading one file after another doesn't help the reader understand how the code fits together.  Some narration is needed.  Reviewers were fairly pleased with the test plan.  It should have been mentioned whether the test plan referred to automated or (more likely) manual tests.  What the automated tests tested should have been defined."
E1902,"Second, evidently if a submission is revised after review, the system e-mails the reviewer saying to revise the review. It would also be nice to fix the message so it tells which review (Review 1, Review 2, etc.) has been revised, and gives the reviewer a link directly to it. Deadline reminders should include a link on where to go to perform the needed function. We added a method in the assignment_participant.rb file (model) to send mails when a participant is added to an assignment on the assignment page by importing a CSV file. We have also added a method in the course_participant.rb file(model), to send the mail when a Course participant is added by importing a CSV file. Both functionalities are implemented using the method from the MailerHelper class i.e send_mail_to_user(). 2) Sending email to reviewer when new submission is availble: Added functionality to send email to the reviewer when new submission is available by making changes in the submitted_content_controller and assignment_participant model.The method handled boundary constraints like checking whether the round was valid and disabling email notification after the last round of review. Extra functionality of specifying the current review round and providing the direct link to reviewer in the mail itself also implemented in the submitted_content controller using the ReviewResponseMap and Response class. 3) Including a specific link for the deadline reminders email functionality for reviewers : Added a review_reminder_email method and mail_reviewers method in the delayed_mailer.rb file which implemented the functionality for sending deadline reminder mails which includes a link on where to go and perform the specific task. Prepared a hash named email_list using the email and participant_id, for each participant who is a reviewer. Using this hash, we are calling the review_reminder_email function. In this function, based on the due date for the deadline_type(i.e reviewer), we fetch the participant id of the same and add it as the suffix in the URL to be visited by the reviewer. Also, the logic of the copy of mail to the instructor is also taken care. Notice that the link in the instructor's email will contain the '?id=' field of the last participant fetched. Then using expect object we verify whether the email was correctly sent by checking the subject, from and to field. Additional Links 1.1. Git pull link: <link> References 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> Team <link> <link> <link>. 1) Email sent when user is added as a participant to assignment : When students' accounts are created by importing a CSV file on the Users page,they receive e-mails but not when user was added as a participant to the assignment. We added a method in the assignment_participant.rb file (model) to send mails when a participant is added to an assignment on the assignment page by importing a CSV file. We have also added a method in the course_participant.rb file(model), to send the mail when a Course participant is added by importing a CSV file. Both functionalities are implemented using the method from the MailerHelper class i.e send_mail_to_user(). 2) Sending email to reviewer when new submission is availble: Added functionality to send email to the reviewer when new submission is available by making changes in the submitted_content_controller and assignment_participant model.The method handled boundary constraints like checking whether the round was valid and disabling email notification after the last round of review. Extra functionality of specifying the current review round and providing the direct link to reviewer in the mail itself also implemented in the submitted_content controller using the ReviewResponseMap and Response class. 3) Including a specific link for the deadline reminders email functionality for reviewers : Added a review_reminder_email method and mail_reviewers method in the delayed_mailer.rb file which implemented the functionality for sending deadline reminder mails which includes a link on where to go and perform the specific task. Prepared a hash named email_list using the email and participant_id, for each participant who is a reviewer. Using this hash, we are calling the review_reminder_email function. In this function, based on the due date for the deadline_type(i.e reviewer), we fetch the participant id of the same and add it as the suffix in the URL to be visited by the reviewer. Also, the logic of the copy of mail to the instructor is also taken care. Notice that the link in the instructor's email will contain the '?id=' field of the last participant fetched. Then using expect object we verify whether the email was correctly sent by checking the subject, from and to field. 1. Git pull link: <link>. 1. <link> 2. <link> 3. <link> 4. <link>.","Good description of the changes to be made.  I would suggest writing ""Implementation approach"" in present tense. In contrast to many documents that have long sequences of code without any explanation, yours has explanations without any references to the code.  Showing code snippets would be helpful."
E1509,"On refactoring controllers, there are some general principals listed on the <link> . For example, 1. <link> . 2. Controllers should be written in a <link> style. Following the REST convention<ref> <link> </ref>, the controllers should perform the standard controller actions, using the standard method names as much as possible. <link> is a web application developed by <link> framework. And it is an open source application and the source code can be cloned on <link> . Here is our <link> . Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.2. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.7. <link> 1.4. <link>. <code>. If not, remove the unused controller. Or, move the functions to a single controller if that makes sense to do. 2. Neither controller is at all RESTful; i.e.., its method names aren’t the standard names new , create , edit , delete , etc. Functionality is divided differently than in a standard controller. <code> 1. Functionality that should be in models is incorporated into the controller. 4. Rename the controller(s) to SignupController and/or SignupSheetController . 5. Some codes does not follow the <link> . <code> This route creates several different routes in the application, all mapping to the SignUpSheetController controller. 1.2. Writing puts sentences to test each method manually. We can find if the method is executed by checking the log on the Console. The purpose of the list method in the SignupSheet controller is to list all the topics in the specific assignment. According to RESTful rules, a method that returns a list of all available objects should be named as index . Therefore, we rename the list method to the index method in the controller and in all the files that have references to the list method of the signup_sheet_controller. Before Refactoring: Method: list <code> After Refactoring: Method: index <code> And we need to change some references to the method: <code> For some others, it is not good to combine some functions with the standard ones. For example, create function creates topics, which is one of the administrator’s functions. The controller connects the model with the view. So we move all the database related functionality in the signup_sheet_controller to related models. The following files were modified: <code> Here are two examples on how these files changed. 1. replace ""where"" in the controller with a new method in related model. Before Refactoring: In signup_sheet_controller.rb : <code> After Refactoring: In signup_sheet_controller.rb : <code> Also add a related method in sign_up_topic.rb <code> 2. replace ""find_by_sql"" in the controller with a new method in related model. Before Refactoring: In signup_sheet_controller.rb : <code> After Refactoring: In signup_sheet_controller.rb : <code> Also add a related method in sign_up_topic.rb <code>. So we separate two functions update_topic_info and check_after_create from create . And we call these two functions in create method instead of executing these codes directly. Before Refactoring: Method: create <code> After Refactoring Method: update_topic_info , check_after_create , create <code> The method update_topic_info updates topics' some attributes according to received parameters, such as permitted max number of choosers and waitlisted users. This method is separated from function create because it doesn't really do any creation works. <code> The method check_after_create check if the assignment is a microtask and if it applies to staggered deadline. These steps should be separated from create function because it doesn't actually do works related with creation. <code> In create method, the two separated methods were called. According to the controller name convention<ref> <link> </ref>, a controller should be a noun. Then the controller name sign_up_sheet_controller is revised into signup_sheet_controller automatically. Here we also make sure every reference for this controller has been changed to match the new controller name. <code> 1. Use key: 'value' , not :key => 'value' <code> 1. Use if (var) instead of if (var == true) <code> 1. Use good conditional statements <code>.","Very good writeup.  One other wiki used a side-by-side display of changes that I thought made it easier to see what had been changed.  Other than that, yours is tops.
"
E17A2.1,"We will be using Credly to make Badges. We will be working on building two badges: 1. Good Reviewer 2. Good Teammate. <image>. The topper badges will be used to honor the team(s) which scores the maximum for an assignment. We have developed two badges — ""Good Reviewer"" and ""Good Teammate"" but the design has been developed in such a way that the badging system can be easily extended to include more badges in the future. The ""Good Reviewer"" badge will be awarded to students who receive very high review grades. The ""Good Teammate"" badge will be awarded to team members who receive very high teammate review scores. By default, the ""threshold"" for earning these badges is set to a score of 95, but this value is configurable on a per-assignment basis by the instructor. A new ""Badges"" tab will be added for instructors on the ""Edit Assignment"" page where instructors can add badges and configure the badge criteria for a given assignment. Badges a student has earned can be seen when they view their ""Task List"" page, and an instructor will be able to view all badges earned by students when they view the ""Participants List"" page. <image>. “Good reviewer” is the badge that one student receives very high review grades assigned by teaching staff (by default 95). The criterion to assign badge should be configurable. After creating a new assignment, the threshold for the badges can be specified in assignments/edit page. <image>. 1. We have inserted the new code related to “Good Teammate” badge to teammate_review_response_map.rb. 2. We have inserted the new code related to “Good Reviewer” badge to review_response_map.rb 3. We have added badges to student_task/list page and a new column named Badge. 4. We have added badges to participants/list for the instructor to view. 5. We have added a tab to edit the badge attributes on the assignments#edit page. 1. As per requirement, the badges need to be displayed in the list view for both instructors and students. Thus, this list method in both the controllers need to be refactored to figure out what badges the team or an individual student needs to be awarded. 3. All business logic regarding badge assignment criteria will be put in teammate_review_response_map.rb and review_response_map.rb created for “Good teammate” and “Good reviewer” badge respectively. <image>. <image>. The following are the testing scenarios and how we went along implementing them: 1. The assignments#edit page has a tab named badges. 1.1. We login using instructor6 1.2. Visit the assignments#edit page 1.3. Try to click the Badges tab 1. In the badges tab, allow the instructor to change the threshold value of the badges, above which the badges will be awarded to the students. 1.1. The badges tab is entered 1.2. The input field for Good Reviewer Threshold is filled with 96 from 95 1.3. The input field for Good Teammate Threshold is filled with 97 from 95 1.4. Check whether these values reflect in the database 1. Assign the “Good Teammate” badge to a student when the student receives a very high average teammate review grade (higher than 95 by default). 1.1. We change to student display 1.2. Obtain teammate review score from the AwardedBadge model's get_teammate_review_score method that we defined 1.3. Obtain threshold for that assignment 1.4. If the threshold is lower, we expect to see a Good Teammate badge on the page 1. Assign the “Good Reviewer” badge to a student when the student receives a very high review grades assigned by teaching staff (higher than 95 by default). 1.1. We change to student display 1.2. Obtain review score from the ReviewGrade model's grade_for_reviewer attribute 1.3. Obtain threshold for that assignment 1.4. If the threshold is lower, we expect to see a Good Reviewer badge on the page 1. Instructor can view all badges assigned to all participants. 1.1. Login as instructor6 1.2. Visit the participants#list page 1.3. Expect to see the badges column in the page <image> <image> <image> Command to run the testcase file : rspec badge_system_spec.rb. See the screencast at <link> . This is the reason why ""Review Score"" page from instructor view takes a long time to load. This involves a large number of computations and increases the home page load time of student view by an unacceptably large margin. This will significantly reduce the latency of the Top Score badge for both student and Instructor view.","The reviewers had several concerns.  One was that the design doc did not explain why the design choices were made.  That is true, but the project was constrained by the specs, which were pretty specific about the functionality to be implemented.  Another concern was that the test plan did not consider edge cases. This seems to be a good observation. Overall, the text is readable and gives a good idea of why changes are being made and what changes are needed.  So I like it better than the reviewers did."
E1716,"However, there are cases where email notifications are sent which are redundant as well as cases where email notifications need to be sent but are not sent. Thus, a participant is notified via email whenever a review for his/her submitted work is provided. 3.Send out an email to the invitee when a participant sends out an invitation to another participant to join a team. But if an account is created by adding them as participants to an assignment when they don't already have an account, e-mail is not sent. Students should receive e-mails upon account creation, regardless of how their account is created. An email will be sent to the gmail account mentioned above. Now, sign in as the user who was invited and accept the invitation to join team. A corresponding email will be delivered in the setup gmail account. Carry out one of the tasks mentioned above (suggesting a topic, inviting members) that will cause an email to be sent. In the setup email account, you will see copies of all these emails generated. (one for each email sent to each user even though it is the same email). Updates/Changes: The suggestions controller is modified so that whenever a student suggests a topic, an email is sent to the professor. <image> The mailer function as shown below contains the to address which is the instructor's email address, the subject along with the topic name and body with the proposer's details. When a participant thus revises his submitted content, an email notification is sent to all the reviewers requesting them to update their reviews. However, in the existing system, an email is sent in both the cases mentioned above. One of our tasks was to fix this to ensure that email is sent only when needed. <image> Development Earlier Scenario: Whenever a user invites another participant to join the team, he/she can just add them in expertiza and must wait until the participant logs into expertiza to see the invitation. Changes/Updates: We have included the mailer call whenever a user is inviting a participant so that an email is sent out stating that an invitation is pending. Whenever a new invitation is created and set into waiting status, the email is call is made in controllers/invitation_controller.rb <image> The email call calls a function named 'accept_invitation' in the invitation controller where the appropriate fields required for the email are gathered and the mailer is called. <image> In the mailer, the 'accept_invitation' function is invoked where the to address is addressed to the participant who is being invited. <image> 4)Notification regarding the Accepted Invitation Earlier scenario: As mentioned earlier, whenever a participant accepts the team invitation the user who sent the invitation gets to know about the news only after logging into Expertiza which may take longer to form the team. Changes/Updates: So here, we have included a mailer so that whenever a participant accepts the team request, an email is sent to the user who invited him/her. Whenever a new invitation is accepted the status is confirmed and the email call is made in controllers/invitation_controller.rb <image> The email call calls a function named 'accepted_invitation' in the invitation controller where the appropriate fields required for the email are gathered and the mailer is called. <image> In the mailer, the 'accepted_invitation' function is invoked where the to address is addressed to the user who invited the participant to join the team in the first place. On consultation with the instructor, the instructor email was added as cc in the mails being sent. <image> 6)Sending emails when user accounts are created by adding users as participants to assignments Test Plan Here, we just had to test whether or not an email is being sent to the created users. Development Earlier Scenario A common method of importing user details to create new user accounts is by importing a CSV file containing the records of all users. On creation of new accounts, each user is notified via email. However, this is not the only way a new account can be created for a user. An instructor can create an account for a user (if it does not already exist) by adding him/her as a participant to an assignment. However, when a user account is created this way, an email notification is not sent to the user. Our job was to fix this functionality so that an email notification is sent to a user on account creation irrespective of the method of account creation. However, in the participants_controller's 'create' method, there was a mailer call when existing users (users whose accounts have already been created) are added to an assignment, by searching users by either their name/ email id. <image> Another choice was to add a mailer in the users_controller when a new user has been created. However, adding a mailer here, did not give the required functionality. Once we fetched the email address, we added a mailer call to send an email to the concerned user.","There are strengths and weaknesses in this writeup: Strengths: It is a very complete description of the changes made, with relevant code snippets provided, showing the changes made to the code. Weaknesses: The text tends to be wordy and repetitive (could be condensed considerably), and did not follow coding conventions for sections of wiki pages, which means that the individual changes don't show up in the table of contents."
E1743,"Expertiza has a feature that allows instructor i (or an admin) to impersonate a user whose account was created by i or recursively by a user that i created. This causes Expertiza to show what the impersonated user would see. Impersonating is currently performed by going to the pull-down menu at the top of the window and selecting Manage > Impersonate user. However, usually the instructor initiates impersonation after finding the student in some kind of list, like a list of users, or assignment participants, or as a member of a team signed up for a topic, etc. In this case, it is inconvenient to have to go to the pulldown menu and type in the user ID. It would be better if the instructor could just click on the ID in the list, and immediately have the impersonated user’s homepage show up. Red: The student ID previously had a link that directs to the user profile page. We have changed that to a link that would impersonate the user immediately. We did this by calling the impersonate function directly from this page and passing the user's ID as a parameter. Blue: The user profile page link was shifted to this column instead. This column originally did not have any link on it. Green: A link on the email address which now invokes a mailto: HTML link. This column also previously did not have any links. - View scores (User IDs could be shown below names in the Contributor column.) - Teammate review report ( “ “ “) All these pages display some part of the user model, meaning they have all the data from the model. Changes: The changes we made on this part are the addition of lines printing the user-ID, and it was presented with a link which calls the impersonate function, using the user's ID as a parameter. We have also switched the user profile link from the user-ID (what it was originally) to the user's full name. A mailto: HTML link has been added on the email address which generates a pop-up with the email ID. <image>. The second problem is that originally, the default for Manage > Users was to list all 6000+ users on one page, which lead to long delays. The default should be to show the first 25 users and there should be options to list 100, 250, or all users. <image> The yellow portion in the above screenshot is where we have added options to display 25, 100, 250, or all users at once, along with links to ‘previous’ and ‘next’ pages. That gem is already added to the gemfile of expertiza, but was not used in this particular page. Once added, it provides a paginate method which automatically generates a paginated list with a per_page parameter. Then that list is passed to the view, which automatically displays the necessary links such as “previous”, “next”, individual page links, etc We have reduced the complexity of the logic that was originally implemented. Previously, it populated the user list by querying the course and assignment models. Here's what the code originally looked like: <image> As suggested by Dr. Gehringer, we add a user to the user list array only if the currently logged in user is able to impersonate them. Here's what we have changed that to: <image>. Manual: Problem 1: All of the altered links will need to be tested to ensure they link to the correct pages. Tests that check if the username link correctly initiates impersonation of that user, and that clicking the full name links to the right user profile. A test user needs to be created and the email link will be used to ensure emails are correctly sent. Problem 2: For the second part of the project, tests need to be set up to check that the correct number of students are being displayed for each display option, and that the user can display subsequent pages of users. Hence, we are not planning to create automated test cases for problem 1. Problem 2: Unit Tests: We will add unit test cases in user_spec.rb. Case I: Condition: page number = 4 and per page option = 25 Result: Ensure users list contain 25 entries. Case II: Condition: page number = 1 and per page option = 50 Result: Ensure users list contain all entries. Here's what we have added in the user_spec.rb file as test cases. <image> A summary of the above code: Firstly, the objects for the user, instructor, and admin are created. Lines 74 to 83 test as an instructor, while lines 85 to 94 test as a super admin. A new object for a super admin was added in factories.rb <image> Also, we have added automated test case for negative scenario. In this case instructor is unable to impersonate any user and thus get_user_list method in user.rb returns an empty user list array.","This document explains the functionality well, but does not say how or where the link functionality is changed.  On pagination of users, it would have been good to discuss how much information was required to be displayed on each page, and how to avoid retrieving more information than is to be displayed.  As noted by reviewers, the test plan could have been described in more detail."
E2058,"Expertiza has Assignment objects, which represent an assignment that is done by some number of users. This project enabled instructors or TAs to customize viewing preference and fixed two bugs in their assigment management process. The goals of this project were to solve tow issues related to assignment management. 1. Issue 1384 : On the homepage, under the “Actions” column in the assignment list when a user (instructor orTA or admin) logs in and navigates to Manage -> Assignments (as shown below). <image> It looks crowded and is easy to be misclicked by some users. The goal of this issue is to add a preference option in user's profile where they can choose wether to show or hide detailed actions on the assignment management homepage. 1. Issue 1430 : What is wrong : 1. A TA or an instructor can assign an assignment to any course even when they don't have access to the course. 2. TAs can unassign an assignment from the course, and if they do so, they lose access to the assignment. What needs to be done : 1. Only those courses should be shown in the dropdown list of courses, the assignment is part of and the instructor or TA has access to. 2. Instructors, but not TAs, would then be allowed to change an assignment to be part of no course. tree_display.jsx profile_controller.rb users_controller.rb user.rb edit.html.erb list.html.erb assignment_helper.rb _general.html.erb assignment_creation_page_spec.rb instructor_interface_spec.rb. Before: <code> After: <code> ... Before: <code> After: <code> ... Before: <code> After: <code>. Before: <code> After: <code> ... Before: <code> After: <code>. Before: <code> After: <code>. Before: <code> After: <code> ... Before: <code> After: <code>. Before: <code> After: <code>. Before: <code> After: <code>. before: <code> after: <code>. Added: <code>. Added: <code>. Now in the user's (instructor or TA) profile page, we have two radio buttons to select from. If we choose not to show actions on the home page, and click 'save' at the bottom of the page: <image> Actions will not show up on the homepage as expected: <image>. Now if we want to assign this final project to another course, we can open up the dropdown list can choose CSC 216 (for example), and click save. <image> The action is successful. <image>. <link> Instructor username: instructor6 Instructor password: password TA username: test_TA TA password: password. 1. On the assignment homepage, if you click on the blank area of an assignment, the 'edit' icon will dispear. This issue is not in the scope of this project. Reload to get it back. 1. Other user email preferences can not be properly updated when rendering to another form, also it's a pre-exsiting issue.","In most places, there is little descripton of the changes made. Code listings occupy at least 2/3 of the document.  It would be better to use the Github diff view; with the Mediawiki boxes, it is very hard to determine what has been changed."
E1634,"Expertiza<ref> <link> </ref> is an open source project for school assignment management for instructors and students based on the Ruby on Rails<ref> <link> </ref> framework. Expertiza allows the instructor to create new assignments and customise new or existing assignments. The due_date.rb file is responsible for informing the users about the deadline for submission of the each assignment. Due dates in Expertiza have their association with many other components like assignments, reviews etc. Code Climate<ref> <link> </ref> is a tool that runs static analysis on a GitHub project and outputs many details like test coverage, complexity, duplication, security, style, and more. To refactor the following two files: 1. due_date.rb 1.1. Ternary operators must not be nested. 1. Create respective RSpec<ref> <link> </ref> files in /spec/models/ and /spec/helper folder and write unit tests for each method in due_date.rb and deadline_helper.rb. It has methods for setting due dates for an assignment, copying due dates from one assignment to a new assignment etc. The assignment also involves writing unit test cases for due_date.rb and deadline_helper.rb in order to increase test coverage. The goal of this project is to attempt to make this part of the application easier to read and write unit test cases that the application must pass. <image>. There were no existing tests for the functions in due_date.rb and deadline_helper.rb. We have added exhaustive set of RSpec tests to test all the code. For both of these two files, all Travis CI<ref> <link> </ref> test cases have passed for all previous test cases as well as the ones added by us with the test coverage for the files due_date.rb and deadline_helper.rb reported as 100%. These RSpec files have 100% code coverage visible at: /coverage/index.html. This file is located at spec/models and tests the functionalities of the due_date.rb file located in app/models. There are 18 test cases in total which are listed below. <code> <code> 1. If the function ""set_flag"" successfully sets the due_date flag. <code> 1. If the function ""due_at_is_valid_datetime"" returns nil (no errors) for a valid datetime in due_at (no invalid test cases can be added here because model does not allow invalid datetime to be set at all). <code> 1. If the function ""self.copy"" is able to copy due dates from one assignment to another. <code> 1. If the function ""self.set_duedate"" is able to create another due date by copying data from an existing due date object. <code> 1. If the function ""self.deadline_sort"" is able to sort the due dates in ascending order. <code> 1. If the function ""self.done_in_assignment_round"" returns the correct number of rounds for specific inputs. This involves an invalid test case as well for 0 rounds. <code> 1. If the function ""self.get_next_due_date"" works as expected. This involves several invalid test cases as well. <code> 1. If the function ""self.default_permission"" returns the correct default permissions for particular deadline and permission types. <code> <code> To test this file run the following command: <code> The output of this RSpec file is present in below screenshot: <image> Code coverage details of the above RSpec files is present in below screenshot: <image>. This is a test file for testing the functionalities of Deadline_helper.rb file located at app/helpers. Different test cases present in this file are: 1. Check if the factory<ref> <link> </ref> is valid: <code> 1. Fail if the due date is invalid: <code> 1. If new due_date object is created: <code> 1. due_at should be same for 0 offset: <code> 1. due_at is calculated correctly if offset is positive: <code> 1. due_at is calculated correctly if offset is negative: <code> 1. The offset is being converted to integer properly: <code> To test this file run the following command: <code> The output of this RSpec file is present in below screenshot: <image> Code coverage details of the above RSpec files is present in below screenshot: <image>. Run the following commands to test the new RSpec files created: 1. rspec spec/models/deadline_helper_spec.rb 2. rspec spec/models/due_date_spec.rb. 1. How to test creation of new assignment with due dates using U(username: instructor6, password: password)I: <link>.","The writeup is somewhat helpful, but I am bothered by the long sequences of code without any annotation.  Also, while low-level changes are comprehensively described, there's no high-level overview of the changes made to classes and methods.  Was this just a set of very localized edits."
E1661,"The website used a JQuery plugin call to sort the elements of the various tables that contained the review scores. The link to 'Alternate View' was placed right next to View My Scores. This word 'alternate' means a choice over the current option and it is absurd that it is being displayed along with the link to the other choice. The link to 'Alternate View' was removed and placed inside the Classic View of Report Scores. <image> <image> Screenshots showing the replacement of the 'Alternate View' link <image> Highlighted code snippet showing the new position of the 'Alternate View' link. While reporting scores, the system did not differentiate between Checkbox and Score Criteria and simply displayed a 1 is place of a right icon and 0 in place of a wrong icon. <image> Screenshot of the newly introduced Checkbox Criteria <image> Highlighted code snippet that showing the introduction of the Checkbox Criteria. At any time, a user must be able to view only one round of review. This was implemented using tabs where only the selected round of review was displayed and the others were hidden from user view. <image> Highlighted code snippet showing the introduction of Review Rounds in Tabs. However, a tabbed view was introduced in the ""Alternate View"" of review scores that should solve this issue. After implementing 'Tabbed View' of Report Scores and some UI fixes, this issue has been resolved. Login as an instructor: Username: instructor6, password: password Login as a student: Username: student5404, password: password. 1. Login as a 'student' or as an 'instructor'. 2. Choose an assignment that is completed and has atleast two rounds of reviews. 3. Click 'Your scores'. 4. Click 'Alternate View' shown at the top of the page next to 'Hide Stats'. 5. You can view the tables with the review score, one for each round of review. 8. Sorting functionality works for all the tables now, whereas earlier it was working only for the first table on the page. 1. Login as a 'student' or as an 'instructor'. 2. Choose an assignment that is completed and has atleast two rounds of reviews. 3. Click 'Your scores'. 4. You can view the link 'Alternate View' at the top of the page next to 'Hide Stats'. 5. As 'Alternate View' is a part of viewing scores, it should be placed on a page where users view the scores in normal format and then should have the option to go to the 'Alternate View' rather than the link placed next to 'Your Scores' in the previous page as shown in step 3. 1. Login as a 'student' or as an 'instructor'. 2. Choose an assignment that is completed and has atleast two rounds of reviews. 3. Make sure that the review questions have at least one question of the checkbox type. 4. Click 'Your scores'. 5. Click 'Alternate View' shown at the top of the page next to 'Hide Stats'. 6. You can view the tables with the review score, one for each round of review. 7. Each row in the table corresponds to a review question. 8. The questions that have checkboxes are given scores 0 or 1 depending on whether they are checked or not, whereas the other questions have a score in the range 0-5. 9. It is not very intuitive that the particular question is a checkbox type question and it might give a false impression that the score is lesser although 1 is the max score for a question of type checkbox. 1. Login as a 'student' or as an 'instructor'. 2. Choose an assignment that is completed and has atleast two rounds of reviews. 3. Click 'Your scores'. 4. Click 'Alternate View' shown at the top of the page next to 'Hide Stats'. 5. You can view the Round 1 table with the review scores. 6. At the top of the first table there are hyperlinks for viewing tables of other rounds. 1. Login as an 'instructor'. 2. Choose an assignment that is completed and has atleast two rounds of reviews. 3. Click 'Your scores'. 4. Click 'Alternate View' shown at the top of the page next to 'Hide Stats'. 5. You can view the tables with the review score, one for each round of review. 1. Login as an 'instructor'. 2. Choose an assignment that is completed and has atleast two rounds of reviews. 3. Click 'Your scores'. 4. Click 'Alternate View' shown at the top of the page next to 'Hide Stats'. 5. You can view the tables with the review score, one for each round of review. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","Very readable.  Good highlighting of code changed, but it would have helped if there were prose describing the changes made.  Screenshots show new functionality, but not how the different review rounds are shown."
E1814.2,"At this time, it only has functions to detect the cycle up to 4 people. For example, if participant A was reviewed by participant B, participant B was reviewed by participant C, participant C was reviewed by participant A and all the reviews were indeed finished, then a three nodes cycle exists. Cases including two nodes, three nodes and four nodes have been covered in collusion_cycle.rb. So there are three functions corresponding to two people, three people and four people separately. The basic algorithm of these detection functions is first to find a closed loop among reviewers. Take three people as an example, a closed loop means A is a reviewer of B, B is a reviewer of C and C is a reviewer of A. After finding the loop among reviewers, the functions will test the validation of the loop. Validation test is necessary because there may be a situation that A was assigned to be the reviewer of B but didn't do the review.That will create an invalid review response which will break the loop. Finally after the functions find a valid closed loop, the function will record all the reviewers and there scores in an array named collusion_cycles. 2. cycle_similarity_score(cycle) The function below is used to calculate the similarity which is the average difference between each pair of scores. For example, if we input a cycle with data like [[participant1, 100], [participant2, 95], [participant3, 85]] (PS: 100 is the score participant1 receives. <code> 3. cycle_deviation_score(cycle) The function below is used to calculate the deviation of one cycle which is the average difference of all participants between the standard review score and the review score from this particular cycle. For example, if we input a cycle with data like [[participant1, 95], [participant2, 90], [participant3, 91]] (PS: 95 is the score participant1 receives.) <code>. For all three functions of collusion detection, the tests can be divided into three parts: test the loop closure, test the review validation and test the final output result. So for the unit test of this function, we first test no collusion situation that participant1 is not a reviewer of participant2. Then we test if response12 or response21 is invalid. Finally we offer the function a totally valid two_node_cycle and test its output. <code> Above is the code for two_node_cycle function test. It's easy to see the test is divided into 3 situations--no collusion, collude but one of the review responses is nil and collude and all responses are valid. These three situations are the basic format of two_node_cycles test, and the following functions are tested by the same way. The only differences are some details, such as the number of responses or how to set the no collusion situation. 2. three_node_cycle <image> For three_node_cycle, we first test no collusion situation. And for no collusion test we don't have to test all the disconnected situation, such as participant2 is not a reviewer of participant1. We only need to test the last connection of the loop--participant1 is not a reviewer of participant3. Then we test validation of all the responses. Set these responses to be nil separately and see what will happen. In the end we input a valid three_node cycle to see if the output result is what it supposed to be. The test for no collusion sets participant1 not to be a reviewer of participant4. Then set the responses to be nil separately to test the validation. Finally create a valid four_node_cycle and test the output result. 1. cycle_similarity_score(cycle) The code below is the unit test for the cycle_similarity_score(cycle) function in CollusionCycle class. The function is very simple, as it doesn't call any other functions. So for each cases, 2 nodes or 3 nodes, I set different cycle as input and check the result of the function. <code> 2. cycle_deviation_score(cycle) The code below is the unit test for the cycle_deviation_score(cycle) function in CollusionCycle class, It calls review_score method from AssignmentParticipant class. This method will return a standard score of the participant. So I set the results of review_score method for each participant. And also set different cycles as input and check the result of the function. <code>. The following figure is the coverage result of our test. <image>. 1. This model can only test cycle containing up to 4 nodes, maybe functions for cycle with more nodes can be added. 2. Apart from adding more functions, combination of all these cycle functions into a new function with parameter n, which represents the number of nodes, will be a better choice. So that detecting cycle with different nodes can be realized by calling the same function with different parameter rather than adding a new function.","This is a good description of what the module is doing, and also a good explanation of the tests.  The authors have included diagrams of the information flow and a screenshot of the running tests.  The only shortcoming is that the diagrams and screenshots would be more readable if they were smaller."
E1711,"1.2. The perform method uses a giant case statement, instead we were to incorporate the use of polymorphism 1.3. The mail_signed_up_users is long and should be broken into smaller and better named methods 1.4. Add/modify test cases as we added/removed/modified areas of the code Information about the assignment can be found on <link> NOTE: All our changes and updates on the project is committed on the ""oss-branch"" in our remote git repository, not the ""master"" branch. As this was a purely refactoring effort, our testing consisted of confirming existing tests did not break, modifying existing tests to match our changes, or adding tests as needed. Below Summary table delves into details of the test cases. <image> <image> Instead the below table summarizes the test cases for delayed_mailer.rb Much of our work consisted of modifying the existing tests so they were more thorough and adding some tests. The selection of the added tests were to verify the functions that were restructured as a part of this effort. Functions that were not touched are out of the scope of this assignment so no tests were added there. Adding tests for other functions can be a future assignment. You can find the test cases in delayed_mailer_spec.rb Also you will note at the start of the tests, a lot of information is created in the DB. Also note that for each of the groups getting emails, the test cases only deliver one email. <table> Our team tried to improve the test file. Well..that was a very poor quality test from our perspective, because the actual functionality of sending emails per different deadline type was not tested and besides that, there were no assignment, no topic, no user, and etc in the test scenario at all. Now in our test cases we have created all the necessary objects and set their relations to create a fair test environment with an assignment, topic, team and user, then added test cases which actually test the ""perform"" method functionality (perform method is the major method of DelayedMailer which eventually sends emails to certain recipients per deadline type). Therefore now we claim our tests cases provide a higher confidence rather than before when they pass. Unfortunately, we found we could not rename the method because the delayed_job gem requires a method named perform in order to work on a custom job. At that point, we weighed the complexity of new code to use polymorphism versus a significantly more simplified case statement, and because of the lack of existing tests, decided that the simplified case statement was not only short, it is also very simple to follow the flow through the code. There were six existing Rspec tests for delayed_mailer.rb , but the existing tests only verify that a new delayed job was added to the queue based on the type of deadline specified when creating a new DelayedMalier . We made the existing tests more complete by adding in sections that properly created the data objects. We also added verification that once the job is executed, the deadline type for the job is what we expected. The six existing tests that we modified were scenarios 1 to 6 listed above. We modified existing test cases for the perform method to be more thorough. The primary objective of this task was that the method is long and could be broken into smaller appropriately named methods. We replaced the existing single method mail_signed_up_users with a shorter version and a new method find_team_members_email_for_all_topics . We also heavily modified (including renaming) the existing method getTeamMembersMail , and it is now called find_team_members_email . Merging the two would require refactoring areas outside the scope of this assignment and a whole new set of test cases to verify a lot of basic functionality is not broken in the process. We recommend this is taken up as a part of a future assignment. We did not find any existing automated testing targeting this area of the code. None of the six existing tests verified if the emails are being retrieved from the database so changes in the database schema would break the feature. We added test cases for each of the methods we changed. There are now 10 test cases that are covering this file. The four new test cases focus on verifying that the functions can access the database to protect against schema changes and making sure the right methods are called. Tests were not added for code that was not within the scope of this assignment but we recommend the remainder of the functions also get similar test cases. It needs to be a standalone file with new tests added. 3. There were practically no tests for this area of the code. We added tests for what we modified but much code still remains that is not being tested. 5. We found out that all assignments in Expertiza are team assignments and querying if the assignment is a team assignment is hardcoded to return true. perform does have some business logic where the recipient of the email depends on whether or not the assignment is a team assignment.","Very good writeup, as far as it goes.  Good discussion of test cases and reasons for refactoring.  It would have helped to see some code snippets.  Good section on Future Refactoring Opportunities."
E1744,"We will add a new feature to provide Expertiza with Github metrics (for example, number of committers, number of commits, number of lines of code modified, number of lines added, number of lines deleted.) from each group’s submitted repo link. This information should prove useful for differentiating the performance of team members for grading purposes. It may also help instructors to predict which projects are likely to be accepted/rejected (even before the final due dates). This project is divided into two parts. One is to extract Github metadata of the submitted repos and pull requests. The second part to be built at a later time is to build a classifier (e.g., Bayesian) to do the early prediction on some projects that are likely to fail. This prediction is based on more than 200 past projects (Fall 2012- Fall 2016). Based on the meta-data from students repos/pull requests, we can warn both authors and teaching staff if our model predicts that some projects are likely to fail. The methodology of this project is to add a means to monitor the individual contributions of various team members throughout the duration of project in order to quantitatively access their work. This will aid the teaching staff and team members during the review process as well as improve visibility to a student of the work he or she has committed. When an instructor goes to the submission records page for particular team on a project, a link will be added below each hyperlink called ""View Github Metrics"" in order to request the metrics from Github on demand. <image> If the link is not a valid github page the controller will return a ""No Results Found"" page. <image> If the link is valid it will pull data from Github using the API described below and show the lines added, lines updated, and lines deleted. <image>. 1. First, get an access token from github. Here are the <link> 2. Save the access token in the environment variable 'EXPERTIZA_GITHUB_TOKEN' 3. Now, github data is fetched from github's <link>. This feature has similar functionality with a web crawler, which is crawling the data from a server and store locally. So that for the architectural style of our subsystem, we would like to choose client/server style, which segregates the system into two applications, where the client makes requests to the server whenever a user is looking for the metrics. In many cases, the server is a database with application logic represented as stored procedures, in our case, is Github. <image>. <image> A new table called github_contributors is created to store the data for each committer. The table contain's the committer's email, github_id and all the metrics associated with a project. At the moment we handle the following metrics: 1. Committer email - commiter_url 2. Committer id - commiter_id 3. Total number of commits - total_commits 4. Number of files changed - files_changed 5. Lines of code changed - lines_changed 6. Lines of code added - lines_added 7. Lines of code removed - lines_removed 8. Lines of code added that survived until final submission - lines_persisted. 9. submission_record_id - Foreign Key to submission_records table. An index on committer_id is added to enable search. The tests will use rspec to validate the unit testing of the system by testing the github contributor controller. To run the rspec test, from the top expertiza directory execute the following command ""rspec spec/controllers/github_contributors_controller_spec.rb"" to run the four unit tests. <table>. THIS WILL NOT BE IMPLEMENTED AS PART OF THIS PROJECT. This is future work to be done.","A pretty terse description of the changes to be made, but considering the Github documentation that is linked to, it is sufficient.  Reviewers did fault the authors on not having a detailed enough test plan.  Also, the document should have said something about how the new views would be integrated into the UI ... how instructors and students would navigate to them.  Would have liked to have seen smaller pictures, so it wouldn't be necessary to scroll to see the whole thing."
E1633,"1. Currently, Expertiza has a quizzing feature which allow student authors to create quiz questions and “test"" the peer-reviewers. The idea behind this is, if a reviewer can answer the quiz questions which were created by the author correctly, we assume that the reviewer has read the artifact carefully enough and thereby we trust the peer-review. 2. Quiz questionnaire is one sub type of questionnaire, so it should follow the design of other type of questionnaires. 2. The different methods defined were edit, view_completed_question, complete and view_question_text. 3. The above methods generated the specified HTML content for the specified question types, namely : MultipleChoiceCheckbox, MultipleChoiceRadio, TrueFalse. 1. When the user chooses the ‘edit’ option in a quiz, the edit method is called. Based on our modification of the view, the edit method is now invoked from /view/questionnaires/_quiz_questionnaire.html.erb 2. When a user tries to take a quiz by pressing on ‘begin quiz’ in the UI, the ‘complete' method is invoked by the given view : view/student_quizzes/take_quiz 3. When a user chooses the option ‘view quiz’ or ‘view quiz questions' in the system, the view_question_text method is called which renders the view : view/questionnaires/view.html.erb 4. When the user decides to choose option ‘view’ on a completed quiz, the view_ completed_question method is called on view/student_quizzes/finished_quiz. The view_question_text method is called when the author of the quiz or the instructor views the quiz. The method is responsible for generating the HTML to display the question along with each of its choices. The correct choice(s) should be bolded. Now the view simply needs to call the method: <code>. The edit method is called when the author creates or edits a quiz. It makes every element of the quiz editable. Prior to refactoring, the HTML was in app/views/questionnaires/_quiz_questionnaire.html.erb : <code> After refactoring, the same file looked like: <code>. Logic is written in multiple_choice_checkbox model for multiple choice checkbox question type. Similarly, same process is followed for remaining question types. To begin a quiz, complete is called from the model. <code>. The logic for viewing completed question and their answers was written in the view app/views/student_quizzes/finished_quiz.html.erb . <code> The app/views/student_quizzes/finished_quiz.html.erb was refactored by removing the logic from the view and making it clean by using a single construct which determines question type and answer type by calling view_completed_question method declared in quiz class as shown below. <code> Similarly, logic was written in models for each of the question types. Following code snippet shows view_completed_question for true/false question type. <code>. But here are tests for each method to verify they are working correctly. 1. Login as a student. 2. Select a quiz assignment. 3. Select ""Your Work"" 4. First you will have to create a quiz by clicking on the link ""Create Quiz"". 5. Select ""View quiz"". 6. You should see each question, followed by the choices. The correct choice(s) will be in Bold. 1. Login as a student. 2. Select a Quiz Assignment. 3. Select ""Your Work"" 4. If you haven't created a quiz yet, go ahead and create one by clicking the ""Create Quiz"" link. 5. Select ""Edit quiz"". 6. You should see each question, followed by the choices, each in an editable text field. The correct choice(s) will be checked. 1. Login as a student. 2. Select an assignment that has quizzing enabled (e.g. Quiz Assignment). 3. Select ""Your Work"" 4. If you haven't created a quiz yet, go ahead and create one by clicking the ""Create Quiz"" link. 5. Select ""Take Quizzes"". 7. You should see each question, followed by the choices. Your answers will be saved. 1. Login as a student. 2. Select an assignment that has quizzing enabled (e.g. Quiz Assignment). 3. Select ""Your Work"" 4. If you haven't created/taken a quiz yet, go ahead and create one by clicking the ""Create Quiz"" link and take the quiz. 5. Find a finished quiz and click on 'View'. 6. You should see each question, followed by the choices. The correct choice(s) will be in bold and your recorded answer will be shown.","Most of the writeup consists of code snippets.  At the very least, these snippets should have been annotated to explain the changes that were made.  There was some explanation, typically 1 sentence, but it paled in comparison to the volume of code."
E1666,"Expertiza is an open source web based peer review system developed and maintained by students and faculty at North Carolina State University. It enables students enrolled in a particular course to form online teams and complete assignments. A typical cycle of an assignment involves the following major steps: 1. A pool of topics is made available to the students to choose from and form team to complete it within a pre-set deadline. 2. After the development phase is finished, begins the peer review phase. Here students can review work of other teams, on the basis of some predefined factors and provide their feedback. 3. Members of a team can also provide feedback for the respective review done for their work. 4. In some projects there is a second development phase which allows team members to improve upon their work keeping past reviews in consideration. 5. After this second development cycle begins another review phase, where original reviewers can re-review the updated work and provide critical feedback. The purpose of this task is to write functional tests for team functionality. Once an assignment is out, a student can select this assignment and others can join in the team. To test this functionality we wrote functional tests for the various scenarios. One such scenario is : 1. Once the assignment is out and a student selects it, he/she can send out invites to other students to join the team. 2. Invited students can accept the invitation and join the team. Functional tests ensure that the functionalities of a software system are working as expected. To write our functional tests, we used the Capybara gem available for Ruby. Capybara gem allows a user to test their web application through simulations. In Expertiza assignments, the only way for a student to join an existing team is to be invited by the leader. Therefore, we will test whether the invitation function run smoothly. But before the test, we need to initialize some information. <code> Here, we created a team, and set the maximum students to 3. Because there can only be one student in each session of browser, we need to create different sessions for different students. The first session is for the leader who will be the first one who select this topic. <code> So far, a team has been created by ‘student2064’, who is the leader. Then, we will let him send an invitation to another user ‘student2065’. Now, let’s create a new session which allows ’student2065’ to log in. After the login, we need to test if he receive the invitation and if he accepts it, whether or not he will be in the team. If he is included in the team, he will be able to see the name of the leader, who is ‘student2064’. <code>. Same as the previous one, we set up the information at the beginning, and then let ‘student2064’ to pick up a topic and send an invitation to ‘student2065’. This time, we will let ‘student2065’ to choose to reject this invitation. If he declines the invitation, the invitation will disappear. <code>. The tests can be run on the terminal using the command: <code> Whether the test fails or succeeds, allows us to determine which parts of the system are functioning properly. <image> <image>. 1. link for forked repository [ <link> ] 2. Github link for original repository [ <link> ] 3. Github link for Capybara [ <link> ].","This is not a long wiki page, but one that does exactly what it needs to: explain the tests to be coded, explain how they are coded, and display the test code."
E1850.1,"<link> is an open source web based peer review system developed and maintained by students and faculty members at North Carolina State University. It enables students enrolled in a particular course to form online teams and complete assignments. <link> is a 'Domain Specific Language' (DSL) testing tool written in Ruby to test Ruby code. It is a behavior-driven development (BDD) framework which is extensively used in the production applications. The basic idea behind this concept is that of Test Driven Development (TDD) where the tests are written first and the development is based on writing just enough code that will fulfill those tests followed by refactoring. It contains its own mocking framework that is fully integrated into the framework based upon JMock. The simplicity in the RSpec syntax makes it one of the popular testing tools for Ruby applications. The RSpec tool can be used by installing the rspec gem which consists of 3 other gems namely rspec-core, rspec-expectation and rspec-mock. <link> is the model file of review response in Expertiza. Expertiza has a function called review, used to provide suggestion to the author of a particular project, hence, the author could give feedback to the reviewer. The review_response_map.rb is responsible for manages the data, logic, and rules of review response. The reveiw_response_map.rb did not has test file. We write RSpec test file review_response_map_spec.rb which tested if the model file run all function properly. The RSpec test tests all 14 methods in the model file with 26 test cases. The test covers lots of edge cases and tests real-life conditions. Also, by using RSpec test we found several bugs in the review_response_map.rb file, and thus author could fix it. 1. Source code <code> 1. Process This is to find certain questionnnaire. Help method: let(:assignment) { build(:assignment, id: 1, name: 'Test Assgt') } 1. Test code 1. when round is not nil <code> 2. when round is nil <code>. 1. Source code <code> 1. Test code <code>. 1. Source code <code> 1. Process This is to delete certain record. When delete, this function will return the record. 1. Test code <code>. 1. Source code <code> 1. Test code <code>. 1. Source code <code> 1. Process This is to export records to csv files. One review_response_map is a record. 1. Test code <code>. 1. Souce code <code> 1. Process This is to import certain record. We use a hash {reviewee: 'person1', reviewers: ['person2']} to do the test. When user or participant of reviewee is nil, ArgumentError will be raised. When they are not nil and team exists, we use reviewee_team, reviwee_user, reviewer_user, reviewee_participant, reviewer_participant to test the method. When the team doesn not exist, we need to first use TeamUser, TeamNode and TeamUserNode to create a reviewee_team. 1. Test code 1. when the user of the reviewee is nil <code> 2. when the user of the reviewee is not nil 2.1. when the participant of the reviewee is nil <code> 2.2. when the participant of the reviewee is not nil <code> 2.2.1. when reviewee does not have a team <code> 2.2.2. when reviewee has a team <code>. 1. Source code <code> 1. Test code 1. when there is no review responses and the response parameter is nil <code> 2. when there exist review responses or the response parameter is not nil and when author feedback response map record does not exist or there aren't corresponding responses <code> 3. when author feedback response map record exists and there exist corresponding responses <code>. 1. Source code <code> 1. Test code <code>. 1. Source code <code> 1. Test code <code>. 1. Source code <code> 1. Test code 1. when the review user is nil <code> 2. when the review user is not nil <code>. 1. Source code <code> 1. Test code <code>. 1. Source code <code> 1. Test code 1. when round number is not nil and is bigger than 1 <code> 2. when round number is nil or is smaller than or equal to 1 <code>. 1. Source code <code> 1. Test code 1. when the round is nil <code> 2. when the round is not nil <code>. The tests can be run on the terminal from inside the expertiza folder using following command: <code> The test coverage is 100% in 102 relevant lines. <link> <link> <link> <link> <link>.","Some of the tests are not described at all (there's just a bullet that says, ""Source code"").  Long tests (e.g., final_versions_from_reviewer) should have some prose describing the various steps in the test. Also, the outcomes should be described (why they pass or fail). It would also be good to motivate why the tests are listed in the order that they are."
E1556,"Suggestion Controller is a module for students to suggest a new topic for their writing assignments, and instructor can approve the suggestion. Typically, there are three cases when instructor approves the suggestion. First, if the student already has a topic and when suggesting a new topic, he chooses 'Yes' in the signup_preference, he will enroll the new suggested topic automatically after the instructor approves the suggested topic. Second, if the student is in the waitlist of a topic, and when suggesting a new topic, he chooses 'Yes' in the signup_preference, he will enroll the new suggested topic and be removed from the former waitlist. Third, if the student is in the waitlist of a topic, and when suggesting a new topic, he chooses 'No' in the signup_preference, after the instructor approves the new topic, he will remain in the waitlist of former topic, and new topic is left as 'no chooser'. The hash operator using the ""hash rocket"": <code> Need to be changed into: <code>. First, approve the suggestion by create a new record in the SignUpTopic model, set relative parameters, and save the new record. Then send notification to the team. In the notification part, if the student doesn’t have a team, a new team should be created and assigned to the suggested topic. Besides, creating a new team can also be written as a new method. After refactor, there are four new methods: approve, notification, create_new_team, and send_email. <code>. For instructor, after log in, please click 'assignment' and click the pencil shape button to edit the assignment: <image> The open the suggestions function by check the second checkbox under 'topic' tab: <image> Click save button at the end of the page: <image> After a student suggestion as topic (see description below), click the archive box shape to view the suggestion: <image> You should be able to see the list of suggested topics. <image> For student users, first you need to login your account, find a certain course, and make suggestion <image> Then, based on your need, choose if you want to work on the suggestion you suggested. <image> After saving, there will be a flash message on your webpage, and the suggested topic would be shown. <image>. In the first test, we are going to test the result of approving a student's suggestion topic if the student is in a waitlist. He will be removed from the waitlist and added to the new list, if he selected the signup_preference to be 'Yes'. We choose 'Writing Assignment 1a' of 'CSC/ECE 517, Spring 2015' as test assignment. I simulate creating a new suggestion with student5717, in team 'Writing Assignment 1a Team14'. First, log in as Student5717 and suggest a new topic, and choose 'Yes' in signup_preference. <code> Then, log out Student5717, and log in with 'instructor6' account, who is the manager of this course. Then approve the suggest. <code> Finally, check if suggestion approved successfully. I need to check topic list with 'instructor6' account logged in and check the selected topic in student5717 account. <code>. For the second test, Writing Assignment 1a team1, whose team id is 23781, was chosen to perform a serial of action. Team no.23781 is holding a topic: Amazon S3 and Rails. And Writing Assignment 1a team5, whose team id is 23800, is in the waiting list of this topic. First, sign in as Student 5404 from team1, send a suggestion for new topic and indicate they want to choose their suggested topic. <code> Then sign in as instructor6 and approve the suggested topic. <code> Finally, to check the results. On the one hand, sign in as student5404 again and see if her/his team is holding the new topic. On the other hand sign in as instructor6 and check if team no.23800 is holding the old topic: Amazon S3 and Rails. <code>. The third test is similar to the second one. Team no.23781 and assignment no.711 are chosen for this test again. First, student no.5404 login to the system, visit the assignment page, and make a topic suggestion. In the suggestion, instead of choosing “yes” in signup preference, the student chooses “no” in order not to use the suggested topic. <code> After the suggestion is made, login as an instructor, find the assignment, and approve the suggestion. <code> In the final step, we check if the new topic is shown in the topic list, then login as student no.5401 again, check if they still hold their old topic. <code>. All test cases passed. <image>.","A bit long on the code snippets, but otherwise good. Clearly describes the motivations for the changes, and how changes were made."
E1503,"Classes involved: <code> Modules involved: <code> What they do These class are responsible for calculating top 3 individuals which is to be displayed as the leaderboard for the class and generate a metric which aggregates peer review scores for all course assignments and then sorts individuals. What needs to be done Methods like getParticipantsScore and extractPersonalAchievements needs to be refactored as these single functions have multiple responsibilities. They can be modularized delegating single resposibility to single method. sortHash method is not an explicit leaderboard model and can be moved to helper methods. Some snippets of code are redundant and have no effect on functionality. They can be removed. Leaderboard model was having public methods containing more than one feature in each method. We refactored such public methods in necessary public and private methods. Since we didn't create any new public method, we used the existing test cases to validate the changes. We removed helper methods from model class to respective helper class and changed all the references in model and controller classes. <table>. <table>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. <code>. We didn't create any new public method as part of this project, instead we refactored the existing code. Existing test suit was suitable for testing our modifications. <references/>.",The wiki is good and indicates that they did decent work.
E1908,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.4. <link> 1.1.5. <link>. <link> is an open source project dependent on <link> structure. Expertiza enables the teacher to make new assignments and alter new or existing assignments. It additionally enables the educator to make a rundown of subjects the students can agree to accept. Students can shape groups in Expertiza to chip away at different undertakings and projects. Students can likewise peer audit other students' entries. Expertiza underpins accommodation crosswise over different record types, including the URLs and wiki pages. The following tasks were accomplished in this project: 1. Improved the clarity of code by improving the variable and parameter names. 2. Followed naming conventions throughout and renamed methods with inconsistent names including the calling methods. 3. Rectified several unwanted if-else conditions in methods and optimized the code. 4. Refactored all instance variables and removed unnecessarily defined variables. 5. Removed certain unwanted flash messages that occur for some user actions. 6. Included comments for functionalities throughout for better understanding. Sign-up sheet controller contains all functions related to management of the signup sheet for an assignment function to add new topics to an assignment, edit properties of a particular topic, delete a topic, etc are included here. 1. Problem 1 : Create method has an if-else condition determining if create or update should be called. Create method should not be responsible for calling update. Identify why the if-else condition exists. The if-else condition exists because the current implementation calls update if a signup sheet with the same name already exists. 2. Solution : Rectified this method by removing the call to update and flashing an error instead. <code> 1. Problem 2 : Update method has a plethora of instance variables defined before updating. These are not necessary (For e.g., look at update method of bookmarks_controller). 2. Solution : Refactored the variables not needed out. <code> 1. Problem 3 : Destroy has a misleading else flash message. 2. Solution : Refactored the mislleading flash messages not needed out. <code> 1. Problem 4 : Add_signup_topics_staggered does not do anything. 2. Solution : Renamed participants variable to 'teams'. <code> 1. Problem 5 : Several method names are renamed to be more intuitive. 2. Solution : load_add_signup_topics is renamed to get_assignment_data and ad_info is renamed to get_ad. <code> 1. Problem 6 : The list method is too long and is sparsely commented. 2. Solution : Added comments. <code> 1. Problem 7 : What are the differences between signup_as_instructor and signup_as_instructor_action methods? Investigate if they are needed and improve the method names if both are needed. Provide comments as to what each method does. 2. Solution : signup_as_instructor specifies the student and displays a new page called via a get request whereas signup_as_instructor_action is an action called via post request which aims to signup a student. 1. Problem 8 : Participants variable in load_add_signup_topics actually means teams that signed up for a topic. 2. Solution : Renamed participants variable to 'teams'. <code> 1. Problem 9 : Signup_as_instructor_action has if-else ladder. 2. Solution : It has been made more elegant using a helper function. <code> 1. Problem 10 : Delete_signup and delete_signup_as_instructor have much in common and violates the DRY principle. 2. Solution : Refactored them by moving the duplicate code to a helper function. <code>. As the project involved only refactoring variables and method names, only build tests and already existing unit tests were performed. 1. <link> 2. <link> The live Expertiza website.","To show the changes made, it would've been better to illustrate the difference between before and after, rather than just display the ""after"" code.  When you remove code, it should be removed rather than just commented out.  And the running text does not describe how the code works, just the changes made.  For someone following on, it would be much more useful to have a description of how the code works. "
E1474,"E1472: Connect changes to score model with changes to score views Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.1.1. <link> 1.1.1.1.2. <link> 1.1.1.1.3. <link> 1.1.1.5. <link> 1.1.1.6. <link> 1.1.1.7. <link> 1.4. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.5. <link> 1.1.1. <link> 1.1.2. <link> 1.6. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.7. <link> 1.8. <link> 1.1.1. <link> 1.1.2. <link> 1.9. <link> 1.10. <link> 1.1.1. <link> 1.1.2. <link> 1.11. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.12. <link> 1.13. <link>. One of the Expertiza features is to report scores to both students and the instructor. The student can see the feedback from other students, such as the max score, the min score and the average score. Current System (After Refactoring Grades_controller): <link> <code> Student: user1600 and user1601 Password: test Original System (Before Refactoring Grades_controller): <link> <code> Student: user1600 and user1601 Password: test All our test result based on the following test cases on expertiza, please follow these step to get it. <code> Student: <code>. <code>. <code> <code> <code> <code> <code> <code>. <code> <code>. <code> <code>. <code>. <code>. <code>. <code>. <code>. The view method reports everyone’s grades to an instructor, and the view_my_scores method reports peer-review scores to a student. The grades_controller class is responsible for displaying grades to students (via view_my_scores) and instructors or Teaching Assistant (via the view method). <image>. 1. view method : handle the functionality of viewing the assignments of the whole class. 1. view_my_scores : take care of displaying the scores pertaining to an assignment to a single user. <image> The figure above mainly illustrates the process of viewing scores for different actors. The instructor and teaching assistant are able to view scores of all the team and could see the reviews of a selected team. Student actor can see his own scores and reviews. For example, when a student want to view his/her grades, there must be something in the database (precondition). <image> The RScore class stores the variables maximum,minimum, average review scores. Create rscore class in models (rscore.rb): <code>. Before: (views/grades/_participant.html.erb) <code> After: (views/grades/_participant.html.erb) <code>. Before :(views/grades/_participant.html.erb) <code> After :(model/assignment_participant.rb) <code>. At the beginning of the final project, the function of viewing scores is very slow by students and instructor. 1. Modify get_assessments_for method in response_map.rb After doing this, the time cost of view function decreased by more than 90% Before Refactoring: <code> After Refactoring: <code>. <table> 1. Original Time for Instructor to View all scores <image> Original Time for Instructor to View all scores 1. Time for Instructor to View all scores after Refactoring <image> Time for Instructor to View all scores after Refactoring 1. Original Time for Student to View all scores <image> Original Time for Student to View all scores 1. Time for Student to View all scores after Refactoring <image> Time for Student to View all scores after Refactoring. <image>. <image>. <image>. <link> <link> <link> <link> <link>. We will stick to the UI design of the grades view and see what else we can do to further improve the performance of the system.","Some of the peer reviewers complained about a lack of design principles/patterns, but this has been addressed.  However, one of the reviewers mentioned that the SSL algorithm is not described, and should be.  I'm not sure I would endorse that, but it would sure be nice to explain how OAuth 2.0 would work in conjunction with Expertiza.  Other than that, fine job.  It really explains how the implementation will be done."
E1551,"It was developed in Ruby on Rails. After completing the project there is an option for submitting reviews as well and updating the reviews. There is an option for submitting new quizzes as well. What it does : response_controller.rb manages Responses. A Response is what is generated any time a user fills out a rubric--any rubric. This includes review rubrics, author-feedback rubrics, teammate-review rubrics, quizzes, and surveys. Responses come in versions. Any time an author revises work, and the reviewer comes back to review it, a new Response object is generated. This Response object points to a particular ReponseMap, which tells who the reviewer is, which team is the reviewee, and what the reviewed entity is. 1. To test the responsecontroller login as user:instructor6 with password:password 2. Go to assignments tab and choose any assignment from the assignments listed. 3. From there click on others work and choose any review among the reviews listed 4. Click on view or begin to start reviewing. 5. You can also test response controller in similar way by logging as student student2064 and password:password. Problem definition latestResponseVersion is misnamed. It returns all versions of a response, and anyway, the method name should use underscores, not camelcase. Solution summary Renamed latestResponseVersion to set_all_responses . Examining latestResponseVersion we were able to determine that it did the following two things: 1. Set the @prev variable to a relation of responses that correspond to the map id of the current response being created or edited. 2. Set the @review_scores variable to an Array version if the contents of @prev . Since the purpose of the code seemed to be to set variables, we renamed it to set_all_responses . We also simplified the method by using ActiveRecord::Relation's to_a to convert the relation to an array. There was some duplicate code in the scores function which we replaced with a call the set_all_responses . Problem definition get_scores has a Java-like name. It should just be scores . Solution summary The method get_scores was renamed to scores . Problem definition The 100+-line method rereview does not seem to be used anymore. The second-round review can be invoked in the same way as the first-round review. Solution summary The method rereview was deleted. Problem definition create and update use completely different code. Factor the common parts out into a partial, thereby simplifying the methods. Solution summary There was not much actual overlap in these two methods. The ResponseController controller has an overall problem in that it knows too much about the subclasses of ResponseMap . There is some major refactoring that needs to occur to clean up this controller's coupling with ResponseMap 's subclasses. We made an attempt to do this, but it was just to large a change to accomplish in the time allotted. Problem definition Authorization needs to be checked in the action_allowed method instead of in redirect_when_disallowed at the bottom of the file. Solution summary So the functionality is moved from redirect_when_disallowed to action_allowed . And also it is made sure that no one other than the author of a review (or another team member, in the case of author feedback) can edit it and then removed the redirect_when_disallowed method. Code before changing <code> <code> Code after changing <code>. Problem definition get_content is a complex method. It should be renamed to content and simplified. Comments should be added explaining what it does. Solution summary The get_content method was renamed set_content , simplified, and documented with comments. A review of the get_content method showed that it's purpose was to set various variables for use by the response views. As such, we renamed this method set_content to help clarify it's intent. We also extracted methods for the more complicated variables into their own methods, making the set_content method easy to understand at a glance. Problem definition This class contains SQL queries. Solution summary No SQL queries were identified. Major refactoring revolved around changing method names according to rails convention, using helper methods for avoiding duplication of code in controller methods. Duplications in Code Original duplications : 172 Post Refactoring : 21 Code Complexity (Compared on Code Climate) Original ResponseController <ref name=""originalresponsecontroller> Original responseController <link> </ref> <image> Refactored Responsecontroller <ref name=""Refactoredresponsecontroller> Refactored responseController <link> </ref> <image>. Some functional tests are written for this class using Rspec. The test coverage has increased from 19% to 24.1% To check these tests. 1. clone the github repository link provided above 2. run the command rspec spec/controllers/response_controller_spec.rb.","The level of coverage of your changes seems to be a little inconsistent; some bigger changes are not described in as much detail as small changes (e.g., rename get_scores)."
E1504,"Classes involved: <code> What they do: The bookmark model and controller work together to create and maintain user specific bookmarks, which can be added to different topics. As a functionality added for convenience, any user can search bookmarks by either users who created them or their bookmark tags. What needs to be done: 1. The search methods in bookmarks model are being used used on a very granular level. This led to redundancy in bookmarks search methods. Therefore, we need to change the names of these two methods to create and edit , respectively. These two methods differ only in 2 lines of code, which make it reasonable to merge them together into a single method that provides functionality of both individual methods. We add the functionality to this method to allow it to also create bookmarks with provided topic_id . 5. Methods add_bmapping and add_bmapping_signuptopic need to be moved to their appropriate model (Bmapping model) rather than reside in Bookmarks model. 6. Add user interface for Bookmarks as this functionality has not been a part of Expertiza 7. Create a functional tests suite covering the functionality of all the methods that have been changed by our team. 8. Create a Cucumber integration test to show the functionality of added user interface for Bookmarks. Single Responsibility Principle: As per Single Responsibility Principle, every class should have responsibility over a single part of functionality provided by software and that responsibility should be entirely encapsulated by the class. Following this principle, we found that methods add_bmapping and add_bmapping_signuptopic were present in the Bookmark model, while they actually belong to Bmapping model. So we moved those methods to the Bmapping model and took care of all the dependencies. We created functional tests for these methods to prove that refactoring was successful. Polymorphism: We realized that the methods search_fortags_allusers , search_fortags_forusers could be combined into one method. The reason for this is because these methods, essentially, offer the same functionality, but using different parameters. So, we wrote a common method which takes parameters and, based on the parameters passed, it provides the required functionality. The consistency of these two methods shows plenty of repetitive code. In order to effectively refactor these methods and reuse the code they both need, our team merged the two methods together by enabling add_this_bookmark method to handle creation of a bookmark when a topic id is provided (main functionality of add_topic_bookmark method). Therefore, we retained the same functionality while reducing the method by 7 repetitive lines of code. Please note that these two methods only differ in a single line of code (line 6 and 16) where line 6 takes an extra parameter ( topic_id ). <code>. <code>. Both these methods contain almost the same code except for few conditional lines. search_fortags_allusers searches for all tags for all users whereas search_fortags_forusers searches only for those tags that belong to the user. <code>. <code>. If we want to search for specified tags for all users, the userid is passed as nil. If we want to search for the specified tags belonging to a particular userid, we pass that userid. <code>. <code>. <code>. If we want to search for all tags for all users, the userid is passed as nil. If we want to search for all tags belonging to a particular userid, we pass that userid. <code>. Visit the url "" <link> "" and click on search button to view the results <image>. Visit the url "" <link> "" to view all tags for the user <image>. Visit the url "" <link> "" , enter the tags separated by comma (example - tag1,tag2) and then click on search button to view the results <image>. Visit the url "" <link> "" , enter the tags separated by comma (example - tag1,tag2) and then click on search button to view the results <image>. The test suite consists of 9 tests providing 14 assertions that cover the functionality of all the method changes described in the former sections of this wiki page. You can run this test suite by simply navigating to expertiza project directory and running command: <code>. In addition to functional tests, we have also provided a Cucumber test as an integration test. The goal of this test is to show that a user can access the Manage Bookmarks page upon successful log in, proving that bookmarks view have been successfully integrated into expertiza system. The construct of this test can be found in following files: <code> To run this cucumber test, please navigate to expertiza project directory and run the following command: <code>. 1. <link> 2. <link> 3. <link> 4. <link> - This might not be available after May of 2015 5. <link> 6. <link> 7. <link> 8. <link>.","Well written, but does not mention design patterns or principles


The prose does explain what was done, which was good.  It covers the basics, and then launches into their changes.  However, it does not talk about the difficulties they faced and how they tried to overcome them.  Such a description would be very helpful to those who come after them."
E1878,"<link> is an Open Source project based on the <link> framework, supported by National Science Foundation. It is the software to create reusable learning objects through peer review. It is a project where students can submit and peer review learning objects(articles, code, websites, etc). The users of this software include students and professors. Expertiza is used by select professors and students in North Carolina State University, for example. It supports team projects, reviews of projects/teammates, submission URLs, Wiki pages and certain document types. Instructors can create projects and the students can bid for the projects. The students can be assigned teams for a particular project or they may form their own team with fellow classmates. Peer-review systems like Expertiza utilize a lot of students’ input to determine each other’s performance. In the same time, we hope students could also gain knowledge from the reviews received thus improve their own performance. Currently, we have a few classifiers that could catch useful components of review comments, such as if it contains suggestions, etc. These classifiers are already ported into web services that we’d like to be integrated into Expertiza. As stated in the Problem statement, we get the response from the REST endpoints as given and integrate it with Expertiza. The suggestion detection algorithm from which we are getting the metrics is added in the ""References"" section in case more details are needed on it. According to the problem statement, we will be considering the ""Suggestion Detection Algorithm"" to be a black box, which take a json with text as input and returns a json with few metrics as given below. Input JSON to ""Suggestion Detection Algorithm"" <code> Output JSON the ""Suggestion Detection Algorithm"" <code>. 1. When a student submits a review, we call this web service with the student’s review as the input. We then tell the student whether their reviews contain suggestions or not, so they can make improvements based on the results of the web service. 2. We evaluate how much time this API is taking. We don’t want the system to be terribly slow. 1. app/views/response/response.html.erb. In its current state, the student directly writes their review in segmented text boxes under instructor specified questions with no further checks about the relevance of the review they have written as shown below: <image>. We are not modifying any models / adding any logic that requires an UML diagram. Most of our changes are on HTML. Our logic to be implemented is pre-processing the review and sending it as JSON to the Suggestion Detection API, getting the JSON response from API, post-processing the metrics to output the Suggestion Analysis. The overall flow of the logic is explained as follows: <image>. Following are the necessary steps needed to be set up in order to have the feature running : 1. Browser: Google Chrome 2. Cores plug-in (link in references) Before the JSON response is displayed, certain fields are first filtered out or formatted. For instance, the field ""text"" is filtered out as it is redundant to display it again. The field ""sentiment_tone"" is formatted with the help of another font color JSON depending on its value. Following is the code snippet of our implementation : <code>. <image>. Test: ViewSuggestionMetricsForReviewSegment <code> <code> <code> <code> <code>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","I think that the Background Information could be better expressed.  For example, ""classifiers are already ported into web services"" is a rather confusing way of saying that we have written a web service that contains code to detect suggestions.  In the Prerequisites section, a large amount of code is pasted in with no real explanation, and only three 1-line comments.  I thought that the demo did a better job of showing the request that was transmitted to the web service and the metrics that were returned."
E1639,"Expertiza has been created and maintained by faculty and students of NCSU. It helps teachers set up assignments for students who can then make submissions. Students can also review work of other students and give feedback to help incorporate improvements. The following OSS project deals mainly with the ResponseController. The goal of this project is make the code more readable, maintainable and to improve elegance of the code. We would like ResponseController to adhere to the DRY principle. It focuses on refactoring some of the more complex methods and removing some redundant code. At present, ResponseController has methods that would better be located in other controllers. The project relocates such methods to its appropriate Controller class. Response controller manages the responses entered by users. When a user fills out any kind of rubric (review rubrics,author-feedback rubrics,teammate-review rubrics,quizzes,surveys), a response is generated. Responses come in different versions. Any time an author revises his/her work, and the reviewer reviews it again, a separate Response object is generated.Each Response object points to a particular ResponseMap, which provides details about reviewer, reviewee and reviewed entity. 1) Refactor the update method which is too long and hard to read. 2) Refactor the saving method to improve the case handling of selfReviewResponseMap 3) Move new_feedback method from ResponseController to ReviewMappingController - ResponseController should only handle one kind of object 4) Modified functional tests for new_feedback method 5) Added functional test for update_method of response controller. Update method is called when any kind of response is edited by the user. This method was very long and unreadable. There was a helper method 'set_questionnaire' which was being called indirectly by the edit method for retrieving the questionnaire.We called the same function. The intuition behind using this same method was that if it is an update, user is not filling a new rubric and the response object should be available.We can find the questionnaire from the question_id in answers.Hence, in this way the if-else block was eliminated by calling the already available function. The function 'create_answers' does exactly the same. Abiding by the DRY principle, we called this function which made the update method look concise and simplified. <image> <image>. Saving method is called to save the response when a user edits any particular response or creates one. This params[:return] value was then further used in redirection method to handle the selfReviewResponseMap separately. We removed the assignment params[:return]= ""selfreview"" from save method. Rather we are directly passing the :return parameter value from edit and new methods of _self_review.html.erb, a view of SubmittedContent controller which handles the selfReview functionality. app -> controllers -> respose_controller.rb -> def saving <image> app -> views -> submitted_content -> _self_review.html.erb <image>. new_feedback method is called when a user provides author feedback for any review. It was defined in the ResponseController earlier which was rather suspect. We moved the method to ReviewMappingController since ResponseController should only handle Response object, while new_feedback is dealing with FeedbackResponseMap object. <image> <image> <image>. We modified the test cases to accommodate changes of the new_feedback method and created new rspec file review_mapping_controller_rspec.rb. We added new test case for update method to test if it located the requested response. <image>. Following steps needs to be performed to test this code from UI: Testing the update method: Click on <link> to view testing screencast for testing the update method 1. Login as instructor. Create a course and an assignment under that course 2. Add say, two students as participants to the assignment 3. Create topics for the assignment 4. Sign in as one of the students who were added to the assignment 5. Go to the assignment and sign up for a topic 6. Submit student's work by clicking 'Your work' under that assignment 7. Sign in as a different student which is participant of the assignment 8. Give review on first student's work and simply click on save 9. Later click on edit and change the review. Click on submit 10. When you click on view, verify the changes made in step 10. If all changes are intact, update method worked successfully Testing the new_feedback method: Click on <link> to view testing screencast for testing the new_feedback method 11. Login as the first student to view feedback given in step 10 12. Click on ""Give Feedback"" to give author feedback ( feedback on the review quality) 13. You would be redirected to a form. Fill in the author feedback and save your changes 14. View your feedback for the review. If your changes are intact, new_feedback method worked successfully.","Very good job.  Figured out some changes that were not in the requirements, and clearly showed how they were accomplished."
E1693,"The existing interface for defining rubric is not very user friendly. In the main area, the parameters to the fields can be configured including field length, options, values, etc. Moreover it provides the option to edit the field information when we create the individual fields. There is an edit option at the top right corner of the field, clicking on which we get a form through which the options can be given. 1. app/assets/javascripts/form-init.js The logic used in the form-init.js file to implement the various rubric items, how the form builder widgets are used to implement the various rubric items,. The implementation of the drag and drop interface for rubrics creation consists of the initialization, provide features for the user to drag and drop the widgets, modify the parameters and save the final rubrics. The old interface provides the users the option to select the widget type, say Criterion and ""Add"" it to the list of widgets with the help of an ""Add"" button. As soon as the users adds the widget, the type of the widget is stored in the database in the questions table. Hence in the new interface, when the user drags and drops the widgets they type of the widget that was dropped by the user is identified and the same widget type is chosen in the old interface field which are hidden and the ""Add"" button click is triggered. This will automatically save the dropped field in the database. The event when the user drops the widget is captured by the plugin option ""typeUserEvents"" which has a ""onadd"" function for each widget that would get fired when the widget is dropped. The old interface adds a row of parameters to a form when the user adds a new widget. The user then fills in the various parameters in the form and clicks on ""Save Questionnaire"". Hence when the user edits the parameters of the widgets by clicking the edit icon on the widget, the values are updated to the hidden fields of the old rubric by the function ""updateHiddenFields"". <code> We tried to implement the new user interface without leveraging the old interface (which is hidden right now but the actual data is still saved through the old interface) but the plugin provides the data in the form of JSON and if we use that we would need to modify the format in which the data is stored in the database. When the user clicks it for the second time, the box will be closed and the user would have edited the parameters of the widgets. <code> Hence updating the widget parameters each time the user edits them is very important to persist the changes the user makes. At present, the drag and drop interface support five types of widgets namely criterion, checkbox, scale, textfield and textarea. The ways in which the form builder widgets are used to create the rubric items are discussed as follows: The form builder provides a dropdown which has been used to create the criterion widget by appending a textarea to it. The parameters of the criterion include question, first and the last value of the dropdown and the size of the textarea. The parameters provided by the form builder for the dropdown field are modified to suit the parameters of the criterion to provide the edit option. The label is converted to the question field, the options are restricted to two just to get the two extreme values of the dropdown and the className field is used to get the size of the textarea. The form builder provides a checkbox which has been used directly to create the checkbox widget. The parameters of the checkbox include only the question which leverages the label field from the form builder widget. The form builder provides a radio-group widget which has been used to create the scale widget. The parameters of the scale widget include question and first and the last values of the radio buttons of the scale. The parameters provided by the form builder for the radio-group field are modified to suit the parameters of the scale to provide the edit option. The form builder provides a textfield which has been used directly to create the textfield widget. The parameters of the textfield include the question and the length of the field. The label is converted to the question field and the length field already exists in the form builder widget. The form builder provides a textarea which has been used directly to create the textarea widget. The parameters of the textarea include the question and the size (rows and columns) of the textarea. These parameters are already found in the plugin widget. To implement this, the fields of Drag and Drop interface are mapped to fields of current existing interface. Hence, the data entered into a particular field in 'Drag and Drop' interface is mapped to its corresponding field in existing interface. The user then drags and drops the widgets of his choice, edits and saves them. 4. Click on 'Create' icon which will forward you to ""form Builder"" page. 5. Now you can create a sample rubrics by dragging and dropping the form fields and configuring the field parameters.","Please add the doc in expertiza wiki. the diagram could reflect the delayed task. what's the buffer time? it should be defined in a config file. or another approach, you could send all available submissions to simicheck when they're due, and then send the late submissions when they're submitted (the ones submitted first won't be plagiarized from the late ones). You mention the wiki content will be extracted, but it's not reflected in the code. Also for other links, html tags should be stripped since html tags would yield high similarities among the files. The files being sent only contains the team name, but not the original file names, which make it difficult for instructors to identify which files You could've saved your self some time by adding a link to github instead of copying them in the doc. I couldn't find the test plan, the doc is only 8 pages, maybe you submitted an old version."
E2055,"<link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. This project in particular intends that the students collaborate with each other and work on making enhancements to the code base by applying the concepts of Rails,RSpec, DRY code,Test driven development etc. This provides an opportunity for students to contribute to an open source project and learn further about software deployment etc. RSpec is a unit test framework for the Ruby programming language. RSpec is different than traditional xUnit frameworks like JUnit because RSpec is a Behavior driven development tool. What this means is that, tests written in RSpec focus on the ""behavior"" of an application being tested. RSpec does not put emphasis on, how the application works but instead on how it behaves, in other words, what the application actually does.Each RSpec file contains one or more tests. The benefit is that tested code is unlikely to break unnoticed.The tests are run every time someone makes, or updates, a <link> . Below are the tables that are related ti student task functionality <link>. The following is an Expertiza based OSS project which deals primarily with the student_task.rb and student_task_spec.rb. It focuses on writing RSpec unit tests for the code affected or added. The goal of this project is to attempt to add sufficient unit tests to this part of the application and increase its path coverage to above 90 percent. The following tasks were accomplished in this project: 1. Complete the insufficient unit tests for student_task.rb. There are different tasks that a student can perform. 1. They can see all the assignments that they have been assigned to. 2. They can see details of each assignment like marks, their team, send invitation to student to join a team 3. Review other students' work. 1. Mock Objects to test: Create a series of mock objects that will be used throughout the testing process 2. The following are a list of the functions that were tested: 3. Topic name 1.1. Retrieves the topic name of an assignment 4. Complete? 1.1. Checks if a student task is complete 5. Incomplete? 1.1. If the assignment is not complete return true 6. Not started? 1.1. Checks if a student task is available to be worked on (i.e in submission/review/metareview stage) and if so has it been started 7. Revision? 1.1. Checks if a student task is now in the revision stage 8. Met reviews given 9. Teamed students 1.1. Returns a list of students that an individual has teamed up with 10. Get due date 1.1. Gets the due date for each assignment assigned to a student 11. Get peer review data 12. Get author feedback 13. Get submission data 14. Get timeline data. The following are our written tests in the order listed above: Details regarding what the test is testing can be seen as comments above each example block Here were are creating all of the mock objects to test the functionality of the student_task model. We are using these from the previous implementation <code> Here we just verify that topic name is stored and that any values for topic name that are falsey will be set to ""-"" <code> Here we are testing the different values that the student tasks status can take on <code> Here we are making sure the content has been submitted during the current stage of the process, only occurss when current_stage is equal to ""submission"" <code> Hyperlinks is modified based on the teams that a user is in. This will be updated if they are in a team or they already have hyperlinks it will remain the same <code> Simply testing to see if the incomplete status is checked correctly <code> Verify the stage of a task and that a started task is evaluated correctly <code> Returns the relative deadline if applicable <code> Checks if an assignment is in a stage where revisions can be made <code> Checks if a metareview was given in current task stage <code> Checks if a student task has been started <code> Checks the current work stage of an assignment <code> The following test returns a list of students that the user has teamed with up to this point. Returns an empty list if they have yet to team with anyone <code> This test returns the due dates of assignments assigned to a student <code> Here we fetch different timelines and account for edge cases where there are no reviews <code> Retrieves author feedback <code> Here we verify different states of submission data and hyperlinks <code> Here we are ensuring that the timeline data is empty when data has not been mapped <code>. <link> <link> <link>.","This document consists mostly of code snippets.  It does help the reader understand what has been added, but it could have been done more clearly.  First, you could have used subheadings in Mediawiki markdown to list the tests, e.g., as sections 6.1, 6.2, etc.  These headings would have been in the table of contents, which would make it easier to find things.  Second, you give a one-line description of what each test tests.  In some cases, comments in the test itself describe its workings in more detail, but in other cases, the reader would have to read the code to figure it out.  It would be considerably easier if you wrote a couple of sentences to describe the strategy used in the test, e.g., as in the comments for ""describe ""content_submitted_in_current_stage?"" ""."
E2000,"Expertiza is a web application using Ruby on Rails framework. The creation and maintenance of this application is handled by NCSU students and faculty. The basic functionalities allow the instructor to create and edit, both new and existing assignments. Also it allows the publishing of surveys and peer reviews, while allowing students the opportunity to sign up for topics, teams, submit assignments and peer reviews. Assignment.rb is a large file, that has dozens of methods and fields. Some methods seem redundant, and some fields and string literals are repeated multiple times throughout the file. Ie. 'Finished'. Each method in the file is essential and provides different data, so the goal for my team was to rename and merge code where we could, while not affecting the end functionality. Due to the fragile nature of the methods in Assignment.rb, our team decided to focus on redundancy in the code and anywhere we could merge redundant code into common methods. Also there were quite a few strings that were used constantly in the file, ie. 'Finished' that we decided to make constants, to reduce complexity if the values ever changed. - One of the main issues I saw in the code was the reuse of string literals in comparisons. These would cause hige efforts to change later if there are hundreds of places where these strings are used. Instead I replaced all instances of these strings in the file with constants, to lower complexity. Added these constants to file: <code> Removed references to string literals and made constant values <code> - The next issue I found was in multiple places where the code was making the same boolean checks. Instead rewtiting tge checks each time I made a method to return True/False for the check. <code>. For testing, assignment.rb was already tested pretty well. According to Code Climate it had a B grade for test coverage. Thus the testing effort for this project was not heavy, but we did want to be sure that none of our changes broke any existing tests, and all of our additional methods were tested. Also there was a method response_map_to_metareview which was not being tested in case of an error, so I added a test case to be sure the exception was raised. For example, one new method we added was: <code> For this method we added a few tests to validate the method was returning the values we expect. <code> <code>.","The document is very short, but so are the changes to the code.  It is a straightforward explanation of the changes made, but it could have identified the places better (it didn't refer to the line numbers where the changes were made). "
E2052,"For some assignments, students need to select a topic before submitting work. Topics associated with an assignment be reached as follows: 1. Log in as an instructor or a TA. 2. Select Manage->Assignments, which will bring up a list of assignments. 4. Click on “Topics” tab in edit assignment page. If an instructor or a TA wants to delete topics, he has to delete one topic at a time and has to wait for the page to refresh and then (s)he can proceed to delete the next topic, topics can only be deleted one by one. 1.There should be a checkbox column, along with other columns in “Topics” tab, where a user can select the topics (s)he wants to delete. 2.There should be a delete button/link at the end of the topic table with the name “delete selected topics” to delete the selected topics after a confirmation, prompted post clicking the button/link. 3.There should be a button/link alongside “delete selected topics” by the name “Select all” so that a user can select all and delete them in one go after clicking on “delete selected topics”. 3. Click ""Topics"" tab. 4. Create some topics by clicking ""New topic"" on the bottom line. 5. Select them and click ""Delete selected topics"". <code>. File: app/views/sign_up_sheet/_add_topics.html.erb Added 'Delete selected topics' button and 'Select All' checkbox We have also written a custom function 'deleteTopics' inside of <script> tag. This will collect all the topic id that we select via the checkbox and will send it to the sign_up_sheet controller for further processing. <code> File: app/views/sign_up_sheet/_table_header.html.erb Added 'Select' and 'Topic ID' header <code> File: app/views/sign_up_sheet/_add_signup_topics.html.erb We have changed one line of code in this file to add the 'id' parameter in the table tag <code> File: app/views/sign_up_sheet/_add_signup_topics_staggered.html.erb We have added a check to see whenever there is no signup topic , it should not show the link for 'Show Due Date' <code> File: app/views/sign_up_sheet/_table_line.html.erb Added checkbox fields for each row and each checkbox has an id called 'topic_check'. Each topic identifier has an id tag = 'topic_id' <code>. File: app/assets/javascripts/signup.js selectAll function checks all checkbox of topics in the table. <code>. File: app/controllers/sign_up_sheet_controller.rb It defines the following functions: delete_all_selected_topics : This function deletes all the selected topics load_all_selected_topics : This function loads all the rows ( tuples ) from sign up topics which have the selected topic ids. <code> File: config/routes.rb Added route for delete_all_selected_topics in signup_sheet_controller <code>. We also have a 'Select All' option at the end of the table. <image> We can select a few topics in the table by clicking on the appropriate check-box <image> We can select all topics in the table by clicking on the 'Select All' option <image> When we click on the 'Delete Selected Topics' button , we get a popup asking for conformation. <image>. The test expects a success flash message 'All selected topics have been deleted successfully. Then it expects to redirected to '/assignments/1/edit#tabs-2' <code> File : spec/features/assignment_creation_topics_spec.rb This test checks the presence of 'Select All' checkbox and expects to check if all the checkboxes are selected when 'Select All' is checked. <code> This checks that if none of the topics are selected and nor the select all checkbox is checked, if the 'Delete selected topics' was clicked the topics would still be present and there would be no change to the page. <code> File : spec/features/staggered_deadline_spec.rb We created an assignment with assignment name 'Assignment1665' and added 3 topics to it (Topic_1,Topic_2,Topic_3) and for each of them we have added staggered due dates. The test expects to select all the topics by checking 'Select All' and delete all the topics after pressing 'Delete selected topics' button. The test checks, that all topics are deleted by checking if the 'Topics' tab has disappeared from the window. <code>.","Document is readable with a good outline for the contents. A couple more relevant screenshots of system before the changes would have been good. Some streamlining needed in the doc (It contains all the relevant information but not arranged the way it should be).  OTOH, there are very good descriptions of the code changes that have been made, and the snippets are short enough to be readable.  This will be a big help to anyone who follows on to this project."
E2007,"In the fall of 2019, <link> was done well but the team did not write any tests for their code. For this collaboration, we implemented appropriate tests for the majority of the methods using RSpec. Refactor review_mapping_helper.rb contains about 25 methods for helping assign reviews and calculate scores some methods had exceeded the limit on the lines of code and was missing proper comments on the functionality of each method. Cyclomatic complexity of most of the methods was way too high as defined in the <link> . <link> is a behaviour-driven development framework written in Ruby to test Ruby code. For our tests we used RSpec to create the test cases for the methods in question. Because the helper file contained methods that couldn't be appropriately tested within the RSpec framework, only the methods that were testable within RSpec were addressed. In total, we wrote 22 tests to verify the methods in review_mappping_helper.rb. The test framework mocks a number of objects and active record entries in order to provide appropriate inputs to methods being tested. Also, a number of methods had bugs that had to be resolved before the test suite could be implemented. Each test has different preconditions to ensure the tests run appropriately, however, most of them included creating active record entries for participants, grades, the review response map and assignments. <code>. The methods below had bug fixes applied in order to ensure proper functionality. tree_display_controller.rb : Added logic to check if child_nodes is not an array object. <code> review_mapping_helper.rb : Refactred submission_state so color.push in in obtain_team_color. <code> response.rb : Added provision to add an empty comment if there is no additional comment, and still maintain array size. <code>. Below is a list with all the classes and methods that were testable within RSpec framework. Included is a short summary of what the method does, and how its functionality is being tested. This method checks if a link was updated since last round submission. The test verifies that it will return false if the link was not updated, and true otherwise. <code>. This method checks if a review was submitted in every round and gives the total responses count. The test verifies that it returns false if there are not enough responses for rounds, and true otherwise. <code>. This method checks if work was submitted within a given round. The test verifies that if no work is submitted it should return false and true otherwise. <code>. This method returns hyperlink of the assignment that has been submitted on the due date. The test checks that if no link is submitted the method returns nil, and when a link is submitted that the right link is returned. <code>. This method returns when a web page was last updated in a date-time object. The test verifies that the method is returning the correct object type. <code>. This method gets the response map data such as reviewer id, review, object id, and type for the review report. The test verifies that the response maps are appropriate for a given dataset. <code>. This method checks the submission state within each round and assigns team colour. The tests here check that the correct colours are being assigned by the method based on the submission state. <code>. This method sorts the reviewers by the average volume of reviews in each round, in descending order. The tests here checks that the method is properly sorting reviewers. <code>. This method returns the average feedback score for an author. The tests check that if the team size is greater than one that the returned object is empty, and if the max team size is one it returns the author score. <code>. This method moves data of reviews in each round from a current round. The test check that the elements are properly initialized. <code>. This method returns review and feedback responses for all rounds for the feedback report. The tests check the number of responses returned by the method is the same as those in the ActiveRecord. <code>. This method sets the values of instance variable. The tests verify the instance variables are properly set. <code>. This method returns review and feedback responses for a certain round for the feedback report. The tests here verify that the feedback responses for the feed back report, adn the associaated information to identify them are properly being handled by the method. <code>. <code>. <code>. The following methods either had functions that existed beyond the scope of what is testable withing RSpec or where not utilized at all in Expertiza, therefore these methods have no tests associated with them: create_report_table_header get_review_metrics initialize list_review_submissions display_volume_metric list_hyperlink_submission display_volume_metric_chart get_css_style_for_calibration_report. <link> <link> <link> <link>.","The documentation shows the changes to the code, but does not explain how the logic has been fixed.  The test plan lists the methods linearly (22 of them), but does not group them into categories that would be easier to understand.  American spelling should be used in the documentation and code; however British spelling seems always to have been used."
E1749,"Expertiza is a website that is used and developed by NCSU students and faculty. Coded using Ruby on Rails the source code is readily available on Github -> <link> . The website is used by students for organizing teams, signing up for topics, reviewing other teams and another bunch of tasks. The faculty i.e. Instructors and TAs use this website to set new tasks, add new questions and a few other tasks. One of several ways to set up the environment and the one we adopted is:- Ubuntu-Expertiza image (.OVA) [Recommended] This is the link for the image. ( <link> ) And you can install VirtualBox (free) and import this image into VirtualBox. Some machine may require you to enable virtualization and then run the following commands. <code> <code> <code> <code> 1. For logging in as an instructor:- Username: instructor6 Password: password. 1. questionnaire_controller.rb 2. questionnaire_controller_spec.rb. 1.1. questionnaires_controller.rb is a fairly complex file. 1.2. It contains a lot of methods that are long and hard to understand, these methods need to be broken down into simpler and more specific methods that are easier to read/understand. 1.3. Also, the few instances of code duplication that exist should be removed. 1. Complete pending tests in questionnaires_controller_spec.rb, and write integration tests for newly-created methods. Please finish one set of pending tests first before refactoring corresponding methods. 2. Refactor create method 1.1. Write failing tests first 1.2. Split into several simpler methods and assign reasonable names 1.3. Extract duplicated code into separate methods 3. Refactor update_quiz, save_choices method 1.1. Write failing tests first. 1.2. Use polymorphism to replace the long switch statements 1.1.1. Move if conditions to corresponding subclasses (eg. MultipleChoiceCheckbox.rb, MultipleChoiceRadio.rb) with same method name 1.1.2. Replace the conditional with the relevant method calls 1.1.3. Remove duplicated code 4. Use find_by instead of dynamic method 1.1. Write failing tests first 1.2. L68, L385, L386, L559, L560. 1. Testing 2. Refactoring Testing. For testing methods, we don't have to check the preconditions, as we have been assigned with refactoring the methods and testing those refactored methods properly. We check the file questionnaires_controller_spec.rb, and test the methods required to be refactored based on our modifications we have to carry out in the spec file for the testing methods. <table>.","There really isn't enough prose to explain what you have done.  For example, there's no prose description of the tests, or the strategy you used in creating tests.  For most refactorings, the before & after code is shown, with no real description of why & how the code was changed or improved."
E1852.1,"<link> is a web application designed for academia. The Rspec file participant_spec.rb existed with test cases for name and fullname methods and provided path coverage of 36.08% for the participant model. The test cases must be written so that the path coverage is above 90%. Also, ensure that the branch coverage is as high as possible for many edge cases. The files to be worked upon are: 1. app/models/participant.rb 2. spec/models/participant_spec.rb. The task is to write unit test cases for testing the participant model file. We used NCSU VCL image of [CSC517, S18] Ruby on Rails/Expertiza. 1. Reserve a NCSU VCL image of [CSC517, S18] Ruby on Rails / Expertiza. 3. Commands executed for setup in terminal of VCL image: <code>. <link> is an open source project written in Ruby, hence it uses <link> which is a unit test framework for the Ruby programming language. To access the effectiveness of our testing, we have used <link> , a code coverage analysis tool. Test responses A Participant has many ResponseMaps that map a connection between this participant as a reviewer and as a reviewee. Each ResponseMap has many Responses associated with it. When responses method is called on a Participant, it should return an array of responses associated to this Participant. <code> The test below will test a participant with no corresponding mapping. Hence the result of the responses provided by the participant is a nil list <code> Test name The method name returns the name of the participants <code> The test below will return the name of the participant. A factory build initializes the participant with the name as student and calls the function to expect student as the outcome <code> A Participant is a User. When name method is called on a Participant, it should return the name of this User. <link> Test fullname A Participant is a User. When fullname method is called on a Participant, it should return the full name of this User. <code> The test is done similar to name that it expects a name which was loaded in the factory build <code> Test delete and Forced delete The method deletes a participant team if the participant is not associated with any team. It makes a call to force delete when the argument is true A single test case can validate the positive scenario of delete method <code> <code> The test case will attempt to delete the participant. Since the participant is not having association it will call the forced delete function and returns participant for deleting. <code> Test topic_name The method return the name of the topic which the participant has been assigned with. <code> The test will check for the error when the participant is having an assignment without a topic, unnamed topic and with a topic. <code> Test able_to_review A simple method which gives the status on whether participant can review. <code> When able_to_review method is called on a Participant, it should return true if it can review and false otherwise. <code> When scores method is called on a Participant, it should return the total scores it received for a given number of questions. Test get_permissions This method returns a hash of the boolean value based on the authorization. The result of the boolean determined the ability to review , take quiz and submit. <code> The test case here checks whether the output hash will have the correct combination of trues and false for the authorization <code> Test get_authorization The method get authorization basically determies the role based on the ability to submit, review and take quiz <code> The test cases below are designed to validate whether the method produced the 3 desired outcomes. The first test case validates the outcome to be reader, second one check for the outcome submitter and third will check if its a reviewer <code> Test sort_by_name Participants are Users. When self.sort_by_name method is called on a Participant, it should sort a given set of participants based on their user names. <code> The test builds participants using <link> methods and assigns name as specified. Then a function calls for sorting and the expected outcome is matched with the result <code> Test Scores The method scores calculates the score based on the number of the round. <code> The first condition is when the round is nil <code> The second condition is when it is not nil <code> Test Email The method here sends a email to the participant with the appropriate message, <code> <code>. We have a coverage of 94.05%. To achieve the coverage for scores(questions) method in participant.rb, we had to comment out the overriding method scores(questions) in its sub-class assignment_participant.rb. The test running can be seen at <link> The repository having the modified model files can be viewed at <link>. 1. <link> 2. <link> 3. <link> 4. <link>.","Some of the tests are described very well, explaining what they test and what the outcomes are.  Other tests have little description.  Tests like the one for topic_name are long, so the various steps should be explained."
E1466,"2. Refactor the conflict_notification method to conflict_email method. 4. Send a conflict email to the reviewer automatically when instructor click the button ""email reviewer"". Current System (After Refactoring Grades_controller): <link> <code> Student: user1600 and user1601 Password: test Original System (Before Refactoring Grades_controller): <link> <code> Student: user1600 and user1601 Password: test All our test result based on the following test cases on expertiza, please follow these step to get it. <code> Student: <code>. <code>. <code> <code> <code> <code> <code> <code>. <code> <code>. <code> <code>. <code>. <code>. <code>. <code>. <code>. 1. Modify if statements: Before Refactoring: <code> After Refactoring: <code> 1. Using Objected-oriented Pattern Before Refactoring: <code> After Refactoring: <code> 1. Using loops rather than duplicate same code Before Refactoring: <code> After Refactoring: <code>. Delegation: The conflict_email should be able to send email. The old conflict_notification action queries an email address list of a certain kind of reviews. In its view conflict_notifiction.html.erb, A email form contains email list for instructor to choose from and email content. <image> Before Refactorring , in conflict_notification: First,Get the instructor email address as sender <code> Then,Based on submission of review, the action query all the reviewers' email address <code> The email list is for instructor to choose from. The process_response method queries the email address. <code> The get_body_text method construct email content which should be removed from controller. <code> The conflict_notification action requiring another two method ""process_response"" and ""get_body_text"" method to get the recipient email list and email content which contributes to extra complexity. The instructor only have to click the button ""send email"" in conflict_notifiction.html.erb and turn to send_conflict_email action, then he/she can send the email. If the instructor want to send another email, the process will repeat again,which will be terrible when reloading the ""view"" scores page. After Refactoring :The querying reviews actually have done in our show_reviews action, and we can get the individual reviewers' email address.In the reviewer table,we add extra button ""email reviewer"".Now the instructor could send to reviewer email directly. <image> In _review_table.html.erb,we add the link to send email. <code> In our new conflict_email action: We still need the instructor as the sender <code> The reviewer_id is passed from the link,we can query his/her email address to send the email <code> The responsibility of sending email has been delegated to a new mailer conflict_mailer. the email was sent from sender's email and to reviewer's email.Some instance variables were used in view. In conflict_mailer.erb <code> In its view send_conflict_email.txt.haml, we edit the email content.By this way, we deleted the get_body_text and well followed the rule of MVC design <code> The link ""email reviewer"" request a ajax,so the current view page will not refresh when the action done <code> If an email was successfully sent,The instructor should get the alert window by ajax. <image>. After refactoring this method, the time cost of views in grade controller decreased by more than 90% . 1. Deleted the unnecessary instance variables Deleted Code: <code> 1. Deleted query for reviews and meta_reviews Deleted Code: <code> 1. Modify get_assessments_for method in response_map.rb After doing this, the time cost of view function decreased by more than 90% Before Refactoring: <code> After Refactoring: <code> 1. Add a new method into grades_controller.rb Add Method: <code> 1. Change view_my_score.html.erb into show_reviews.html.erb in views. 1. Add in views(show_reviews.html.erb) <code>. 1. The following test results based on the test case on Expertiza(Assignments: Program 2 style) <table> 1. Original Time for Instructor to View all scores <image> Original Time for Instructor to View all scores 1. Time for Instructor to View all scores after Refactoring <image> Time for Instructor to View all scores after Refactoring 1. Original Time for Student to View all scores <image> Original Time for Student to View all scores 1. Time for Student to View all scores after Refactoring <image> Time for Student to View all scores after Refactoring.",Good writeup; could use a bit more narration
E1838,"In Expertiza, if the instructor doesn’t specify the assignment directory for a submission, the directory defaults to the home directory. This can lead to multiple assignment submissions being in the same place and creating confusion. The aim of the project if to handle all the scenarios that can arise when the instructor is not specifying any directory name. Issue #391: In Expertiza, if the instructor doesn’t specify the assignment directory for a submission, the directory defaults to the home directory. This can lead to multiple assignment submissions being in the same place and creating confusion. Please take a look at the Github issue for suggestions on how to solve this. Issue #1190: An issue with conflicting directories for copied assignments was fixed. You need to write the test to verify that this issue doesn’t recur. This test should check that the assignment directories for copied assignments are distinct from the original directories. Issue #1201: Expertiza has the feature to auto generate the directory names for submissions from the assignment name. However, this may be concerning if two assignments have the same name, in which case the submission folders would be the same and this would again create a problem. This needs to be fixed. 1) /app/views/submitted_content/_submitted_files.html.erb 2) /app/controllers/assignment_controller.rb 3) /app/views/assignments/edit/_general.html.erb. -> When the instructor has not specified a directory path, there is no directory where the files can be stored. -> Hence we allow only links to be submitted in such an assignment. -> In the view of submitted content controller we disabled the button to upload files in such assignment where the directory path is null. -> We displayed the message 'Fie submissions are disabled' whenever anyone tries to upload files to such assignment. Pseudo Code: Added following logic in /app/views/submitted_content/_submitted_files.html.erb <code> Explanation: If the assignment directory path is specified by the instructor then the button to upload files will be displayed else the warning message 'File submissions are disabled will be displayed'. Expertiza has the feature to auto generate the directory names for submissions from the assignment name. However, this may be concerning if two assignments have the same name, in which case the submission folders would be the same and this would again create a problem. Approach taken to solve the issue: Logic for Auto generation of the directory names: Append assignment_name, assignment_id, course_id to make the directory name unique. Files modified: /app/controllers/assignment_controller.rb /app/views/assignments/edit/_general.html.erb 1) /app/views/assignments/edit/_general.html.erb Pseudo code: <code> Explanation: Added a checkbox in the view for creating an assignment. An instructor can select if file submissions are allowed. If he selects 'yes' then if the instructor has given an empty directory path, the name of the directory for the assignment will be auto generated. 2) /app/controllers/assignment_controller.rb <code> Explanation: If the check box is checked, it will pass the value ""on"" to the assignment controller and the directory name will be auto generated. <image>. Link to ScreenCast Bug #391 : <link> Link to ScreenCast Bug #404 : <link>. Steps to test Issue #391 and #1201 1) Login as Instructor 2) Click on Manage , select assignments. 3) New public assignment/ New private assignment 4) Fill in the details 5) Select if you want to allow file submissions 6) If 'yes', then file directory name will be auto generated as 'assignment_name'_'assignment_id'_'course_name' 7) If 'no' 8) Login as a student and you can see that only links can be submitted and file submissions are disabled since the directory is not specified. Following RSPEC Code is added to assignments_controller_spec.rb: The below code RSPEC snippet tests for the issue where in the assignment which is duplicated does not have the same directory for submissions as the original assignment. <code>.",The wiki is not detailed at all. They do not have any screenshots for their functionality. The test plan is not detailed and doesn't include any borderline cases.
E1461,"Expertiza allows students to create and communicate with teams as well as an easy platform for online assignment submission. One part of the OSS project for Fall 2014 was refactoring of different sections of Expertiza. Our team was tasked with refactoring of the StudentTeamController. <code> <code>. Changes were made inside StudentTeamsController.rb as well as anywhere that used routes pointing to StudentTeamsController which consisted of: 1. advertise_for_partner_controller.rb 2. invitation_controller.rb 3. join_team_requests_controller.rb 4. reports_controller.rb 5. response_controller.rb 6. app\views\advertise_for_partner\show.html.erb 7. app\views\student_task\view.html.erb 8. app\views\student_teams\view.html.erb The routes changed were as follows: Before Refactoring: <code> After Refactoring: <code>. All where method calls in the controller were refactored to reflect current style guidelines. These calls were changed from the older style more closely resembling a sql WHERE statement to the more conventional style. In addition, the check variables used in the create and update methods were changed to existing_assignment and matching_teams to better reflect what they represent. Finally, in places where "".where"" was being used to find just one instance, it was instead changed to ""find_by"". The changes made are shown below: Old Where Method Calls <code>. <code>. <code> They were changed to: <code>. Replace <code> With <code>. Different method refactoring techniques were used to make clarity and understanding of code very easy and simple. For example, Rename method technique was used for ""remove"" method which didn't mean anything to more understandable name ""remove_advertisement"". <code> <code> Pull up method refactoring technique was used to DRY up the code and avoid duplication. For example, statement in code below was used at 3 different places in original code so pulling up that command in one method and calling ""team_created_successfully"" at all places made it easy to read code. <code>. Two lines were repeated in multiple methods in the StudentTeamsController, one to set the @student instance variable and one to set the @team instance variable. The setting of the @student variable is used in the view, update, edit, create, and leave methods while @team is set in the edit and update methods. The setting of these variables was moved to methods which cache the values to set the local variables lazily. These methods had to be used as before_actions in order to be usable by the view and edit views. Finally, in order to standardize the setting of the instance variable, the name of the :id params value was changed to :student_id in all redirect calls. Old Code <code> Refactored Code <code>. Commented out code can be restored from the repository. Blocks like the one shown below were removed <code>. The correct name for the view method is show. <code> Everything past the 14th line of code is bookeeping that should be handled by the model itself. The team was only able to implement rudementary tests. Additional tests are required to ensure good code coverage. Instructions to Manual Testing: 1) Open Expertiza Website <link> 2) Login using Username: user2 and Password: password 3) Click on Assignments on Top Bar 4) Choose assignment Team Test 2 5) Click on Your Team 6) From this next page, 4 methods can be tested: <code> <image>. There is no such construct as a ""Student Team"". In fact, ""Student Teams"" can currently have members who are not students (instructors), though the permissions for the instructors actually doing anything in the controller are tied off. The current permissions scheme forces the permissions to be checked at the beginning of the controller. This makes it so that the controller has the dule role of interfaceing the views with the model AND managing its permissions. to have to be set inside `action_allowed?`. However, this method is not called in the case of a Super User login, and therefore these types of members need to be set both in the action_allowed? and before the view is shown. Finally, the current permissions scheme causes the odd structures we see in the ""View"" call. <code> As you can see, the view method checks permissions again in this call (outside action_allowed?). In addition, this is not very dry, as the are defined here copies of the actual permissions set in the InitiationsController. Currently, Ruby throws: <code> on <code> This hapens with the unrefactored codebase (Git Rev d2144d13a6fd26203e464a90beaaaceb69506c6f) as well. <link> <link> <link> <link>.","Very detailed writeup, with suggestions on what should be done next."
E1948,"This page gives a description of the changes made for the review_mapping_helper.rb of Expertiza based OSS project. Expertiza is a web application where students can submit and peer-review learning objects (articles, codes, websites, etc). Instructors add and grade the assignments submitted by students to Expertiza. Students can be assigned in teams based on their selection of the topics. It has functionalities such as peer reviews in which students can provide feedback on other's work which helps peer in better developing the project. It is supported by the National Science Foundation. The review_mapping_helper.rb has multiple functions with a high complexities namely - Cognitive, Perceived, Cyclomatic, Assignment Branch Condition size (ABC size) and Lines of Code (LOC). The review_mapping_helper.rb has methods which exceeds the limit on lines of code Also, it is missing proper comments for each functionality. Cyclomatic complexity of most of the methods is way too high as per the standard defined in the <link> . The following process is carried out to complete the project- <image>. The comments about the internal functionality of the following functions were added : get_review_metrics , get_review_metrics , get_review_metrics , get_review_metrics , get_review_metrics and their sub-functions. Example : get_review_metrics function Before <code> After <code>. The method get_review_metrics had cognitive complexity of 6 and ABC size complexity 25. It was refactored using .dig() function and removing .to_s function by changing the variable type. Before: <code> After: <code> The method get_awarded_review_score had ABC size complexity of 19. It was refactored using .dig() function and creating new variable for redundant computations. Before: <code> After: <code> The method get_team_color had Cyclomatic, Perceived, Lines of Code and ABC size complexity. It was refactored by breaking the logical functionality into two sub functions and the main (get_team_color) function. Before: <code> After: <code> The method get_each_review_and_feedback_response_map had high ABC size complexity. It was refactored by breaking the logical functionality into a sub function and the main (get_each_review_and_feedback_map) function. Before: <code> After: <code> The method get_css_style_for_calibration_report had ABC size complexity of 19. It was refactored using .dig() function and creating new variable for redundant computations. Before: <code> After: <code>. There were refactoring changes made in the function. Testing was carried out to check the Cognitive, Cyclomatic, Perceived, Lines of Code and Assignment Branch Condition (ABC) size complexities of these functions. Rubocop was used to test these complexities of the functions. We also did automated testing using RSpec. Also, Travis-CI build of each pull request merge was checked to ensure that the code is working properly after refactoring. Rubocop testing results for ""get_review_metrics"" function after refactoring. <image> Rubocop testing results for ""get_awarded_review_score"" function after refactoring. <image> Rubocop testing results for ""get_team_color"" function after refactoring. <image> Rubocop testing results for ""get_each_review_and_feedback_response_map"" function after refactoring. <image> Rubocop testing results for ""get_css_style_for_calibration_report"" function after refactoring. <image>. Travis-CI Build Test of the beta branch after a refactored function is merged in the beta branch. <image>. We carried out automated testing using Rspec for the files where we made changes to, during the project. All the 14 test cases in the spec file successfully passed. Note: In some cases, to resolve the code climate issues we have broken down an existing long function into logical smaller functions. In these cases, we are neither manipulating any instance or class variables nor are we manipulating any values being fetched from the database in any way. Hence we decided it would not be practical or useful to write RSpec tests to test inbuilt Ruby and Rails functionalities. We followed ""The Magic Tricks of Testing by Sandi Metz - Rails Conf 2013"" [ <link> which asserts the importance of not adding any unnecessary new tests as well as getting rid of any kind of unnecessary tests. Link to Rspec Testing Video: <link> <image>. 1) <link> 2) <link> 3) <link> 4) <link> 5) <link> 6) <link> 7) <link>.","1) Document is detailed. Could have explained why they made the changes they did.  Comments such as ""# Setting values of instance variables"" and ""# Iterating though the list"" would be pretty obvious to the reader.  For example, what is in the list, and WHY do we need to iterate through the list?
2) Explained properly what changes they made.
3) Added screenshot and code of what they did and how it was before
4) They could have removed few GIT screenshots. Not required here
5)It is good that you added comments.  But comments like, ""# Iterating though the list"" just tell how the code is structured, and do not say what the loop is doing.  The reader needs to understand what the loop is doing, and this comment does not help.
6) Likewise, for the comment, "" # loops through the number of assignment review rounds and obains the team colour"", the reader would like to know WHY it is important to get the ""team color.""
7) The get_team_color method uses American spelling for some names and British spelling for others.  American spelling should be used throughout."
E2012,"An assignment can have a list of signup topics. The teams associated with the assignment can bid on the signup topics to try and get assigned one they find more favorable. At a high level, the lottery controller assigns teams to topics based on the priorities the team gave to each signup topic during the bidding process. In more detail, each student starts off on a team of size 1. They can bid on signup topics by arranging them in priority order. A team can invite other users to join their team. If student2 from Team B joins Team A which includes student1, student2 will lose their bids and take on the bids of TeamA and student1. When the lottery controller is called to run its method run_intelligent_assignment , a web service takes the bidding data from each team and returns a new list of teams, each of which is closer to the maximum team size specified for the assignment. The web service combines teams together that have similar bid data and then assigns those new teams to topics, giving each team their top bid on a topic that hasn't been assigned yet. Teams with larger team sizes and more bids are assigned their topics first. The create_new_teams_for_bidding_response method does more than 1 thing, both creating new teams and deleting residual teams that none of their team members remained in their teams. 2. Created 6 students that were assigned this assignment. 3. Created 4 topics for the assignment that will be bid on by the students. 4. Created 4 teams that the students may form to work cooperatively and bid as one team. 5. Created a bid based on a topic each student wants to work on. 3. construct_users_bidding_info: 1.1. Set up topics for teams to bid on. Set up teams with bids for those topics. Execute the method. Expect to return the bidding information of the teams with bids. This test includes cases like: 1.1.1. Team with more than 1 member (assignment_team1) 1.1.2. Team that has more than 1 bid (assignment_team2) 1.1.3. Team with no bids (assignment_team4) 1.1.4. Team with 1 bid of priority 0 (assignment_team3) 4. construct_teams_bidding_info: 1.1. Setup unassigned teams. Setup topics for those teams. Execute the method. Set up bids for those students. Set those students to two separate teams. Execute the method. Set up a team. Set up that team’s bidding information. Execute the method. 1.2. Set up an unintelligent assignment. Set up a team. Set up that team’s bidding information. Execute the method. Set up a team with those users. Execute the method. Expect the team’s user count to decrease. 8. remove_empty_teams: 1.1. Create 1 team that has no users. Execute the method. Expect the team to be deleted. Expect the team counts to decrease. Set up a team with bidding information. Execute the method. Expect the number of signed up teams to increase. Set up teams. Set up users on those teams. Set up user bids for each created user. Execute the method. Expect bid count to increase. Expect the new bid information to be a combined bid for the new team. The new tests that were added for each of the newly condensed methods include testing for the following: 1. Constructing the hash table for the users' bidding information 2. A more exhaustive running Intelligent Assignment method 3. Generate the hash for a whole team's bidding information 4. Match new teams to a topic based on their bids 5. Remove a user from a team 6. Destroying teams that have no users 7. Merging the bids from teams that have merged together so that they have a weighted uniform bid 8. Assigning open topics to teams that do not have a topic yet 9. Matching teams to topics based on their weighted bids. Note: The previous implementation does the intelligent assignment on a team basis. That is, students who do not belong to any team will not get assigned to topics (see method construct_users_bidding_info ). 3. Scroll down the page and find the assignment with the name New test assignment . 1.2. Has topics? 3. Under the Topics tab, make ""Enable bidding for topics?"" And by signing up topics, you indirectly create teams for them. 1. Improving the RSpec test for assigning open topics for teams without topics. The new test only checks for 1 open assignment and 1 unassigned team. The method is capable of assigning multiple open topics for multiple unassigned teams, but testing for this would require more Factory objects for assignments and teams. 2. Improving the time-space complexity for the method that merges bids from teams that are merging together.","This is excellent. I particularly liked the way you described all your changes and the reasons for them. They show that you had a clear understanding of what your goals were. This will help future teams ... not only ones that touch this code, but teams that look at your wiki page as a model for their documentation. While there are pluses and minuses, I liked the way you showed the code changes in popups. This made it possible to get more text on the page than if the code had been inserted in the wiki page. You also did a thorough job of describing the tests."
E1709,"Expertiza assignments are based on a peer review system where the instructor creates rubrics for an assignment through questionnaires which students use to review other students' submissions. The author of the submission is given an opportunity to provide feedback about these reviews. Instructors can see a report on the scores of a student given by reviewers, on the score of feedback given to the reviewers and many other reports. A report of average class scores for each rubric in the questionnaires would help instructors refactor their rubric and understand where students generally perform well and where they struggle. This new report forms the second part of the requirement. Our work would involve modifying the review report and creating a new report for average class scores. The project requires completion of the following tasks: 1. Integrate review data with author feedback data to help instructors grade the reviewers. 2. Create a new table for review and author feedback report. 3. The new table should have the following information: reviewer name, the number of reviews he has done, length of reviews, review summary, whether there is a link or a file attached, Average author feedback rating per team, Author feedback summary and a field where an instructor can give his grades and write comments. 4. Add interactive visualization to show the class performance of an assignment to an instructor. 5. Create a new route/view/controller for class performance. 6. Add a new link to point to the new controller created. This new link will be created per assignment. 8. Create graphs to show the class performance as per the rubric metrics selected dynamically. When we are implementing the response and author feedback report, we will be iterating through each reviewer to get the review performed by them and then each author based on the feedback given for each review. For the class performance report, we will be iterating through each questionnaire per assignment, and thereafter each question per questionnaire. The same iteration will also be required to get answers per question per reviewer. 1. When the instructor will select the show review report, it will show him the screen shown below. This report is an enhancement of the review report. 1. A new metric filter is provided so that the instructor can select the average author feedback, average length of comments, check and open the file if it is added by the reviewer. 5. From ReviewResponseMap and AssignmentParticipant, for each reviewer we will get number of reviews completed, length of reviews, summary of reviews and whether reviewers had added a file or link for their review. 6. From FeedbackResponseMap and Response, we will get the number of author feedbacks given to a reviewer. Using this we will get the average feedback score for a particular reviewer from all the feedbacks. 8. Hyperlinks are provided where necessary, so that the instructor can view additional details. to view review summary or author feedback summary. The demo for the Review report can be seen here: <link> The pull request is here: <link> . 1. The instructor can view the class performance on assignments by clicking on the graph icon on the assignments page as shown below. <image> 1. Once you click on the graph icon, it will take the instructor to the page shown below where the instructor can select various rubric questions used for evaluation of that assignment. <image> 1. Once you click on the graph icon, it will take the instructor to the page shown below where the instructor can see the performance of the class based on various selected rubric questions. In order to implement the above functionality for the class performance report, we have finally implemented the following: 1. We added a new controller ClassPerformanceController . This view will allow instructors to select a number of rubrics to evaluate the class performance on. 1.2. A view to show_class_performance . This view will display the class performance using relevant graphs to represent the information clearly. We need to provide a link to the instructor to see this view. These are displayed to the instructor. It then routes the instructor to the show_class_performance view upon selection of rubrics. It will then calculate the average score per question for the entire class from those answers and pass this to the view. The demo for the class performance report can be seen here: <link> The pull request is here: <link>. 1. View Review and Author Feedback Report as Instructor : As an instructor, he can see the different metrics of reviews and average feedback rating received per student done for an assignment or a project. 2. View Class Performance as Instructor : As an instructor, he can select 5 rubric metrics used per assignment. The instructor is able to see the graph to check the class performance based upon the metrics selected. 1. For use case 1 , test if the instructor can see the text metrics of reviews and author feedbacks received for an assignment or a project per student. 2. For use case 2 , test if the instructor can any number of rubric metrics used for an assignment. Also, test if the instructor can view the class performance from a graph using the metrics selected by the instructor.","A few reviewers said that the design doc explains the requirements, but not how your team is going to achieve them.  We agree.  Most of the changes are changing names, which doesn't require any explanation.  The doc should focus on what you are going to create, rather than show what is in the current system.  You're going to add an ""Update"" link for the expert reviews, but didn't say anything about what code will be changed to do this.  And there is no testing plan."
E1681,"Expertiza is an online system that is used by students to view/submit assignments and review others' work. Expertiza also provides tools to visualize the scores and gauge the improvements made during the course semester. It also facilitates and monitors team projects. It is targeted at educational and non-profit organizations. The project is funded by the National Software Foundation (NSF), NCSU Learning in a Technology-Rich Environment (LITRE) program, the NCSU Faculty Center for Teaching and Learning, the NCSU STEM Initiative, and the Center for Advanced Computing and Communication. Expertiza is an open-source project with the source code available as a public repository on GitHub. It is developed using Ruby on Rails and is increasingly becoming robust thanks to the innumerable bugs being fixed by the community. The project has a micro-blog on SourceForge where the developer community report bugs and document updates. Student-generated quizzes is the feature that students use for writing quizzes for the Wikipedia contribution assignment. In this project, we need to do refactoring and create functional tests for this feature. We need to refactor questionnaires_controller.rb and write the Rspec tests file in /specs/ folder. <image>. There is some problems in valid_quiz method which is in questionnaires_controller. For now, this method checks the questions one by one. We will refactor it to make it able to create the quiz_question objects and quiz_choice objects. Then we need to call “quiz_question.valid?” to check whether the question is valid. The code below is how we do refactoring: def valid_quiz <code> The code above is what we changed in questionnaire_controller. And then we created a new method in 3 types question model. <code>. We will test the following functionalities: 1. The instructor can set up an assignment which supports quizzing feature by 1.1. Checking the “has quiz” box 1.2. Setting the # of question for each set of quiz 1.3. Setting in which deadline can student reviewers take the quizzes 2. Student authors can create quizzes and edit them: 1.1. They can create quizzes on the “Your work” page 1.2. They can edit the quiz questions. 1.3. They can view the quiz questions. 1.4. If the quiz question has something missing, the system will flash an error message, either: 1.1.1. The name of quiz is missing. 1.1.2. The question text is missing for one or more questions. 1.1.3. The choices are missing for one or more questions. 1.1.4. The correct answer(s) have not been provided. 3. Student reviewers can take the quizzes on the work they have reviewed/they need to review 1.1. They need to request the artifact to review first. If this artifact has a quiz associated, they can take the quiz in the round which quiz-taking is allowed. 1.2. They can click “take quiz” then request quizzes to take. 1.3. They can fill in their choices on the quizzes. 1.4. After taking the quizzes, and submitting, they will see their grade on the “Take quizzes” page 1.5. On the “take quizzes” page, they can see their question-by-question scores for finished quizzes by clicking “view” 4. Instructor can view the quiz questions and quiz scores on the tree display by clicking “view quiz questions” icon. Let's see an example of how we wrote functional tests: <code>. 11/07 - 11/15 Design work 11/14 Discuss with instructor 11/14 - 11/20 Write first version 11/20 - 11/25 Debug and test 11/25 - 12/02 Final deployment. Refactor: Yi Wei Test: JunYi Liu(Last 2 bullets), Zhongzhi Qi(First 2 bullets) Deployment: Lei Zhang Document Writing: Everyone.","The document describes the workflow, but not the changes that will be made to individual files.  This is an important part of the design, so that readers can see that appropriate principles and patterns are being used.  OTOH, it does have a very detailed testing plan."
E17A5,"For journals and papers, we need to allow the user to create an account to submit the paper, unlike the standard system where the instructor is supposed to create account for all the students. Also, when a user wants to add a co-author for his/her paper/submission, he should be able to invite them irrespective of the fact that the invited user has an account or not. If the invited user does not have an account, a new account must be created for him/her. For the new system, submitting and reviewing is same as the peer assessment system. 1. Any non-Expertiza user can sign up, for submitting his/her work 2. Document upload privileges for that user. 3. Adding co-authors to a paper being submitted for reviewing. <image> <image> Name: Sign up Actor: Writer Other Participants: None Precondition: He/she should not have existing account on Expertiza Primary Sequence: 1. Go to Conference Reviewing section 2. Provide information in form for signup Captcha 3. Activate account by opening link, provided via e-mail Name: Add contributors Actor: Writer Other Participants: None Precondition: Writer must have uploaded a paper for reviewing Primary Sequence: 1. Sign in 2. Select the uploaded document 3. Select option to add contributors 4. Add information of co-authors. Email, Name, etc Name: Create a submission Actor: Writer Other Participants: None Precondition: The user is logged in and wants to submit a paper. Primary Sequence: 1. Selects the “Submit your work” button 2. Enter the details of the paper, like track of paper (which can be selected from a dropdown). 3. The writer is redirected to an upload page where the user can upload the submission. Name: Upload Paper Actor: Writer Other Participants: None Precondition: The writer has already created a submission window and is at the upload page. Primary Sequence: 1. The writer clicks the “Upload paper”button. 2. The writer selects the paper to be submitted from local device. 3. The writer clicks the “Submit” button. Table to handle many to many relationship between contributors and paper writer. <image>. 3. add_coauthors.html.erb : This file is needed to allow the writer to invite co-authors for his/her paper. The writer enters the details of the co-author to be invited in this page. Test plan for Publishing a paper 1) Click on the link from conference website 2) Enter name, password, and email ID 3) Publish paper 4) Fill in the details for the paper to be published 5) upload paper 6) add collaboraters (enter name and email of contributors) Test plan for editing paper attributes 1) Login 2) Select paper from displayed paper list 3) update attributes and save. <image> The User Signup screen: The user needs to signup to submit his/her paper for reviewing. The user can signup using this signup page. <image> The Login Screen: The user, after signup, will be redirected to this page. The account successfully created notification will be displayed on the top. Now the user can login to his/her account from this page. <image> To submit a paper for conference reviewing, the writer needs to create a paper and provide details about it like conference where it is being presented, primary topic of the papers, etc. The user can upload multiple papers related to a particular conference to this single paper instance created. <image> Once the paper has been created, the user sees the above screen as a confirmation that the paper has successfully been created. <image> The home screen of the user displays all the paper submitted by the user. The user thus can view all of them and edit them using the SHOW link provided next to each paper. <image> The show button is provided next to the listing of all the papers for a particular user. This button redirects to the page where one can edit the details of the paper uploaded. The user can edit details like paper name, date, contributors, etc. as well upload or change the files submitted. <image> The user can upload the files from this page. The user can click on browse button to select a file from the local computer and upload it as a part of the submission. The files uploaded by the writer will be uploaded to the given upload path: pg_data/research_paper/paperID.paperName <image> The user can select a file from personal computer device to upload it for conference reviewing. <image> The user can add contributors to add their inputs to a paper. The user can enter the email address and name of the contributor to send an invite to join the system for contribution. This is a screenshot of a typical mail that will be sent out to the contributors when invited by the author of the paper. <image> Once the contributor has been added, the user can see all the contributors in the Your Team section. The User himself is also listed as a contributor.","With regard to the db changes, what is the table that maps contributors to authors?  Why couldn't the same function be served by the teams table?  What is the new role you created?  Why aren't the existing roles (author, reviewer, etc.) sufficient?  Creating a new table parallel to assignments is a serious violation of the DRY principle, since the functionality is so similar. Don't worry about a few unused words in each record.  The test plan is not sufficiently detailed. It does not say what should be observed at each step.  Also, you have reimplemented a lot of existing model functionality, and should define tests for it.  Your series of screenshots does serve to illustrate the functionality nicely."
E2015,"The student Summary Report shows the scores submitted by the reviewers for each question of the rubric for that assignment. The instructors have more options to view student submitted feedback in the form of Reviewees Summary Reports which shows the average review scores for an assignment for each round with each reviewer's comments, and Review Reports which shows what teams' assignment were reviewed by each student. In the current implementation, during the peer review phase of an assignment, email notifications are sent out to the instructor whenever a submitted review score differs “significantly” from the average score of other submitted reviews for that submission. The email that gets sent to instructors contains three links: a link to the conflicting review, a link to the summary page of grades for the reviewee, and a link to edit the assignment. When a review is submitted that triggers a conflict, an email gets sent to instructors that contains three links: a link to the conflicting review, a link to the summary page of grades for the reviewee, and a link to edit the assignment. The information sent in the email should be updated to contain a link to a report page which should contain more details about the newest conflict as well as information on previous review conflicts for the assignment. The conflict report page should have an easy to understand visualization showing the assignment's reviews with scores that cause a conflict. If the difference between the average score and the newly submitted score is more than the notification threshold specified for the assignment, an email is sent out to the instructor. The email sent to the instructor contains the names of the reviewer and reviewee and a link to the conflicting review, a link to the summary of review responses, and a link to edit the assignment. The link to the conflicting review is helpful, but doesn't provide any context for for why that review was in conflict. The link to the summary of review responses provides more insight into how the assignment is being scored overall, but it doesn't provide a clear picture of which reviews are in conflict and have scores that are outliers. When an review is in conflict and an email gets set to the instructor, the body of the email contains links to the review, review summary page, and a link to edit the assignment. The <link> resolved the email related issues and also created a simple UI report page for analyzing the conflict. See a screenshot from the previous implementation of a snippet of the information from the conflict report page: <image>. 1. The UI for the conflict report included a bar graph that showed the grades of reviews that were in conflict. 3. It was also not obvious from the bar graph which review scores caused a conflict as they were not highlighted or distinguished in any way. Therefore, you can't tell what review scores would actually cause a conflict. 7. The code for the conflict report view included a lot of logic. Once the existing code determines that a conflict has occurred, the code will create a report view for the conflict. Next, a URL for the report page will be added to the email body. 1.2. app/views/reports/response_report.html.haml 1.1.1. Modify the html to render the conflict report partial if the option to view a conflict report was selected. 1.1.2. Plot the review scores on a horizontal bar chart, highlighting those that caused a conflict. 1.1.3. List the threshold for conflict review score, max review score, average review score, and standard deviation. 3. Modify the bar chart code to highlight bars representing scores that cause conflict. 6. Add additional metrics specifying threshold for conflict to the conflict report so you can see what scores would cause a conflict. <image>. <code> Solution: We highlighted the review scores that fell below the lower threshold in yellow and highlighted the review scores that fell above the upper threshold in orange. <image> <code> Solution: We added the lower and upper threshold metrics to the report page so users could understand why certain review scores caused a conflict. Submit the review 6. Since the scores differ by more than 15% the email will be sent to the instructor. 7. Access the email by logging in to the instructor email account and check if the email contains the following details: 1. Names of the reviewer and reviewee 2. Link to the conflicting review 3. Link to the newly created report view corresponding to the conflict 4. Link to edit the assignment notification limit 7. The conflict report can be accessed in 2 ways: i. Access the report page using the link mentioned in the email. Login to instructor account and in the reports section select 'Conflict Review Report' The screenshots below display conflict email and the conflict report. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. <link> 8. <link> 9. <link> 10. <link> 11. <link> 12. <link> 13. <link> 14. <link> 15. <link> 16. <link> 17. <link>. Github: <link> Pull Request: <link>.","In terms of prose, this report is quite good, describing the problem well in narrative fashion.  Changes are described well too, making it easy to see and understand what has been done. Also, there are a variety of diagrams and screenshots used to illustrate the changes.  The only issue I see is that some of the lists are pretty long (~ 10 items), and it might have been easier to grasp if they had been broken down into sublists."
E1679,"Currently, the functionality of calibration is limited. It does not support varying-rubric-by-round feature. And for student side, there is no way to notify for an author to tell that a particular review that they received was submitted by an expert. Moreover,if an expert (instructor or TA) has reviewed an assignment, the students should be able to see how that expert rated the assignment, just like they can see calibration results for calibrated assignments by clicking on the “Show calibration results” link. Snapshots of what is currently implemented: 1.Log in as instructor6 and edit an assignment. 2.In “General” tab, check the box of “Calibration for training” and save the change, then “Calibration” tab will be shown. <image> 3.Go to “Calibration” tab and the a list of student works will be given and the instructor can select one of them to begin a calibration review. <image> 4.The review rubrics for calibration is the same as student reviewing and the instructor can make his own review. <image> 5.After the instructor submitted his review, the student can see the detail of this review in his “score” section. But currently, there’s no way to distinguish student reviews and expert reviews. In addition, the instructors cannot implement a multi-round review and vary the rubrics for different review rounds. <image>. 1.app/views/student_review/_responses.html.erb 2.app/views/assignments/edit/_calibration.html.erb 3.app/views/student_review/list.html.erb 4.app/views/grades/_reviews.html.erb. Change the “is_calibrated” field in assignment table to “has_expert_review” Change the “calibrate_to” field in response_map table to “expert_review_to” A new DB migration file would be added to change name of the two existing columns in the DB to a new one and all related search of these 2 column in the files involved above have to be changed to the new name. In assignment setting page (“General” tab), change the checkbox title from “Calibrated peer-review for training?” To “Add expert peer review?”. The related page is at app/view/assignment/index.html.erb. <image>. When instructor clicks that checkbox, there will be a new tab named “Calibration”. Change the tab name from “Calibration” to “Expert review” on the assignment setting page and also change the partial file name from “_calibration.html.erb” to “_expert_review.html.erb”. <image>. To make second round review with different rubric, we can refer to the “/student_review/list” page by impersonating a student, clicking a vary-rubric-by-round assignment and then clicking the “Others' work” link. A student can conduct second or third round review by clicking the update link, then new review form with different rubric will be shown. The related page is at app/view/assignments/edit/_calibration.html.erb. On this page, an update link would be added when an assignment has the second round review as it is in student review page. <image>. Remove “@assignment.is_calibrated == true” condition from app/views/_responses.html.erb, line 80, which means this link will show if expert peer reviews are available no matter whether this assignment is a calibration assignment or not. After this condition is removed, the “Show calibration results” will always be presented to students in their review list rather than the assignment itself also have to be “calibrated”. <image>. <image> As the image shown above, among all the reviews received by the students, if Review 1 is the expert review by the Instructor, two asterisks will be added ahead of its name to indicate that it’s an expert review by the instructor rather than a normal student review.","Design approach is well defined. Could've used observer pattern to log the events. should've listed the location of the source code where the events are to be logged. Testing could be elaborated more than just saying ""RSpecs will be written wherever required"". List the test cases, e.g., filtering user ID, date..."
E1686,"2. when do reviewers submit peer-reviews. 3. when do reviewees send author feedback. 4. when do reviewers update their peer reviews. <image> From a perspective (both instructors and students), users should be able to see such a timeline with all the events for each submission of an assignment. The events can be - 1. add/edit events of various submission links/files 2. Reviews 3. author feedbacks 4. peer reviews Each of these artifacts can be edited and updated multiple times. We use the table suggested in the problem description “submission_histories”- 1. Id :: integer- primary key for this table. 2. team_id :: integer ← foreign key to the teams table 3. submitted_detail :: string ← details of the event. This can be one of x values. 1.1. Link - if it is a assignment submission link. This can further be of 4 types - 1.2. Google Docs 1.3. Wikipedia 1.4. Github repository 1.5. Any other web link 4. Review ids - if the event is a review submission 5. Author feedback id - if the event is an add or edit operation on author feedback. 6. Peer review id - if the event is an add or edit operation on peer review. 7. Submitted_at :: datetime ← to store the timestamp of the event 8. Type :: string ← field which distinguish between different types of events - to be used for polymorphism. 9. Action :: string - add / edit / delete based on the event. These are the common components under which each component in the timeline can be classified. Each of these components are explained in detail on how it fits into the timeline and its significance and types listed. Data stored in submission_histories table 1. Google Document, Wikipedia article, Github repository url : All of these are types of links given by the team during their submission. 3. Peer Reviews, Author feedback: Peer reviews and author feedbacks are updated into the submission history table for every edit that takes place. The “updated_at” field acts as the current timestamp for edits in the Peer Reviews and Author feedbacks and the “created_at” field marks the start of these Events. Data retrieved from existing tables 1. Reviews: Timestamp for assignment reviews are taken from “responses” and “response_maps” table. The responses table contains round field and when “is_submitted” flag is true, the submission appears on the reviewee timeline where the “reviewee_id” retrieved from response_maps table. The reviews attached to the respective reviewee are collected and updated_at field gives the submission timestamp which is used on the timeline. Each review is collected and is added to the single Event map. 2. Timeline Parameters: Values corresponding to an assignment which are common for a given Assignment are retrieved from the assignments table. And the timeline parameters are obtained by calculating from the created_at which is the start date for the assignment and the field rounds_of_reviews determines the deadline by adding up the value stored in days_between_submission field of the same table. The Events - Start Date, Submission Deadline and Revision Deadline and Final assignment deadline exists for each assignment. All the components are then added into one single map - Event -> Timestamp which is sorted on timestamp values and is displayed on screen. <image>. <code> <code> 1. files_submission_history <code> 1. github_pull_request_submission_history <code> 1. github_repo_submission_history <code> 1. github_submission_history <code> 1. googledoc_submission_history <code> 1. link_submission_history <code> 1. submission_history <code> 1. wikipedia_submission_history <code> Controllers 1. submitted_content_controller <code> Views 1. submitted_content/_main.html.erb <code> 1. submitted_content/_submission_history.html.erb <image> <image>. 1. models/github_pull_request_submission_history_spec.rb <code> 1. models/github_repo_submission_history_spec.rb <code> 1. models/link_submission_history_spec.rb <code> 1. models/submission_history_spec.rb <code> 1. models/wikipedia_submission_history_spec.rb <code> 1. UI Testing 1.1. Login as student/instructor. 1.3. Here you will find a timeline with several tags like submission, review, resubmission, rereview. 1.4. Also, There will be a tags for the authors submitting and updating their artifacts, reviewers submitting peer-reviews, reviewees sending author feedback and reviewers updating their peer reviews. 1. <link> 2. <link>.","Screenshot is too big. I am not quite understand ""Refactor files"" section; more narrative description is needed. Section ""The file we need to edit"" should be ""Files we need to edit"""
E1457,"Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.5. <link> 1.1.6. <link>. <ref> <link> </ref> ""Expertiza project uses peer review to create reusable learning objects. ""<ref> <link> </ref> Students select from a list of tasks to be performed, with several students selecting each task. These learning objects can be improved iteratively; for example, the next year’s class can be presented with the examples developed by students the previous year, and asked to identify shortcomings and develop improved examples.<ref> <link> </ref> More information on Expertiza can be found <link> . Refactoring helps to<ref> <link> </ref> 1. Understand what led to poor code design 2. Fix code which is difficult to understand 3. Express each idea “once and only once” 4. Recognize missing or inadequately formed classes 5. Simplify overly complex relationships between classes 6. Achieve the right balance of responsibilities among objects 7. Make code easier to test and more maintainable. We identified the following categories of code smells in the helper module: 1. Lengthy Definitions : These are the methods that have too many responsibilities and collaborators. 1. Duplicated Code : These are those pieces of code that does almost the same functionality of some other piece of code leading to a bad design style. 1. Bad method names : A good method name is expected to adhere to the Ruby style and design style guidelines. A good method name in combination with good practices should resemble a user story. 1. Used and unnecessary methods : These are those methods that were useful when the code was first developed. There are many documented refactoring techniques, and a few common ones are below.<ref> <link> </ref> 1. Rename Method : Renaming identifiers can reduce the need for code comments and nearly always helps to promote greater clarity. For example: <code> Should be: <code> 1. Extract Method : It consists of breaking up long methods by shifting overly complex chunks of code into new methods which have very descriptive identifiers. For example: <code> Becomes: <code> 1. Inline Method : Sometimes you want the opposite of the Extract Method technique. So to fix this problem we'll convert the method invocation into an inlined piece of code. 1. Pull Up Method : When you have duplicated code across two separate classes then the best refactoring technique to implement is to pull that duplicate code up into a super class so we DRY (Don't Repeat Yourself) out the code and allow it to be used in multiple places without duplication (meaning changes in future only have to happen in one place). The DynamicReviewMapping Controller is actually a helper to the ReviewMapping controller. The review mapping controller maps reviews to each user. Currently, there are two ways to assign reviews to user: The user can either select a submission himself, which he wants to review, or the site can suggest a review to the user. Currently, the user can give more than two reviews. The ReviewMapping controller had a method so that all the users are assigned reviews automatically. The dynamic review controller helped the review mapping controller assign reviews so that the reviews are never mapped such that the last user does not have any review to map, except his own. For example, consider three users, U1, U2 and U3. If U1 is assigned U2's work and U2 is assigned U1's work, U3 would not have any work to review. The dynamic review mapping controller makes sure that such a condition does not occur. The code had a single method, and the method did not have any useful functionality. 1. The code block between line 808 to 825 was duplicated in 3 places in this file. We have refactored the code to remove this bad smell. We have created a method called create_message to avoid duplication in the code. Eliminated duplication in code) 1. Method assign_metareviewers, assign_reviewers_team were too long. Eliminated lengthy methods and meaningless method names) 1. Method assign_reviewers_individual was not used anymore. None of this would actually change the functionality of the code. To make sure, we tried to look for the usage of the code. Again, after extensive searching, we figured that the code was never used. As such, currently the Controller is not used. We made the changes, but we have no way to check the code. We did the best we could, and we are sure that there are no errors in the refactored code. 1. <link> 2. <link>.",Very little of the writeup refers to changes made by their project.
E1402,"There are three review strategies in Expertiza: 1. Auto Selected 2. Student Selected 3. Instructor Selected In auto-selected reviewing, a reviewer picks the topic to review on, but not the individual submission. Student-selected allows the reviewer to pick from a list of submissions, not topics. In auto-selected and student-selected reviewing, the student is not allowed to pick from any topic or submission, but only to choose among those that have received the fewest reviews so far. This strategy may be modified by selecting a non-zero threshold k as follows: A topic is review able if the minimum number of reviews already done for the submissions on that topic is within k of the minimum number of reviews done on the least-reviewed submission on any topic. It is a peer-review system that allows students to select a topic to work on, submit their work and review their peers' submissions. As mentioned above there are different strategies available for reviewing other student's work. It allows students to choose many topics without submitting any review for them. In some cases, this causes total number of reviews for a submission to exceed the maximum limit set for assignment. Allowing only the topic/submission with the minimum reviews to be allowed for review, did not allow users to select a topic which has few reviews more than the minimum but has not yet crossed the maximum threshold. 2. Ability to set maximum threshold of reviews for an assignment should be available only for Auto-selected and Student-selected but not for Instructor-Selected review strategies. The existing design hid this option to set max threshold for Auto-selected only. Another design alternative was to display this field only for student and auto selected. 3. If the assignment had no topics, the user was directed to a page with a single button which further directed him to the page which listed available submissions for review. 4. The existing design had no restriction on the number of reviews the student is allowed to begin without actually submitting any of them. As mentioned before, this could evade the maximum number of reviews for a submission. Another problem was some students were unable to perform any reviews as others performed too many. If we restrict the outstanding number of reviews per student to three, number of selections per student will get restricted if they have more than 3 outstanding (i.e. topic selected, but review not started) reviews. 5. A topic with only reviewer's own submission or with already reviewed submissions was also available for selection. Since reviewer can't review own submission or any submission already reviewed, he/she was provided a message that no submission is available to review after selecting such a topic. The user then had to go back and select some other topic if available. We have improved this design by displaying only topics with valid submissions to review. Update code for Student-selected reviewing to cycle through submissions and not topics. > We observed that student-selected reviewing cycles through submission after topic-selection. The topic selection makes sense instead of listing out all submissions in a topic-based assignment since reviewer can make a better choice of shortlisting submissions to review after choosing a topic of interest. Make the ‘maximum threshold’ input field appear on Create/Edit assignment>Review Strategy tab only when Auto-selected or Student-selected reviewing is chosen and not when Instructor-selected is chosen. Allowing a student to choose any number of reviews to do, without submitting any of them, allows a student to work on multiple reviews at the same time, but it also allows students to evade the limit on number of reviews that can be done. Introduction of a fixed threshold value - '3' which limits the number of reviews the user can begin without submitting previously selected reviews. This will help in limiting the evasion of maximum threshold. <code> Also we have introduced code to reject user's own submission and submissions already reviewed by user so that user has right choice of submission to review every time mentioned in Objective 5. If there are no topics, Auto-selected reviewing should still work, but it should select one of the submissions that has the fewest reviews so far. > If the reviewer selects his own submission for review, he is not allowed to perform the review and presented with message saying “ There are no more submissions to review on that topic.” Instead it would be better not to allow him to select his own submission for review. Also, if the user has reviewed the submission/topic with the least reviews, he should be allowed to perform review on other topics which have not reached their maximum threshold. There were many issues faced in the process of fixing the review strategies. We created a new assignment with 5 topics. 1. Fix control flow of student-selected reviewing similar/through auto-selected reviewing. 1.2. Contributors are removed if they have not selected a topic or not submitted. 1.3. Contributors are removed if their topic is not reviewable at the current time. 1.4. Contributors are removed if they have “too many” reviews (as determined by the review threshold).","Pretty good on many aspects, but does not explain design principles or patterns used, which was a major objective of the assignment."
E1981,"The rubrics in expertiza are created by instructors. These Rubrics only contain questions that are related to the existed topics. Now, Expertiza only supports students to pull questionnaires is specific rubrics to get some help. Even that they can ask about anything that is relevant to all the projects that will be submitted But when students encounter difficult problems which are not in the existed topics, and they want to get special advice on that new field, the demand for creating supplementary review questionnaire raises. This project (E1981) aims to solve this problem by allowing students to add questions to the standard instructor generated rubric so that they can get specific feedback on from the reviewers. The github repository is <link> . We will add the Supplementary Review Questions to the current Review Questions, and show these student-generated questions under the rubric given by instructor. Goal: In Expertiza, all kinds of rubrics and surveys are subclasses of Questionnaire. A Questionnaire can contain “questions” of several types (e.g., checkboxes, dropdowns, text boxes). We'll add a new subclass of Questionnaire called, say, SupplementalReviewQuestionnaire. 1. there should be a checkbox when creating the whole questionnaire to indicate whether this questionnaire will have supplemental review questions or not. 2. there should be a button that has the content ""add supplemental questions"". <code> <code> 3. After the reviewer finished the review, student can find the supplemental questionnaire in the review page. How we will do this: 1. add a variable in the questionnaire class. 2. add another file for a supplemental questionnaire and save them to the database. 3. add a method to get the corresponding supplemental questionnaire and to add questions into the existed questionnaire. 4. we should add another method to show the supplemental questionnaire in the review page. 1. Assignment Creation Page in Instructor's Account We plan to implement a check box under the column of Rubrics in the assignment creation page indicating whether the instructor allows students to add specific questionnaires with respect to their projects. 2. Your Work Page in A Student's Account We plan to implement a link or button on the Your Work page of an assignment of a student whose assignment is enabled to create supplementary review questionnaires by the instructor, in order to redirect to the Review Rubrics Creation page. 3. Review Rubrics Creation Page In this page, students are able to create supplementary review questions regarding the specifics of their own assignments. 4. Review Page In the Review Page of reviewers, the supplementary review questions created by the owner of the assignment will be shown to reviewers along with the standard review questions created by the instructor. 5. Review Results Page The Review Results Page should display the results of standard questions created by the instructor as well as the results of supplementary review questions created by the instructor. <image>. 1. There should be no link for ""Supplementary Review Questionnaire"" for team members or reviewerss, if the instructor disables this section in Assignment Creation Page. 1. If the instructor enables this section, the link for ""Supplementary Review Questionnaire"" should appear in the ""Your Work"" section of a student, and redirect to Review Rubrics Creation Page. 1. After created or edited, the supplementary review questions should appear as part of the whole review question sheet in Review Page (along with the standard review questions created by the instructor), to team members, reviewers, and the instructor. 1. After a reviewer saves or submits, the responses to the supplementary review questions should appear when (s)he views the responses. 1. After review deadline, all responses to the supplementary review questions of reviewers should appear in My score page of students. spec/controllers/supplementary_review_questionnaires_spec.rb Test if the link of ""Create Supplementary Review Questionnaire"" correctly redirects to the right page. <code> spec/features/supplementary_review_questionnaire_spec.rb Test if a supplementary questionnaire can be created, modifid and stored. <code> spec/models/team_spec.rb <code>. 1. When a new assignment is created, the instructor can enable supplementary questionnaire via the highlighted checkbox. <code> <image> 2. In the submit stage, all team members can create and edit one supplementary quetionnaire to their team. <code> <image> <image> 3. In the review stage, reviewers will get one complete questionnaire (including both the regular questionnaire created by intructor, and the supplementary questionnaire created by the team) and do the review. <code> <image> 4. After review stage, team members can view the list of all the scores and responses of the complete questionnaire of their team. <code> <image>. All modifications are included in the <link> . A new class SupplementaryReviewQuestionnaire (subclass of Questionnaire) is created. Expertiza on Github: <link> Pull Request: <link> Pull Request History: <link> <link> <link> <link> <link> <link> Video: <link>.","Good description of what is needed, but as to what was done, code files are displayed with no explanation of the strategy followed.  It would be just as easy to read a code listing.  This is also true of the automated tests."
E1450,"What it does: Change UI of Expertiza to support varying rubric feature (allow instructors to specify different review rubrics for different review rounds). 1. A checkbox “Review rubrics vary by round” should be added to the “Rubric” tab in the view of creating/editing assignment. No corresponding field in “assignments” table is necessary. We can tell if this checkbox should be checked by checking “assignments_questionnaires” table by current assignment_id. If there is no record with a non-null value in “used_in_round” field, this assignment is not using this feature and the checkbox should not be checked. (if one assignment has 2 rounds but they are using the same set of rubrics, for each type of rubric there should be only one entry with “used_in_round” field null)R 1. There should be a editable “deadline name” for each due date on “due date” panel if this type of review is specified to be “varying by rounds” in the “rubrics” tab (the input should be recorded in deadline_name field in due_dates table) 1. Another “description URL” text box should be editable when this type of review is specified to be “varying by rounds” in the “rubrics” tab (the input should be recorded in description_url field in due_dates table) 1. The ""deadline_name"" and ""description URL"" could be hidden when you change the status of the checkbox in Due_Date tab 1. A drop-down box which help instructor to select review rubric should be added for a review round when this type of review is specified to be “varying by rounds” in the “rubrics” tab (the input should be recorded in assignments_questionnaires table) 1. There are no tests for the code. No checkbox for ""Varying Rubric by Round"" on the general tab for Instructors. In Rubrics Tab, add a Review rubric varies by round checkbox, when checked, it displays corresponding number of rounds of Review round 1 to Review round n; when unchecked, it displays as usual. At the same time, it will store new data in the table into database, in assignment_questionnaires table, it will add 1,2,3...n to used_in_round column if the review rubric varies by round; if not, it will store NULL. Everytime webpage refreshes, the checkbox is checked or not according to the value of used_in_round column in the assignment_questionnaires table. No test_box for ""deadline_name"" and ""description_url"" on due_date tab. 1. Add Due Date Name and Description_url to the table, users can fill in blanks and store them in DB 2. Rewrite set button function calling, everytime the button is pressed, it calls submit_form() and update in assignment_controller, then change the @assignment.rounds_of_review value in order to make changes in the DB instantly, which will help Rubrics tab display correctly 3. Add a Change name and description url checkbox. If checked, the Due Date Name and Descripton_url will whow up; if unchecked, the two columns will hide. 4. Everytime when webpage refreshes, the checkbox value will be set according to whether there’s value that is not empty in the deadline_name or description_url columns in due_dates table in DB. <ref> <link> </ref> Here's the example: We need to add a round_number for the questionnaire() method in order to make it return different values (actually from different rows of the assignment_questionnaire table) because there're more than 1 rounds now and each round may have different values. A few cucumber tests are added to perform the functional and integrated test for our project, such as: Scenario 1: An instructor can set the ""Review Rubric Varies by Round"" for an assignment, and set due dates for all of submissions and reviews, as well as different rubrics would be used Scenario 2: A student should see the review rubric for 1st round in the other's work link Scenario 3: The instructor change the due date to start the 2nd round of review Scenario 4: A student should see the review rubric for 2nd round in the other's work link. <image> <image> As you can see, a Review rubric varies by round checkbox will make a difference, which makes sense. <image> <image> As you can see, a Change name and description url checkbox will make a difference, which makes sense. <references/>.","The screenshots are at the end, which is too far down.  They should be near where the screens are talked about.  I don't think the Javascript functions are adequately defined.  Exactly what do they do (and it looks like they are too long)?"
E1405,"This model allows for much of the functionality the student requires to interact effectively with expertiza. Here a student is able to sign up for topics, form teams, submit assignments, review other students' work, and check his or her own scores. Initially, there were 26 tests with errors. Many tests required functionality or fixtures that were likely changed by people working on expertiza over the years. Many fixtures required to correct the tests were missing, and had to be added or created. Additionally, several tests were referencing deleted elements of fixture files which were added in order to correct test functionality. Finally, there were certain elements of the code itself in the controller file which had to be corrected in order for tests to run. All tests now pass without errors, failures or deprecation warnings: ......................... Finished in 1.235192136 seconds. 25 tests, 26 assertions, 0 failures, 0 errors, 0 pendings, 0 omissions, 0 notifications. After digging into the code, it became clear that what's needed isn't more tests, but better tests. The existing tests were very obtuse and frequently broken. They are now much more maintainable. There is no current unit test file for student_task, which means there aren't unit tests. Such tests should be added in the future in order to ensure proper functionality. With regard to student_task_controller_test.rb, it really should be refactored more than expanded. It has reasonable test coverage, what it needs is easier to understand, more elegant tests.","Very short, only gives a vague idea of what was done.  You really have to read the code to tell."
E1986,"If the choice of which submission to review is left to student itself, he/she would choose to review those topics which are related to their project or whatever they are highly interested in. When an assignment participant wants to review others’ work, they will be asked to choose an assignment topic. The participant will be allowed to choose from among those assignment topics that have not been already assigned to 10 other participants. If they choose the ‘I do not care about the topic I review’ option, a random topic will be chosen from all the available topics and will be assigned to them. <link> <link>. <image> However, Students and Reviews have many-to-many relationship (a student can choose multiple submissions for review and a submission can be given to multiple students for review) <image> The Mathematical formulation is itself wrong in E1856 and E1928 and they have used the below shown diagram to represent the relationship. <image>. <link> (One-to-One) <link> (One-to-Many). 5. The algorithm needs to skip the review topic that the user has worked on. Taken in reference from <link> (Basically a Gale-Shapely version for many-to-many matching situations) We have a set of students S = {S 1 , ..., S n }, and a set of topics T = {T 1 , ..., T m }. Each student must get exactly q S topics (The threshold in our case is q S = 4, it’s up to the student to decide how many of these they want to actually review. ), while each topic must be assigned to at least q T reviewers. Students will submit a list of preferences over the set of topics in linear order. If they submit the preferences for only a certain topics, the rest of the topics will be appended to their preference list in a random order. The topics shall have (possibly different) linear order preference over the set of students according to the timestamps of their time of bid and the total number of topics they have bid for. Students with lower timestamps and who bid for lower number of topics will be given higher preference. To begin, we will try to obtain a matching with an approximately equal number of students reviewing each topic, which we call uniform distribution. The average number of reviewers assigned to each course will be <image> where n is the number of students, and m is the number of courses. Let us assume that <image> where <image> Matching 𝝁 is a mapping which assigns exactly qS different topics to each student in Sand at least qT different students to each topic in T. We denote the set of topics assigned by matching 𝜇 to the student si and the set of students who were assigned the topic tj as 𝜇(si) and 𝜇(tj),respectively. Blocking Pair (Defined according to our problem): A pair (s, t) is called a blocking pair, if the student is associated with the topic (If he/she is in the group which works on topic t). The goal is for each topic to be assigned to either p| and p| students, and to assign exactly qS courses. The algorithm: 1. Step 1: Each topic proposes to accept the first pI students in its preference list. Each student accepts no more than qS proposals according to his/her preferences, rejecting the rest. 1. Step k: Each course that has z < pI students proposes to accept pI - z students it has not yet proposed to. The algorithm stops when every topic that has not reached the maximum quota pI has proposed acceptance to every student. <code>. 1. A new link is added in the student_task/view.html.erb file, so that the user can be redirected to the review bidding view to bid for a review topic. <code> <code> 1. We are assigning color based on number of people who have chosen for that particular topic, this is handled in Review_bidding_controller.get_quartiles(topic_id) method 2. In the equation for the average number of reviews assigned to each course, we can compute n and m which are essentially #number of participants and #num of topics, the value is qs is taken from @num_reviews_allowed parameter which is associated with every assignment. <code>. 2. It is guarenteed that every participant would have recieved a certain number of reviews based on the hyperparameter @num_reviews_allowed defined for every assignment in the Assignment 3. Inputs for the service is as follows: <code> 1. Output is a map of arrays where every user has a list of topic id's that are to be done. <code>. 3) Guide using gunicorn server: <code> 4) Guide for using Apache Web Server <code> <code> <code> <code> <code>. <link> <link> <link> <link>.",This is an excellent description of the problem and the mathematical basis for a solution.  What it is missing is a description of how the tests work.
E1572,"The instructors can create assignments using this application and customize and manage them. We were expected to write a feature test which mocks the creation of an Assignment. For Expertiza Assignment management is the central part of the workflow. Goals: 1. Understand the flow of the Assignment creation by instructor manually. 2. Mock the same steps using capybara 3. Create multiple assignments with different options and testing their existence. 1. <link> 2. <link> 3. <link>. Visit <link> for the repository URL. <code> See <link> for help on setting up git, authenticating with SSH keys, and checking out a repository. In the expertiza directory: <code>. 1. Go to the expertiza directory. <code> 1. Create the development and test databases. <code> 1. If available, import the database dump that you received in class to pre-populate your database. eg: <code> 1. Run the Expertiza database migrations. <code>. 1. Go to the expertiza directory if you are not already there. 1. Run the test <code> Note : As our project involves implementation of feature tests for assignment creation rather than refactoring, we do not test the new code via UI (as the new code added are themselves tests). Note : Travis CI build fails because we are directly using the development database for our tests, thus Travis CI is not able to locate the login information. This was done because it was not possible to create factories or fixtures for our tests. 2. Then set the JAVA_HOME environment variable by typing this on the terminal <code> 1. Run bundle install again. 1. To solve this, we have to install PostgreSQL. 2. Then type in the following set of commands in the terminal <code> 1. Run bundle install again. 1. Here is the link of Expertiza scrubbed DB ( <link> ) 2. Download the file, unzip it and dump to MySQL. 3. Then type <code>. For any other kind of errors faced during setting up the repository, you can write to us at any of the following ids. 1. aslingwa@ncsu.edu 2. gmeneze@ncsu.edu 3. vpaul@ncsu.edu. 1. assignment_creation.rb 2. spec_helper.rb 3. rails_helper.rb The assignment_creation.rb contains the feature tests written to test the creation of the assignment. The rails_helper is copied to spec/ when you run 'rails generate rspec:install'. We have used Capybara and RSpec to test our application. Capybara helps you test web applications by simulating how a real user would interact with your app. One of the major reasons for selecting Capybara to write our tests was that it has an intuitive API which mimics the language an actual user would use and also we can run tests from fast headless mode to an actual browser with no changes to our tests. No matter which combination of parameters are selected in the creation of the assignment, the test cases should pass. Following are some of the scenarios which we have tested. 1. Create Assignment with Has teams parameter 2. Create Assignment with Has quiz parameter 3. Create Assignment with Wiki assignment parameter 4. Create Assignment with Micro-task assignment parameter 5. Create Assignment with Reviews visible to all other reviewers parameter 6. Create Assignment with Is code submission required parameter 7. Create Assignment with Available to students parameter 8. Create Assignment with all options 9. Create Assignment with no options 10. Create Assignment with Has teams and Has quiz parameters 11. Create Assignment with Micro-task assignment and Reviews visible to all other reviewers parameters 12. Create Assignment with Is code submission required and Available to students parameters 13. Create Assignment with Has team, Has quiz and Wiki assignment parameters 14. Create Assignment with negative scenario. 1. Create Assignment with has teams parameter 2. Create Assignment with has quiz parameter 3. Create Assignment with has Wiki Assignment parameter 4. Create Assignment with has Micro-task assignment parameter 5. Create Assignment with has Reviews visible to all other reviewers parameter 6. Create Assignment with has Is code submission required parameter. <code> Given above is a portion of the code which we have to execute before testing each scenario. In order to be able to create assignments, the instructor has to first login. So we set up the environment of logging in in the before(:each) block and navigating to the page where assignments can be created. We have written a total of 27 test cases in the assignment_creation.rb testing all the permutations and combinations with which an instructor can create an assignment. Listed below are a few of those test cases for the creation of a private assignment. <code> <code> The test cases written also contain tests for the creation of public assignments. Listed below are the following tests. Once again we need to sign in the instructor before he can create any assignments. <code> <code> <code>.",Organization is poor.
E1527,"This project is developed as part of Expertiza project <ref> <link> </ref>. Feedback is provided to reviewers on the following metrics: 1. Review relevance: This metric tells the reviewer how relevant the review is to the content of the author's submission. Numeric feedback in the scale of 0--1 is provided to indicate a review's relevance. 2. Review Content Type: This metric identifies whether the review contains 'summative content' -- positive feedback, problem detection content' -- problems identified by reviewers in the author's work or 'advisory content' -- content indicating suggestions or advice provided by reviewers. A numeric feedback on the scale of 0--1 is provided for each content type to indicate whether the review contains that type of content. 3. Review Coverage: This metric indicates the extent to which a review covers the main points of a submission. Numeric value in the range of 0--1 indicates the coverage of a review. 4. Plagiarism<ref> <link> </ref>: Indicates the presence of plagiarism in the review text. 5. Tone: The metric indicates whether a review has a positive, negative or neutral tone. 6. Quantity: Indicates the number of unique words used by the reviewer in the review. Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> 1.5. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.4. <link> 1.6. <link>. Currently, Autometareviews project is used as a gem<ref> <link> </ref> in Expertiza project. Purpose of this project is to migrate this gem to a web service<ref> <link> </ref> and expose its methods on web, which can be consumed by any application as web service. Older gem was dependent old libraries<ref> <link> </ref> such as Stanford-core-nlp, rwordnet, etc. We will migrate them to new libraries without breaking the existing feature-set. We will not add any new feature to the existing feature set provided by the gem. There are three separate scope items in this project - 1.1. Migration of existing gem application to a web service 1.2. Refactoring the existing ruby classes 1.3. Migrating to newer libraries, wherever possible. Any major code change due to inclusion of newer libraries will be communicated to Expertiza project team. Existing code will be tested to ensure the functionality does not change. All developed code will adhere to the ruby on rails coding guidelines<ref> <link> </ref>. Metioned below are the tasks we will perform as part of this project.<ref> <link> </ref> This system is still in nascent stage and have many performance related issues. We will review the method used and present our finding about areas of concern. 4. Legacy Code Description: As the system has been modified for bug fixes and enhancements, unnecessary code has accumulated. Solution: Isolate and remove all dead code. 5. Code beautification Description: Coding style used in gem is not based on Ruby on Rails style, which makes it difficult to read for any Ruby programmer. The libraries used by gem are very old. Libraries, we have identified are: 1.1. stanford-core-nlp <ref> <link> </ref> 1.2. rwordnet <ref> <link> </ref> 1.3. rjb <ref> <link> </ref> 1.4. bind-it<ref> <link> </ref> We will also migrate the project to use Java 8<ref> <link> </ref>. Expertiza system tries to evaluate each review using an automated meta-review system. This system is packaged as a library and used by Expertiza. Automated Metareview system is an independent entity and can be used by other peer review systems as well. There are many other peer review systems, which can benefit from this system, if this is available for them to evaluate their rubrics. We are working on migrating this system from a library to a web service. The Metareview system is Natural Language Processing based system that compares the reviews written with the original article. <image> Web Service Design The request JSON object to the method will have the following parameters : 1.1. original article 1.2. review written for this article 1.3. rubric used during article review. The web service will return the meta-review as a JSON object. For the project, the code that is being modified is assumed to be correct and meet all feature requirements of the system. We will be using the existing test suite used by gem to test any new code modification. We will be writing new test cases for web service implementation and any new public method exposed by existing classes.","Very clear (and correct!) description of what needs to be done. All tasks that will be done are well described. Rather abrupt beginning, fails to show where the project fits in the context of Expertiza and other PR systems."
E1979,"1. In Expertiza, peer reviews are used as a metric to evaluate someone’s project. Once someone has peer reviewed a project, the authors of the project can also provide feedback for this review, called “author feedback.” While grading peer reviews, it would be nice for the instructors to include the author feedback, since it shows how helpful the peer review actually was to the author of the project. 1. Currently, the instructor can only see several information, including numbers of review done, team the student which have reviewed, about author feedback. The current view report can be shown as below. 2. So the aim of this project is to build more feedback information into the reviewer report. So that the instructor of the course is able to grade reviewers based on author feedback and review data. 1. We need to implement the integration of review performance which includes: 1. # of reviews completed 2. Length of reviews 3. [Summary of reviews] 4. Whether reviewers added a file or link to their review 5. The average ratings they received from the authors 6. An interactive visualization or table that showed this would be GREAT (We may use “HighChart” javascript library to do it.) 1. After analysis the current code, we found that the number of reviews, summary of reviews and visualization of length of reviews have already existed in the system. So we only need to finished the following tasks. 1. Whether reviewers added a file or link to their review 2. The average ratings they received from the authors 1. As the description of our object, the average ratings part of this project has been done last year. And they add a new column (author feedback) to review report. So we also need to improve the several functions of author feedback. 1. Fix code to calculate the average score of feedback 2. Make the author feedback column adjust to existing view. 1. So here is our plan and solutions to finish this project. The basic design of this project can be shown in the UML flow chart below. 1. We decide mainly change the page of ""Review report"" (Log in as an instructor then go to Manage -> Assignments -> View review report.) 1. We are planning to add one more column to show the average ratings for feedback for a student's review of a particular assignment. The logic for calculating the average score for the metareviews would be similar to already implemented logic for the ""Score Awarded/Average Score"" column. 2. We are planning to improve the column of review length. Now it is just bare data and average data. We will make the review length into visualized chart by using “HighChart” javascript library. So that length of review will become more clear for instructors. The chart will be shown like below. 3. We are planning to add all links which attached to their reviews below Team name. If there are links in the review, the links will be shown below. The Controller design is based on the data we need for view. As we found that the links and files in review are both stored as URLs, so we only need to list url in reviews. Specify changes will be shown in File Change. Here is the file we have changed. 1. _review_report.html.erb We add a new column to show average score of feedback score. <code> Then we use new-added method to show all URLs below each Team name. <code> 2. review_mapping_helper.rb We first fix calcutate_average_author_feedback_score method. <code> Then we add a new method called list_url_in_comments to shown all urls. <code> 3. review_mapping_helper_spec.rb 4. review_mapping_spec.rb Finally, we add some tests for the changes made. The specific test cases will be shown in Test Plan. As we add new column for Average Author feedback, we add corresponding Rspec test in review_mapping_helper_spec.rb. <code> During the testing process, we found that there are no tests for other columns as well. So we also add some tests for number of reviews completed, length of reviews and summary of reviews in review_mapping_spec.rb <code> <code> <code>. 1. Log in as an instructor 2. Click Manage and choose Assignments 3. Select the Assignment you want to further check, for example, Final project (and design doc) 4. Choose review report and click view 5. Check ""Average Feedback Score"" column, for example, student5061 have reviewed Team_BEND_Final_Project and his Average Feedback Score is 13 of total score 15. 6. Check urls below each ""Team reviewed"", for example, student5698 have reviewed Final project(and design doc)_Team_113, and there is a URL about reactkungfu in his review The anticipated result can be same as below.","I think it would have been clearer to start out by describing what you were going to do, and then explain what you didn't need to do, rather than the other way around.  The code snippets provided from _review_report.html.erb don't really give enough context to see what is being done.  When you said you fixed something, it would be helpful to say what was broken and then highlight what fixes it, rather than just giving a code sequence."
E1738,"Given that submissions to Expertiza are digital in nature, the opportunity exists to utilize tools that automate plagiarism validation. SimiCheck has a web service API that can be used to compare documents and check them for plagiarism. The goal of this project is to integrate the SimiCheck API into Expertiza in order to allow for an automated plagiarism check to take place once a submission is closed. . The completed code from previous projects did not clearly demonstrate successful integration with SimiCheck from Expertiza, and was not deemed production worthy. 1.2. Since SimiCheck has already implemented file diffs, links will be provided in the Expertiza view that lead to the SimiCheck website for each file combination 1.3. Comparison results for each category will be displayed within Expertiza in a table 1.1.1. Each row is a file combination with similiarity, file names, team names, and diff link 1.1.2. Sorted in descending similarity 1.1.3. Uses available data from the SimiCheck API’s summary report. The current New Assignment interface has two new configuration parameters, which have also been added to the Assignment model. SimiCheck Delay (hours) and SimiCheck Similarity Threshold (percentage) were added. The Plagiarism Comparison Report was added to the ""Review Report"" interface's select box for a selected assignment. There is no need to store the raw content sent to SimiCheck. We added ""simicheck"" and ""simicheck_threshold"" properties to the the existing Assignment model. The ""simicheck"" property accommodates the number of hours to delay the execution of the Plagiarism Checker after the assignment's due date. ""simicheck"" is -1 if there is no Plagiarism Checker scheduled, and between 0 and 100 (hours) if the assignment is to have a Plagiarism Checker Report. The ""simicheck_threshold"" property is a percentage that filters the Plagiarism Checker's Similarity results. The threshold refers to the percentage of text that is the same between two documents. It stores the file IDs returned from SimiCheck, the percent similarity between them, the Team IDs, and a URL to a detailed comparison (diff). It represents the results of the comparison among submissions for the assignment. The current assignment configuration UI has been modified to contain 2 new select boxes. These select boxes determine how long to delay the Plagiarism Checker after an assignment's due date, and on what similarity percent to filter the Plagiarism Checker Comparison results. After the results have been aggregated they can be viewed in a results report page. This report includes the submission names, the responsible teams, the similarity percentage, and a link to view the similarity results. The Plagiarism Checker Report UI looks similar to this: <image> To view the interface changes, login to Expertiza as an instructor; navigate to Manage... Click ""New public/private assignment"". The last two fields on the New Assignment page say ""SimiCheck Delay"" and ""SimiCheck Similarity Threshold"". In ""SimiCheck Delay"", select a value between 0 and 100 to enable the Plagiarism Checker. In ""SimiCheck Similarity Threshold"", select a percentage value to filter the Plagiarism Checker Comparison results. The percentage refers to the percent of same text between two documents. After the assignment ends and the delay period has passed, you can view the Plagiarism Report. Click the ""View review report"" icon containing a magnifying glass and two people (in the third row of per-assignment icons). Select ""Plagiarism Checker Report"" from the select box, and click ""Submit"". If there is any plagiarism to report, it will load. In Expertiza there already existed functionality to schedule or queue tasks for the task system. Once this task type is detected on a scheduled task, the SimiCheck comparison is initiated. We wrote unit tests for the new functionality that we implemented, this included models, helpers, SimiCheck logic etc.. In order to properly unit test we mocked all interfaces and black box tested the new functionality. Since the GitHub and Google Docs API fetchers do not do any scrubbing of the content after receipt there is no need to test this functionality. Lastly a unit test is provided for the Simicheck webservice to ensure that the logic we added to handle the API works. Essentially the test creates a comparison and runs it through the methods used to interact with the Simicheck REST API to ensure that it still works. A high level test using Capybara could also be added to click through the UI and using the factories to create test data as submissions, but there are many complexities to consider there and we opted not to implement here until an API testing gem would be added to the code to replay API responses and calls.","The issues found by the reviewers appear to have been addressed.  This is a well written design doc.  Some of the diagrams could have been a little narrower for the sake of readability.  The document could have addressed the parts of the Expertiza code that were modified.  And it could have included a screenshot or two.  But, it flows much better than most docs and includes almost all of the important issues."
E1792,"Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can also peer review other students' submissions. Instructors can also use Expertiza for interactive views of class performances and reviews. This would aid the instructors to judge outcomes of reviews and class performance in assignments via graphs and tables, which in turn would ease the process of grading the reviews. 1.2. Issue 2 : Two adjacent bar represents the response in round 1 to round k. It makes sense only if the rubrics in all review rounds are all the same. If the instructor implements the vary-rubric-by-round mechanism, this visualization will not make sense. 1.4. Issue 4 : An interactive visualization or table that shows how a class performed on selected rubric criteria would be immensely helpful. It would show the instructors what they need to focus more attention on. Description: The scale is blue to green, which does not make sense. Approach: Here the color coding is blue to green and also it changes randomly which one color in one graph may represent some other score in the next graph. Description: Two adjacent bar represents the response in round 1 to round k. It makes sense only if the rubrics in all review rounds are all the same. If the instructor implements the vary-rubric-by-round mechanism, this visualization will not make sense. Approach: Here the problem was that the data was represented rubric-wise, that is, if there are 5 rubrics, there would be 5 graphs. A graph for a particular rubric would show the performance of a team in that rubric in all rounds of submissions. This is fine when the rubrics are same for all the rounds. But, since rubric 1 of round 1 may not be same as rubric 1 of round 2, therefore this representation seems illogical. In our approach, the graphs are rendered submission-wise, the performance of a team in all rubrics in a particular round are shown in one graph pertaining to that round of submission. Data is now stored in the highchart in form of hash-maps which contain the score as key and score pertaining to different rounds of reviews as value. Earlier, data was stored in the hash map in a way that in the value scores pertaining to different rubrics were getting stored. In the earlier approach, data was represented rubric-wise. A graph for a particular rubric would show the performance of a team in that rubric in all rounds. But, since rubric 1 of round 1 may not be same as rubric 1 of round 2, therefore this representation seems illogical. Now, the graphs are submission-wise, the performance of a team in all rubrics in a particular round are shown in one graph pertaining to that round of submission. This addresses the problem of varying rubric by round. We can now have different number of rubrics in different rounds without affecting the visualizations for instructors. Description: An interactive visualization or table that shows how a class performed on selected rubric criteria would be immensely helpful. It would show me what I need to focus more attention on. Approach: The issue is about getting the performance of the entire class graded using the 5 rubrics criteria.Scores will be color coded for each of the rubrics in each of the submissions. When hovered over the graph , for each score, the instructor should see the number of students , the percentage of students that has scored that particular point in that rubric in that submission. 1. 1) Login as instructor 2. 2) Create a dummy assignment and come dummy reviews for the same.Log out. 3. 3) Login as a student. Attempt the assignment. 4. 4) Login as another student and repeat step 3. 5. 5) Login as either student and attempt the review. 6. 6) Login as instructor. 1. 1) Login as instructor. 2. 2) Create an assignment. Select 2 reviews. Also select different rubrics for both reviews. 3. 3) Login as a student (""A"") and submit the assignment. Repeat this for another student(""B""). 4. 4) Login as student A and perform review. Do this for student B too. 5. 5) Now resubmit assignment as student A and B again. 6. 6) Resubmit reviews as student A and B again. This time the rubrics will be different from the previous round. 7. 7) Now login as instructor and see the visualization of the reviews. You can see the different graphs for different submissions. 1. 1) Login as instructor 2. 2) Create a dummy assignment with some teams. 3. 3) Login as a student and attempt the assignment and logout. 5. 5) Login as instructor. 1. 1) Login as the instructor 2. 2) Click on the button to compute graphs 3. 3) Compare the bar graphs with separate scores of students in each assignments.","Excellent textual description and explanation of changes to be made.  Only issue is that screenshots are too large relative to the rest of the text, and the reader needs to zoom out to see them all.  Would be nice to update doc to reflect changes made in project."
E2076,"Expertiza allows the instructor to create new assignments and customize new or existing assignments. When they do, an account is implicitly created for them. If the assignment is tagged to be of conference type a link is generated which can be used by the user to sign up to the conference page. 1.1. Ensure that new users who are not current users in the Expertiza website can sign up and join a conference assignment. The current users of the Expertiza website can also sign up in the conference assignment using the invite. Assuming that the author already has the link to sign up for expertiza. After account creation, Author will receive email with login ID and password. 2. Author submits paper to expertiza for review : Now that the author has an account, he can login to his expertiza account and then click the assignment. They would not receive any mail, they would simply get an invite in their expertiza account. 2. Instructor creates an assignment by checking a new check box - “Will this be a conference type of assignment”, to mark the assignment to be of conference type. If author does not have account already in expertiza, a new account will be created for him. 2. When Author clicks on joining link, there could be two cases based on whether author has expertiza account or not. 1. If Author already has an account he will be able to view the assignment assigned to him and a default team. 2. If Author does not have expertiza account, he/she will be asked to put some details, pass the re-captcha test in order to create account with role as student. After account creation, Author will receive email with login ID and password. 4. When inviting the Co-Authors, Author can give Expertiza user name of Co-Author if they already exists in expertiza or Author can invite them by giving email id of Co-Author. 5. The role for both Author and Co-author is a student type because the difference in the 'conference type assignment' and a normal assignment is only in the way that users are added to it(i.e., by creating an account for themselves if they don't already have an account). 1. If Co-Author's expertiza account already exists, then he or she will be able to see conference assignment in Assignments page and ""Your Team"" section will be having the invite sent by the author. 2. If Co-Author's expertiza does not exists then he/she will receive an email with username and password and expertiza link on his/her email, that was given by author to invite the co-author. 1. invitations_controller.rb : We have modified invitations controller such that if an author invites another user to be the co-author, and if that user doesn't have an expertiza account, a new user account will be created for them automatically and those details will be sent to them via e-mail. We have added link generation if the assignment is marked as conference assignment. This spec would test the following scenarios when an author is inviting co-authors to join his/her team 1. When the co-author does not have an expertiza account : It is expected that invitation create method should increase the User count by one and Invitations count by one 2. When the co-author already has an expertiza account : It is expected that invitation create method should increase only the Invitations count by one as user is already existing 3. When email entered by the author is in wrong format and co-author does not exist already : It is expected that no new invitation should be created. 4. When the assignment is not of conference type and the assignment participant tries to add a teammate who does not have an expertiza account : It is expected that no new invitation or user should be created. This spec would test the following scenarios when an author is joining the conference assignment as a participant 1. When the author does not have an expertiza account : It is expected to increase both user and participant count by 1 and to give a flash success message of ""You are added as an Author for assignment <assignment-name>"", when the user is created. 2. When the author already has an expertiza account but is logged out : It is expected that only participants count should increase by one and a flash success message of ""You are added as an Author for assignment <assignment-name>"" is displayed. 3. When the author already has an expertiza account and is logged in : It is expected that only participants count should increase by one and the response page is expected to redirect to "" <link> "" 4. When new user tries to join with an e-mail address that already exists in the system : It is expected to return a flash error "" A user with username of this email already exists, Please provide a unique email to continue."" 6. When author tries to login with incorrect re-captcha : It is expected that the user count will not increase.","The document describes changes to implement a conference_controller and related functionality. Would have liked to see the screenshots organized in some way, instead of just ""Here are some screen captures.""  The screenshots cover only a small portion of the 634 lines of code you wrote, and the captions above them don't explain what the different methods do."
E2023,"Understanding how much time a student spends reviewing another's work is beneficial in order to better estimate the quality of said review. It is important that functionality be added so Expertiza can track and display the given amount of time a student spends on a review. The time spent on each review is a summation of multiple sources: 1. Time spent of the Expertiza review itself 2. Time spent looking at external links 3. Time spent looking at downloadable files The overall amount of time directly spent on the review is most important. One can track the amount of time spent on the review by tracking the amount of time from when the page is opened untill when the review is saved/submitted. Therefore, being able to track the time from once a resource is opened till when the review is saved/submitted will provide a reasonable estimate of the amount of time spent on each resource. This has the benefit of only needing to track information interacted with on the Expertiza review page, as opposed to other external files and links. The following tasks need to be implemented: 1. Time spent on an Expertiza review must be tracked 2. Time spent on external links and resources should be tracked/estimated 3. Overall time spent on the review should be displayed in a ""user friendly manner"". These previous projects are summarized below: 1. <link> identified how to track the active time of windows opened from the submitted links. 2. <link> provided detailed insights on how they planned to track time taken by a student in viewing a submission and possible edge cases. 3. <link> tried to solve this by incorporating the statistics in the review reports page, but their UI made the page cluttered and not friendly. ( <link> ) 4. <link> tried to solve this by building off of <link> . The team took the base code and attempted to implement the ability to track time spent on the review page, as well as other external links, however the code was not merged due to a large amount of white-space, as well as difficulty in distinguishing actual code changes. In review of previous iterations of this project, it was found that project <link> would prove to be a good reference for completion of this project's requirements. This build has already implemented necessary functionality that helps track of time spent viewing external pages. We were able to add the following functionality, while reducing project size from 5000 line changes to less than 1000 line changes: The time spent on the Expertiza assignment review page needs to be tracked. At that point, the time contributed towards the total by the Expertiza page is paused until the user interacts with the popup to indicate they are still working. This is already implemented in project <link> . The time spent viewing the external links/downloadable files needs to be tracked or estimated 1. Currently, if a student has an external link open as well as the Expertiza page, time is being tracked for both. Tracking of external links may be unnecessary for the project, and instead an estimation approach may be taken. 2. There are a few solutions one could implement to fix such an issue, such as marking both the start time and end time for when an external link or application was accessed by a user. Another solution which we will attempt in our first iteration of development is to track the time that an external link was clicked, and use the submission time of the review as our estimated end time for the external link. We thought of this design choice because once the report is submitted, the access time to external links should be stopped since the review is complete. The overall time spent on the review needs to be displayed in a ""user friendly manner"" on the ""Review Report"" page. Students will be interacting with the implementation when filling out a review. Initially, the user will click on the review they want to complete. Once the link is clicked the time will start to be logged. Upon the clicking of an external link another another timer will begin tracking it. In the case where a review was previously saved, the timer will pick up from the last tracked time. They will then be able to select a review from the given list and look at statistics about resources accessed and time spent on each resource. The following section shows various alterations to the Expertiza user interface in order to display information about time spent on a given review. Additionally, some alterations were made to the student's user interface to assist them in their review. 1. Added time value to the table on ""Review Reports"" page. Found in ""Team Reviewed"" column of the table 1. Added a pie chart to show breakdown of where time was spent during the review. Round contains an int variable associated with the specific round review, link contains a character string storing the external link the reviewer clicked on, start_at contains the starting time the external link was pressed, while end_at contains the time when the link was closed. The displayed review report will also need to be edited to present review reports in a visually appealing manner. <link> <link> <link>. <link> <link> <link> <link>.","The narrative portion of this document is fine.  It is descriptive and easy to read.  The listing of files edited should be more than just a list of filenames.  At the least, it should have a link to the Github diff view for the file.  That would not be hard to add.  The test plan should describe the tests, not just say, one test for this, two tests for that."
E1848.1,"For the participant, it can be used to decide if a participant is in a given team and view the members of the team or remove a member. Then we get the unit test plan and complete the test following test steps. 1. two test cases for method ""include? "": When the team includes a given participant and When the team doesn't include a given participant 2. one test case for method ""parent_model"": It returns ""Assignment"" when the method is called. 3. two test cases for method ""self.parent_model(id)"": When it's given a correct id and When it's given an incorrect id. 4. one test case for method ""fullname"": When the participant has an full name. 5. one test case for method ""review_map_type"": It returns ReviewResponseMap when the method is called. 6. one test case for method ""self.prototype"": It returns an new instance of AssignmentTeam when the method is called. 7. two test cases for method ""assign_reviewer(reviewer)"": When the team has an assignment and When the assignment record can not be found. 8. one test case for method ""reviewd_by? 9. one test case for method "" topic"": When it returns the correct id. 10. three test cases for method ""has_submissions? "": When the team doesn't submit any file or link, when team submits a link instead of files and when the team submits some files. 11. two test cases for method ""participants"": When no participants in this team and When adding some participants and get all the participants. 12. one test case for method ""add_participant"": When adding an participant, it will return an instance of AssignmentParticipant. 13. two test cases for method "" delete and destroy"": Testing delete and destory. 14. one test case for method ""get_first_member"": Let a team have two members, the first assigned member is expected to be returned by this method. 15. two test cases for method ""hyoerlinks"": the current teams submitted hyperlinks and not submitted the hyperlinks 16.three test cases for method ""submit_hyperlink"": the hyperlink is empty, the hyperlink is not empty and it calls the method on NET::HTTP,the hyperlink is not empty and it raises error 17.three test cases for method ""team"": the participant is nil, the participant exists and the team user exists 18.two test cases for method ""export_files"": an exception is expected if team is not exist or a new exported file is expected. 2 test cases are designed to test this method: 1. The team includes a given participant. <code> 2. The team doesn't include a given participant. <code>. 1 test case is designed to test this method: <code>. 2 test cases are designed to test this method: 1.When it's given a correct id. <code> 2.When it's given an incorrect id. <code>. 1 test case is designed to test this method: <code>. 1 test case is designed to test this method: <code>. 1 test cases is designed to test this method: <code>. 2 test cases are designed to test this method: 1. When the team has an assignment. <code> 2. When the assignment record can not be found <code>. 1 test case is designed to test this method: <code>. 1 test case is designed to test this method: <code>. 3 test cases are designed to test this method: 1.The team doesn't submit any file or link. <code> 2.The team submits a link instead of files. <code> 3. The team submits some files. <code>. 1. No participants in this team <code> 2. add some participants and get all the participants <code>. <code>. <code> <code>. 1. import a team to a non-existing assignment and expect an exception <code> 2. export teams into a csv file <code>. <code>. 2 test cases are designed to test this method: 1. when the current teams submitted hyperlinks <code> 2. when current teams did not submit hyperlinks <code>. <code>. 3 test cases are designed to test this method: 1. when the hyperlink is empty <code> 2. when the hyperlink is not empty and it calls the method on NET::HTTP <code> 3. when the hyperlink is not empty and it raises error <code>. <code>. 2 test cases are designed to test this method 1. when the team_name equals false <code> 2. when the team_name equals true <code>. <code>. 3 test cases are designed to test this method 1. when directory_num >= 0 <code> 2. when the directory_num does not exist and it gets max num <code> 3. when the directory_num does not exist and it updates attribute <code>. <code>.","The test plan simply lists 18 tests.  It would have been very heplful to separate them into groups and describe the motivation for each group.  It's hard to remember 18 items that are not connected to each other.  The rest of the documentation mostly copies the test code, with a one-line description of each test.  It would be better if the reason for the test was explained, along with what condition the test will succeed (or fail) on."
E2101,"There are various types of questionnaires that a user can create in Expertiza. These questionnaires assist in evaluating submissions and teammate contributions. Questionnaire is a superclass to many different types of questionnaires offered in Expertiza. The Questionnaire controller is responsible for creating, displaying and managing these items. Therefore, due to the importance of this controller, refactoring it was of interest to help improve the readability of its features. 1. Replaced literal values with defined constants to aid in the understanding of code behavior. 2. Investigated whether the method create_questionnaire is used. 3. Fixed the methods that have a questionnaire_id as a parameter, as it is not needed, since those methods should be contained within the model class anyways. 4. Removed one of three checks for QuizQuestionnaire. 5. Corrected the dropdown's default alternatives to reflect the questionnaire's min and max question score. 6. Updated the dropdown's RSpec test to reflect the change in behavior. 7. Discovered more software faults. 8. Moved three of four private methods from the controller to the model. The reason for this method is when there is a teaching assistant that is creating a questionnaire for an instructor, the questionnaire's instructor_id field is assigned to be the instructor of the course, instead of the user's (in this case, the TA). The RSpec test for this method expects that the application will be redirected to tree_display after calling this method, therefore it is unclear if the application could instead redirect to questionnaires/edit, or if it has to redirect to tree_display. The normal create function assigns the questionnaire's instructor_id as the id of the current user, and redirects to questionnaires/edit. However, we have not seen an instance where create_questionnaire is used, except in the RSpec test. Thus, it may be possible to move some of the code from create_questionnaire into the create method, if the RSpec test can be safely deleted. Though, we do not know if that is the case. Some methods in the Questionnaire controller had a parameter called questionnaire_id, and it was suspected that we could use params[:id] instead. However, we found that those methods were also private and should instead be in the model class. By moving those methods to the model class, we were able to remove the questionnaire_id parameter, and in some cases replace it with a params argument instead. The Questionnaire controller checks to see if the questionnaire type is QuizQuestionnaire, and it is believed that this may be unnecessary. We were able to eliminate one of three checks in the code, namely, the method save_new_questions which has been moved to the model class. Before our refactoring, the dropdown had a default literal value of '0|1|2|3|4|5' which was an error. This is an error because it is possible it exceeded the default value of the questionnaire max question score or allowed for points below the questionnaire min question score. Instead, this was replaced with code to make the dropdown's alternatives more responsive to the Questionnaire's min/max question score. However, we noticed that when the Questionnaire's min/max question score is edited after it has been created, the dropdown's alternatives could violate the new constraints, and also upon adding a new item e.g. dropdown, the edited (but not saved) min/max question score is reset to the initial values that were set upon creation of the Questionnaire. Upon fixing the dropdown's behavior, the RSpec test did not meet the expected behavior since before the alternatives were hardcoded in. So, now the dropdown code requires the min/max question score to be set in the questionnaire it is assigned to, so that the default value for the dropdown's alternatives do not violate the constraints of the questionnaire. See Dropdown default alternatives . Three of the four private methods that were in the controller were able to be removed and placed within the Questionnaire model class. The remaining private method called save was left in the controller since RSpec tests expected to find it in that location, and it appeared to be tightly coupled with existing functionality.","In the problem statement, I don't see that you did some of the items that you said you did, e.g., removing a questionnaire_id parameter.  The diff (https://github.com/expertiza/expertiza/pull/1912/files) of the pull request shows that a ""params"" parameter has replaced questionnaire_id in delete_question, but that's the only change I see.  If anything was moved from the controller to the model, I missed it.  There are many discrepancies with what has actually been implemented in the pull request.  The design doc could help by showing (and describing) code, but it does not.

As far as the documentation is concerned, an introduction is needed to explain why the changes were made.  As it is, the prose jumps right into describing the methods without putting them in context.

Testing is not covered."
E1795,"Currently Peerlogic’s services can be used by anyone calling them. This application have two major modules: 1. User facing portal: The user facing portal will be a deployed application with an user interface that a user/admin can use to register himself, request an API key for his/her app (in case of user), approve API keys (in case of admin), manage keys, and other similar functions. 2. REST APIs for Peerlogic: There will be REST API created which Peerlogic can call to check whether a request received by Peerlogic is authorized and authenticated. <image> The system includes a SSO portal, Peerlogic and different apps trying to access Peerlogic services. The types of users are admin and generic user (who will be responsible for creating a client account with SSO. Note: In the following description, client has been used interchangeably with app. 1. Once the client users registers himself/the client, and client account is created. He can now request a client ID and a client key to be used by his/her app. (Step 1) 2. SSO sends this request forward to the admin, who either approve/reject this request. The admin tells whether the request is to be approved or not and forwards this information back to peerlogic. (Steps 2 and 3) 3. If the admin, approves the request, SSO generates a client ID and a client token that will be used by the client to send requests to SSO. (Step 4) 4. This client ID and key is seen by the consumer and they add this to the client app. (Steps 5 and 6) 5. When the client app decides it wants to call Peerlogic web services, it communicates with SSO, sending a request for a token, this request includes the client id and client key in order to let know SSO know he is a valid requester for token. (Step 7) 6. SSO generates a unique, one time use token for the client and passes it back to him. (Step 8) 7. The client now calls the Peerlogic web service and adds this token in the request as a header. (Step 9) 8. Peerlogic, after receiving the client request, sends a request to SSO with the token, asking if the token is valid and is allowed access to the service that client is requesting. (Steps 10 and 11) 9. If Peerlogic receives a positive response from SSO, it lets client use its API, else returns an unauthorized/unauthenticated access error. 2. We will use a random generator to generate the key for every client once the admin approves the request for the key. 3. AES encryption algorithm, one of the safest encryption algorithms, will be used to generate the token for every client. This token will hold information including the client key, access rights and the time the token was generated. 4. When we decrypt the key, we will check whether we have such a client key in our database and whether they are allowed access to whatever it is that they are requesting. It will store which client id has what key. Also the owner of the client will be stored in this table. 3. Access Rights will store information about which client has access to what APIs. This table will be used when we are checking the authorization of a particular client. 4. Users will store information about the users/ The term user here is used to represent the entity which will represent the client. So a user account is nothing but a client facing account. 1. SSO App The user will login to the Single Signon App and can ask for keys and enable the APIs for using Peerlogic services. 1. SSO REST APIs Once the key is approved by the admin, the Apps which use the Peerlogic service will use this keys to communicate with the REST Endpoints. A token will be generated from this which will be used by Peerlogic to authenticate and authorize the app. 1. Demo App We have made a Demo App to show how the API calls to Peerlogic work and token validation. This token will be sent in the header of the request to Peerlogic while making an API call. 1.2. Peerlogic verifies this token with SSO. 2. Create a new app, and request the client key for that. 5. Once the approval is done, copy the client key and keep it somewhere safe. 6. Now, to access the rainbow graph API, send a request to the SSO for token along with client key. 7. After the token is sent to you, you can use the token as Authorization header in the Rainbow graph API. There are a couple of challenges we have identified: 1. Creating a client id and key and storing it: Given the rise of open source software, it is essential that the client id and key that is generated for an app is stored in a secure place, invisible to the world.","This isn't the most readable document, and I didn't see why until I realized that most of it is a set of lists. It would help to have the lists preceded by prose to give a general overview.  Other than that, ti does not have any obvious deficiencies."
E2071,"The Expertiza project is software to create reusable learning objects through peer review. It also supports team projects, and the submission of almost any document type, including URLs and wiki pages. As an instructor, you are able to view tables with information on student performance across the various courses they are taking and their assignments. Currently, these tables always show the same information and you are not able to specify if you only want to see certain data. Furthermore, the source code has some variables names that are not clear to what their purpose is in the code. 1.There should be a dialog that appears before navigating to the pages where the table views are that contain a list of checkboxes to allow the user to choose which columns they would like to see. Selectable columns: 1. Instructor Assigned Scores 2. Peer Grades 3. Topics. File: app/views/tree_display/_dialog.html.erb This file is a ruby view partial that contains the html for the checkbox dialogs. <code> File: app/assets/javascripts/tree_display.jsx Added functions to toggle dialog. <code> Added buttons to replace links that trigged dialog popups. <code> File: app/views/assessment360/all_students_all_reviews.html.erb, app/views/assessment360/course_student_grade_summary.html.erb Added conditionals to show selected columns for the html tables <code>. File: app/controllers/assessment360_controller.rb Added Variables to check if corresponding columns should be shown. <code>. File: app/controllers/assessment360_controller.rb Renamed @teamed_count to @total_unique_teammates <code>. File: app/controllers/assessment360_controller.rb Added ability to calculate average peer review score for each student in a course. <code> <code>. Before navigating to aggregated teammate and meta reviews, a dialog shows to allow the user select which columns they would like to see. <image> Similarly, before navigating to course grade summary, another dialog shows to allow the user select their columns. <image> <image> <image>. There was an existing test case for the assesment360 controller. We have added the test scenarios for our implementation of the average_peer_review_grades and all_students_all_reviews_all_grades. We tested url parameters as well as the average score pertaining the peer review of a student. Following steps needs to be performed to test this code: 1. cd expertiza 2. rspec spec/controllers/assessment360_controller_spec.rb. <link>.","In the description of the changes, you gave only ""after"" snippets of the code.  It would be clearer if these were contrasted with ""before"" snippets, e.g., by using screenshots of the Github diff view.  Each change was described in a single sentence.  Often a more detailed description, explaining the strategy, would have been helpful.  The screenshots of the output also don't have prose describing what they show.  Test scenarios should have been included in the document."
E2024,"Currently, Expertiza has no way to associate mentors with teams. For assignments with topics, like the OSS project, mentors are associated with topics, and then whichever team is assigned to the topic inherits the mentor for that topic, However, for assignments without topics (like Program 2), there is no good way to “automatically” assign mentors to projects. The instructor needs to watch teams being formed, and every time a new team is formed, a new mentor needs to be assigned, outside of Expertiza. This leads to a lot of work for the instructor, as well as sometimes long delays before a team is assigned a mentor. Develop a trigger that: 1. Is activated when any team has been formed that has k members, where k is greater than 50% of the maximum team capacity 1.1. ex. max members = 4, trigger activated when the team size reaches 3 2. Assign a mentor to the team. Mentors should be evenly assigned to teams, so a good strategy is to assign the mentor who has the fewest teams to mentor so far. 3. Notify the mentor via email that they are now assigned to a specific team, and provide the email addresses of the team members. 4. Possibly notify the team members that they have been assigned the mentor with contact information. <image> <image>. <image> <image> Assignments with or without a topic could be assigned with mentors automatically <image>. <image> 2. Reduce the number of conditional statements checking for mentor. 4. Make the code DRYer <image> II. Correct Previous Design 1. Remove mentors from being included in a team's number of members count. 2. Change the View to make mentor separate from the team. BEFORE <image> AFTER <image> 3. Change the conditional statement that checks if a mentor has to be added to the team. (The strength of the team has to be greater than 50% of the team size). <image> 4. Fix the SUBMIT button issue during role selection <image> <image> III. Example: 1. The email code moved to the email module. 2. Code written in team file moved to the assignment team file. 1. The mentor should be able to check submissions of his team. This is a new functionality, where a mentor when logged in , would be able to view all the teams assigned under him for an assignment, when he clicks view and manage teams. <image> <image> 1. Email notification for mentor/ team members This functionality aims at generating an email notification to the mentor/ team member when a team is created giving details about the team name and the team members/mentor they have been assigned with. Additionally a notification is generated for every team member that is newly added to the group. <image> <image> 1. Accommodate changes in team members/assigned topics after a mentor has been assigned. This is planned to be addressed as per the new flow diagram, where a check will be performed to see what type of a team it is, new or modified one. If the strength of the team reduces below the threshold, the assigned mentor is removed and a new mentor is added when the threshold is reached again. <image>. Part 1: 1. Login as the instructor6 2. In the assignments view, select the add participants icon. Add a new participant or change permissions. This could be a member or mentor for our case. 4. Fix the max team size of the project. This size will decide when to add a mentor. (Here set as 4) Part 2: 1. Login as student575 (added to the program by the instructor) 2. In the assignments view, select program 1. Within that select your team link. 3. Currently there is no team. Create a new team. 4. Invite student573 (who's also a participant in this project) 5. Invite student574 (who's also a participant in this project) Part 3: 1. Login as student573. 2. In the assignments view, select program 1. Within that select your team link. 4. Will be added to the team and a mentor is assigned. (here it is 563) 5. Check for a received email regarding team information. <image> <image> Part4: 1. Login as student574. 2. Steps are the same as Part3. The difference will be in the email received. No new team formed or mentor assigned. Only 574 is added to the team and he alone gets the email. Part5: 1. Login as student563. (Mentor) 2. In the assignments view, select program 1. Within that select your team link. All the mentor's teams for that project will be listed. 3. The mentor would have gotten an email when a new team is formed and they are added as the mentor. <image> <image>. 1. Rubrik for a Mentor has to be implemented. 2. If a mentor is removed from an assignment, reassignment of mentor has to be done.","I would prefer that you not start with what the last team did, because this means that to understand your work, someone needs to read the previous design doc.  In the listing of files modified, it would be very helpful to say why they needed to be modified, and what changes were made. The test plan should describe the tests that you modified or reverted."
E1648,"This page provides a description of the Expertiza based OSS project for Fall 2016. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. The following tasks required completion in this project: 1. Adding past due assignments to the task list. 2. Highlighting the next immediate due date on the assignment list. 3. Correcting the stage deadline of finished assignments. 1. Assignments that are past due are not present in the task list The assignments that the user is a participant of and are past the deadline but not yet completed are not part of the task list of the user. Currently only tasks that are not yet started by the user are being shown in the task list. 1. Next immediate due date As per the current implementation, it is hard to pick the when and which assignment has the next immediate due. 1. Stage deadline of a finished assignment According to the existing implementation, the stage deadline of any finished assignment is being shown as one year from the current time which is misleading from the actual final stage deadline of that assignment. 1. Problem 1: next_due_date is being assigned string value instead of DueDate object While finding the current stage of the assignment, the next due date returned from the DueDate model currently returns nil for the assignments which have their due dates past the current time. Then, if the next due date is found to be nil or 'Finished' it is being assigned the value 'Finished'. In the list.html.erb of the student_task view, the stage deadline of the student task for an assignment is fetched as the due_at attribute of the next due date object. As the finished assignments have a next due date as a string they are being caught as an exception and rescued by showing the stage deadline as an year from the current time. 1. Problem 2: While fetching next_due_date from the DueDate model, it returns next due date from the assignments which have due dates greater than current time. If the due date is past, next due date is nil. The past due dates are not being retrieved in case if the next due date is nil. 1. Solution: If the next_due_date of an assignment is found to be nil while finding its current stage, its past_due_date is retrieved and name of the deadline type is looked up from the DeadlineTypes model with the deadline_type_id attribute of the past_due_date. <code> 1. The get_current_stage method returns the name of the deadline type from the DeadlineType controller with the deadline_type_id key. For this the deadline type 'Finished' is maintained in the deadline_types table. <code> <code> 1. The late tasks are collected into latetasks by selecting the tasks which are in the 'Finished' stage but does not have any submitted content. These are shown in the student task view in the task list. <code> <code> 1. The next immediate deadline from the current time is fetched from the student_task controller and compared with stage deadline of every assignment while iterating to find and highlight the assignemnt that has next immediate due. <code> <code>. 2. Check in the task list present on the left side of the screen. 3. Check the list of assignments in the table below. 1.1. The assignment that has the next immediate due date from current time will be highlighted with bold font weight. 1.2. The stage deadline column shows past time for the assignments with current stage as 'Finished'. If there are no assignments in the task list, we can test the functionality by following below steps 1. Login as instructor and create an assignment. 2. Assign the assignment to the student user we are testing for. 3. Adjust the due date of the assignment such that it is the next immediate due date in the assignment list. 4. Login back as student. 1.1. The assignment should be highlighted in bold font. 1.1. Adjust the due date such that the due date is past the current time. 6. Login back as student. 1.1. The assignment now shows up in the late tasks section in the task list. 1.2. It is no longer highlighted in the assignment list. 1.3. The stage deadline of the assignment will now show the due date that we have set now,which is past. 1. <link> 2. <link> 3. <link>.","There was not too much to say on this wiki page, as solving the problems did not require writing much code.  But the team was responsive to reviewer suggestions, and created a pretty readable descrption of what they did."
E2106,"The student_task/list page is the page displayed to a student after logging in into expertiza. It has mainly two div(s), one to show the upcoming tasks along with some important information, another div is to display all the assignments and their information in which the student is participating. We have to modify the view to remove extraneous information and make it clearer and more concise. 1. Modify the view to remove extraneous information and make it clearer and more concise 2. Add checkbox to Publishing Rights column, when checked the permission_granted boolean variable is set to true 3. In general, no column needs to be shown if there are no values in it. This would apply to “Badges” if no assignments in the list contain badges. 4. Also, it doesn’t make sense to have a column for Review Grade, and not for the grade for submitted work (“Submission Grade”). 5. We should consider the cases where a student might be enrolled in assignments from more than one course. In this case, assignments should be grouped by course, with the course name given before the listing of the first assignment. (This allows for the column for course to be removed, making the display more compact. Log in to Expertiza as any of the students mentioned below. Without the changes the original view is as shown below. 1. instructor6 1. student7487 1. student7490 1. student7496 Password for logging in for any student/instructor is : password Once logged into the page click on ""Assignments"" tab. A modified view is observed as compared to the earlier view <image> To address issue 1 we added CSS style properties and removed the unnecessary space between two divs by using HTML comment. <image> The modified view is as shown below <image> To address issue 2, we did the following modifications 1. In app/assests/javascripts/submissions.js, we have added an ajax call to update the permission_granted boolean variable in Participant table <image> 1. In app/controller/student_task_controller.rb, we are defining a method named permission_granted which routes the action from checkbox event <image> 1. app/views/student_task/list.html.erb, we have added code to include an information banner on Publishing Rights column and checkboxes <image> 1. In config/routes.rb, we have added a functionality to route the checkbox event to permission_granted action in student_task_controller.rb <image> After all proposed modifications, we see the below shown view <image>. Since this project involved mostly UI changes it was not necessary to write test cases for the same. So there is no test plan. 1. <link> 1. <link> 1. <link> 1. <link>.","This page would have been easier to follow if you had (1) numbered the issues in Section 2 (I changed it to a numbered list) and (2) mentioned briefly what you were addressing in Section 3 (not just ""issue 2"", but ""issue 2, adding a checkbox for publishing rights"").  Also, the code changes are described in the Functionality Testing section, which is not right."
E1567,"The Expertiza project is a web application to create reusable learning objects through peer review. It supports various features such as team projects, and the submission of various documents including URLs and wiki pages. It is being extensively used across various universities for select courses. The page describes the various changes and modifications done to improve the source code of the application. The changes were accompanied by unit/functional test cases written in RSPEC to affirm no breakage in code. Just a note for the reviewers, for this project, we had done all the necessary forks, modifications and pushes. But after creating a pull request, there were some merge conflicts with the code. Since this can't be changed at our end(as we dont have the access rights), we are in touch with the people at expertiza. Users Controller is one of the controllers in the Expertiza Rails Application. It is used for the basic CRUD operations - creating new users, updating the details for an existing users or deleting an existing user in the system. It is also used to determine the role of particular user in the system. The role could be one of the following - Administrator, Instructor, Student, Teaching Assistant, Super-Administrator or Unregistered User. The associated model class for interacting with the user table is the User model. It is also used to verify the various access privileges for each user, import or export users. The VCL image of the project is : <link>. 1. users_controller.rb 2. user.rb 3. user_spec.rb. Code refactoring is process of changing the existing computer code to make it more maintainable, without changing the external functionality of the code. Some of the reasons for performing refactoring are: <code>. The User_controller file was subject to code modifications and refactoring. The objective was to implement DRY code principles and reducing code complexity. The following were the suggested changes according to the Design document. 1. Initially, various functions were calling the same redirect method to redirect to the same controller. This was inimical to the code reusage principle. Following the DRY code principle, instead of calling the same link, with the action and controller as arguments, a method(redirect_to_home) was created and called from the 3 different methods namely show, index and key . <image> 2. Initially, the create method in Users_contoller was being used to send emails to new users by passing strings as arguments to the mailer template. The strings were harcoded as arguments, this was modified so that varaibles were passed as parameters to the mailer template. This helped remove hardcoded code while maintaining the functionality. <image> 3. Initially, in the destroy method, queries were being executed directly from the controller method , which doesn't follow Ruby on Rails code ethics. So the queries were moved to a new method destroy_user in User Model file and the method was called from within the delete method in controller . <image> <image>. 1. Initially, the code had a very long method called get_users_list . <image> 1. The search_users method had a complicated if-else ladder. The method has now been optimized using a case statement. The original method also had a repetitive way of forming a search query. This has been refactored in accordance to the DRY principle into a new method named fetch_results that returns the list of users based on role, user_id, letter, search_by parameters passed to it. <image>. <link> is a <link> (BDD) framework for the <link> , inspired by [JBehave] <link> . It contains its own mocking framework that is fully integrated into the framework based upon JMock <link> . David Chelimsky joined the team that summer, and accepted leadership of the project in 2006. David also built rspec-rails, which provided tight integration with Ruby on Rails. Test cases were written for the user model. <code>. <code>. <code>. <code>. Login Credentials for review : username: administrator5 password: password To setup the local environment do the following steps: 1. Clone the repository using git clone <link> 2. Run bundle install 3. Run rake db: migrate RAILS_ENV = ""test"" to migrate the test database. 4. Make sure there is a test database created in mysql. 5. Run the rails server using rails server in the root directory of expertiza. To run the test cases, follow the steps given below: 1. Open terminal 2. Navigate to the expertiza root directory. 1. Login using the credentials mentioned above. 2. Hover over the manage link in the top navigation bar & click on the Users option in the dropdown. 3. You can now do the following actions : create a new user by clicking the ""New User"" link. 4. Click the name of the user to see/edit the user details and/or delete the user.",Very nice writeup.  An intuitive description of the changes.  Good display of code.  Remember to skip a space before open paren (except in parameter lists).
E1993,"CSC/ECE 517 classes have helped us by “tagging” review comments over the past two years. Our goal is to help reviewers by telling them how helpful their review will be before they submit it. Tagging a review comment usually means sliding 4 sliders to either side, depending on which of four attributes it has. Studies on other kinds of “crowdwork” have shown that the time spent between assigning each label indicates how careful the labeling (“tagging”) has been. We believe that students who tag “too fast” are probably not paying enough attention, and want to set their tags aside to be examined by course staff and researchers.. We would like to modify the model reflecting review tagging actions (answer_tag entity), adding new fields to track the time interval between each tagging action, as well as revise the controller to implement this interval tracking functionality. The first step would be to examine the literature on measuring the reliability of crowdwork, and determine appropriate measures to apply to review tagging. The next step would be to code these metrics and call them from report_formatter_helper.rb, so that they will be available to the course staff when it grades answer tagging. We propose to use `updated_at` in `answer_tags` model for each user to calculate gaps between each tagging action, then use `report_formatter_helper` together with `reports_controller` to generate a separate review view. <image> <image>. What chartjs does is it takes a series of parameter and compile them into different kinds of graphs when getting called in front-end, so this project is divided into several components: 1. Extracting data 1.1. First we would need to see what data is needed in generating report, we found that: 1.1.1. We would need student information to generate report for the specific student 1.1.2. We would need Assignment information to generate report for assignment (currently the report button is under each assignment) 1.1.3. We would need Review data to see what could be tagged 1.1.4. And we would need tagging information to generate time associated with it 2. Compiling chart parameters 1.1. This stage requires understanding of the gem, this particular gem takes two piece of information 1.1.1. Data, which include the data to be presented on the chart as well as labels associated with axis's 1.1.2. Options, which captures everything else, including size of chart and range of data to be displayed 3. Calling gem to generate graph. 1. Data Data is stored across multiple tables, specifically if we need to gather Assignment, review, tagging, and user data, we would need at least Tag_prompt_deployment and answer_tags table. Automated testing is not available for this specific project because: 1. To test the review tagging interval one has to 1.1. Create courses 1.2. Create assignment 1.3. Setup assignment dues dates as well as reviews and review tagging rubrics 1.4. Enroll more than 2 students to the assignment 1.5. Let students finish assignment 1.6. Change due date to the past 1.7. Have students review each other's work 1.8. Change review due date to the past 1.9. Have students tag each other's work, with time intervals (pause or sleep between each review comment, having at lease one interval longer than 3 minutes) 1.10. Generate review tagging report 1.11. Generate review tagging time interval line chart And you cannot verify what's on the line chart with Rspec since it's a image, we wouldn't be able to see if the interval greater than 3 minutes is filtered Each time this script runs, it would take minutes to test, let along having the intervals, and each time Expertiza runs a system level testing, this script would be included, adding who knows how long to the already too long testing process. <image> As described, we tested this feature in the following sequence: 1. As instructor 1.1. Create courses 1.2. Create assignment 1.3. Setup assignment dues dates as well as reviews and review tagging rubrics 1.4. Enroll more than 2 students to the assignment 2. As Student 1.1. Finish assignment 3. As instructor 1.1. Change due date to the past 4. As Student 1.1. Review each other's work 5. As instructor 1.1. Change review due date to the past 6. As Student 1.1. Have students tag each other's work, with time intervals both over and under 30 seconds 7. As instructor 1.1. Generate review tagging report 1.2. Generate review tagging time interval line chart The result is shown in the graph above, manual testing showed that intervals greater than threshold did get filtered and students without any tagging activities are dropped in graph creation.","All in all, I don't think this documentation makes it clear what was done.  Long code sequences are given with only a few sentences' explanation.  It says that automated testing doesn't make sense, but that's not true.  Given a set of records of tagging actions, tests could make sure that the averages and other statistics about tagging times were calculated correctly."
E1939,"On each line of the signup sheet are two icons, one for adding a bookmark to the topic, and another for viewing bookmarks on the topic. The bookmarks are attached to each project topic and user can suggest by filling up a questionnaire. As soon as a user creates a bookmark, the project author is able to view all the bookmarks that are created for his project. The author can give a feedback on the bookmark that he has received which helps even the user know the usefuless of his bookmark. It also allows the author to rate the bookmarks that he has received for his project. Project Juniper Bookmark Enhancements is an attempt to make the bookmarks more user-friendly and credible. We have improved the functionality for an author to descriptively evaluate the bookmark that he has received on his project using rubrics as set by the instructor. 1. Fixing the “Back” button 2. Validations on the form for adding bookmarks were missing 3. Allowed the creator of bookmark to rate himself and fixed the logic for calculating average rating 4. Bookmark Rating Questionnaire could not be created. Fixing the Back button: When user visits “Create Bookmarks"" and ""View Bookmarks"", the back button was not functional which refrained the user from going back to the Signup-sheet. Earlier: <image> Files Changed: app/controllers/bookmarks_controller.rb <code> <code> app/views/bookmarks/list.html.erb <code> The changed code can be found <link> The screencast can be found <link> Bookmark Validations The form for creating a new bookmark allowed malformed URLs to be entered into the system. Files Changed: app/controllers/bookmarks_controller.rb <code> app/models/bookmark.rb <code> The changed code can be found <link> The screencast can be found <link> Self Rating of Bookmarks and average calculation When reviewing the bookmark, the average rating for that bookmark shown was calculated wrongly and showed average rating for the bookmark that wasn’t reviewed. Also, the user who created the bookmark could rate himself. Now, the user cannot rate his own bookmarks and the average rating is calculated perfectly after one or more people have reviewed it. Files Changed: app/models/bookmark_rating.rb <code> app/views/bookmarks/list.html.erb <code> app/controllers/bookmarks_controller.rb 1. method to check if a dropdown is used for rating bookmarks <code> The changed code can be found <link> Review bookmark using rubric functionality The bookmark functionality earlier only allowed for the users to rate the bookmark and not give feedback about the the quality of the Bookmark. Now, feature is added so that the instructor can decide whether to allow for bookmark to be just rated or a have a rubric . Files Modified app/controllers/bookmarks_controller.rb <code> app/controllers/questionnaires_controller.rb <code> app/controllers/response_controller.rb <code> The screencast can be found <link>. 1. Enable Bookmarks 1. After logging in as instructor, go to Manage > Assignments 2. Select Edit under Actions for assignment 3. Under Topics Tab select 'Allow participants to create bookmarks?' to allow bookmarks 4. Go to Rubrics tab, under 'Bookmark Rating' select the Bookmark review questionnaire to use the rubric for reviewing the bookmarks , select None for dropdown. is out of scope of the current project and the error can safely be ignored from point of view of this project ' 1. Fixing the back Button & Validations 1. Log in as an instructor and impersonate as a student using the credentials given above 2. Select ‘Exercises’ assignment and go to the Signup sheet 3. We can see a list of projects with 2 columns to add or remove the Bookmark, select any of them 4. You’ll be redirected to the corresponding page where the back button will be visible 5. Select add bookmark and the form can be tested for Validations. 1. Create new Bookmark Rating Rubric 1. As an instructor, go to Manage>Questionnaires and select Bookmark Rating field 2. Create a new rubric with required details 3. Start adding questions. 1. View Bookmarks 1. Log in as an instructor and impersonate as user using the credentials mentioned above and then select assignment ""Exercises"" 2. Add bookmarks to other topics. 3. The owner of that project should be able to see all the bookmarks created for his project and can rate the bookmark through the way instructor has defined it (rating or rubric). <code> Rspec testing videos can be found <link>. 1. Giving credit to the author of the bookmark for his contribution. 1. Github Link: <link> 2. Pull Request: <link> 3. <link> 4. Expertiza on Github <link>.","My biggest concern is that the code changes are shown, but not explained.  It would be easier to read them from the pull request than from the documentation.
Better to use the Github diff view to show code rather than the monochrome box provided by MediaWiki.  Video is useful, but should contain audio; too hard to follow it without audio.
The test plan is incomplete; it says there are a lot of new tests, but does not say what they test."
E1631,"When a participant of a team reviewed an assignment, his/her review is independent of his teammate’s reviews. To allow teammates to discuss and review together, allowing teams to submit reviews for the team as a whole should be allowed ideally. 1. Currently all reviews in Expertiza are done by individuals. This is true regardless of whether the assignment is done by individuals or teams . 2. There are occasions when it's advantageous to review projects as a team . The field reviewee_id refers to the team who is being reviewed. The field reviewer_id refers to the individual/team performing the review. # We added a boolean field ""reviewer_is_team"" to identify if the review is being performed by a team or an individual. 2. The review strategy is assignment specific and hence we have added a field reviewer_is_team to the assignments table as well 3. For an Instructor to specify whether the review is a Team/Individual based review, we have provided a dropdown on the Review Strategy tab of assignment creation. 4. If reviewer_is_team field is true the reviewer_id in the response_map is set to the corresponding team_id of the user 5. Ensure that features such as ""view my scores"", or the ""alternate view/heat map"" continued working. Model View Controller In an MVC model, a software application is divided into three major components: Model, View and Controller. Model - Keeps data, logic and relations between objects and the database. View - Displays the data received from the controller in the user interface. Controller - Accepts the client's input and converts it into action points for the model or view. Other responsibilities include querying models and organizing data in a structure that is displayed by the view. Name: Specify review type on Review Strategy tab. Actor: Instructor. Description: The instructor specifies whether this review is an individual review or a team based review on the Review Strategy tab. Name: Perform Review. Actor: Individual Student/Team. Description: The individual/team will perform a review for the Assignment. <image>. 1. The below fields have been modified in the response_maps table: <table> The description of the fields of the database for ResponseMap: i. reviewer_id: Based on the reviewer_is_team flag in the assignments table , the assignment team or the participant id is added in this column. reviewer_is_team: If this field is ‘true’, the reviewer_id refers to the id of the “AssignmentTeam” to which the participant belongs. Else, it refers to the id of the “Participant” itself. 2. The below fields have been modified in the assignments table: <table> 1. reviewer_is_team: - This field is set based on the discretion of the instructor who decides if the assignment is a to be reviewed individually or as a team. Below are the key files modified: 1. review_mapping_controller.rb: 1. We have added a check in the assign_reviewer_dynamically method that checks if the assignment is a team_reviewed assignment to fetch the respective row from the participants or the teams_users table <image> 2. Also while redirecting to the student_review controller the participant_id or the team_id is passed based on the type of review <image> 1. response_controller: 1. Below is the get_reviewer_from_response_map method that returns the team or participant id based on the type of review . Also this value is passed forward to the respective controller we redirect to. The get_participant method returns the row from the participants table corresponding to the current user. <image> <image> 1. student_review_controller: 1. Same logic as applied in the review mapping controller to obtain the reviewer. <image>. 1. assignment_team.rb: 1. A row is being created in the response_maps table depending on if it's a team or individual review. The same logic is being applied to check and retrieve the appropriate row form the response map. <image> 1. assignment.rb: 1. The logic to not allow reviewers to review their own work has been modified to include scenarios when it's a team based review. <image>. 1. assignments/edit/_review_report.html.erb: 1. Added the below drop down so that the instructor can select the review strategy for the assignment. <image>. Factory Girl is used for creating Assignment and Team objects to be used for testing. Factory Girl is a replacement for fixtures. Fixtures have to be updated whenever we change a data model whereas adding and removing fields is much easier in Factory Girl. 1. If the instructor selects ""Review by team"", check if the review is done by a team member, not by participant. 2. If one teammate is working on a review, another teammate should not be able to edit it at the same time.","Design doc is mostly screenshots of code, which don't explain enough about why the project was coded the way it was. ""There are too many checks of """"reviews_is_team"""".
Login issue with action_allowed as pointed out during demo. 
There are too many screenshots of the code changed in the design doc."""
E1560,"Code refactoring is process of changing the code to make it more maintainable, without changing the functionality of the code. Some of the reasons for performing refactoring are: 1. To remove duplicate code. 2. To make the code more maintainable. 3. To divide functionality of the class. Expertiza is a web application where students can submit and review learning objects like code, writings, etc. It gives scope for creation of reusable learning objects. Students submit assignments, which can than graded through peer reviews. The Expertiza project is supported by the National Science Foundation. JoinTeamRequestsController and InvitationController. invitation_controller.rb is used by a user to invite other users to join his/her team. It performs validation before creating a request. Following chunk of code checks whether the user is allowed to get the invite or not. <code> Now, invited user can accept or reject the request. Once the user has accepted the request, he can be seen as a part of the team. join_team_requests_controller.rb is used when user decides to join a team. This is achieved by creating an advertisement for the team. Once the advertisement is created, it is shown in the Topic Selection section. The user who wants to join the team can send a ""Request"" to the members of the team. The members can then decide whether to send him/her an invite or decline the request. The invitation_controller.rb is doing the required task but it is difficult to understand the code, hence it becomes difficult to maintain the code. And the functions in the accept and create method can be broken down into separate methods. In join_team_request_controller.rb has duplicate code in various methods which can be removed by creating a separate method for this common code. invitation_controller.rb 1. Rename to Invitations_Controller.rb, as is not in accordance with current naming convention. 2. Add comments explaining what each method does, and comments on how important variables are used as currently there are no comments. 3. Refactor create and accept methods. Shorten and clarify them by adding private methods, as create and accept methods currently have a lot of code. 4. Change the find_by_sql call(s) to Rails (Active Record) statements. 5. Make sure that it can be used by a user with a TA or instructor account, if they are participating in this assignment. 6. Change grammatically wrong or awkward flash messages. join_team_requests_controller.rb 1. Add comments to the code. 2. Remove duplicate code, from create and accept methods. 3. Decline and destroy method should check for successful operation before returning. 4. Change grammatically wrong or awkward flash messages. The controller renaming had to be incorporated in different files of the project. The table contain the file names along with the lines before and after the changes. <table>. <table>. <table>. <table>. To test the functionality of join_team_request_controller and invitations_controller, please follow the steps provided in the video below. This video covers the functionality of how these controllers work. This will help in manually testing the functionality. <link>. <link> <link> <link> <link> <link>.","Writeup does not clearly show changes.  In long code sequences, code removed, changed, or inserted could have been highlighted."
E1994,"For assignments with topics, like the OSS project, mentors are associated with topics, and then whichever team is assigned to the topic inherits the mentor for that topic However, for assignments without topics (like Program 2), there is no good way to “automatically” assign mentors to projects. The instructor needs to watch teams being formed, and every time a new team is formed, a new mentor needs to be assigned, outside of Expertiza. This leads to a lot of work for the instructor, as well as sometimes long delays before a team is assigned a mentor. Develop a trigger that: 1) Is activated when any team has been formed that has k members, where k is greater than 50% of the maximum team capacity 1. ex) max members = 4, trigger activated when the team size reaches 3 2) Assign a mentor to the team 1. Mentors should be evenly assigned to teams, so a good strategy is to assign the mentor who has the fewest teams to mentor so far. 3) Notify the mentor via email that they are now assigned to a specific team, and provide the email addresses of the team members. 4) Possibly notify the team members that they have been assigned the mentor with contact information (further discussion here). <image> Implementation for our project <image>. For assignments without a topic, there is no way to assign a mentor to the team on Expertiza system but to manually assigned one via Email out of the system. <image> In the above case, there is no mentor role for the current Expertiza system, only to assign mentor manually. Assignments with or without a topic could be assigned with mentors automatically <image> Also, mentor and team members will be notified by Emails (Results showing in UI Test). General workflow and specific add member workflow <image> <image>. The solution we proposed generally follow the chain of responsibility and the work flow The solution will follow steps list here: 1. Allow instructor to assign mentors for assignments without a topic 2. Check the topic of assignment and number of team members whether reach the requirement or not 3. Assign mentor for the team automatically 4. Notificate both mentor and student 5. Team member added after the mentor assignment will also get a email notification about mentor. Since we implemented a whole new feature and kept the original work flow unchanged at the meantime, most modifications are in models: Models: 1. app/models/assignment_team.rb 2. app/models/assignment_participants.rb 3. app/models/team.rb 4. app/models/team_users.rb 5. ... Views: 1. app/views/student_task/view 2. app/views/student_teams/view 3. app/views/shared_scripts/_add_individual 4. app/views/participants/_participant 5. ... Here we present some essential codes with explanation <image> First, add mentor role for assignment. Set authorization for mentor which could not do review, take quiz or submit. <image> Add a mentor role for instructor/admin when add participant for assignment <image> To assign a mentor, there are several requirements: 1. There should be at least one mentor in this assignment 2. The current team size is greater than half of max size 3. The team do not have a mentor yet <image> Always assign mentor with lowest number of mentoring teams, in order to do so: 1. First, get all mentors for this assignment 2. Traverse all mentors and calculate how many teams he/she mentored, store the one with lowest number 3. Return mentor with lowest number of team she/he mentored <image> Use Mailer class to send email notification about mentor and team members information(method used to send email notification for student is similar to this). To make sure the refactor code can work correctly, we need to run the original rspec test code and add some new test. Besides, we are plaining to test from UI to make sure all the features work. The test results are shown below. 1. Run and pass existing RSpec Tests after Modification 2. Develop New RSpec Tests for the new features 3. UI testing on the deployed project. 1. Add new participant type mentor in factories.rb <image> 2.Test new added method in team_respec, like half, add_member, size... <image> <image>. 1. Instructor/Admin add mentor for specific assignment <image> 2. Student create team and invite others 3. When team size greater than half of max size, assign mentor and send emails <image> <image> 4. When student accept from a team which has already been assigned with mentor, he/she would receive a email <image> 5. Also we extend our work to make all teams visible to mentors <image>. 1. Mentor could not see teams' submissions since authorization control is working on the view assignment page and mentor does not have rights to submit 2. Rspec Test for email functions.","You motivated the project, and described its functionality.  Along with the code snippets, there should be a description of what changes have been made and why.  Ditto for the tests, which show the code, but don't describe what is tested."
E1849,"This class acquires reviews from a given questionnaire and assignment, and creates a heat map visualization of the review scores a reviewee received from other people (reviewers) for an assignment. There are currently no test cases for vm_question_response.rb. We seek to create unit tests to attain at least 90% coverage by line. app/models/vm_question_response.rb spec/models/vm_question_response_spec.rb. Testing VMQuestionResponse hinges upon collaboration verification, so that we know VMQuestionResponse is getting the right messages from the right classes, so that it can appropriately create its data structures. We first went through each method of the VMQuestionResponse class and determined whether the method was a command, or query and whether the method was incoming, outgoing, or sent-to-self. For each method we will write tests for valid and invalid inputs as well as edge cases. Here is an outline of our implementation strategy: To describe VMQuestionResponse 1) Test initialize 1. in the context when VMQuestionResponse is initialized with a review questionnaire 1. in the context when VMQuestionResponse is initialized with any other questionnaire type 2) Test add questions 1. in the context when VMQuestionResponse is given a list of questions 3) Test add_reviews 1. in the context when VMQuestionResponse is initialized with a review questionnaire 1. in the context when VMQuestionResponse is initialized with a author feedback questionnaire 1. in the context when VMQuestionResponse is initialized with a teammate review questionnaire 1. in the context when VMQuestionResponse is initialized with a metareview questionnaire 4) Test display_team_members 5) Test add_team_members 6) Test listofteamparticipants 7) Test max_score_for_questionnaire 8) Test add_answer 9) Test get_number_of_comments_greater_than_10_words. 1. initialize : This tests that the VmQuestionResponse is initialized with the appropriate round number. <code> 1. add_questions : This tests that the VmQuestionResponse adds questions from a given review <code> 1. add_reviews : This tests that the VmQuestionResponse adds reviews and reviewers from a given review <code> 1. display_team_members : This tests that the VmQuestionResponse can print out the appropriate team member names. <code> 1. add_answer : This tests that the VmQuestionResponse adds all of the review scores from its reviews to VmQuestionResponseCells in VmQuestionResponseRows. <code> 1. get_number_of_comments_greater_than_10_words : This tests that VmQuestionResponse only finds comments that have at least 10 words. <code>. We have now attained 97.25% coverage. <link> <link>.","What is here is good, but I think it should be enhanced by describing under what conditions tests succeed or fail, and for long tests (e.g., add_reviews) the general structure and funcion of each context should be described."
E1608,"1. Method has too many lines: Line 35 - 158 [106/30] Wrap the specific code into different instance methods. 1. Cyclomatic complexity for complete is too high: Line 35 - 158 [28/6] Wrap the code into different instance methods to reduce cyclomatic complexity <code> 1. Identical code found in 1 other location: Line 20 - 32 (mass = 89) Also found in app/models/scale.rb:17…28. The following method is removed from subclass: criterion and added to their superclass: scaled_question <code> 1. Identical code found in 1 other location: Line 135 - 139 (mass = 50) Also found in app/models/scale.rb:50…54. Wrap the duplicated code into an instance method and add the instance method into superclass: scaled_question <code> 1. Identical code found in 1 other location Line 13 - 14 (mass = 40) Also found in app/models/scale.rb:10…11. Wrap the duplicated code into an instance method and add the instance method into superclass: scaled_question <code> 1. Similar code found in 1 other location Line 103 - 105 (mass = 26) Also found in app/models/criterion.rb:107…110. Wrap the duplicated code into an instance method <code> 1. Similar code found in 2 other locations Line 152 - 153 (mass = 22) <code> <code> 1. Similar code found in 3 other locations: Line 130 - 134 (mass = 18) Also found in app/models/criterion.rb:145…149, app/models/scale.rb:45…49, app/models/scale.rb:60…64. Wrap the duplicated code into an instance method and add the instance method into superclass: scaled_question <code>. 1. Cyclomatic complexity for complete is too high. Method has too many lines <code> 1. Identical code found in 1 other location: line 17-28 app/models/criterion.rb:20…32, def view_question_text. The following method is removed from subclass: scale and added to their superclass: scaled_question. <code> 1. Identical code found in 1 other location: line 50-54 app/models/criterion.rb:135…139. Wrap the duplicated code into an instance method and add the instance method into superclass: scaled_question. <code> 1. Identical code found in 1 other location: line 10-11 app/models/criterion.rb:13…14. Wrap the duplicated code into an instance method and add the instance method into superclass: scaled_question <code> 1. Similar code found in 3 other locations: line 60-64 app/models/criterion.rb:130…134, app/models/criterion.rb:145…149, app/models/scale.rb:45…49. Wrap the duplicated code into an instance method and add the instance method into superclass: scaled_question <code>. 1. Method has too many lines. By moving codes to private methods outside this method, this problem can be fixed together with the following one. Here is the new complete method together with two additional private methods: hasAnswer(html, answer) and nextQuestionTail(html, next_question). The source codes are listed as below. <code> 1. Cyclomatic complexity for complete is too high. This problem can be solved by moving branches outside to other private methods. See source code above. 1. Similar codes in edit method are found in 2 other locations. (questionnaire_header.rb and upload_file.rb) Such code duplication can be eliminated by moving the identical part of the similar edit method to a new function, named edit_prefix(html, count) to their common superclass, which is Question (question.rb). Here is the source code of the added edit_prefix method in question.rb: <code> The original code are commented out and insert the function call of the above function, html will be returned in the above function, see codes below: <code> 1. Similar codes in view_question_text method are found in 4 other locations. (dropdown.rb, questionnaire_header.rb, text_response.rb, upload_file.rb) The solution to this problem is the same as above one, below is the function added in the most common superclass, which is Question, that contains the common parts of the codes found in the view_question_text methods in all five classes. <code> The original code are commented out and insert the function call of the above function, html will be returned in the above function, see codes below: <code>. All problems in this file are solved after solving the problems found in checkbox.rb. All problems in this file are solved after solving the problems found in checkbox.rb.","The wiki does not include the information on how to test the code manually.
And it is quite mechanical, with little explanatory prose.
However, the text that is there manages to do a very good job of drawing attention to what was done."
E2113,"The staff can assign the score and provide feedback using the textboxes provided in the right columns of the table. The staff are also allowed to read the reviews in the summary view. These issues have to do with calculation of a student's score / average score, the visual representation of the scores, efficient usage of space within the view, and a need for rows of the table(s) to be numbered. Certain aspects of the UI and minor score calculation logic of the review grader system in Expertiza need to be enhanced/refactored. <image>. There were some serious inconsistencies, bugs, and syntax issues with the beta branch review grader section. 2. Fix the “Score awarded/average score” column so that it is populated with the correct numbers. It is supposed to report the score by the current student reviewer in the first round, the average score by all reviewers in the first round, and ditto for the second round. If the number of rounds ≠ 2, then the number of scores should be adjusted appropriately. 1.1. There is a bug having to do with ""Avg. score"" not being calculated sometimes, like when the team that was reviewed should definitely have an average score to be displayed, even if the current student reviewer did not complete the review. 3. Number the rows of the table (e.g., “2. Student 8370”) so it is easy to count the lines. 1. The ""Scores"" issue. 1.1. The variable @avg is computed in the file app/models/answer.rb, and is initially set to nil if an assessment is not present. The variable @avg is also set to a placeholder ""----"" in the file app/helpers/review_mapping_help.rb. If ""@avg_and_ranges[team_id][round][metric]"" is not nil, the ""@avg"" will be set to the average scores. 1.2. The ""Score awarded/average score"" column in the table is actually composed of two rendered partials: views/reports/_team_score.html.erb and views/reports/_team_score_score_awarded.html.erb. It is within this helper file that the @avg instance variable is also defined. It appears as though the previous team spent some time tracking down the source of the bug in the presentation of the ""Avg. score"" in the table, but were unable to fix it. <image>. 2. Adjust column width intelligently. The “Reviewee” and “Score” columns are much wider than necessary. The “Comments” column is also too wide for easy reading. 3. Get rid of “Review: Round1”. It should be, “Review Round 1”. Original : <image> <image> Mock_up: <image> 1. Concerning column width, we will play around the preset width in /app/views/popup/view_review_scores_popup.html.erb, the previous team went with 10% for ""Reviewee"", 5% for ""Score"" and it looks reasonable. 2. ""Review Round"" header is located at /app/models/review_response_map.rb, and can be easily modified by adding white space. <image> According to Expertiza Bot, our code test coverage increased by 3.6%. 3. There will be a dropdown selector to choose which report to view - select ""Review report"" from the dropdown, and click ""View"". 4. Check to make sure that the ""Avg. score"" for reviewed assignments is being shown correctly. 5. Check if column widths are appropriate. Make sure the text ""Score awarded / Avg. score"" instead reads ""Score / Avg. score"". 6. Verify the bar graph display of scores. The review mapping helper is a module that is used extensively throughout the peer review system in Expertiza to perform a number of things (perhaps too many) including calculating scores, finding team colours, preparing grade data visuals, and other useful computations. <image> Comments: <image>. <image>. <image>. 1. We decided to fix all of our issues with summary page like columns taking too much width, header texts like ""Reviewee"" and ""Score"" repeated unnecessarily by reorganizing the page to take better advantage of the available space. 2. ""Scores"" and ""comments"" column were merged together for aesthetic reasons and to improve readability. The scores are displayed with a colorful background indicating its value. Before Modification <image> After Modification <image> 1. “Review: Round1” was changed to “Review : Round1”. Also the title ""Review scores: student5061"" was changed to ""Review scores by student5061"" as its more indicative as a title. Before Modification <image> After Modification <image> <image>.","Very good description of design strategy, and changes are nicely described and illustrated with screenshots."
E1780,"1.4. Instructor notifications of where reviews disagree by more than a threshold # of points should point the instructor to the reviews that disagree. 1.5. Send out an email to the invitee when a participant sends out an invitation to another participant to join a team. 1.7. Notify an instructor by e-mail when a student suggests a topic. 1.8. Instructor should get a copy of all emails sent to the student. 1. Use Case1 2. Use Case Description: Create an Option to create a participant when he doesn't exist 3. Actor: Instructor 4. Precondition: Participant does not exist 5. Post Condition:Gets option to create participant 1. Use Case2 2. Use Case Description: Get an Email once a review is done with a link for the review page 3. Actor: Student 4. Precondition: Reviews a team 5. Post Condition:Reviewed team gets emails with review link. On clicking the link , it directs to the corresponding review page 1. Use Case3 2. Use Case Description: Get an Dead line reminder Email once a deadline to review is approaching 3. Actor: Student 4. Precondition: Reviews a team 5. Post Condition: Gets deadline reminder in email to review a team.Email has the link to the review page 1. Use Case4 2. Use Case Description: Gets email notifications for reviews contradicting by a particular threshold 3. Actor: Instructor 4. Precondition: Team reviews are done by at least 2 reviewers 5. Post Condition: Instructor gets email notifications for reviews contradicting by a particular threshold along with the links the contradicting reviews. 1. Use Case5 2. Use Case Description: Email should be sent to the invitee with the team -join request when join request is sent. 3. Actor: Student 4. Precondition: Invites another participant to join a team 5. Post Condition: Email sent to the invitee with the team -join request 1. Use Case6 2. Use Case Description: All activity Emails should be sent to student 3. Actor: Student 4. Precondition: Activity is done in expertiza by team members. 5. Post Condition: Student receives email on all activity on ad responses and invitations performed by other team members. 1. Use Case7 2. Use Case Description: Instructor receives an email for the suggestion request by student 3. Actor: Student 4. Precondition: Suggests a topic 5. Post Condition: Instructor receives an email for the suggestion request 1. Use Case8 2. Use Case Description: Instructor receives a copy of email for all the mails sent to student on assignment. 3. Actor: Instructor 4. Precondition: Activity done on assignment. 5. Post Condition: Gets a copy of all emails sent to the student regarding the activities done on assignment. Related code snippet <image>. Related code snippet <image>. Related code snippet <image>. Related code snippet <image> <image> <image>. When a new topic is suggested by a student to the instructor , an email is sent to the instructor regarding the same for his decision to approve or decline. Related code snippet <image> <image>. Related code snippet <image> <image> <image> <image> <image> <image> <image> <image> <image>. Adding a non-existent user as a participant in an assignment 1. Login as an instructor. 2. Click on an existing active Assignment . 1. Login as an instructor. 2. Click on an existing active assignment. 3. Add an existing user as a reviewer and another user as a participant to this assignment. 4. Login as the reviewer and submit your review. 5. Result: The participant must have received an email on this review submission with a link to the review submitted. 1. Instructor notifications of where reviews disagree by more than a threshold # of points should point the instructor to the reviews that disagree. 1. Login as an instructor and create three students. 6. Result : This should send an email to the instructor with the below text. 1. Send out an email to the invitee when a participant sends out an invitation to another participant to join a team. 1. Login as an instructor --> click on Assignments tab --> Select an existing active assignment . 2. Add one user as a participant , login as the participant and invite a student to join the team for the assignment. 3. Result: Email has been sent to invitee. 1. Notify an instructor by e-mail when a student suggests a topic. 1. Login as an instructor--> Create a user with Student role 2. Login as a student--> Click on existing active Assignment . 5. Login as an instructor--> Create a user with Student role 6. Login as a student--> Click on existing active Assignment . 1. Login as an existing instructor --> go to profile tab. 3. Go to Manage Users --> Create a student. 1. 1. Login as the instructor and go to the Profile tab. 1. Result2(positive testing) : Both the created user and the instructor receives the email.","The description of the solutions seems disconnected from the problems.  The reader would have to refer back to the problem requirements document to understand the writeup.  The writeup should be more self-contained.  Moreover, it would be very helpful to have more comments in, or juxtaposed with, the code..  Some of the screenshots are quite long, without comments that would tell the reader what is being done.  Headings of ""Requirement1"", ""Requirement2"", etc. are not very helpful; the headers should refer to the functionality that the section addresses.  And there should be a space after ""Requirement""."
E2064,"<link> is a peer review based system which provides incremental learning from the class. It also supports submission of different file types for assignments, including the URLs and wiki pages. The solution is the reputation system. This file is the controller to calculate the reputation scores. This controller implements the calculation of reputation scores. It contains a lot of methods that are long and hard to understand (for e.g. send_post_request). These methods need to be broken down into simpler and more specific methods that are easier to read/understand. Also, the few instances of code duplication that exist should be removed. 1. There is a lot of unused/commented code, which should be removed. 2. Figure out what the code is doing and write appropriate comments for it. 3. Rename bad method names such as (db_query, json_generator). Method names should be verbs, and should say what the method does. Method names should not be so general that they could apply to many different methods.. 4. In the case of db_query, the name should say what it queries for. Also, this method not only queries, but calculates sums. Since each method should do only one thing, the code for calculating sums should be in another method. And there should be comments in the code! There needs to be a method comment saying what the parameters are. send_post_request is 91 lines long, far too long. 7. There is a password for a private key in the code (and the code is open-sourced!) 8. Fix spelling of “dimention” 9. client is a bad method name; why is stuff being copied from class variables to instance variables?. <code> Method names should not be so general that they could apply to many different methods. The other problem with the method was that it did not follow the good practice of having each method perform only one task. This method got the review responses with a db query. Also, it iterated over the review responses to perform a calculation of peer review grades. We have split the method into two to have the review responses do only the get responses part. <image>. <code> We also added a comment to indicate the calculate weighted sum part. <image> <code> <image> Similarly, we have changed db_query_with_quiz_scores to calculate_quiz_scores <image>. <code> Also,there needs to be a method comment saying what the parameters are. We have added the method comments with parameter information as seen below. <image>. We have created two separate methods ( encrypt_request ) ( decrypt_response ) In the image below we can see that we have separated Encryption functionality from ( send_post_request ) to ( encrypt_request ) <image> On the similar lines we have separated Decryption functionality from ( send_post_request ) to ( decrypt_response ) <image> ( encrypt_request ) has been refactored as follows <image> ( decrypt_response ) has been refactored as follows <image>. <image>. We changed the class variables in the code to instance variables because we realized that the send_post_request method and client method were the only methods using the class variables. A client.html.erb file was used to call our controller to fill out a form for send_post_request which set values of class variables then immediately redirected control to the client method which set the instance variables to those class variables. The instance variables were then used in the rest of the client.html.erb file. The process of setting class variables to instance variables with a function was redundant, so we removed simply set the instance variables within the send_post_request method and took them out of the client method. The client method did have a few actions that it completed besides setting class variables which we have left in the method until we can find a solution to replacing them. <image> Old client method <image> Newest client method The reason why we kept the client method's name is because the routes.rb file specifies the client method in the code and we haven't fully tracked down the impact of that yet. Since we are refactoring it, Our testing plan is to have an automated testing to ensure that the refactoring such as splitting a method into separate methods does not affect the existing implementation. We also added steps for the manual testing to make sure the page loads as expected after the refactoring. We have tested the two new methods created during refactoring and also a renamed method. <image>. <image> Once in there, copy on of the student names (such as student7487) and then go to Manage... -> Impersonate User and enter their name (student7487) into the text field. <image> After impersonating them, you should be able to see their assignments. <image> <image>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.","The changes are for the most part clearly described.  When you say you ""refactored"" something ""as follows,"" you could also describe the changes you made; that would make it easier to follow.  But, the code is still clearer than a lot of code in the system."
E1778,"This page provides the documentation of the UI fixes for assignment creation in Expertiza. Expertiza allows the instructor to enable and disable different features to be used in an assignment. Some of these setting e.g., allow peer review to be done in iterations, allow third party to assess the quality of the peer feedback, can be changed from manage>assignment and click on edit icon. Some of the UI to enable and disable these features were broken and the aim of this project was to fix the following issues. The following issues were fixed in this project: 1. Issue <link> : While editing an assignment, changing the number of review rounds doesn't work in Expertiza. 2. Issue <link> : Once an assignment is duplicated from another assignment with metareview enabled, metareview deadline cannot be disabled. 1. Issue <link> : was already fixed before the start of this project. A working demo of the fixed issues can be found <link> . The changed code can be found in the pull request made <link> . The first two actions of enabling and disabling metareviews show the fixed issue #961. The action of reducing the rounds of reviews shows our fix to issue #972. The main problem as stated in the problem statement is that .last() does not exist for the array. This method was used to identify the last element in the array of elements. This was solved by identifying the last element as the (array.length - 1)th element of the array. The issue was the instructor was not able to change the rounds of reviews for an assignment. The reason for this issue was found to be the actual rounds of reviews was overridden by the maximum of submissions and review count in the database. This constraint was introduced to restrict the instructor from resetting the rounds of reviews lesser than the submissions count. The constraint was not necessary for some scenarios which should have allowed the instructor to reset. To solve this scenario, we introduced a warning message with a confirmation option to allow the instructor to override the rounds of reviews. After realizing the actual location of the code that was causing the bug, we realized that assuming the current rounds of reviews by the maximum amongst the submissions count, reviews count, and the rounds of reviews led to a scenario where even when the instructor wanted to update the rounds of reviews, he wasn't allowed to do so. This was a problem because, there would have been a certain situation where the instructor had to override the existing value because of a previous error (maybe even typographical). Thus, a confirmation message with a warning was the way to go. The problem was the need for metareview could not be disabled while editing an assignment. This was because the DueDate table was not updated with the necessary cascade actions. This issue was solved by implementing the cascade action manually in the update action in the assignment controller. After realizing that the issue was caused by the cascade action not being implemented, implementing it was the way to go. After the implementation in the update action of the Assignment controller, the instructor was able to update the metareview required or not checkbox. 1. Go to the edit action in the assignments controller. ( <link> 2. Click on the due dates tab. 3. Change number of rounds of reviews to a value less than 3. (At this stage, our fix would throw a confirmation message with a warning) 4. Upon pressing submit, the rounds of reviews will not be updated. (In our fix, the rounds of reviews will only change upon accepting the confirmation). 1. Go to the edit action in the assignments controller. ( <link> 2. Click on the due dates tab. 3. Uncheck the metareviews allowed checkbox. 4. Upon submission, the update will not be visible. (Our fix would allow this action and the update will be visible). 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link>.",Straight forward description. No automatic test was defined. Think of using selenium in the future. 
E1787,"This project involves revision of score calculation bug of Expertiza homework reviewing mechanism. Sometimes when a reviewee of a project or homework fills out the review form, he or she may leave certain review question blank. When taken into score calculation for the project or homework, the application instead fills in 0 on blank answers. This behavior is incorrect as the blank review answers should never be used when used to calculate final score. Issue - <image>. Solution - <image>. Git Original link 1. <link> Pull request link 1. <link> Git Revised link 1. <link>. We implemented using the MVC (Model View Controller) pattern. We felt it was the pattern used in expertiza , usage of same pattern would be much easier. We have run unit test using RSpec and Carpybara. The test file path is spec/models/vm_question_response_row_spec.rb. For the test, we have identified 2 scenarios. First one is regarding correctness on average score calculation, where we will create a VmQuestionResponseRow object with sample test scores inside and call its average_score_for_row method, then we match returned average to the expected average (vm_q1 object); Second one is regarding whether average score calculation includes nil values, where we will create a VmQuestionResponseRow object with one or more nil sample test scores inside and call its average_score_for_row method, then we match returned average to the expected average to check if nil is redefined and used in score calculation (vm_q2 object). In addition, we have also tested the initialization of VmQuestionResponseRow object with 5 parameters and 6 parameters to ensure the initialization process works as intended (see in code for vm_q1 and vm_q3 objects). However, due to decrease in coverage for the test (after we added it, the coverage dropped by 0.4%), we have reverted it back to original 2 test cases. The additional test cases can be found below in snapshots, and original test cases with highest coverage in on github. test file: vm_question_response_rows_spec.rb;. For the OSS project, the topic is fixing and modification on Expertize team score calculation mechanism. For this project, a meeting once every week for 2 weeks with TA was proceeded. Some of notable issues on setting up include theRubyRacer dependency problem on project, Node packages not recognized by rails (Windows), Font-Awesome-Rails path issues, etc, which were solved through file tracing, problem identifying, and debugging. For the rest of these a little over 2 weeks period, several issues were identified with the project. The main issue for program include the false score calculation mechanism by expertiza where empty scores are assumed automatically to 0 and included in calculation; this would in turn give a false score calculation result as empty scores are not supposed to be set to 0 and then included in for calculation. Through debugging and defining the problem, it was identified that the reason for such issue involves average_score_for_row method in vm_question_response_row.rb in model as shown below in red - where the row_average_score dividend was not been used correctly. Comparison of code changes can be seen in Pull request. The issue can be solved by modify the calculation for dividend using a counter to exclude nil values and modified the constructor for VmQuestionResponseRow classs that it can dynamically accept 5 or 6 parameters, as shown below (note: not_null_reviews.zero? check are used two times in order to pass the github check on coding, as combining these two lines into one (row_average_score = (row_average_score / not_null_reviews).round(2) unless not_null_reviews.zero?) would resulting in failing on github check, while the other solution which is putting both line into an unless block would not have any benefit execution efficiency wise). Code after first modification - <image> <link> Code after second modification - <image> <link> The first modification was done as it fix the issue while keep code at its most simplicity; (As shown in screen shot) The second modification was done to accommodate the scenario where an extra parameter - score row - is needed during object initialization process. It would be a more efficient constructor to use when retrieving scores from database as it allows program to initialize a VmQuestionResponseRow object now with a list of AssignmentScore objects instead of having to initialize to an empty list and putting in AssignmentScore objects one by one through a loop. (Note: the implementation for using constructor with extra parameter in project is not implemented as it is originally not part of our requirement). Afterward, several tests were performed for the model class modifications using RSpec, with some of the code as shown below: <image> <image> <image> For this project, techniques such as Unit testing, constructor overloading, and technologies such as bower, carpybara, RSpec, etc, were used.","The prose description of the changes could be more readable.
The section on tests does not describe the rationale for the tests, but just displays the code."
E2063,"This page provides a description of the Expertiza based OSS project. Contents 1.1. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.6. <link> 1.1.1.1. <link> 1.1.7. <link> 1.1.1.1. <link> 1.1.8. <link> 1.1.9. <link> 1.1.10. <link>. <link> is an open source project based on <link> framework. Expertiza allows the instructor to create new assignments and customize new or existing assignments. It also allows the instructor to create a list of topics the students can sign up for. Students can form teams in Expertiza to work on various projects and assignments. Students can also peer review other students' submissions. The tree-display.js and its tree_display_controller.rb files are designed to allow Expertiza users to view their Assignments, Courses and Questionnaires at one place. This is the primary control page, as well as the home page for instructors on Expertiza which allows them to create, modify, delete and view Assignments. The primary problem with this is that both the files, due to their bulky and unoptimized methods, slow the rendering of UI on screen. Moreover, any obsolete or unused methods can be removed and DRY principle should be implemented. The following tasks were accomplished in this project: 1. Removed methods that were not used 2. Modified tree display controller to better parse data prior to being accessed by the react client 3. Fixed beta branch issue with showing dropdowns for courses and questionnaires. 4. Fixed beta branch issue with showing edit option for courses and assignments. This class manages different the different tabs: courses, assignments, and questionaires. 1. Instructors can view the course, assignment and questionnaire tabs. Instructors can select rows for questionnaire's and courses to view a dropdown of more information. For course rows, they have options to edit, delete, copy, add TA, create an assignment, create teams, view grades, assign surveys, and view reviews. For assignments, they can edit, delete, copy, assign to course, create teams, assign reviewers, view submissions, view scores, view reports, and view survey responses. 1. Problem 1 : The dropdown doesn't work for assignments and questionaires. <code> 1. Solution : Change the the JQuery route to a post because you can't give parameters to a get route and also change this in routes.rb file. <code> <code> 1. Problem 2 : Tree display controller needs to better parse the data prior to being access to the react client because currently, there are too many comparisons when checking for the type of tab. Example: <code> 1. Solution : Centralize the attributes of each tab so that the tree_display doesn't need to keep parsing between the tabs. 1. Problem 3 : The Assignments and Courses tab isn't showing the edit option for each row. It seems that what's implemented is trying to verify that there was an active user and the active user is null. <code> 1. Solution : Remove the active user implementation and replace with a check to make sure the current tab isn't Questionnaire. <code> 1. Drawback :The assignments tab did not have any data when we used the reset debugging extension (i.e. the childNodes attribute was null). Thus we assumed there was no data to display underneath each assignment. -After debugging, we found that the ""nodeType"" attribute in the :reactParams field of the post request identifies the type of childNodes to be retrieved (i.e. ""Courses"" or ""Questionnaires"") -We found that a ""FolderNode"" value for this attribute equates to a questionnaire. An example of how its currently implemented for courses is: <code> With a centralized implementation, we consolidated this information into const node_attribute. (See code repository for implementations for questionnaire and assignments, Course only shown for simplicity of demonstrating implementation). <code> With this new implementation to obtain these actions, we just use the getActions function. Additionally now call the is{Tab} to receive the name of the tab. <code>. Unused Methods and Functions were commented out 1. Example 1 : <code> 1. Example 2 : The assignments tab did not have any data when we used the reset debugging extension (i.e. the childNodes attribute was null). Thus we assumed there was no data to display underneath each assignment <code>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link> 6. <link> 7. Clean Code: A handbook of agile software craftsmanship.","tree_display_controller is used to display hierarchical items, such as assignments in different courses, or different kinds of questionnaires.  For Problem 2, no solution code is shown.  I found the solution of Problem 3 to be described confusingly.  You say, ""Unused methods and functions were commented out.""  Do you mean that you commented them out, or that you removed methods that had been commented out?  Examples 1 and 2 of code improvement don't show what was improved.  The testing sections are empty."
E1949,"This page is a description of Expertiza OSS project E.1949 Write Unit Tests for Importing assignment participants and import glitches. Expertiza is a web application where students can submit and peer-review learning objects (articles, code, web sites, etc). It is used in select courses at NC State and by professors at several other colleges and universities. The import feature is the most helpful feature for instructors to set up assignments. The instructors usually have a list of students, teams, etc from their learning management system. Being able to import these into expertiza saves a lot of time when setting up an assignment. 1. Importing participants redirects to a confirmation screen listing the users that are going to be imported but the users do not seem to be imported. 2. This is an intermittent issue that can be addressed through a test case. We looked into the files responsible for importing assignment participants. The imported file goes through the following process. 1. Add one line to expect that #create_new_user method in import_file_helper is NOT called in each test case that the user HAS an account, and do the opposite in case the user DOES NOT HAVE an account. <code>. 1. Thoroughly test the #import method in the sign_up_topic model. This includes the following test cases: 1. The record is empty 2. The record is not empty and the topic is not existing, including special cases 3. The record is not empty and the topic is existing, including special cases <code>. 1. Thoroughly test the #import method in the team model. This includes the following test cases: 1. Duplicates exist. Ignore the new team. 2. Duplicates exist. Replace the existing team with the new team. 3. Duplicates exist. Insert any new members to the existing team. 4. Duplicates exist. Rename the new team and import. 5. Duplicates exist. Rename the existing team and import. <code> <code>. 1. To view the testing vedio, please click the link upon. 1. This video shows the complete test process of the CSC/ECE 517-E1949 task 1, 2 and 3 using RubyMine, all tasks have been tested successfully. The modification of testing code and testing result of each task can also be found in the Test Plan section and Result section above respectively. 1. All tests passed successfully except for the part 2 of task 3. The fail of part 2 is as expected and the reason part 2 of task 3 failed is explained in Result part above. More details please see Result in Part 2: Reason for building failing in the Result Section. 1. All test passed. <image>. 1. All test passed. <image>. 1. Part1: All test passed. <image> 1. Part2: Reason for build failing: One of our tasks is to add a test for a function that does not exist yet, namely to rename the existing team when there is import conflict. Therefore, as per test-driven development practice, the test will always fail until the function is correctly implemented. <image>. 1. <link> 2. <link> 3. <link> 4. <link> 5. <link>.","If you used snippets from Github instead of typing the code into Mediawiki textboxes, you could more clearly show what has been changed.  That is not clear from the code you provided.
Tests could have been described more completely, e.g., Why is this test necessary? What does it test? How does it test it?
In general, most of the document is just a listing of code.  Saying more about why you made the changes you did would have been helpful.
They have uploaded a video that shows testing on their development environment and that cleary shows their contribution"
E1460,"Expertiza is a web application developed using Ruby on Rails that serves as a peer-review system. The application allows students to submit and peer-review learning objects (articles, code, web sites, etc)<ref> <link> </ref><ref> <link> </ref>. It is an open source project and it's codebase is maintained in GitHub. We are contributing to Expertiza as a part of our Object-Oriented Design and Development's Open-Source Software (OSS) Project. Our goal in this project is to refactor the StudentQuiz controller . In this Wiki Page, we would be explaining the changes that we have made for the same. Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.1.4. <link> 1.1.5. <link> 1.1.6. <link> 1.1.1.1. <link> 1.1.1.2. <link> 1.1.1.3. <link> 1.1.1.4. <link> 1.1.1.5. <link> 1.1.1.6. <link> 1.1.1.7. <link> 1.1.1.8. <link> 1.1.1.9. <link> 1.1.7. <link> 1.1.8. <link> 1.4. <link>. The StudentQuiz controller consists of methods involved in creating, scoring & recording responses of the quizzes taken by reviewers or students of the other teams with the same topic. The changes that are needed to be done are described as follows:<ref> <link> </ref> 1. Pluralize the class. (StudentQuizzesController) 2. Rename methods to conform to RESTful style. (e.g. :- Rename the list method to index.) 3. Reduce the number of instance variables per controller action. 4. Review Method graded? for boolean zen. 5. Perform Code cleanup by removing unused code. 6. Use good Ruby style guidelines in the code. 7. Split a method performing multiple tasks, into seperate methods. 8. Fix logical errors in the code. <references/>.",Very detailed writeup; every line that was changed is explained.
E1510,"Currently when an Instructor logs into Expertiza,there are a lot of select* from assignments queries being fired on database which would have an adverse effect on performance. We analyzed the source of this issue and made some changes, which reduced the number of select queries executed. The performance is high improved. The mission involved is tracing the source of the issue and modify the code to fix the issue. Before the improvement is achieved, each time an instructor logs into Expertiza, there would be several database queries, which are more than needed and take more time to render the view. Below is the console outputs when an instructor logs in. <image> There are 7 assignment queries after load _row_header.html.erb , 3 assignment queries after load _shared_actions.html.erb , and 3 assignment queries after load _assignments_actions . All of these queries are same. These duplicate queries have an adverse effect on the performance. To locate the files that generate the duplication of queries, we use a Gem called QueryReviewer<ref> <link> </ref> to help trace the datebase queries. QueryReviewer is an advanced SQL query analyzer<ref> <link> </ref>. It accomplishes the following goals: 1. View all EXPLAIN output for all SELECT queries to generate a page 2. Rate a page's SQL usage into one of three categories: OK, WARNING, CRITICAL 3. Attach meaningful warnings to individual queries, and collections of queries 4. Display interactive summary on page. Installing query_reviewer is simple. All you have to do to install it into your Rails 2 or 3 project is <code> Right now if you use bundler, simply add this to your Gemfile : <code> or to use the latest from github: <code> After installing and running this Gem on the Rails application, it would pop-up database query information on the webpage, as is shown below. <image> We can follow the trace and locate the source of the issue in assignment_node.rb , also the source code in _assignment_action.html.erb. We log into Expertiza as an instructor with the QueryReviewer activate and watch the output of QueryReviewer. The above figure shows the tracing result of the QueryReviewer and it tells us that we should pay more attention to the three files: assignment_node.rb, _row_header.html.erb and _entry.html.erb. In file <link> , we can find in 3 places use Assignment.find(node.node_object_id) , which is actually a database query request. <code>. In <link> : <code> we can see in this view, parent_node is a AssignmentNode object, it execute: 1. parent_node.get_name method 2. parent_node.get_directory method 3. parent_node.get_creation_date method 4. parent_node.get_modified_date method However, in <link> : <code> We find all these method called Assignment.find(self.node_object_id) method, which is actually a database query request. These 'find's are actually redundant for a specific Assignment instance. So we will figure out a way to eliminate those redundant method calls. An instance variable @assignment is used here instead of multiple times of calling .find method, thus reducing database queries. <code>. In this class, we define a new variable @assign_node , and in every get_ method, instead of using Assignment.find(self.node_object_id) to find the AssignmentNode object, we first search if @assign_node variable exist, if not, we define @assign_node = Assignment.find(self.node_object_id) , else we directly use @assign_node . Because _row_header.html.erb file uses many get_ method, after modification, the number of assignment queries decreases much. <code>. 1. Originally there are 13 queries after loading these related pages, and now there are only 5 of them. As shown below. 2. The time consumed for rendering the view is 943 sec before and 284 after the modification. We can see the performance has been highly improved. If we have a larger database, the improvement would be more significant. <image>. Before our modification, when an instructor open the expertiza website and log in, it takes much time to show the page after log in, especially when a larger database hiding behind. We saw the problem on the console windows which emerged as a duplication of unnecessary queries. After our modification, the duplication disappeared and the time consumption is reduced significantly. Now when an instructor log in expertiza, it takes shorter time to get to page after log in. Please check our new version of <link> on github. <references/>.","Describes the changes made very well.
The prose is quite readable.  Code has been added to explain what was not elaborated in the ticket.  However, to be helpful for people doing followup projects, the writeup should've explained hurdles that were encountered and how they might be able to be overcome.  There should be a summary at the end of the report."
E1839,"2. Auto-selected: Case reviews are not assigned until a student seeks to choose something to review. A reviewer is ordinarily allowed to choose only among work that has received the minimum number of reviews so far. For example, if all submissions have received at least one review, the next person who tries to review is allowed to choose only a submission that has only one review so far, unless there are no more such submissions, in which case the reviewer chooses from among submissions that have 2 reviews (if there are any), or the minimum number of reviews, whatever that is. For assignments that have topics, this severely constrains a reviewer’s choice of what topic to review on. (For assignments that don’t have topics, a reviewer doesn’t have anything to choose; (s)he just gets one of the submissions that have the fewest reviews so far.) To allow reviewers a larger set of topics to choose from, the instructor can set the threshold (on the Review Strategy tab of assignment creation/editing) to some integer k > 0. Then any submission that has within k reviews of the fewest number can be chosen by a new reviewer. Let’s say that all submissions have at least 1 review. If k = 3, then the reviewer can choose any topic where there is a submission that has 4 or fewer reviews so far. Suppose that the minimum number of reviews for any submission is 2, but that the person has reviewed all the submissions that have only 2 reviews. Then they are not allowed to review at all (unless k > 0). That’s wrong; they should always be allowed to review the work with the least reviews that I have not already reviewed. And that should generalize to situations in which k > 0. Another issue is that there is no way for Expertiza to tell a reviewer how many reviews are required. Issue #402 : To allow reviewers a larger set of topics to choose from, the instructor can set the threshold (on the Review Strategy tab of assignment creation/editing) to some integer k > 0. Then any submission that has within k reviews of the fewest number can be chosen by a new reviewer. Let’s say that all submissions have at least 1 review. If k = 3, then the reviewer can choose any topic where there is a submission that has 4 or fewer reviews so far. Suppose that the minimum number of reviews for any submission is 2, but that I have reviewed all the submissions that have only 2 reviews. Then I’m not allowed to review at all (unless k > 0). The reviewer will get assigned a submission even if it has fulfilled the required number of reviews, to ensure that the reviewer always receives a new submission to review as long as it is not his own. Issue #228 : To Allow a reviewer who has already reviewed all submissions that have the minimum number of reviews m to review any submission that has ≤ m+k reviews. If the student has already reviewed the least number of reviewed assignment, then he/she will get the next least reviewed assignment. <code> This snippet of code will do the following features: 1. Return nil if the array of choices of review is empty 2. Reject contributors that have not selected a topic, or have no submissions 3. Reject contributions of topics whose deadline has passed, or which are not reviewable in the current stage 4. Filter submissions already reviewed by a reviewer 5. Filter the contributors with the least number of reviews 6. If this assignment does not allow the reviewer to review other artifacts on the same topic, remove those teams 7. Add topics for all remaining submissions to a list of available topics for review Issue #417 : Implement a num_reviews_required (and num_reviews_allowed) field in the assignments table to say how many reviews per reviewer are required, and how many are allowed (default should be # allowed = # required.). Do the same for meta-reviews (“reviews of reviews”), which students can also be assigned to do for an Expertiza assignment. So if he has already reviewed all the other submissions of his topic oss1 and he requests for one more submission of oss1, he will not get any more submission to review because the only one left is his own submission. The two statements ""Set Allowed Number of Reviews per reviewer"" and ""Set Required Number of Reviews per reviewer."" 1. b) When the number of allowed or required reviews are not set on the Review Strategy tab, the system does not have a message to display to a reviewer about how many submissions of work they are required to and allowed to review depending on the values set by the instructor in the ""allowed number of reviewers per reviewer"" field and the ""Set Required Number of Reviews per reviewer."" field. 1. c)The capitalization and punctuation of statements such as ""Set Allowed Number of Reviews per reviewer"" and ""Set Required Number of Reviews per reviewer."" in review strategy tab are incorrect.",This design doc consists mostly of excerpts from the project requirements and the code.  The description of Issues 402 and 228 just collects together the comments from the code.  The text describing what was done to fix Issue 417 is at the end of the test plan!
E1467,"Project name: <link> <ref> <link> </ref> Our project is to refactor the code in the ""Leaderboard"" functionality of the web application <link> <ref> <link> </ref>. The leaderboard functionality is to show top 3 individual scorers in each questionnaire type ( ReviewQuestionnaire , AuthorFeedbackQuestionnaire , MetareviewQuestionnaire and TeammateReviewQuestionnaire ), in each course of the logged-in user. The leaderboard also shows the current standing of the logged in user under personal achievements. <image> <table> Contents 1.1. <link> 1.2. <link> 1.3. <link> 1.4. <link> 1.5. <link> 1.6. <link> 1.7. <link> 1.8. <link> 1.1.1. <link> 1.1.2. <link> 1.1.3. <link> 1.9. <link> 1.10. <link>. Classes involved: leaderboard.rb and associated other model and controllers classes. 1. Come up with an efficient way to search for participants based on assignment ids. (method: extractPersonalAchievements ). 3. Refactor addEntryToCSHash according to your new metric method. 5. Refactor getParticipantEntriesInAssignmentList method. 6. Refactor addEntryToCSHash according to your new metric method. Leaderboard.rb class gets all the assignments within all the courses taken by currently logged in user. It also fetches any independent assignments (not associated with any course), that the user has taken. Then, it fetches all the participants who have participated in the computed list of assignments and aggregates their scores based on the questionnaire type. Several questionnaire type is associated with a single assignment. Direwolf application has - Review Questionnaire , Author Feedback Questionnaire and Teammate Review Questionnaire . Leaderboard model has following 3 important methods: <table>. In the OSS project, we have refactored these methods along with other smaller methods in Leaderboard.rb , Leaderboard_helper.rb , Leaderboard_controller.rb and associated views files. We have also refactored ambiguous variable and method names. We have keenly focussed in reducing the database calls, loops and redundant storage and computation. We have refactored many files related to Leaderboard implementation leading to reduction in overall complexity of the feature. Also, there was a requirement in the project, that we should come up with an efficient way to search for participants based on assignment ids. This is very useful while computing leaderboard. Changes made in the methods of model leaderboard.rb <table>. Changes made in methods of Helper leaderboard_helper.rb <table> There are several other changes in the views and controller which deal with renaming of the methods and variables, adding proper comments etc and minor code refactoring. We reduced the complexity and redundancy of database calls by reducing database calls from 625 to 111 to do the same task. Login by any user and navigate to Home > Leaderboard to test the functionality. Note for testing : It is recommended that in order to test the leaderboard functionality by any user who has participated in several assignments, some of them which is associated with any course and there are other existing users who have participated in the same assignment. <link> <table>. The refactoring process included reducing the database calls, loops and redundant storage and computation in all classes associated with Lleaderboard functionality. While refactoring, the team has ensured to improve the readability of the code too by renaming ambiguous method and variable names and adding relevant comments to explain the objective of a code construct. In the project description code complexity has been highlighted for several methods. <link> <ref> <link> </ref> has been used to measure the code complexity of the current repository of Expertiza. Code Climate to measure the code complexity. Following is the snapshot of code complexity of Leaderboard.rb from Code Climate. <table> The report shows that all the 3 methods to be refactored have improved code complexity by over 50%. Following is the overall improvement report by Code Climate. <image>. In the original code there were 625 database select access generated for the leaderboard view. In the new refactored code the number of select calls dropped to 111 . Shown below is the number of select calls generated per table. <table>. Google Chrome extension <link> <ref> <link> </ref> gives time to load a page. This table indicates time to load page in seconds <table>. Based on use case and requirement, we can implement a metric to calculate final scores based on weights of an assignment or a questionnaire type. However, it solely depends on the the requirement whether such logic should be implemented in the Leaderboard model or the Score computation model. The team recommends that such manipulation and calculation of scores should not be part of Leaderboard model. Leaderboard model should focus on determining the eligible participants and compute the final leaderboard list.","Good writeup, though not as detailed as some"
